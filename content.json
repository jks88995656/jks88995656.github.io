{"meta":{"title":"一只柴犬","subtitle":"","description":"","author":"凯凯超人","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2021-08-02T14:36:04.948Z","updated":"2021-08-02T14:36:04.948Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"JavaScript 篇（包含ES6）面试题","slug":"VScode自定义配置代码片段详细教程","date":"2023-08-20T14:58:01.000Z","updated":"2023-08-28T07:10:28.000Z","comments":true,"path":"2023/08/20/VScode自定义配置代码片段详细教程/","link":"","permalink":"http://example.com/2023/08/20/VScode%E8%87%AA%E5%AE%9A%E4%B9%89%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/","excerpt":"","text":"@TOC VScode自定义配置代码片段详细教程VScode的html文件中通过“ ！”的快捷方式可以直接生成html模板 可以通过自定义配置，来配置Vue2、Vue3的预设定的代码片段 转码连接 进行转译你配置的代码片段，在配置的时候需要先经过处理 转码链接：snippet generator 按照上述的步骤 例如我们创建一个 vue3+ts 指令是 vue3-ts vscode 打开配置代码页面点击左下角的齿轮（设置），点击配置用户代码片段（中文版），User Snippets（英文版） 打开之后，会出现设置 触发的环境配置的选择 英文版里面，我们选择 New Global Snippets file 然后我们需要设定一个名称，例如上面的 vue3-ts 就是我上一次设置的 然后我们打开这个创建的全局环境，将上面的转译之后的代码段，复制到这里 最后保存即可 实际使用然后我们创建模板的时候，直接 vue3 就会显示出对应的快捷模板代码了。 点击之后就会生成。","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://example.com/tags/JavaScript/"}]},{"title":"前端 JS 选择题笔试","slug":"前端 JS 选择题笔试","date":"2023-03-23T15:52:02.000Z","updated":"2023-03-20T10:53:16.000Z","comments":true,"path":"2023/03/23/前端 JS 选择题笔试/","link":"","permalink":"http://example.com/2023/03/23/%E5%89%8D%E7%AB%AF%20JS%20%E9%80%89%E6%8B%A9%E9%A2%98%E7%AC%94%E8%AF%95/","excerpt":"","text":"前端 JS 选择题笔试Git 指令1https://blog.csdn.net/qq_38111015/article/details/84885809 Git 暂存操作的API git stash 利用二分法的思想，来查找哪一次代码提交引入了错误 git bisect 切换 git checkout 合并（拉公共分支最新代码的时候使用） git rebase 合并（拉代码或者push代码都可使用） git merge 远程端下载至本地 git fetch/clone 本地分支-&gt;远程主机 git push Linux 指令 Linux su（英文全拼：switch user）命令用于变更为其他使用者的身份 Linux chown（英文全拼：change owner）命令用于设置文件所有者和文件关联组的命令 Linux chmod（英文全拼：change mode）命令是控制用户对文件的权限的命令 JS 基础语法问题JS 的基本数据类型基本数据类型 string,number(NaN属于这里表示非数字),boolean,symbol,null,undefiend JS 变量的命名规则在javascript中,标识符不能以数字开头,即第一个字符不能为数字,必须是字母、下划线“_”或美元符号“$” JS的五种模块加载方案详细可查看 https://juejin.cn/post/6844903808418447367?time=1673685516275 https://www.cnblogs.com/mingweiyard/p/13891510.html?time=1673968266192 AMD (异步模块定义)和 CMD （公共模块定义）都是浏览器端的JS模块化规范，分别由require.js和sea.js实现 CommonJS（缩写：CJS ）是服务器端的js模块化规范，由NodeJS实现 ES6 提出的方案（ESM），使用 import 和 export 的形式来导入导出模块，在nodeJS新版本中可以直接使用。 另外还有一些独特的例如 UMD （通用模块定义）他是 AMD 和 Common JS 糅合的产物。 JS 精度丢失问题在 JS 的 Number类型中 12345const one = 0.1;const two = 0.2;const three = 0.3;console.log(two - one); //0.1console.log(three - two); //0.09999999999999998 JS 数字丢失精度的原因：计算机的二进制实现和位数限制有些数无法有限表示，就像一些无理数不能有限表示，如 圆周率 3.1415926…，1.3333… 等。JS 遵循 IEEE 754 规范，采用双精度存储（double precision），占用 64 bit。 1位用来表示符号位 11位用来表示指数 52位表示尾数 JS API 细节问题valueOf 和 toString valueOf() 方法用于返回指定对象的原始值，若对象没有原始值，则将返回对象本身。 toString() 方法主要有3个用途 1.返回一个【表示对象】的【字符串】 2.检测对象的类型 1Object.prototype.toString.call(arr)===&quot;[object Array]&quot; 3.返回该数字对应进制的字符串。 1console.log(10.toString(2)) //10专为为2进制&#x27;1010&#x27; {} 的 valueOf()方法 的值为{} [] 的 valueOf() 方法 的值为 [] {} 的 toString()方法 的值为[object object] [] 的 toString() 方法的值为””(空串) isNaN这个函数接受一个参数，该参数可以是任何类型，而函数会帮我们确定这个参数是否“不是数值”。 isNaN()在接受一个值后之后，会尝试将这个值转换为数值。某些不是数值的值会直接转换为数值，例如字符串”10”或Boolean值，会返回 false。而任何不能被转换为数值的值都会导致这个函数返回true。 1234isNaN(NaN) // true 因为NaN不是数值isNaN(10) // falseisNaN(&#x27;10&#x27;) // falseisNaN(&#x27;blue&#x27;) // true parseFloatparseFloat() 从第一位开始检查，是数字就转换，直到一个不是数字的内容 开头就不是数字，那么直接返回 NaN 认识小数点（但只认识第一个），没有小数点认整数,， 并且其忽略前导0。 1234parseFloat(&#x27;1234blue&#x27;) // 1234parseFloat(&#x27;0xA&#x27;) //0后面都是字符（和进制无关）0parseFloat(&#x27;22.34.5&#x27;) //只认识第一个小数点，第二个当字符了所以停止 为 22.34parseFloat(&#x27;0908.5&#x27;) //忽略前导0 所以是908.5 HTML 相关HTML中的特殊字符一般常考的特殊字符有如下几种： &lt;!DOCTYPE&gt; 的记忆点 必须声明在HTML文档的第一行，在&lt;html&gt;之前 他是没有结束符的 其对大小写不敏感，也就是大小写都可以！ 他不是一个 HTML 标签，是一个指令。用于指示 web 浏览器关于页面使用哪个 HTML 版本进行编写的指令。 如下就是声明 为 HTML5 1&lt;!DOCTYPE html&gt; 之前的版本例如 HTML 4.01 Strict，是这么声明的。很复杂： 1&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/strict.dtd&quot;&gt; HTML5 的新特性1.语义化标签 2.增强型表单包括属性以及元素 ，增加了大量的表单类型和表单属性； 3.新增视频&lt;video&gt;和音频&lt;audio&gt;标签 ，，还引入了&lt;source&gt;标签配合媒体标签使用； 4.Canvas 图形 ，新增了&lt;canvas&gt;，使用 JavaScript 在就可以网页上绘制图像； 5.地理定位 6.拖放API ，增加了draggable属性设置元素可拖放； 7.SVG绘图 8.Web Worker 9.Web Storage ，提供了两种在客户端存储数据的新方法localStorage和sessionStorage； 10.Web Socket 11.增加了DOM查询操作querySelector和querySelectorAll； iframe 标签一个内联框架被用来在当前 HTML 文档中嵌入另一个文档。 iframe会阻塞主页面的onload事件； HTML （dom）加载与解析过程 会阻塞dom解析的资源有：1.内联css2.内联js3.普通外联js4.外联defer js5.js之前的外联css MDN解析：当初始HTML文档已完全加载和解析时，将触发DOMContentLoaded事件，而不需要等待样式表，图像和子框架页面加载（事件可以用来检测HTML页面是否完全加载完毕(fully-loaded)）。 CSS 相关CSS 样式优先级右侧表示权重 !important ​ 内联样式（1000） ​ ID选择器（0100） ​ 类选择器/属性选择器/伪类选择器（0010） ​ 元素选择器/伪元素选择器（0001） ​ 关系选择器/通配符选择器（0000） 带!important 标记的样式属性优先级最高； 样式表的来源相同时： **!important > 行内样式>ID选择器 > 类选择器 > 标签 > 通配符 > 继承 > 浏览器默认属性** CSS 样式定位归纳div+p ： 是紧跟着div后面的p标签 CSS GPU加速浏览器在处理下面的 css 的时候，会使用 GPU 渲染 transform（当 3D 变换的样式出现时会使用 GPU 加速） opacity 用于指定元素透明度 filter 修改所有图片的颜色为黑白 will-change 过告知浏览器该元素会有哪些变化，使浏览器提前做好优化准备，增强页面渲染性能。 CSS3 属性考法transformCSStransform属性允许旋转，缩放，倾斜或平移给定元素。只能转换由盒模型定位的元素。 盒模型定位元素根据经验是指具有display：block；的元素，对内联元素不可用。 transform变形默认圆点为中心。 可通过 transform-origin 设置改变 transform变形后占位不会变化，它会创建一个新的图层来显示。 12//定义 3D 转换，使用 16 个值的 4x4 矩阵。transform: scale(0.5) translate(-100%, -100%); matrix3d(n,n,n,n,n,n,n,n,n,n,n,n,n,n,n,n) CSS加载 的影响 css加载不会阻塞DOM树的解析 css加载会阻塞DOM树的渲染 css加载会阻塞后面js语句的执行 计算机网络（包括JS来获取信息）相关URL 地址格式通常情况下，一个URL的格式是： 1protocol :// hostname[:port] / path / [;parameters][?query]#fragment protocol 协议 hostname主机名 port端口号 path路径 parameters 参数 query查询 协议：//主机：端口/路径名称?搜索条件#哈希标识 window Location 获取 Url相关信息window Location location.host 返回 web 主机的域名+端口，只是如果是80 控制台不会显示而已 location.hostname 返回 web 主机的域名 location.pathname 返回当前页面的路径和文件名 location.port 返回 web 主机的端口 （80 或 443） location.protocol 返回所使用的 web 协议（http: 或 https:） 七层模型和五层模型 及其对应协议 进程与线程进程有独立的地址空间，进程间可以通过网络通信，内存也可以共享，进程是系统进行资源分配和调度的基本单位。 进程和线程的关系： ​ 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。 ​ 资源分配给进程，同一进程的所有线程共享该进程的所有资源。 ​ CPU 分给线程，即真正在 CPU 上运行的是线程。 ​ 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。线程是指进程内的一个执行单元,也是进程内的可调度实体. 进程与线程的区别： （1）调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位 （2）并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行 （3）拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源. （4）系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。 UDP 和 TCPHttp2.0 建立在 TCP，Http3.0 建立在 UDP 目前题目说的，包括常用的还是 Http2.0 Http 相关浏览器Http请求和响应过程浏览器端构建HTTP请求，并发送 -&gt; 服务器端接收到HTTP请求，并进行解析 -&gt; 服务器端发送HTTP响应 -&gt; 浏览器端接收到响应，解析Http响应，而后进行页面渲染。 Http 版本区别 HTTP/0.9：功能捡漏，只支持GET方法，只能发送HTML格式字符串。 HTTP/1.0：支持多种数据格式，增加POST、HEAD等方法，增加头信息，每次只能发送一个请求（无持久连接） HTTP/1.1：默认持久连接、请求管道化、增加缓存处理、增加Host字段、支持断点传输分块传输等。 HTTP/2.0：二进制分帧、多路复用(解决了HTTP阻塞线头)、头部压缩、服务器推送 并没有解决 TCP 队头阻塞的问题 ​ 采用HTTP/2时，浏览器一般会在单个TCP连接中创建并行的几十个乃至上百个传输。如果HTTP/2连接双方的网络中有一个数据包丢失，或者任何一方的网络出现中断，整个TCP连接就会暂停，丢失的数据包需要被重新传输。因为TCP是一个按序传输的链条，因此如果其中一个点丢失了，链路上之后的内容就都需要等待。 客户端渲染 与 服务器渲染客户端渲染 用户输入地址，客户端向服务器发送请求 =&gt; 服务器传给浏览器相应的网页文件 =&gt; 浏览器解析文件 =&gt; 遇到ajax请求则向服务器再次请求一些数据 =&gt; 服务器再次向浏览器发送相应的数据 =&gt; 浏览器拿到ajax请求返回的数据后，将数据渲染在页面上 优点： 可以向用户快速展示页面的内容，增加用户体验 给别人爬虫爬取相应的内容增加一定的困难 缺点： 可能需要向服务器请求多次数据 不利于SEO（搜索引擎优化），即百度、搜狗等搜索引擎搜索不到客户端渲染的数据 服务器渲染 SPA（单页面）是客户端渲染的 客户端向服务器发送一次请求 =&gt; 服务器接收请求，并在服务端操作网页文件，将对应数据导入文件 =&gt; 服务器在服务端渲染好整个网页，发送给客户端 =&gt; 客户端接收服务器发送过来的网页文件，不需要做任何操作，直接呈现 优点 只需要向服务器请求一次 利于SEO 搜索引擎优化，即能被搜索引擎搜索到，能向用户展示你网页的东西 缺点 如果数据量过大，在服务器渲染的时间就会过长，造成浏览器暂时的空白 容易被爬虫爬取 如何区分客户端渲染和服务器渲染 若页面做整体的刷新，即网址发生改变，就是服务器渲染 若页面做了局部刷新，即网址没发生改变，就是客户端渲染 前端安全系列防止XSS详细文档：https://tech.meituan.com/2018/09/27/fe-security.html?time=1673952294336 解决的方法有： 过滤用户请求种的非法字符 对请求种的特殊字符进行转译 配置 CSP（Content Security Policy） 浏览器相关Chrome浏览器都有哪些进程最新的 Chrome 浏览器包括： 1 个浏览器（Browser）主进程 1 个 GPU 进程 1 个网络（NetWork）进程 多个渲染进程和多个插件进程。 浏览器缓存浏览器缓存是性能优化中简单高效的一种方式，按照缓存位置划分为以下几种类型：. service Worker. Memory Cache. Disk Cache. Push Cache. 浏览器请求时，会按照如上的优先级顺序，进行查找缓存，都没有命中时，才会去请求网络 在浏览器中，浏览器会在js和图片等文件解析执行后直接存入内存缓存中，那么当刷新页面时只需直接从内存缓存中读取(from memory cache)；而css文件则会存入硬盘文件中，所以每次渲染页面都需要从硬盘读取缓存(from disk cache)。 解决跨域 webpack本地代理，即proxy反向代理 JSONP 是服务器与客户端跨源通信的常用方法。最大特点就是简单适用，兼容性好（兼容低版本IE），缺点是只支持get请求，不支持post请求。 CORS 跨文档通信 API：window.postMessage() 面像对象编程相关面向对象编程设计的特点面向对象编程特点：抽象、封装、继承、多态 Vue 相关Vue 路由vue中的路由模式 路由模块的本质就是建立起url和页面之间的映射关系，vue-router有3种路由模式：hash，history，abstract. vue组件间通信方式(这里是 Vue2 和 Vue 3 都算上了) 通过 props 传递 (父传子属性或者函数等) 通过 $emit 触发自定义事件 使用 ref 同样需要触发 $emit EventBus （事件总线） $ parent /$children 或 $ root attrs 与 listeners Provide 与 Inject Vuex 前端开发细节GBK 和 UTF8 编码GBK： 中文、英文、数字均使用双字节来表示 UTF-8： 汉字占3个字节、数字占1个字节、英文字母占1个字节 加密算法对原来为明文的文件或数据按某种算法进行处理，加密后的数据不可读，是“密文”，只能在输入相应的密钥之后才能显示出原容 可逆加密算法 对称加密：发送方发送 明文+加密密钥一起打包使用特殊的加密算法得到加密密文，收信方 使用加密密钥和相同加密算法的逆算法进行解密，获取明文。其特点在：加密密钥只有一个，收发双方使用的是一个。 优点当然是计算量小而且快，缺点也就是相对于非对称不安全。 用途： 一般用于保存用户手机号、身份证等敏感但能解密的信息。常见的对称加密算法有: AES、DES、3DES、Blowfish、IDEA、RC4、RC5、RC6、HS256 非对称加密：公开密钥（publickey）和私有密钥，公有密钥加密，私有密钥解密。私钥加密的内容，通过公钥可以解密读取出来，反之，通过公钥加密的内容也可以由私钥解密读取出来 用途： 一般用于签名和认证。私钥服务器保存, 用来加密, 公钥客户拿着用于对于令牌或者签名的解密或者校验使用. 解释：在区块链网络上进行一笔交易时，我没有办法确定交易的是不是你本人，这个时候就可以让你用私钥加密一段内容作为数字签名发过来，然后我通过已经公开的公钥进行破解，因为私钥只有你本人保留，如果我能用语之对应的公钥成功破解，就说明是你本人在进行操作，如果不能破解，则说明是别人盗用了你的身份，因此解决了我是我，这是我在交易的问题。 常见的非对称加密算法有： RSA、DSA（数字签名用）、ECC（移动设备用）、RS256 (采用SHA-256 的 RSA 签名) 不可逆加密算法：旦加密就不能反向解密得到密码原文. 种类: Hash加密算法, 散列算法, 摘要算法等用途：一般用于效验下载文件正确性，一般在网站上下载文件都能见到；存储用户敏感信息，如密码、 卡号等不可解密的信息。常见的不可逆加密算法有： MD5、SHA、HMAC 特殊：Base64编码：网络上最常见的用于传输8Bit字节代码的编码方式之一。 Base64编码可用于在HTTP环境下传递较长的标识信息。通常用于把二进制数据编码为可写的字符形式的数据。采用Base64编码解码具有不可读性，即所编码的数据不会被人用肉眼所直接看到。注意：Base64只是一种编码方式，不算加密方法。 算法复杂度算法稳定性与时间复杂度 JS 里一些奇怪的东东，现在不知道处于哪里Redux（react的） Vuex同类Redux 是 JavaScript 状态容器，提供可预测化的状态管理。 其和 Vuex 实现的内容一致。 用的貌似不多。 Redux遵循的原则 单一数据源：整个应用的state被存储在一棵object tree中，并且这个object tree只存在于唯一一个store中； state是只读的：唯一改变state的方法就是触发action，action是一个用于描述发生事件的普通对象； 使用纯函数修改数据； 宏任务和微任务可查看的教程：https://blog.csdn.net/weixin_50238437/article/details/126082425 宏任务和微任务都是异步任务，都在任务队列中，但是它们在不同的队列中 重点：在准备取出每个宏任务准备执行前要执行完所有的微任务 宏任务包括： setTimeout 和 setInterval， I/O， 事件 postMessage setImmediate (node中的特性，浏览器已经废弃该API) requestAnimationFrame() 请求动画帧 他的作用就是代替定时器做更加流畅高性能的动画，做可以匹配设备刷新率的动画，他解决了定时器做动画时间间隔不稳定的问题（也就是解决定时器做动画不流畅的问题）。他的用法与setTimeout差不多。 UI渲染 ajax 微任务包括： Promise.then catch finally async/await MutationObserver（chrome种 node无） process.nextTick (node中) 所以下面这段代码的执行结果为： 刚开始先同步代码执行，先输出开始和结束 // 依次输出：开始 结束 佩奇（因为 promise是微任务） 定时器执行 12345678910111213console.log(&#x27;开始&#x27;)setTimeout(() =&gt; &#123; console.log(&#x27;定时器执行&#x27;)&#125;, 0);new Promise((resolve, reject) =&gt; &#123; resolve(&#x27;佩奇&#x27;)&#125;).then((data)=&gt;&#123; console.log(data)&#125;)console.log(&#x27;结束&#x27;)","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://example.com/tags/JavaScript/"}]},{"title":"代码随想录  （题目 与 类型归纳）","slug":"代码随想录  （题目 与 类型归纳）","date":"2023-03-22T15:52:03.000Z","updated":"2023-03-20T10:53:24.000Z","comments":true,"path":"2023/03/22/代码随想录  （题目 与 类型归纳）/","link":"","permalink":"http://example.com/2023/03/22/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%20%20%EF%BC%88%E9%A2%98%E7%9B%AE%20%E4%B8%8E%20%E7%B1%BB%E5%9E%8B%E5%BD%92%E7%BA%B3%EF%BC%89/","excerpt":"","text":"代码随想录 （题目 与 类型归纳）一些值的记忆的JAVA代码点数组与List数组和 List 的相互转换 Arrays.asList1234// 数组转 List List&lt;String&gt; wordList = Arrays.asList(String数组);// list 转 int[]int[] res = result.stream().mapToInt(Integer::intValue).toArray(); 二维数组 按行初始化 Arrays.fill123456chessboard = new char[n][n];// 使用 Arrays方法for (char[] c : chessboard) &#123; // 填充棋盘 Arrays.fill(c, &#x27;.&#x27;);&#125; 二维数组转list将一个二维数组，变成一个一维度的 List 例如： 12345for (char[] c : chessboard) &#123; // String.valueOf() 返回char数组参数的字符串表示形式 // 那对于不同类型肯定不一样啦 list.add(String.valueOf(c));&#125; 字符串比较字符串两者字母是否数量一致 Arrays.equals123456char[] str1 = s.toCharArray();char[] str2 = t.toCharArray();Arrays.sort(str1);Arrays.sort(str2);// 使用 equals 方法看看是不是一直 return Arrays.equals(str1, str2); 字符串和 char[ ] 互相转换 toCharArray() new String( )1char[] sentence = s.toCharArray(); 12345String s = new String(sentence);// 如果创建一个新的String s = new String(new char[]&#123;&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;&#125;);// 截取String.valueOf(s, 0, 取不到的索引位置); 字符串（数字）宇整型 Int 互相转换1234// 字符串转数字int num = Integer.parseInt(str); //比较耗费时间// 数字转字符串String str = String.valueof(num); 替换字符的方法 replace1String result = s.replace(&quot; &quot;, &quot;%20&quot;); 字符串拼接 List内容 String.join1String.join(&quot; &quot;, wordList); Collection 相关方法（针对 List）将List 的内容全部逆序 Collections.reverse1Collections.reverse(wordList); Compare 用法其实涉及这块，我还是觉得 用 js 写起来简单一些 用于sort 1234567891011121314 Arrays.sort(people, new Comparator&lt;int[]&gt;() &#123; public int compare(int[] person1, int[] person2) &#123; if (person1[0] != person2[0]) &#123; return person2[0] - person1[0]; &#125; else &#123; return person1[1] - person2[1]; &#125; &#125; &#125;);有时候甚至不需要这个库 我们后面其实 这个return 返回的应该是一个正数或者负数 注意因为简写所以不需要 return 最好别用这种，碰到数据超了 或者值超了 = = 就不行了 Arrays.sort(points, (p1, p2) -&gt; p1[1] &lt; p2[1] ? -1 : 1); 优先队列（顶堆）实现小（大）顶堆，并按规则排序 PriorityQueue1234567// 例如 小(大)顶堆内存储的节点为 key ，按照存储key对应的value 大小排序为 小顶堆PriorityQueue&lt;Integer&gt; minHeap = new PriorityQueue&lt;&gt;(new Comparator&lt;Integer&gt;()&#123; public int compare(Integer a,Integer b)&#123; return HashMap.get(a) - HashMap.get(b); //return HashMap.get(a) - HashMap.get(b); &#125;&#125;); 优先队列的函数 API12345678// 其插入会自动进行堆排序的（自行调整堆）minHeap.add(key);// 弹出堆顶 返回结果 minHeap.poll();// 查看堆顶 返回结果minHeap.peek()；// 查看堆是否为空 返回 布尔值minHeap.isEmpty() 二叉树求一个二叉树的最大高度（递归）123456789101112131415int depth = 0;public int maxDepth(TreeNode root) &#123; // 还是宏观来看 // 根节点为空 肯定没深度 if(root == null) return 0; // 有根节点的话 // 我们就去看左右子树的深度 // 左右 深度大的那个 肯定是根节点的深度 -1 // 最后加上 根节点就是答案 int left = maxDepth(root.left); int right = maxDepth(root.right); depth = Math.max(left,right); return depth + 1;&#125; 求是不是一颗二叉排序树（递归）123456789101112131415class Solution &#123; long pre = Long.MIN_VALUE; public boolean isValidBST(TreeNode root) &#123; if (root == null) &#123; return true; &#125; boolean left = isValidBST(root.left); if (root.val &lt;= pre) &#123; return false; &#125; pre = root.val; boolean right = isValidBST(root.right); return left &amp;&amp; right; &#125;&#125; 题目分类 打钩的表示 肯定会做； 绿色 表示我能写出来，但是不一定 不熟，有时候就想不到 蓝色 表示有想法做出来但是过不了或者 不是考的想法，时间复杂度太高 橙色的意思是，大概率还是写不出来，但是我看得懂； 红色的意思是，我估计写不出来，只能靠默写，原理不是很明白 数组 [x] 二分查找 方法：二分查找 [ ] 移除元素 方法：双指针（可用覆盖隐式双指针） [ ] 序数组的平方 方法：双指针 [ ] 长度最小的子数组 方法：滑动窗口（双指针实现） [ ] 螺旋矩阵Ⅱ 方法：模拟 找到合适判断条件转方向 链表 [x] 移除链表元素 方法：头结点 [x] 设计链表 方法：头结点，index超过 需要先判断null [ ] 反转链表 方法：递归 [x] 两两交换链表中的节点 方法：递归 或 头结点+双指针 [x] 删除链表的倒数第 N 个结点 方法：头结点+栈 [ ] 链表相交 方法：双指针 [ ] 环形链表 II 方法：头结点+快慢指针+数学 或 哈希Set 哈希 [x] 有效的字母异位词 方法：equals函数 或 哈希表 [ ] 查找常用字符 方法：哈希表 （但逻辑比较复杂） [x] 两个数组的交集 方法：哈希Set [ ] 快乐数 方法：数学+哈希Set+ 获取一个数所有位数操作 [x] 两数之和 方法：哈希表 [ ] 四数相加Ⅱ 方法：分两段暴力 + 哈希表 [ ] 赎金信 方法：哈希表（用数组哈希更快一些） [ ] 三数之和 方法：循环内双指针（去重考虑难度大） [ ] 四数之和 方法：双循环内双指针（去重考虑难度大） 字符串 [x] 反转字符串 方法：双指针 [ ] 反转字符串Ⅱ 方法：双指针 [ ] 替换空格 方法：字符串API replace 或 StringBuilder遍历 [x] 反转字符串里的单词 方法：API trim + 正则表达 + 双指针+ StringBuilder 或者 正则+list+collection+join [x] 左旋转字符串 方法：StringBuilder [ ] 重复的子字符串 方法：数学 栈与队列 [x] 用栈实现队列 方法：Java 类定义写法 注意：什么时候将第一个队列全部放到第二个中 [x] 用队列实现栈 方法：使用Deque 里面有 removeFirst removeLast方法 更快 [x] 有效的括号 方法：使用Deque 正着写就行（就是麻烦点），反着写比较难写 [x] 删除字符串中的所有相邻重复项 方法：使用Deque 正着写，利用 Deque双端 简单一些 [ ] 逆波兰表达式 方法：使用Deque栈，使用正则表达式判断是否会数字 [ ] 滑动窗口最大值 方法：使用Deque 编写单调栈，要前后两头都考虑 [ ] 前K个高频元素 方法：哈希表 + 优先队列（小顶堆） 二叉树 二叉树的遍历方式 [x] 二叉树的前序遍历 方法：递归 [x] 二叉树的后序遍历 方法：递归 [x] 二叉树的中序遍历 方法：递归 [x] 二叉树的层次遍历 方法：Queue队列 二叉树的属性 [ ] 对称二叉树 方法：递归 [x] 二叉树的最大深度 方法：递归 或 层次 [ ] 二叉树的最小深度 方法：递归 [ ] 完全二叉树的节点个数 方法：递归 或 层次 [ ] 平衡二叉树 方法：递归 [ ] 二叉树的所有路径 方法：递归 [ ] 左叶子之和 方法：递归 （如何判断是左叶子！） [ ] 找树左下角的值 方法：递归（如何判断是最后一层最左侧） 或 特殊的 BFS 方法 [ ] 路经总和 方法：递归 二叉树的修改和改造 [ ] 翻转二叉树 方法：递归 [ ] 从中序与后序遍历序列构造二叉树 方法：哈希表 + 递归 [ ] 最大二叉树 方法：递归 （用左右控制截取nums） [ ] 合并二叉树 方法：递归（都有的创建新节点来做简单） 搜索二叉树的属性注意搜索二叉树其实就是 排序二叉树，可以利用到 左边小，右边大的性质，这样更快 **其中序排序是 有序序列** [x] 700. 二叉搜索树中的搜索 方法：递归，利用性质更快 [ ] 98.验证二叉搜索树 方法：递归，用改良中序 [ ] 530.二叉搜索树的最小绝对差 方法：递归，同上改良 [ ] 501.二叉搜索树中的众数 方法：中序递归按情况计数，需要记录前节点 [ ] 538.把二叉搜索树转换为累加树 方法：右根左 递归，记录前节点累加，类似于上题 二叉树公共祖先问题 [ ] 236.二叉树的最近公共祖先 （最近经常出 字节啥的） 方法：递归 [ ] 235.二叉搜索树的最近公共祖先 方法：循环判断（利用二叉搜索树的性质） 或者 同上题 二叉搜索树的修改和改造 [x] 701.二叉搜索树中的插入操作 方法：循环判断 （利用二叉搜素树的性质） 注意：我考虑的插入的一定是 叶子节点 或者 递归 [ ] 450.删除二叉搜索树中的节点 方法：循环判断 或者 递归 都比较难没咋看懂 [ ] 669.修剪二叉搜索树 方法：递归 难想 [ ] 108.将有序数组转换为二叉搜索树 方法：递归 要注意右侧落点（否则- -会死循环） 回溯算法 组合问题 [ ] 77.组合 方法：回溯 剪枝优化 large - (k - path.size()) + 1 [ ] 17.电话号码的字母组合 方法：哈希（转换为数组更快）+ 回溯。 树的高度应该是 电话号码的个数 [ ] 39.组合总和 方法：利用begin的回溯法，需关于值的 剪枝 break 降低复杂度 [ ] 40.组合总和Ⅱ 方法：利用begin的回溯法，需要额外的重复剪枝 continue，不然答案会重复 12if(begin &lt; i &amp;&amp; candidate[i-1] == candidate[i] ) continue; [ ] 216.组合总和Ⅲ 方法：类似于 组合总数，只是要在 return 的时候注意 只有长度为k的才可以 分割 [ ] 131.分割回文串 方法：回溯 begin ，需要截取字符串 (begin, i+1) [ ] 93.复原IP地址 2021.3.24虾皮笔试 方法：回溯 begin 和上题很像 但是要注意细节处理 使用path记录，最后拼接答案（我用的 get() 和 sub Integer.parseInt 是比较慢 = =的 ） 子集 [ ] 78.子集 方法：回溯 begin 递归出口直接写就好 [ ] 90.子集Ⅱ 方法：回溯 begin 同上 只是要剪枝。 要先sort一下，不然剪枝无效的。 12if(begin &lt; i &amp;&amp; candidate[i-1] == candidate[i] ) continue; 排列 [ ] 46.全排列 方法：回溯 begin=0 + visited数组 [ ] 47.全排列Ⅱ 方法：回溯 begin=0 + visited数组 + 剪枝 12if( i &gt; 0 &amp;&amp; numbers[i-1] == numbers[i] &amp;&amp; visited[i-1] == true) continue; 棋盘问题 [ ] 51.N皇后 方法：回溯 begin 变成 row 行， 每次找到当前行哪一列位置好使进行递归。 答案用的是一个 二位数组记录并判断是否合适 [ ] 37.解数独 方法：回溯中有 3层for ，backtrack有返回值 boolean 因为只要获取一个 1https://mp.weixin.qq.com/s/VCirGskFGPln-S2LGFTgKg 其他问题 [ ] 491.递增子序列（和子集问题很像） 方法：回溯 begin 哈希去重（如果用 path判断的 话 有个样例有bug， 不能盲目i的用之前的去重办法） 12if (path.size() != 0 &amp;&amp; path.get(path.size() - 1) &gt; numbers[i] ) continue; [ ] 332.重新安排行程 方法：begin = 0， 类似于全排列的做法。 backtrack有返回值 boolean 因为只要获取一个。 在判断的时候，需要判断 123// 刚开始就字典序排序Collections.sort(tickets,(a,b) -&gt; a.get(1).compareTo(b.get(1))); // 字典序排序// 贪心算法 贪心的本质是选择每一阶段的局部最优，从而达到全局最优。 简单题目 [x] 455.分发饼干 方法：贪心 双循环 [ ] 1005.K次取反后最大化的数组和 方法：贪心思路比较难想 [ ] 860.柠檬水找零 方法：模拟，但是有两种情况，用方法去考虑规避 中等题目排序问题 [ ] 376. 摆动序列 方法：非常优化的动态规划 其他方法太复杂 [ ] 738.单调递增的数字 方法：从右往左改数字 贪心解决股票问题 [ ] 122.买卖股票的最佳时期Ⅱ 方法：动态规划 或 贪心 [ ] 714.买卖股票的最佳时期含手续费 方法：动态规划和上题基本一模一样，这里的贪心策略比较难想 两个维度权衡问题 [ ] 135.分发糖果 方法：贪心算法，从左和从右考虑两次 [ ] 406.根据身高重建队列 方法：贪心算法，分两步 有点难度区间问题 [ ] 55.跳跃游戏 方法：贪心算法 和 动态规划 我觉得对我来说都不好想 = = [ ] 45.跳跃游戏Ⅱ 方法：贪心算法，从左和从右考虑两次 重叠区域 [ ] 452.用最少数量的箭引爆气球 方法：贪心算法 这道题用 java sort 的时候需要注意 普通 a[1] -b[1]是不行的 得用三目表达式 return 正负回去 [ ] 435.无重叠区间 方法：贪心算法 和上题一样只是 需要添加判断等于的时候 最后用减法即可， length - 穿过的箭就是答案 [ ] 763.划分字母区间 2022美团测试开发题 方法：其规则比较难想，转换为上面两题的做法答案思路是不一样的，所以这里他其实巧妙的保存了最后一个元素的索引，然后特殊遍历去做 [ ] 56.合并区间 方法：JS使用来回两次 用splice方法增加删除 就是速度慢，java想实现同样的想来太慢了。这个想法是按右侧先排，然后再左右合并。 代码最简单的想法是，先按左侧排序，然后在将合适的填入（更快）。 [ ] 53.最大子序和 方法：用动态规划 最简单 [ ] 134.加油站 方法： 在用模拟方法的时候，需要 i+count+1 才可以 他的意思是说 例如 x到 k 就不行，那 x到k中，所有的点到Z肯定也是不行的。 [ ] 968.监控二叉树 困难题 天堂硅谷竞赛题 方法：后续遍历 ，子节点告诉父节点干嘛 摄像头尽可能的装在父节点上，0，1，2表示3种状态，被监视到，放摄像头，没监视到 动态规划 [x] 509.斐波那契函数 方法：基础 一维 动态规划 [x] 70.爬楼梯 方法：和上面一题 动态转移方程一模一样 [x] 746.使用最小花费爬楼梯 方法：上一题的 在加上 cost[i]，也很简单 [x] 62.不同路径 方法：简单的二维动态 [x] 63.不同路径 II 方法：上题 加个判断 [ ] 343.整数拆分 方法：动态规划（比较难想，属于背包问题），用数学方法最佳，根据数学推断 分成3一堆一堆，最大 [ ] 96.不同的二叉搜索树 方法：动态规划很难想 记不住 建议背下来 背包问题 0-1背包问题也就是每个东西只能拿一次 **滚动数组的内循环，从后往前** 12345for(let i = 0; i &lt; nums.length; i++)&#123; // 内循环 从后往前 for(let j = amount; j &gt;= nums[i]; j--)&#123; &#125;&#125; [x] 416.分割等和子集 方法：就是最基本的 0-1背包问题 只是 weight[i] 变成 nums[i] ，二维一维都可写。 这道题的暴力做法，为回溯。 [x] 1049.最后一块石头的重量 II 方法：转换思想后 完全就是 0-1背包 只是最后 return 你要想清楚返回的是啥 [x] 494.目标和 方法：转换思想后 是个 0-1背包的 组合问题，其动态转移方程 有变化 为 dp[j] += dp[j - nums[i]]; 并且初始化 dp[0] 要考虑清楚。 二维写不出来，= = 回溯看了别人的可以过哎，就是很慢。 [x] 474.一零和 方法：0-1背包问题，这里的滚动数组 内层变成了二维双循环，所以 滚动数组为二维 滚动数组定义为 最多有i个0和j个1的strs的最大子集的大小 其状态转移方程为 dp[i][j] = max(dp[i][j], dp[i - zeroNum][j - oneNum] + 1); zeroNum 与 oneNum 表示为当前 完全背包问题**其实就是 滚动数组的内循环，不再从后往前，为从前往后** **这个适用于组合问题** 12345for(let i = 0; i &lt; nums.length; i++)&#123; // 内循环 从前往后 for(let j = nums[i]; j &lt;= amount; j++)&#123; &#125;&#125; 遍历顺序问题： **组合问题** （求组合个数） 对于组合问题或者背包问题 **都采用 先遍历物品，再遍历背包** 对于组合问题（问排序数） **都采用 先遍历背包，再遍历物品** **dp的定义为 dp[i] 为当前 i 下 有几个的组合数** 采用的 动态转移方程为 1dp[j] += dp[j - nums[i]]; 初始化要注意： `dp[0] = 1` **求组合问题中的 最佳** **dp的定义为 dp[i] 为当前 i 下 可以的数字组合中，长度的最小值** 采用的 动态转移方程为 1dp[j] = Math.min(dp[j], dp[j- coins[i]] + 1) 初始化要注意 一般： `dp[0] = 0`， 其他都为 `Infinity` 无穷大 对于排序问题，其遍历顺序是有区别的 我应该先遍历容积，再遍历背包 1234567for(let j = 0; j &lt;= n; j++)&#123; for(let i = 0; i &lt;= nums.length; i++)&#123; if(j &gt;= nums[i])&#123; dp[j] += dp[j - nums[i]] &#125; &#125;&#125; - [x] 518.零钱兑换 Ⅱ 方法：完全背包的**组合问题 ** 其动态转移方程 有变化 为 `dp[j] += dp[j - nums[i]];` 并且初始化 dp[0] 要考虑清楚。应该初始为 1 - [x] 377.组合总数Ⅳ 方法：**组合数** 就是目标和 那道题的 完全背包 （数字可以重复用） `dp[j] += dp[j - nums[i]];` 并且初始化 dp[0] 要考虑清楚。应该初始为 1 **不过这道题求的是排序数 不是 组合数 所以 内外循环 遍历顺序需要变换**。 **昨天刚做个这个 所以我第一次做出来了** - [x] 70.爬楼梯（完全背包解法) 方法：同样这道题 也可以理解为 **排序数** 和上题做法一模一样。 就是 nums[] 物品数组 变成步数而已 {1,2} - [x] 322.零钱兑换 方法：**求组合问题中的 最佳** - [x] 279.完全平方数 方法：**求组合问题中的 最佳**， 和上题一样，就是这题需要自己先构建处 一个 物品[ ] 出来 这题用 java 比较麻烦，因为构造这个 物品[ ] 只能用list 还要转 = -= 自讨苦吃，所以我不写。 - [x] 139.单词拆分 方法：属于**排序问题** 但是这个递推公式比较难想 > 如果确定dp[j] 是true，且 [j, i] 这个区间的子串出现在字典里，那么dp[i]一定是true。（j < i ）。 > > 所以递推公式是 if([j, i] 这个区间的子串出现在字典里 && dp[j]是true) 那么 dp[i] = true。 #### 打家劫舍 这个类型的题其实不算 0-1背包问题， **因为 背包问题没有限制取包的规则** - [ ] 198.打家劫舍（线性） 方法： `dp[i] = Math.max(dp[i-2] + nums[i] ,dp[i-1])` 没写出来，太蠢了，白写题目了，以前这个题做的出来的啊 - [ ] 213.打家劫舍Ⅱ （环状） 方法：由于是环状，其实最后的落点一定在 倒数第一家或者倒数第二家。所以我们可以把数组拆成 0- n-2 和 1- n-1 来取其中最大值，每一段的取值和上一题线性一致。 - [ ] 337.打家劫舍Ⅲ （树形dp） 方法：**必须后续遍历递归做**，**因为通过递归函数的返回值来做下一步计算**。dp为2维度 为 【不偷，偷】的分别最大值。 递归逻辑为 如果抢了当前节点，两个孩子就不能动，如果没抢当前节点，就可以考虑抢左右孩子（**注意这里说的是“考虑”**）递归出口为 碰到 null 返回 [0,0] #### 股票问题 - [ ] 121.买卖股票的最佳时机 （只能买卖一次） 方法：这题一定要是1维度的，因为他只买卖一次，不能用下面的二维来做。 - [ ] 122.买卖股票的最佳时机Ⅱ （可以买卖多次） 方法： 定义dp 的理解上， `dp[i][0]表示第i天不持有股票, dp[i][1]表示第i天持有股票`。 所以首先要合理初始化， 然后遍历讨论 `dp[i][0]` 和 `dp[i][1]` 的可能性，分别各自有两种。 - [ ] 123.买卖股票的最佳时机Ⅲ （最多买卖两次） 方法： **这道题的 dp定义为 `dp[i][j]` 描绘的是当天整体处于的状态，不是当天的操作** `dp[i][0]` 第 i 天没有操作， 那前面也不可能操作 ​ dp[i][0] = dp[i - 1][0]; `dp[i][1]` 第 i 天第一次买入，这个意思是 之前是的状态是第一次买入，但今天可以不卖 ​ 或者是 前面一直是静默状态，今天买入了 ​ dp[i][1] = Math.max(dp[i - 1][1], dp[i - 1][0] - prices[i]) `dp[i][2]` 第 i 天第一次卖出，这个意思是 之前的状态已经是卖出第一次了，我今天静默；或者是今天确实是第一次卖出 ​ dp[i][2] = Math.max(dp[i - 1][2], dp[i - 1][1] + prices[i]); `dp[i][3]` 第 i 天第二次买入 ，这个意思就是 之前已经卖出过第一次了，此刻已经是买入的状态。有可能为之前已经买入第二次，今天是静默 或者 是今天买的第二次，之前一直是第一次卖出的状态 ​ dp[i][3] = Math.max(dp[i - 1][3], dp[i - 1][2] - prices[i] `dp[i][4]` 第 i 天第二次卖出，这个意思是 此时整体是第二次卖出的状态，有两种可能：第一之前已经卖出了第二次了，我今天是静默；第二我就是今天卖的 ​ dp[i][4] = Math.max(dp[i - 1][4], dp[i - 1][3] + prices[i]); **初始化中** `dp[i][1] = -prices[0]` 第二次买入依赖于第一次卖出的状态，其实相当于第0天第一次买入了，第一次卖出了，然后在买入一次（第二次买入） ​ `dp[i][3] = -prices[0]` **最后的 return 可定是** `dp[prices.length - 1][4]`，因为我要满足两次都卖出的时候状态并且是最后一天的时候。 - [ ] 188.买卖股票的最佳时机Ⅳ （最多买卖k次） 方法：这题就是上一题 2 => k **变成循环就完了** - [ ] **309.买卖股票多次 但是买入之后需要一天的冷冻期 方法：** - [ ] 714.买卖多次 但是每次有手续费 方法：这题就是 122.买卖股票的最佳时机Ⅱ （可以买卖多次） 卖了多个费用而已 #### 子序列问题 ##### 子序列（不连续）问题 **全部是正常遍历顺序** - [ ] 300.最长递增子序列 方法：`dp[i] = max(dp[i], dp[j] + 1);` 初始化全为1 两层for 循环 - [x] 1143.最长公共子序列 方法：`dp[i][j]` 的含义是 `text1[0:i-1]` 和 `text2[0:j-1]` 的最长公共子序列。 如果`text1[i - 1] 与 text2[j - 1]`不相同，那就看看`text1[0, i - 2]与text2[0, j - 1]的最长公共子序列 和 text1[0, i - 1]与text2[0, j - 2]的最长公共子序列，取最大的。` ![](http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/QQ截图20220915200451.png) - [ ] 1035.不相交的线 方法：**和上面一题一模一样，代码都是一样的**，就是换个场景。 语法糖啊。 ##### 子序列（连续）问题 **全部是正常遍历顺序** - [ ] 674.最长连续递增子序列 方法：这道题 和 300.最长递增子序列 想法是一样的，只是 j 的变化范围的区别，在这里必须是连续的 所以 j 的取值只有 i 的前一个，但是 不连续的情况下， j 的取值是 [0, i-1]。 所以只需要在 300的基础上，需改 j 的初始值wei i - 1 即可。 - [ ] 718.最长公共子数组 方法：这道题1143.最长公共子序列 一模一样，就是这里是连续，连续和不连续的区别在于，动态转移方程不同 对于 非连续 1234if(text1[i-1] == text2[j-1]) dp[i][j] = dp[i-1][j-1] + 1else dp[i][j] = Math.max(dp[i-1][j],dp[i][j-1]) 对于 连续 只有 并且最大的并不是 dp最后，所以需要一个 result 去维护 12if(text1[i-1] == text2[j-1]) dp[i][j] = dp[i-1][j-1] + 1 - [ ] 53.最大子数和 方法：正常的一维动态规划 ##### 编辑距离 **全部是正常遍历顺序** - [ ] 392.判断子序列 方法：用最大公共子序列，然后判断最后结果必须和 s序列长度一样。这个方法是可行的. 12// 这位 t 对比上了 所以去掉这位 继续dp[i][j] = dp[i][j-1] - [ ] 115.不同的子序列 方法：这道题其实就是编辑距离，只是仅仅考虑删除，不包括修改和增加。**并且只考虑左侧字符串。** 并且这道题是考虑 匹配的数量，所以动态规划表达式有所区别。 - [ ] 583.两个字符串的删除操作 方法：这道题是上一题的变成了 2个字符串都删除，求删到一样的最小步数。其实最佳的结束点就是最大公共子序列，步数就是 长度- 最大公共子序列啊。。 - [ ] 72.编辑距离 方法：这道题是最经典的编辑距离的问题，也就是上面 115.不同的子序列的完全版，需要同时考虑 删除、修改和增加，这道题dp考虑的是操作数。 `dp[i][j] 表示以下标i-1为结尾的字符串word1，和以下标j-1为结尾的字符串word2，最近编辑距离为dp[i][j]。` ​ 其中删除和增加的 动态规划表达式是一样的 ​ `if (word1[i - 1] != word2[j - 1])`，此时就需要编辑了，如何编辑呢？ ​ **操作一：word1删除一个元素，那么就是以下标i - 2为结尾的word1 与 j-1为结尾的 word2的最近编辑距离 再加上一个操作。** ​ 即 `dp[i][j] = dp[i - 1][j] + 1;` ​ **操作二：word2删除一个元素，那么就是以下标i - 1为结尾的word1 与 j-2为结尾的 word2的最近编辑距离 再加上一个操作。** ​ 即 `dp[i][j] = dp[i][j - 1] + 1;` ​ 对于修改 ​ 就是该 word1[i-1] 为 word2[j-1] ，也就是 `dp[i][j] = dp[i-1][j-1] + 1` ​ // 初始化 ​ `dp[i][0] 和 dp[0][j]` 肯定是分别删除它的全部啦 ​ #### 回文 **这里的题 dp 全部不用 + 1** **遍历顺序全部为 i 从下到上 j 从左（i/i+1 开始自己分析情况）到右** - [ ] 647.回文子串 方法：动态规划法 （需要注意遍历顺序）， 另外还有中心扩散法，这个方法比较巧妙并且空间复杂度低 - [ ] 5.最长回文子串 - [ ] 516.最长回文子序列 方法：动态规划法 12345678910111213for(let i = 0; i &lt; length; i++) &#123; dp[i][i] = 1;&#125;for(let i = length - 1; i &gt;= 0; i--) &#123; for(let j = i + 1; j &lt; length; j++) &#123; if(s[i] === s[j]) &#123; dp[i][j] = dp[i+1][j-1] + 2; &#125; else &#123; dp[i][j] = Math.max(dp[i+1][j], dp[i][j-1]); &#125; &#125;&#125; **另一种新奇的思路试， 将s.reverse()， s 和 s.reverse() 的最大公共子序列就是最长回文子序列** ### 单调栈 什么时候用单调栈呢？ **通常是一维数组，要寻找任一个元素的右边或者左边第一个比自己大或者小的元素的位置，此时我们就要想到可以用单调栈了**。时间复杂度为O(n)。 **单调栈的本质是空间换时间**，因为在遍历的过程中需要用一个栈来记录右边第一个比当前元素高的元素，优点是整个数组只需要遍历一次。 **注意点：** 单调栈里只需要存放元素的下标i就可以了，如果需要使用对应的元素，直接T[i]就可以获取。 单调递增递减怎么看？ **指的是栈头到栈底应该保持一种单调的状态** 如果求一个元素右边第一个更大元素，单调栈就是递增的 如果求一个元素右边第一个更小元素，单调栈就是递减的。 使用单调栈在 遍历一次数组中 一般来说有3种情况 当前遍历的元素T[i]小于栈顶元素T[st.top()]的情况 当前遍历的元素T[i]等于栈顶元素T[st.top()]的情况 当前遍历的元素T[i]大于栈顶元素T[st.top()]的情况 难点主要在对三种情况应该具体怎么分析入栈和出栈的 [ ] 739.每日温度 方法：求右侧第一个最大的，单调栈从栈顶到栈底，单调递增。 [ ] 496.下一个最大的元素Ⅰ（不循环） 方法： 这道题利用 indexOf 再双循环非常的简单。 使用单调栈的话，其实他非常依赖于 nums2 的长度，因为他把每一个 后面第一个值大于之前某一值的 键值对存入，然后在用数组一的 值作为key去找，其实速度并不快，但是思路也清晰的。（我自己写可能还是不行） [ ] 503.下一个最大的元素Ⅱ（循环） 方法：和上一题一样，就是 nums 需要扩张一倍，然后 index 需要mode一下 1234567891011121314var nextGreaterElements = function(nums) &#123; let numsTemp = [...nums,...nums] let stack = [] let result = new Array(nums.length).fill(-1) stack.push(0) for(let i = 0; i &lt; numsTemp.length; i++)&#123; while(stack.length &amp;&amp; numsTemp[stack[stack.length - 1]] &lt; numsTemp[i])&#123; let index = stack.pop() % nums.length result[index] = numsTemp[i] &#125; stack.push(i) &#125; return result&#125;; [ ] 47.接雨水 方法：暴力双指针，带数组双指针（推荐），单调栈（一样是 从小到大的顺序） 额外需要注意的题目","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"前端性能优化","slug":"前端网络相关面试题_凯凯超人版本","date":"2023-03-22T15:51:03.000Z","updated":"2023-03-20T10:52:50.000Z","comments":true,"path":"2023/03/22/前端网络相关面试题_凯凯超人版本/","link":"","permalink":"http://example.com/2023/03/22/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/","excerpt":"","text":"前端网络相关面试题考点1: http 协议面试题：浏览器Http请求和响应过程浏览器端构建HTTP请求，并发送 -&gt; 服务器端接收到HTTP请求，并进行解析 -&gt; 服务器端发送HTTP响应 -&gt; 浏览器端接收到响应，解析Http响应，而后进行页面渲染。 面试题：客户端渲染 与 服务器渲染的区别客户端渲染 SPA（单页面）是客户端渲染的 用户输入地址，客户端向服务器发送请求 =&gt; 服务器传给浏览器相应的网页文件 =&gt; 浏览器解析文件 =&gt; 遇到ajax请求则向服务器再次请求一些数据 =&gt; 服务器再次向浏览器发送相应的数据 =&gt; 浏览器拿到ajax请求返回的数据后，将数据渲染在页面上 优点： 可以向用户快速展示页面的内容，增加用户体验 给别人爬虫爬取相应的内容增加一定的困难 缺点： 可能需要向服务器请求多次数据 不利于SEO（搜索引擎优化），即百度、搜狗等搜索引擎搜索不到客户端渲染的数据 服务器渲染 客户端向服务器发送一次请求 =&gt; 服务器接收请求，并在服务端操作网页文件，将对应数据导入文件 =&gt; 服务器在服务端渲染好整个网页，发送给客户端 =&gt; 客户端接收服务器发送过来的网页文件，不需要做任何操作，直接呈现 优点 只需要向服务器请求一次 利于SEO 搜索引擎优化，即能被搜索引擎搜索到，能向用户展示你网页的东西 缺点 如果数据量过大，在服务器渲染的时间就会过长，造成浏览器暂时的空白 容易被爬虫爬取 如何区分客户端渲染和服务器渲染 若页面做整体的刷新，即网址发生改变，就是服务器渲染 若页面做了局部刷新，即网址没发生改变，就是客户端渲染 面试题：常见http status1XX系列：指定客户端应相应的某些动作，代表请求已被接受，需要继续处理。由于 HTTP/1.0 协议中没有定义任何 1xx 状态码，所以除非在某些试验条件下，服务器禁止向此类客户端发送 1xx 响应。 2XX系列：代表请求已成功被服务器接收、理解、并接受。这系列中最常见的有200、201状态码。 3XX系列：代表需要客户端采取进一步的操作才能完成请求，这些状态码用来重定向，后续的请求地址（重定向目标）在本次响应的 Location 域中指明。这系列中最常见的有301、302状态码。 4XX系列：表示请求错误。代表了客户端看起来可能发生了错误，妨碍了服务器的处理。常见有：401、404状态码。 5xx系列：代表了服务器在处理请求的过程中有错误或者异常状态发生，也有可能是服务器意识到以当前的软硬件资源无法完成对请求的处理。常见有500、503状态码。 2开头 （请求成功）表示成功处理了请求的状态代码。 200 （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 201 （已创建） 请求成功并且服务器创建了新的资源。 202 （已接受） 服务器已接受请求，但尚未处理。 203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。 204 （无内容） 服务器成功处理了请求，但没有返回任何内容。 205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。 206 （部分内容） 服务器成功处理了部分 GET 请求。 3开头 （请求被重定向）表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。 300 （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。 301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。 302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。 304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。 305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。 307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 4开头 （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。 400 （错误请求） 服务器不理解请求的语法。 401 （未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。 403 （禁止） 服务器拒绝请求。 404 （未找到） 服务器找不到请求的网页。 405 （方法禁用） 禁用请求中指定的方法。 406 （不接受） 无法使用请求的内容特性响应请求的网页。 407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。 408 （请求超时） 服务器等候请求时发生超时。 409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。 410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。 411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。 412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。 413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。 415 （不支持的媒体类型） 请求的格式不受请求页面的支持。 416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。 417 （未满足期望值） 服务器未满足”期望”请求标头字段的要求。 5开头（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。 500 （服务器内部错误） 服务器遇到错误，无法完成请求。 501 （尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。 502 （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。 503 （服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。 504 （网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。 505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。 面试题：http 和 https 的区别 HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全 HTTPS协议 引入了数据加密（对称加密和非对称加密相结合的方式实现）和身份验证机制（数字证书来验证服务器身份）。在开始传输数据之前，通过安全可靠的 TLS 协议进行加密，从而保证后续加密传输数据的安全性。 数据加密：HTTPS使用SSL/TLS协议对传输的数据进行加密，从而防止第三方窃听、篡改或伪造数据。SSL/TLS协议使用对称加密和非对称加密相结合的方式，对传输的数据进行加密和解密，确保数据的机密性和完整性。 证书验证：HTTPS使用SSL/TLS协议中的数字证书来验证服务器的身份，防止中间人攻击和伪造服务器。数字证书是由可信的第三方机构颁发的，它包含了服务器的公钥和其他相关信息，客户端可以通过验证数字证书来确认服务器的身份和信任服务器。 安全性强：HTTPS使用SSL/TLS协议对数据进行加密和解密，加密强度高，具有一定的抵抗攻击的能力。同时，HTTPS还可以使用数字证书来验证服务器的身份，可以避免中间人攻击和伪造服务器。 原来是 SSL，现在 已经被废弃，使用 TLS协议了 TLS 协议：传输层安全性协议（Transport Layer Security，TLS）及其前身安全套接层（Secure Sockets Layer，SSL）是一种安全协议，目的是为了保证网络通信安全和数据完整性。 HTTPS和HTTP的区别主要如下： 1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 2、http是超文本传输协议，信息是明文传输，https则是具有安全性的 SSL 加密传输协议。 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 4、http的连接很简单，是无状态的；HTTPS协议是由 TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 面试题：http协议 各版本的区别 HTTP/0.9：功能捡漏，只支持GET方法，只能发送HTML格式字符串。 HTTP/1.0：支持多种数据格式，增加POST、HEAD等方法，增加头信息，每次只能发送一个请求（无持久连接） HTTP/1.1：默认持久连接、请求管道化、增加缓存处理、增加Host字段、支持断点传输分块传输等。 HTTP/2.0：二进制分帧、多路复用(解决了HTTP阻塞线头)、头部压缩、服务器推送 并没有解决 TCP 队头阻塞的问题 ​ 采用HTTP/2时，浏览器一般会在单个TCP连接中创建并行的几十个乃至上百个传输。如果HTTP/2连接双方的网络中有一个数据包丢失，或者任何一方的网络出现中断，整个TCP连接就会暂停，丢失的数据包需要被重新传输。因为TCP是一个按序传输的链条，因此如果其中一个点丢失了，链路上之后的内容就都需要等待。 http2.0 各个特点展开说就是： HTTP2使用的是二进制传送，HTTP1.X是文本（字符串）传送。 二进制传送的单位是帧和流。帧组成了流，同时流还有流ID标示 HTTP2支持多路复用 因为有流ID，所以通过同一个http请求实现多个http请求传输变成了可能，可以通过流ID来标示究竟是哪个流从而定位到是哪个http请求 HTTP2头部压缩 HTTP2通过gzip和compress压缩头部然后再发送，同时客户端和服务器端同时维护一张头信息表，所有字段都记录在这张表中，这样后面每次传输只需要传输表里面的索引Id就行，通过索引ID查询表头的值 HTTP2支持服务器推送 HTTP2支持在未经客户端许可的情况下，主动向客户端推送内容 面试题：http 的请求方式 有哪几种 OPTIONS 查询服务器支持的请求方式，OPTIONS请求用于查询服务器支持的请求方式，客户端可以用这个方法来测试服务器的功能性。 具体的说：客户端可以对特定的 URL 使用 OPTIONS 方法，也可以对整站（通过将 URL 设置为“*”）使用该方法 HEAD 与GET请求类似，但是不返回响应体，只返回响应头。 GET 从服务器获取资源，GET请求是最常用的请求方式，用于请求服务器上的数据。 注意：GET方法不应当被用于产生“副作用”的操作中，例如在Web Application中，其中一个原因是GET可能会被网络蜘蛛等随意访问。Loadrunner中对应get请求函数：web_link和web_url POST 向服务器提交数据，用于向服务器发送数据，例如表单数据等。）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 Loadrunner中对应POST请求函数：web_submit_data,web_submit_form PUT 更新服务器上的资源，PUT请求用于更新服务器上的指定资源，客户端需要提供完整的资源数据。 DELETE 删除服务器上的资源，DELETE请求用于删除服务器上的指定资源。 TRACE 追踪请求-响应的传输路径，TRACE请求用于追踪请求-响应的传输路径，客户端可以用这个方法来诊断网络连接问题。 CONNECT 这个比较特殊。它不是通过传输数据来操作服务器资源，而是建立一个管道，从而支持客户端和服务器之间的数据传输。因为 CONNECT 请求方法的作用比较特殊，所以一般不在普通的 Web 应用程序中使用。 面试题：GET和POST区别 get用来获取数据，post用来提交数据 **get参数有长度限制（受限于url长度，具体的数值取决于浏览器和服务器的限制，最长2048字节），而post无限制** **get请求的数据会附加在url之 ，以 \" ？ \"分割url和传输数据，多个参数用 \"&\"连接，而post请求会把请求的数据放在http请求体中。** get是明文传输，post是放在请求体中，但是开发者可以通过抓包工具看到，也相当于是明文的。 get请求会保存在浏览器历史记录中，还可能保存在web服务器的日志中 考点2： TCP 协议 与 UDP 协议面试题：TCP的三次握手建立连接的过程TCP三次握手的过程如下： 第一次握手（SYN）：客户端向服务器发送一个SYN（Synchronize Sequence Number）报文段，表示客户端请求建立连接。SYN报文段包含一个随机的初始序列号（ISN）。 第二次握手（SYN+ACK）：服务器收到客户端的SYN报文段之后，会向客户端发送一个SYN+ACK报文段，表示服务器已经收到了客户端的请求，并且同意建立连接。SYN+ACK报文段包含服务器的初始序列号（ISN）和确认号（ACK）。 第三次握手（ACK）：客户端收到服务器的SYN+ACK报文段之后，会向服务器发送一个ACK（Acknowledgment）报文段，表示客户端已经收到了服务器的响应，并且同意建立连接。ACK报文段包含确认号（ACK），确认号的值为服务器的初始序列号（ISN）+1。 完成三次握手后，TCP连接就建立起来了，客户端和服务器可以开始进行数据传输。三次握手的过程中，主要是为了确保客户端和服务器都知道对方的存在，并且建立一个可靠的连接，以保证数据传输的安全性和可靠性。如果有任何一次握手失败，连接就会建立失败，需要重新发起三次握手建立连接。 面试题：TCP的四次握手释放连接的过程**注意 客户端和服务端 都可以提出释放连接的请求**。**因为 TCP是一种全双工（full-duplex）协议** 1. **发起关闭连接的一方（称为主动关闭方，Active Close）**发送一个**FIN报文段**（也就是连接释放报文段），表示停止发送数据，并请求关闭连接。主动关闭方进入FIN_WAIT_1状态，等待另一方的确认。 2. **接收到关闭请求的另一方（称为被动关闭方，Passive Close）**收到**FIN报文段**后，它会**发送一个ACK报文段**作为确认，并进入CLOSE_WAIT状态，等待关闭请求的另一方关闭连接。 3. **被动关闭方在发送完所有数据之后，也发送一个FIN报文段**，表示它已经没有数据要发送了，并请求关闭连接。被动关闭方进入LAST_ACK状态。 4. **主动关闭方收到被动关闭方的FIN报文段后，发送一个ACK报文段作为确认**，并进入TIME_WAIT状态。**在这个状态下，主动关闭方等待2倍的最长报文段寿命（Maximum Segment Lifetime, MSL）后，连接彻底关闭。** ![img](https://uploadfiles.nowcoder.com/images/20230131/473144517_1675142925083/D2B5CA33BD970F64A6301FA75AE2EB22) #### 面试题：TCP vs UDP的区别 - TCP是一种**面向连接的**、可靠的、基于字节流的传输层通信协议，是专门为了**在不可靠的网络中提供一个可靠的端对端字节流而设计的，面向字节流。** - UDP（用户数据报协议）是iso参考模型中一种**无连接的传输层协议**，提供**简单不可靠的非连接传输层服务**，**面向报文** **区别：** 1. TCP是面向连接的，可靠性高；UDP是基于非连接的，可靠性低 2. 由于TCP是连接的通信，需要有三次握手、重新确认等连接过程，会有延时，实时性差，同时过程复杂，也使其易于攻击；UDP没有建立连接的过程，因而实时性较强，也稍安全 3. 在传输相同大小的数据时， TCP首部开销20字节；实际数据最多为 60字节 UDP首部开销8字节，**TCP报头比UDP复杂，故实际包含的用户数据较少**。TCP在IP协议的基础上添加了序号机制、确认机制、超时重传机制等，保证了传输的可靠性，不会出现丢包或乱序，而UDP有丢包，故**TCP开销大，UDP开销较小** 4. 每条TCP连接只能时点到点的； UDP支持一对一、一对多、多对一、多对多的交互通信，即可多播 **应用场景选择** - 对实时性要求高和高速传输的场合下使用UDP;在可靠性要求低，追求效率的情况下使用UDP; - 需要传输大量数据且对可靠性要求高的情况下使用TCP #### 面试题：七层模型和五层模型 及其对应协议 ![](https://gitee.com/kaikai-superman/imgs/raw/master/img/QQ截图20230117200355.png) - DNS (Domain Name Service 域名服务) 协议基于 UDP协议 - FTP (File Transfer Protocol 文件传输协议) 基于 TCP协议 - DNS和FTP都是应用层协议 **1.应用层** 作用：它是与其他计算机进行通信的应用，它是对应应用程序的通信服务的。各种应用软件，包括web应用。 协议：DNS、FTP、HTTP、SMTP、TELNET、IRC、WHOIS **2.表示层** 作用：这一层的主要作用是定义数据格式和加密。 **3.会话层** 作用：控制应用程序的会话能力，它定义了一段会话的开始、控制和结束，包括对多个双向消息的控制和管理，以便在只完成一部分消息时可以通知应用。 协议： HTTP（Hyper text Transfer Protocol）协议：超文本传输协议使用TCP的80端口 FTP（File Transfer Protocol）文本传输协议 SMTP（Simple Mail Transfer Protocol）简单邮件传输协议，TCP是我25端口用户发邮件。 POP3（Post Office Protocol version3）邮局协议版本3，TCP的110号端口，用于收邮件的。 DNS（Domain Name System）域名解析协议。使用TCP和UDP的53号端口，作用是把www的域名解析成IP地址。 **4.传输层** 作用：对差错恢复协议和无差错恢复协议的选择，对同一主机上不同数据流的输入进行复用，对数据包进行重新排序。是最关键的一层，是唯一负责整体的数据传输和数据控制的。对上三层提供可靠的传输服务，对网络层提供可靠的目的地信息。在这一层数据的单位被称为数据段。 协议：TCP、UDP等 **5.网络层** 作用：主要负责寻找地址和路由选择，网络层还可以实现阻塞控制、网际互联等。 协议：IP、IPX、RIP、OSPF等 **6.数据链路层** 作用：负责物理层面上的互联的、节点间的通信传输；该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。在这一层，数据的单位称为帧（frame） 协议：ARP、RARP、SDLC、HDLC、PPP、STP、帧中继等 **7.物理层** 作用：负责0、1 比特流（0/1序列）与电压的高低、逛的闪灭之间的转换 规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性；该层为上层协议提供了一个传输数据的物理媒体。在这一层，数据的单位称为比特（bit）。 典型规范：EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45、fddi令牌环网等 #### 面试题：DNS解析的过程 DNS是应用层协议，事实上他是为其他应用层协议工作的，包括不限于HTTP和SMTP以及FTP，用于将用户提供的主机名解析为ip地址。 具体过程如下： 1. 客户机提出域名解析请求 , 并将该请求发送给本地的域名服务器 ; 2. 当本地的域名服务器收到请求后 , 就先查询本地的缓存 , 如果有该纪录项 , 则本地的域名服务器就直接把查询的结果返回 ; 3. 如果本地的缓存中没有该纪录 , 则本地域名服务器就直接把请求发给根域名服务器 , 然后根域名服务器再返回给本地域名服务器一个所查询域 (根的子域) 的主域名服务器的地址 ; 4. 本地服务器再向上一步返回的域名服务器发送请求 , 然后接受请求的服务器查询自己的缓存 , 如果没有该纪录 , 则返回相关的下级的域名服务器的地址 ; 5. 重复第四步 , 直到找到正确的纪录 ; 6. 本地域名服务器把返回的结果保存到缓存 , 以备下一次使用 , 同时还将结果返回给客户机 ; ### 考点3： URL #### 面试题：URL 路径包含什么, URI 是什么 **URL 路径包含什么** 通常情况下，一个URL的格式是： 1protocol :// hostname[:port] / path / [;parameters][?query]#fragment protocol 协议 hostname主机名 port端口号 path路径 parameters 参数 query查询 协议：//主机：端口/路径名称?搜索条件#哈希标识 **URI 是什么** **URI**是一个用于标识互联网资源名称的字符串。 该种标识允许用户对网络中（一般指[万维网](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/万维网)）的资源通过特定的协议进行交互操作。URI的最常见的形式是统一资源定位符（URL），经常指定为非正式的网址。更罕见的用法是统一资源名称（URN），其目的是通过提供一种途径。用于在特定的命名空间资源的标识，以补充网址。 #### 面试题：浏览器地址栏输入 URL 敲下回车后发生了什么？ ##### Step 1：浏览器解析URL 一个`url`的结构解析如下： ![](https://gitee.com/kaikai-superman/imgs/raw/master/img/url解析.png) ##### **Step 2： DNS查询** 浏览器检查本地缓存，如果有的话，直接使用缓存中的副本。 没有就要进行 DNS查询的内容，这个部分看上面的 DNS解析过程。 **此步骤目的是为了，获取到了域名对应的目标服务器`IP`地址** Step 3：建立 TCP 连接在确定目标服务器服务器的IP地址后，则经历三次握手建立TCP连接。具体三次连接的步骤看上面。 Step 4：客户端（浏览器）发送 HTTP 请求当建立tcp连接之后，就可以在这基础上进行通信，浏览器发送 http 请求到目标服务器 请求的内容包括： 请求行：包含请求方法、URL、HTTP版本信息 请求头 请求主体（请求数据） Step 5：服务器响应请求当服务器接收到浏览器的请求之后，就会进行逻辑操作，处理完成之后返回一个HTTP响应消息，包括： 状态行：包含HTTP版本、状态码、状态码的原因短语 响应头 响应正文 ​ 在服务器响应之后，由于现在http默认开始长连接keep-alive，当页面关闭之后，tcp链接则会经过四次挥手完成断开 Step 6 : 页面渲染当浏览器接收到服务器响应的资源后，首先会对资源进行解析： 查看响应头的信息，根据不同的指示做对应处理，比如重定向，存储cookie，解压gzip，缓存资源等等 查看响应头的 Content-Type的值，根据不同的资源类型采用不同的解析方式 关于页面的渲染过程如下： 解析 HTML 和 CSS：浏览器首先将 HTML 和 CSS 解析成 DOM（文档对象模型）和 CSSOM（CSS 对象模型）两个树形结构，这两个结构合并后便构成了渲染树（Render Tree）。 布局：浏览器根据渲染树中每个元素的位置和大小计算出它们在屏幕上的实际位置，这个过程叫做布局（Layout），也称为回流（Reflow）。 绘制：浏览器根据渲染树和布局计算出来的元素位置和大小，将它们绘制到屏幕上，这个过程叫做绘制（Paint）。 合成：浏览器将绘制好的层按照它们的层级关系合成成最终的图像，并显示在屏幕上。","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前端性能","slug":"前端性能","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD/"}]},{"title":"VuePurchase易购平台项目笔记","slug":"VuePurchase易购平台项目笔记","date":"2023-03-20T15:55:01.000Z","updated":"2023-03-20T10:54:24.000Z","comments":true,"path":"2023/03/20/VuePurchase易购平台项目笔记/","link":"","permalink":"http://example.com/2023/03/20/VuePurchase%E6%98%93%E8%B4%AD%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/","excerpt":"","text":"VuePurchase易购平台项目笔记安装前端包与配置环境Step1：首先在当前地址中，创建我们的 项目文件 vue-purchase 1vue create vue-purchase 默认选择 Default Vue2.0 的版本。 我当前脚手架的版本是 5.0.8。 Step2：进入该项目文件 cd vue-purchase 并配置我们需要依赖的库 例如： 12345678910111213// 前端安装依赖npm i axios -Snpm i querystring -Snpm i echarts -S// 路由npm i vue-router@3// 配置后端服务 // 技术：node.js + mysql + mock.jsnpm i express -Snpm i cors -Snpm i mockjs -Snpm i mysql -S 其中 可以在事先就引入 Element UI 1vue add element 选择部分导入 import on demand 再选择 **zh-CN** 出现 `Successfully invoked generator for plugin: vue-cli-plugin-element` 表示成功 **Step3：`vue-purchase ` 项目中专门配置一个 server 文件夹用于配置服务器相关代码** **Step4：启动前端项目** 1npm run serve **Step5：删除初试项目中没用部分** 例如 App.vue 全部初始为啥也没有，组件里原本的东西都不要。 **Step6：添加所需部分** **assets** 静态资源 然后 assets 文件夹内，创建 css 和 images 文件夹，方便以后使用。 并再 css 文件中引入`reset.css` 、`iconfont.css` - `reset.css`，其是重置浏览器标签的样式表，百度可以直接搜到里面的内容。 - `iconfont.css` ，其是作者自己创建的一个图标库内容 其css的内容为 引入外部css文件。 1@import url(&quot;https://at.alicdn.com/t/font_2448847_ogyed8on8j.css&quot;); 然后这两个库需要再 main.js 入口文件中进行 注册： 1234//css 初始化import &quot;./assets/css/reset.css&quot;// iconfontimport &quot;./assets/css/iconfont.css&quot; **plugins** Element UI 另外就是 需要补全 `plugins` 文件夹中 element.js 文件引入的内容。 其实可以需要用到然后再引入，但是为了方便嘛这里全部引入算了。 引入的内容需要取 Element2.0的官网，快速入手中找到 `完整组件列表和引入方式（完整组件列表以 [components.json](https://github.com/ElemeFE/element/blob/master/components.json) 为准）`将其后面代码中所有的内容 都放到 element.js 中就进行替换即可。 **request** axios封装 另外就是要创建 request 文件夹，里面 request.js 。 里面实现 axios 的二次封装。 **views** 布局文件 再创建一个 views文件夹，内部创建两个布局（因为我有一个登录界面 和 一个后端页面）所以呈现的结构为： ![](https://gitee.com/kaikai-superman/imgs/raw/master/img/views.png) **router 路由** 另外就是 router，store 文件夹需要自己初始化配置好。 1234567891011121314151617181920// // 该文件专门用于创建整个应用的路由器import Vue from &#x27;vue&#x27;import VueRouter from &#x27;vue-router&#x27;import Layout from &#x27;@/views/Layout&#x27;import Login from &#x27;@/views/Login&#x27;//引入组件Vue.use(VueRouter)const routes = [ &#123;&#125;]//创建并暴露一个路由器export default new VueRouter(&#123; mode:&quot;history&quot;, base:process.env.BASE_URL, routes&#125;) 配置数据库用于后端服务首先你需要有一个 Apache + mysql 我这里使用的是 phpStudy， 作者用的那个 服务在我这开不起来。 APACHE就是一个网络服务器，这个服务器侦听一个TCP端口，一般是80，对端口收到的命令进行解释，然后提交一些结果。APACHE解释的最主要的命令就是GET和POST，一般对应客户端在浏览器输入地址、浏览器里面点击链接和提交一个表单。 APACHE对GET和POST命令进行解释的时候，如果GET和POST的对象是一个HTML、CSS、JS、RAR、TXT等一般文件，就直接把文件的内容发回客户端； https://blog.csdn.net/Quantum_Dog/article/details/109270685 Step1：先开启 Apache 和 mysql Apache 映射的端口为 80 Step2：需要下载 phpMyAdmin 需要打开软件管理，下载 phpMyAdmin 然后点击第一张图的数据库工具，打开按钮进入 phpMyAdmin 默认账号和密码 都是 root Step3：创建ego数据库 并载入数据表 并载入数据表 使用 Element UI 实现侧边栏页面侧边栏去 ElementUI中进行复制，保留自己想要的部分。 主要功能是要实现配置侧边导航栏的路由跳转，需要和 Element UI 进行级联 配置 router 文件夹 中的 index.js 如下 需要注意的点为 / 为一级路由， 后面 home页面路由、 产品管理路由、订单管理路由、广告分类路由均为同级别的二级路由，其各自里面的组件配置为三级路由 以 产品管理路由为例子 GoodsManage 作为路由的出口 用于显示三级路由的内容 123456&lt;template&gt; &lt;div&gt; &lt;!-- 路由出口 --&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt;&lt;/template&gt; 其里面包含两个三级路由 GoodsCategory 和 GoodsList 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import VueRouter from &#x27;vue-router&#x27;//引入组件import Layout from &#x27;../views/Layout/layout.vue&#x27;import Login from &#x27;../views/Login/login.vue&#x27;import Home from &#x27;../views/Home/home.vue&#x27;// 产品管理import GoodsManage from &quot;../views/GoodsManage/goodsManage.vue&quot;import GoodsCategory from &quot;../views/GoodsManage/GoodsCategory/goodsCategory.vue&quot;import GoodsList from &quot;../views/GoodsManage/GoodsList/goodsList.vue&quot;// 订单管理import OrderManage from &quot;../views/OrderManage/orderManage.vue&quot;import OrderCollect from &quot;../views/OrderManage/OrderCollect/orderCollect.vue&quot;import OrderList from &quot;../views/OrderManage/OrderList/orderList.vue&quot;import OrderAudit from &quot;../views/OrderManage/OrderAudit/orderAudit.vue&quot;// 广告分类import AdvertiseCategory from &quot;../views/AdvertiseCategory/advertiseCategory.vue&quot;import AdvertiseList from &quot;../views/AdvertiseCategory/AdvertiseList/advertiseList.vue&quot;import AdvertiseMagage from &quot;../views/AdvertiseCategory/AdvertiseMagage/advertiseMagage.vue&quot;//创建并暴露一个路由器export default new VueRouter(&#123; routes:[ &#123; path:&#x27;/&#x27;, component:Layout, children:[ // 配置 home页面路由 &#123; name:&quot;home&quot;, path:&quot;home&quot;, component:Home &#125;, // 配置 产品管理路由 &#123; name:&quot;goodsManage&quot;, path:&quot;goodsManage&quot;, component:GoodsManage, children:[ &#123; name:&quot;goodsCategory&quot;, path:&quot;goodsCategory&quot;, component:GoodsCategory &#125;, &#123; name:&quot;goodsList&quot;, path:&quot;goodsList&quot;, component:GoodsList &#125; ] &#125;, // 配置 订单管理路由 &#123; name:&quot;orderManage&quot;, path:&quot;orderManage&quot;, component:OrderManage, children:[ &#123; name:&quot;orderCollect&quot;, path:&quot;orderCollect&quot;, component:OrderCollect &#125;, &#123; name:&quot;orderList&quot;, path:&quot;orderList&quot;, component:OrderList &#125;, &#123; name:&quot;orderAudit&quot;, path:&quot;orderAudit&quot;, component:OrderAudit &#125; ] &#125;, // 配置 广告分类路由 &#123; name:&quot;advertiseCategory&quot;, path:&quot;advertiseCategory&quot;, component:AdvertiseCategory, children:[ &#123; name:&quot;advertiseList&quot;, path:&quot;advertiseList&quot;, component:AdvertiseList &#125;, &#123; name:&quot;advertiseMagage&quot;, path:&quot;advertiseMagage&quot;, component:AdvertiseMagage &#125; ] &#125; ] &#125;, &#123; path:&#x27;/login&#x27;, component:Login &#125; ]&#125;) 在 Element UI 中进行路由联动的属性为 router 12345/*default-active 用于根据路由 选择高亮哪一个*/ &lt;el-menu default-active=&quot;$route.path&quot; router class=&quot;el-menu-vertical-demo&quot; :collapse=&quot;isCollapse&quot; background-color= &quot;#252236&quot; text-color=&quot;#fff&quot; active-text-color=&quot;#ffd04b&quot; &gt; 所以我们需要修改后面的 index 索引来配置路由，其实挺简单的 如下所示为 menu组件中 123456789101112&lt;!-- 点击跳转的路由 产品管理为 home 二级路由--&gt;&lt;el-submenu index=&quot;/goodsManage&quot;&gt; &lt;template slot=&quot;title&quot;&gt; &lt;i class=&quot;el-icon-location&quot;&gt;&lt;/i&gt; &lt;span slot=&quot;title&quot;&gt;产品管理&lt;/span&gt; &lt;/template&gt; &lt;!-- 点击跳转的路由 三级路由--&gt; &lt;el-menu-item-group&gt; &lt;el-menu-item index=&quot;/goodsManage/goodsList&quot;&gt;产品列表&lt;/el-menu-item&gt; &lt;el-menu-item index=&quot;/goodsManage/goodsCategory&quot;&gt;产品分类&lt;/el-menu-item&gt; &lt;/el-menu-item-group&gt;&lt;/el-submenu&gt; 实现上方菜单导航折叠 首先修改 content.vue 中的 顶部区域 header 添加标签效果，并配置样式 另外左侧 Menu.vue 你会发现有空隙，你查看css样式，发现导航栏被渲染为li了，里面有个 border。你需要修改： 123.el-menu&#123; border-right: 0px;&#125; 而后导航的折叠，其实是由 Element UI 中的一个属性 collapse 所决定的 collapse 是否水平折叠收起菜单（仅在 mode 为 vertical 时可用） boolean — false 所以我们动态的 修改collapse 就可以实现这个效果。 不过这涉及到 子组件中的通信 iscollapse 属性写在父组件 layout.vue中，传递给 menu组件。 menu组件可 v-model动态判断 在content组件标签上，父组件需要挂载一个 自定义事件 , 这里让这个事件去修改 iscollapse 的状态。 1&lt;Content @OperateCollapse=&quot;OperateCollapse()&quot; &gt;&lt;/Content&gt; 在content组件中 触发函数中去调用他，这里不用传递参数 123changeMenu()&#123; this.$emit(&#x27;OperateCollapse&#x27;);&#125; 另外要实现点击改变 样式的效果 这里使用了一个 动态 class :class=&quot;&#123;active:isCollapse&#125; 1234&lt;div class=&quot;content&quot; :class=&quot;&#123;active:isCollapse&#125;&quot;&gt; &lt;Content @OperateCollapse=&quot;OperateCollapse()&quot; :isCollapse=&quot;isCollapse&quot; &gt; &lt;/Content&gt;&lt;/div&gt; 12345678.content&#123; padding-left: 200px; /* transition: all 1s; */&#125;/*被触发的时候 改变 padding-left*/.active&#123; padding-left: 64px;&#125; 实现上方右侧的 当前时间需要用到 day.js 库 官网： https://dayjs.fenxianglu.cn/ 具体安装看 我的安装笔记，用法也同安装里写的一样。 如下 获取我们想要的时间，不过这还是静态数据，插值语法引入界面，是不会动的。 1this.nowTime = dayjs(new Date()).format(&#x27;YYYY-MM-DD HH:mm:ss&#x27;) 实现后端部署涉及到 express 首先要先配置 index.js 其涉及到 express 创建本地服务器 server 文件夹里面的所有东西 这里我直接全复制过来了，不懂这个的编写 ，需要先把没讲到的注释掉，这个看 nodemon 报错就好了，注掉需要下载的东西和对应的路由。 vscode 控制台路径 到 server文件夹 需要下载 库 nodemon 进行全局配置 1npm install nodemon -g 然后在命令行中输入 nodemon ，就会打开 定义的 9898端口 使用 http://localhost:9898/home/dataCount 做个测试，出来就 ok 实现主页首页实现顶部数据统计信息首先需要在 src 中 创建一个 api 文件， 并在其中创建文件 base.js 和 index.js base.js 映射了之前 在 server 中配置的 接口路由 index.js 根据base.js 提供的接口路由地址，使用 axios get 获取数据，并封装到对应的方法中，用于调用 而后 我们需要在 入口文件 main.js 中引入 index.js 中的 api，自己写项目的话需要自己写哦。 在 home 组件中我们需要请求数据 配置 axios 请求 123456789101112131415161718192021222324252627export default &#123; name:&quot;HomeVue&quot;, data()&#123; return&#123; objCount:[] &#125; &#125;, // 防止数据还没有请求过来 显示为空的情况 filters: &#123; num(val) &#123; if (!val) return &#x27;&#x27;; return val.toLocaleString(); &#125; &#125;, mounted()&#123; //-获取顶部统计数据信息 this.getHomeCount(); &#125;, methods:&#123; //-获取顶部统计数据信息---------------------------------------- async getHomeCount() &#123; let res = await this.$api.getHomeCount() console.log(res.data.data.list); this.objCount = res.data.data.list; &#125;, &#125;&#125; 而后 上面使用 对objCount 使用插值语法就可以了。 作者这里 Mock.js 产生的数据格式有点问题，一个list就包含这8个值了。 另外他还配置了一个 过滤器 filter，所以其插值语法，举个例子： 1&lt;div class=&#x27;num&#x27;&gt;&#123;&#123;objCount.saleTotal | num&#125;&#125;&lt;/div&gt; 用 echarts 画图将原项目中 plugins 里的 echarts 整个包 复制到 我这里的 plugin中 在 入口文件 main.js 中引入 123import * as echarts from &#x27;echarts&#x27;;// 身上就会挂载一个 $myEchartsVue.use(echarts) 去 echarts 官网中 查看完整代码 在 Home.vue中 引入 echarts 整个引入就好了 1import * as echarts from &#x27;echarts&#x27;; 然后折线图绘制的代码，写在methods里 1234567891011121314151617181920212223242526// 绘制折线图drawline()&#123; // 需要绘制的区域 var chartDom = document.getElementById(&#x27;main&#x27;); var myChart = echarts.init(chartDom); var option; option = &#123; xAxis: &#123; type: &#x27;category&#x27;, data: [&#x27;Mon&#x27;, &#x27;Tue&#x27;, &#x27;Wed&#x27;, &#x27;Thu&#x27;, &#x27;Fri&#x27;, &#x27;Sat&#x27;, &#x27;Sun&#x27;] &#125;, yAxis: &#123; type: &#x27;value&#x27; &#125;, series: [ &#123; data: [820, 932, 901, 934, 1290, 1330, 1320], type: &#x27;line&#x27;, smooth: true &#125; ] &#125;; option &amp;&amp; myChart.setOption(option);&#125; 同理画饼图也是一样的操作。 获取数据 1234567891011121314151617181920212223// 绘制 Mock.js 模拟数据 的折线图async getHomeFormat()&#123; let res = await this.$api.getHomeFormat() console.log(&#x27;-获取绘制折线图--------&#x27;, res.data.result.data.sale_money); let arr = res.data.result.data.sale_money; //声明变量存储x轴 y轴数据 let xData = [], yData = [], yBarData = [], pieData = []; arr.forEach(ele =&gt; &#123; xData.push(ele.name) yData.push(ele.total_amount) yBarData.push(ele.num) //获取对象结构存储饼图数据----- let obj = &#123;&#125; obj.name = ele.name; obj.value = ele.total_amount; pieData.push(obj) &#125;); // 绘制折线图---动态数据--------------- this.drawline(xData, yData, yBarData); // 绘制饼图--动态数据-------[&#123;name:&#x27;&#x27;,value:&#x27;&#x27;&#125;,&#123;&#125;]---- this.drawPie(pieData)&#125;, 看着将数据填充入 echarts中，并修改一些属性就可以了。 然后再 mounted 生命周期函数中使用 123456mounted()&#123; //-获取顶部统计数据信息 this.getHomeCount() // 获取数据并 绘制折线图和饼图 this.getHomeFormat()&#125;, 实现下方的订单这个通过接口获取数据 添加到data中 很简单 1234// 获取订单数据async getHomeOrder()&#123; let res = await this.$api.getHomeOrder() this.Orderlist = res.data.list 然后插值语法显示即可 实现产品管理实现产品分类页面这个页面没啥好说的 就是引 elementUI，然后显示和查询特定都是有接口的 12345678910111213141516created()&#123; this.getGoodsList(1)&#125;,methods: &#123; // 根据产品名称 查询数据 async getGoodsList(page)&#123; let res = await this.$api.getGoodsList(&#123;page&#125;) console.log(res.data) if(res.data.status === 200)&#123; this.tableData = res.data.data &#125;else&#123; alert(&quot;请求产品数据失败&quot;) &#125; &#125; ...&#125; 就这个表单中 prop 指的是 tableData中直接的键 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;div class=&quot;list-table&quot;&gt; &lt;el-table :data=&quot;tableData&quot; border style=&quot;width: 100%&quot;&gt; &lt;el-table-column type=&quot;selection&quot; width=&quot;55&quot;&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;id&quot; label=&quot;商品ID&quot; width=&quot;100&quot;&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;title&quot; label=&quot;商品名称&quot; width=&quot;180&quot;&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;price&quot; label=&quot;商品价格&quot; width=&quot;100&quot;&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;num&quot; label=&quot;商品数量&quot; width=&quot;180&quot;&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;category&quot; label=&quot;商品类目&quot; width=&quot;100&quot;&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;image&quot; label=&quot;商品图片&quot; width=&quot;180&quot; &gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;sellPoint&quot; label=&quot;商品卖点&quot; width=&quot;180&quot; show-overflow-tooltip&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=&quot;descs&quot; label=&quot;商品描述&quot; width=&quot;180&quot; show-overflow-tooltip&gt; &lt;/el-table-column&gt; &lt;el-table-column label=&quot;操作&quot;&gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;el-button size=&quot;mini&quot; type=&quot;primary&quot; icon=&quot;el-icon-edit&quot; @click=&quot;handleEdit(scope.$index, scope.row)&quot;&gt;编辑&lt;/el-button&gt; &lt;el-button size=&quot;mini&quot; type=&quot;danger&quot; icon=&quot;el-icon-delete&quot; @click=&quot;handleDelete(scope.$index, scope.row)&quot;&gt;删除&lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt;&lt;/div&gt; 实现公共分页器另外比较特殊的就是实现分页器，因为后面每个页面都需要用到。 所以分页器是一个 components。 再 components 文件夹中创建 Pagination 文件夹，里面创建一个 pagination.vue 这个分页器同样是由 element UI 来做 主要有两个功能 我请求的数据分页每个多少个啊 总共多少啊 goodList.vue 需要传递给 pagination.vue 当然采用的是 props 因为是父传子 然后子这边页面发生变化 ，elementUi提供的方法为 @current-change=&quot;getPagination&quot;，绑定我们的自定义事件getPagination，这个事件应该把 再子组件中的数据传给父组件。可以使用自定义事件，再getPagination方法中我们触发自定义事件 1234// current 为当前页getPagination(current)&#123; this.$emit(&#x27;getPagination&#x27;,current)&#125; 那对应的 父组件中 注册子组件的标签上 应该配有自定义事件 getPagination 12&lt;!-- 部分三 ：分页器组件部分 --&gt;&lt;pagination :totalPage=&quot;totalPage&quot; :pageSize=&quot;pageSize&quot; @getPagination=&quot;getPagination&quot;&gt;&lt;/pagination&gt; 1234567891011121314151617// 获取点击页码：getPagination(page)&#123; //默认产品列表的分页功能 this.getGoodsList(page)&#125;, // 根据页面 查询数据 async getGoodsList(page)&#123; let res = await this.$api.getGoodsList(&#123;page&#125;) console.log(&quot;表单数据 res.data&quot;, res.data) if(res.data.status === 200)&#123; this.tableData = res.data.data this.totalPage = res.data.total this.pageSize = res.data.pageSize &#125;else&#123; alert(&quot;请求产品数据失败&quot;) &#125; &#125;, 实现搜索产品名 显示数据功能查询其实就是 调用接口很简单，这里要注意 传过去的对象，键一定要是 research 另外就是 有一些特殊的情况，例如如果查出来的数据是大于 页面容量8的话，需要截断显示。 接口调用如下： 1234567891011121314151617181920212223242526272829303132333435363738// 根据产品名称 查询数据async getGoodsSearch(goodsName)&#123; // let res = await this.$api.getGoodsSearch(&#123;goodsName&#125;) // console.log(res.data) // if(res.data.status === 200)&#123; // console.log(res.data) // &#125;else&#123; // alert(&quot;没有这个表单数据&quot;) this.$api.getGoodsSearch(&#123;search:goodsName&#125;) .then(res =&gt;&#123; console.log(res.data) if(res.data.status == 200)&#123; this.listTotal = res.data.result // 我拿到的数据是 如果超过页面上线 就要分页 if(this.listTotal.length &gt; 8)&#123; // 截取出8个 作为第一页展示 this.tableData = res.data.result.slice(0,8) &#125;else&#123; this.totalPage = res.data.result.length &#125; this.pageSize = Math.min(8, this.pageSize) &#125;else&#123; // 啥数据没查出来 就是空 this.tableData = [] this.totalPage = 0 &#125; &#125;) .catch( err =&gt;&#123; console.log(&quot;请求失败&quot;, err.data) &#125;)&#125;,onSubmit() &#123; if(!this.formInline.goodsName)&#123; this.$message.error(&#x27;请输入信息再去搜索&#x27;); return &quot;&quot; &#125; this.getGoodsSearch(this.formInline.goodsName)&#125;, 另外又有一个新的bug，就是我如果截取了前8个，剩下点第二页的时候，由于前面的事件绑定是显示全部数据的第二页，此时我应该显示的是查询剩下的内容。 我们在 data 中添加一个 searchStatus 用来标识，我是不是处于查询状态 然后根据状态执行对应修改页码的逻辑即可，分页逻辑是归纳的 1234567891011// 获取点击页码：getPagination(page)&#123; if(!this.seachStatus) //默认产品列表的分页功能 this.getGoodsList(page) // 在查询状态下，显示查询剩余内容 else&#123; // 0-7 8-15 this.tableData = this.listTotal.slice((page - 1) * 8, page * 8) &#125;&#125;, 实现选择时间的格式修改时间需要进行格式的转换，这里还是使用 dayJS 首先需要先 导入 dayJS 1import dayjs from &quot;dayjs&quot; 然后由于 el-table-colum 属性的title 是由prop 这个属性来定义的，不能修改，可以再下面使用template进行修改，例如如下： 123456&lt;el-table-column label=&quot;载入时间&quot; width=&quot;180&quot;&gt; &lt;!--prop=&quot;create_time&quot; prop获取列字段标识/template slot-scope=&quot;scope&quot;当前作用域下 scope获取当前行的数据信息 --&gt; &lt;template slot-scope=&quot;scope&quot;&gt; &#123;&#123; dayjs(scope.row.create_time).format(&#x27;YYYY-MM-DD HH:mm:ss&#x27;) &#125;&#125; &lt;/template&gt;&lt;/el-table-column&gt; 实现删除商品 指的是每一行的右侧我现在的实现有问题 得以后解决，因为我现在没有第5页数据了，我得学会了添加才能回来再试对不对 触发删除的按钮为 12345&lt;el-button size=&quot;mini&quot; type=&quot;danger&quot; icon=&quot;el-icon-delete&quot; @click=&quot;handleDelete(scope.$index, scope.row)&quot;&gt;删除&lt;/el-button&gt; 定义这个函数 1234567891011121314151617181920212223242526// 实现 数据某一行 删除方法handleDelete(index, row) &#123; console.log(index, row); this.$confirm(&#x27;确定删除这一行的商品数据?&#x27;, &#x27;提示&#x27;, &#123; confirmButtonText: &#x27;确定&#x27;, cancelButtonText: &#x27;取消&#x27;, type: &#x27;warning&#x27; &#125;).then(() =&gt; &#123; // 删除这个数据 这里就是请求后端的删除接口 this.deleteItemById(row.id) // 删除成功了之后 应该重新渲染页面 dom // 理论上现在是第几页 就重新再渲染一次第几页 // 要考虑到这次删掉是最后一条，那我应该跳到上一页 // 这个判断需要判断 我删除之后 此时条的总数是不是 pageSize 的倍数，是的话就应该渲染上一页 if(this.tableData.length % this.pageSize == 0) this.getGoodsList(this.currentPage - 1) else this.getGoodsList(this.currentPage) &#125;).catch(() =&gt; &#123; this.$message(&#123; type: &#x27;info&#x27;, message: &#x27;已取消删除&#x27; &#125;); &#125;);&#125; 其中定义了 删除数据接口 deleteItemById 12345678910// 删除数据的接口 ------async deleteItemById(id)&#123; let res = await this.$api.deleteGoods(&#123;id&#125;) if(res.data.status == 200)&#123; this.$message(&#123; type: &#x27;success&#x27;, message: &#x27;删除成功!&#x27; &#125;); &#125;&#125; 实现数据的添加页面先配置路由数据添加是一个新的页面，逻辑上应该是 点击添加商品按钮后，跳转到新的页面 1&lt;el-button type=&quot;warning&quot; icon=&quot;el-icon-check&quot; @click=&quot;toProductPage() &quot;&gt;添加商品&lt;/el-button&gt; 并再 GoodList 文件中 再创建一个 goodsAddPage.vue 然后需要配置路由，打开 router 的 index.js 中配置在 goodsManage下配置一个新的子路由 12345&#123; name:&quot;goodsAddPage&quot;, pat:&quot;goodsAddPage&quot;, component:GoodsAddPage&#125; 配置 click 方法 1234// 点击跳转 增添商品页面 ++++togoodsAddPage()&#123; this.$router.push(&quot;/goodsManage/goodsAddPage&quot;)&#125;, 配置数据添加页面碰到一个问题就是，我这个路由并没有在左侧的 导航栏中有对应的 index高亮。我们还是想要在产品列表对应高亮，所以这个怎么办呢？ 首先应该在路由中配置 meta 12345678&#123; name:&quot;goodsAddPage&quot;, path:&quot;goodsAddPage&quot;, component:GoodsAddPage, meta:&#123; // 配置高亮标识 对应的路由路径 activeMenu:&quot;/goodsManage/goodsList&quot; &#125;&#125; 做法：当目前的访问path 为/goodsManage/goodsAddPage时，我会自动的先变成 /goodsManage/goodsList。 这样我的 Menu 激活就能实现了。 刷新并且打印这个添加页面的 $route，你可以看到此页面是存在 meta的。 我们就利用这个东西，来实现上面的变换功能。 **这里实现方式，是使用 `watch` 来监听路由的变化，获取 meta 里的值。** 在 Menu.vue 中 123456789101112131415watch:&#123; $route(to, from)&#123; console.log(&quot;watch--to&quot;, to) console.log(&quot;watch--from&quot;, from) // 判断当前的路由里面 meta 中是否有值 // 我只拿里面的 meta 和 path let &#123;meta, path&#125; = to console.log() if(meta.activeMenu)&#123; this.active = meta.activeMenu &#125;else&#123; this.active = path &#125; &#125; &#125; 然后将上面 1234&lt;el-menu :default-active=&quot;active&quot; router class=&quot;el-menu-vertical-demo&quot; :collapse = &quot;isCollapse&quot; background-color= &quot;#252236&quot; text-color=&quot;#fff&quot; active-text-color=&quot;#ffd04b&quot; &gt; **但是这样有个问题，就是刚进入的时候，menu的 active 会失效，因为watch 并没有监听到路由的改变。** 所以可以在 created() 中先初始化一下最初的状态 1234567created()&#123; if(this.$route.meta.activeMenu)&#123; this.active = this.$route.meta.activeMenu &#125;else&#123; this.active = this.$route.path &#125;&#125;, 实现产品类型列表 的 树形菜单首先我们需要创建一个新的 vue组件，goodsTreeProdct.vue 。然后需要找到 Element UI 中的 树形菜单， 选择懒加载的组件。 将这个组件作为我们 goodsAddPage的子组件， 123456&lt;div class=&quot;nav&quot;&gt; &lt;div class=&quot;title&quot;&gt;产品类型列表&lt;/div&gt; &lt;div class=&quot;tree&quot;&gt; &lt;goodsTreeProdct&gt;&lt;/goodsTreeProdct&gt; &lt;/div&gt;&lt;/div&gt; 具体属性需要看 Element 文案 我们需要实现的就是 每一层点击，都要进行一次数据后端读取 api 为 this.$api.goodsItemCategory()。整体该组件代码如下所示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;template&gt;&lt;!-- 树状懒加载结构 show-checkbox 节点是否可被选择 boolean 默认为 false props 配置选项 具体看下表 object label 指定节点标签为节点对象的某个属性值 string, function(data, node) — — children 指定子树为节点对象的某个属性值 string — — disabled 指定节点选择框是否禁用为节点对象的某个属性值 boolean, function(data, node) — — isLeaf 指定节点是否为叶子节点，仅在指定了 lazy 属性的情况下生效 boolean, function(data, node) — — load 加载子树数据的方法，仅当 lazy 属性 为 true 时生效 并且其是一个函数 function(node, resolve) lazy 是否懒加载子节点，需与 load 方法结合使用 boolean — false --&gt; &lt;div&gt; &lt;el-tree :props=&quot;props&quot; :load=&quot;loadNode&quot; lazy&gt; &lt;/el-tree&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data() &#123; return &#123; props: &#123; label: &#x27;name&#x27;, children: &#x27;zones&#x27;, isLeaf: &#x27;leaf&#x27; &#125;, &#125;; &#125;, methods: &#123; loadNode(node, resolve) &#123; // 初始上来就是 第0层，然后展开第一层的内容 if (node.level === 0) &#123; // 这个 data 应该来自于 ajax请求 // let data = [&#123; name: &#x27;region&#x27; &#125;] this.$api.goodsItemCategory().then( res =&gt; &#123; if(res.data.status == 200) return resolve(res.data.result); else return resolve([]) &#125; ) &#125; if (node.level &gt;= 1) &#123; // 请求下一级别 this.$api.goodsItemCategory(&#123;type:node.data.cid&#125;).then( res =&gt; &#123; if(res.data.status == 200) return resolve(res.data.result); else return resolve([]) &#125; ) &#125; &#125;, &#125;, &#125;;&lt;/script&gt; 实现产品类型列表 的 右侧添加表单用全局总线来实现 左侧分类右侧显示首先第一行这个 所属分类，我们需要拿到左侧导航栏这个node的名称。在element的回调方法中有 @node-click = &quot;clickHandle&quot;，我们配置自定义函数 clickHandle，用来触发全局总线传递数据（因为这里是 子传子） 在 树结构Vue中 1234// 点击tree的节点触发的事件clickHandle(data)&#123; this.$bus.$emit(&#x27;sendTreeNode&#x27;,data)&#125;, 在 FormVue 组件中 123mounted() &#123; this.$bus.$on(&#x27;sendTreeNode&#x27;,this.sendTreeNode)&#125; 然后右侧表单整体的布局需要修改为需要效果1234567891011121314151617181920212223242526272829303132333435363738&lt;el-form :model=&quot;ruleForm&quot; :rules=&quot;rules&quot; ref=&quot;ruleForm&quot; label-width=&quot;100px&quot; class=&quot;demo-ruleForm&quot;&gt; &lt;el-form-item label=&quot;所属分类&quot; prop=&quot;name&quot;&gt; &#123;&#123;ruleForm.category&#125;&#125; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;商品名称&quot; prop=&quot;title&quot;&gt; &lt;el-input v-model=&quot;ruleForm.title&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;商品价格&quot; prop=&quot;price&quot;&gt; &lt;el-input v-model=&quot;ruleForm.price&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;商品数量&quot; prop=&quot;num&quot;&gt; &lt;el-input v-model=&quot;ruleForm.num&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;商品卖点&quot; prop=&quot;sellPoint&quot;&gt; &lt;el-input v-model=&quot;ruleForm.sellPoint&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;上传图片&quot; prop=&quot;image&quot;&gt; &lt;!-- &lt;GoodsUpload @sendImage=&quot;sendImage&quot; :fileList=&quot;fileList&quot;&gt;&lt;/GoodsUpload&gt; --&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;商品描述&quot; prop=&quot;descs&quot;&gt; &lt;!-- 富文本编辑器 --&gt; &lt;!-- &lt;WangEditor @sendEditor=&quot;sendEditor&quot; :editorData=&quot;editor&quot; ref=&quot;myEditor&quot;&gt;&lt;/WangEditor&gt; --&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;首页轮播推荐&quot; prop=&quot;isBanner&quot;&gt; &lt;el-switch v-model=&quot;ruleForm.isBanner&quot; active-color=&quot;#13ce66&quot;&gt;&lt;/el-switch&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;是否推荐商品&quot; prop=&quot;recommend&quot;&gt; &lt;el-switch v-model=&quot;ruleForm.recommend&quot; active-color=&quot;#13ce66&quot;&gt;&lt;/el-switch&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;是否上架商品&quot; prop=&quot;shelves&quot;&gt; &lt;el-switch v-model=&quot;ruleForm.shelves&quot; active-color=&quot;#13ce66&quot;&gt;&lt;/el-switch&gt; &lt;/el-form-item&gt; &lt;el-form-item&gt; &lt;el-button v-show=&quot;ruleForm.title!=&#x27;详情&#x27;&quot; type=&quot;primary&quot; @click=&quot;submitForm(&#x27;ruleForm&#x27;)&quot;&gt;保存&lt;/el-button&gt; &lt;el-button v-show=&quot;ruleForm.title!=&#x27;详情&#x27;&quot; @click=&quot;resetForm(&#x27;ruleForm&#x27;)&quot;&gt;重置&lt;/el-button&gt; &lt;el-button @click=&quot;goGoodsList()&quot; type=&quot;info&quot; plain&gt;取消&lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; 其中data的内容为 12345678910111213141516171819202122232425262728293031323334353637data() &#123; return &#123; ruleForm: &#123; category: &#x27;&#x27;, title: &#x27;&#x27;, price: &#x27;&#x27;, num: &#x27;&#x27;, sellPoint: &quot;&quot;, image: [], descs: &#x27;&#x27;, isBanner: true,//轮推荐 recommend: true,//推荐 shelves: true,//商品上架 &#125;, rules: &#123; title: [ &#123; required: true, message: &#x27;请输入商品名称&#x27;, trigger: &#x27;blur&#x27; &#125;, &#123; min: 3, max: 5, message: &#x27;长度在 3 到 5 个字符&#x27;, trigger: &#x27;blur&#x27; &#125; ], price: [ &#123; required: true, message: &#x27;请输入产品的价格&#x27;, trigger: &#x27;blur&#x27; &#125; ], num: [ &#123; required: true, message: &#x27;请输入产品的数量&#x27;, trigger: &#x27;blur&#x27; &#125; ], sellPoint: [ &#123; required: true, message: &#x27;请输入商品的卖点&#x27;, trigger: &#x27;blur&#x27; &#125; ], type: [ &#123; type: &#x27;array&#x27;, required: true, message: &#x27;请至少选择一个活动性质&#x27;, trigger: &#x27;blur&#x27; &#125; ], descs: [ &#123; required: true, message: &#x27;请输入商品的描述&#x27;, trigger: &#x27;blur&#x27; &#125; ] &#125; &#125;; &#125;, 实现表单 Form 中的图片上传 并回调存储信息首先又要创建一个 组件 upLoadImg.vue 123&lt;el-form-item label=&quot;上传图片&quot; prop=&quot;image&quot;&gt; &lt;upLoadImgVue&gt;&lt;/upLoadImgVue&gt;&lt;/el-form-item&gt; 随后我们去 ElmentUI 中寻找 图片上传的 组件。选用的是 Upload 上传中的 照片墙。 其中 vue 模板中的代码如下 12345678910&lt;el-upload action=&quot;https://jsonplaceholder.typicode.com/posts/&quot; list-type=&quot;picture-card&quot; :on-preview=&quot;handlePictureCardPreview&quot; :on-remove=&quot;handleRemove&quot;&gt; &lt;i class=&quot;el-icon-plus&quot;&gt;&lt;/i&gt;&lt;/el-upload&gt;&lt;el-dialog :visible.sync=&quot;dialogVisible&quot;&gt; &lt;img width=&quot;100%&quot; :src=&quot;dialogImageUrl&quot; alt=&quot;&quot;&gt;&lt;/el-dialog&gt; 我们其实要修改的是 action中，我们传递的服务器地址接口 post请求。 我们这里的服务器是 express 构建的，所以我们在 sever 中定义了 我们需要在 server 下创建一个 upload文件夹，用于我们的文件上传然后再 src 的 api/base.js 文件中对应的接口为： uploadUrl:&quot;/api/upload&quot;, `//导出图片 上传` export const uploadUrl=&#39;/api/upload&#39; 随后再 我们的 upLoadImg.vue 中进行引入 123456789101112import &#123;uploadUrl&#125; from &quot;../../../api/base&quot;// 并在 data 中进行注册export default &#123; name:&quot;upLoadImgVue&quot;, data() &#123; return &#123; uploadUrl, dialogImageUrl: &#x27;&#x27;, dialogVisible: false &#125;; &#125;, ... 将原来控件中的 action 修改为 双向绑定 :action=&quot;uploadUrl&quot; **我这里碰到了一个 bug，就是我上传的图片如果有中文 会乱码** 现在上传成功了，现在需要将 这个上传图片的地址，存到我 form 表单的 image 属性中 在控件中引入 :on-success=&quot;handleSuccess&quot; 然后就在 handleSuccess中执行需要的内容即可，我们这边需要将 图片url 传递给 父组件表单vue。 这里肯定需要一个 子传父的 自定义事件 这肯定会的啦，就不详细说了 123456789// 上传成功回调处理handleSuccess(response, file, fileList)&#123; // url: &quot;upload\\\\1677749642735-614.png&quot; const fileName = host + &quot;/&quot; + response.url.split(&quot;\\\\&quot;).pop(); console.log(fileName) console.log(response,file,fileList) this.$emit(&quot;sendImage&quot;, fileName)&#125; 然后修改 表单中的 image 属性 123sendImage(imgUrl)&#123; this.ruleForm.image.push(imgUrl)&#125; 实现表单 Form 中的富文本组件 上传富文本编译器，需要用到第三方的插件，这里使用的是 wangEditor 富文本编译器 所以我们也需要创建 wangEditor 这个Vue文件，然后我们这里也同样采用 自定义事件，进行父传子。 1&lt;wangEditor @sendWangEditor=&quot;sendWangEditor&quot;&gt;&lt;/wangEditor&gt; 最后实现商品的添加点击保存应该 可以提交此时的填写的商品信息，并且添加到数据库。 在表单Vue中，对按钮绑定事件： 12345678910submitForm(formName) &#123; this.$refs[formName].validate((valid) =&gt; &#123; if (valid) &#123; console.log(&quot;添加商品&quot;, this.ruleForm); &#125; else &#123; console.log(&#x27;error submit!!&#x27;); return false; &#125; &#125;);&#125;, router （express） 定义的 接口为： 1router.get(&quot;/goods/item/insertTbItem&quot;, (req, res) =&gt; &#123;...&#125; 对应 src api 下的 base.js 中的 addGoods:&quot;/api/goods/item/insertTbItem&quot;,*//商品添加地址* 然后对应的 src api 下的 index.js 123addGoods(params) &#123; return axios.get(base.addGoods, &#123; params &#125;);&#125; 然后就是撰写 Form 表单的方法：1234567891011121314151617181920212223242526272829303132333435363738// 提交事件 --------submitForm(formName) &#123; this.$refs[formName].validate((valid) =&gt; &#123; if (valid) &#123; console.log(&#x27;获取表单的输入信息：----&#x27;, this.ruleForm); //添加商品----参数： title cid category sellPoint price num descs paramsInfo image let &#123; title, cid, category, sellPoint, price, num, descs, image &#125; = this.ruleForm; this.insertTbItem(&#123; title, cid, category, sellPoint, price, num, descs, image: JSON.stringify(image) &#125;) &#125; else &#123; console.log(&#x27;error submit!!&#x27;); return false; &#125; &#125;);&#125;,// 添加商品的接口 -----------------async insertTbItem(params)&#123; let res = await this.$api.addGoods(params) console.log(&quot;+++++++++++++++++++++++++++++++++&quot;, res) console.log(&quot;添加商品&quot;, res.data); if (res.data.status === 200) &#123;//添加成功-- //信息提示 this.$message(&#123; message: &#x27;恭喜你，添加商品成功&#x27;, type: &#x27;success&#x27; &#125;); //跳转到产品列表界面--- this.$router.push(&#x27;/goodsManage/goodsList&#x27;) &#125; else &#123; //错误信息提示 this.$message.error(&#x27;错了哦，添加商品失败&#x27;); &#125;&#125;, INSERT INTO project(title, image, sellPoint, price, cid, category, num, descs, paramsInfo) VALUES (&#39;214&#39;,&#39;[&quot;http://localhost:9898/1677766470520-618.png&quot;]&#39;,&#39;13134&#39;,&#39;142&#39;,&#39;1001&#39;,&#39;新鲜水果&#39;,&#39;13124&#39;,&#39;&lt;p&gt;hello&lt;/p&gt;&#39;,&#39;&#39;) 这个源代码里 sql 语句是正确的，但是数据库有一个字段 upgrated 实现点击重置功能**重置功能，但是 上传图片区域 ** 首先对于 上传图片 的 upLoadImage Vue 文件，需要先定义一个 ref 用于找到这个控件 12345678 &lt;div&gt; &lt;el-upload... ref=&quot;upload&quot; multiple &gt;... &lt;/div&gt; 并在 methods 中定义 方法 clear 1234clear()&#123; // 自带 api clearFiles this.$refs.upload.clearFiles()&#125; 然后在 Form 组件中，对 upLoad 标签，给定一个 ref 1&lt;upLoadImgVue @sendImage=&quot;sendImage&quot; ref=&quot;uploadImage&quot;&gt;&lt;/upLoadImgVue&gt; 然后重置按钮，添加对应的 找到 ref 执行器 clear 方法 1234567resetForm(formName) &#123; this.$refs[formName].resetFields(); // 清空图片列表 这个办法是 组件自己的方法 this.$refs.uploadImage.clear() // WangEidtor&#125;, **重置功能， 富文本区域并没有 清空** 同样在 Form 组件中定义一个 ref 1&lt;wangEditor @sendWangEditor=&quot;sendWangEditor&quot; ref=&quot;wangEdit&quot;&gt;&lt;/wangEditor&gt; 然后在重置按钮中，写方法 123456789resetForm(formName) &#123; this.$refs[formName].resetFields(); // 清空图片列表 这个办法是 组件自己的方法 this.$refs.uploadImage.clear() // WangEidtor // this.$refs.wangEdit.html = &quot;&quot; // 或者 用其 api 方法 this.$refs.wangEdit.editor.clear() &#125;, 实现List 页面的 选中某几项 然后批量删除首先 table 在 Element UI 中对于选择哪几个，是有专门的触发函数的 12345678910111213141516&lt;!-- event: select:当用户手动勾选数据行的 Checkbox 时触发的事件 selection row select-all 当用户手动勾选全选 Checkbox 时触发的事件 selection--&gt;&lt;!-- 部分二 ：表格部分 --&gt;&lt;div class=&quot;list-table&quot;&gt; &lt;el-table :data=&quot;tableData&quot; header-cell-class-name=&quot;textCenter&quot; border style=&quot;width: 100%&quot; @select=&quot;selectHandle&quot; @select-all=&quot;selectHandle&quot; &gt; .... 触发的事件回调函数 是一致的 都是我们自己定义的 selectHandle 12345// 点击勾选选择框 ————————————selectHandle(selection)&#123; // 可以获取所有选中的 行 console.log(&quot;selection&quot;, selection)&#125;, 点击按钮批量删除，触发对应方法 123456789101112131415161718192021222324// 批量删除partDelete()&#123; console.log(&quot;批量删除 --ids--&quot;, this.ids); // 需要拼接是因为 我们的接口输入的是个 字符串 let idsStr = this.ids.join(&quot;,&quot;) this.$confirm(&#x27;确定删除选中的商品数据?&#x27;, &#x27;提示&#x27;, &#123; confirmButtonText: &#x27;确定&#x27;, cancelButtonText: &#x27;取消&#x27;, type: &#x27;warning&#x27; &#125;).then(() =&gt; &#123; this.$api.batchDelete(&#123;ids:idsStr&#125;).then( (res)=&gt;&#123; // 删除成功需要重新渲染列表 if(res.data.status == 200)&#123; this.$message(&#123; type: &#x27;success&#x27;, message: &#x27;删除成功!&#x27; &#125;); this.getGoodsList(1) &#125; &#125; ) &#125;)&#125;, 然后需要解决的bug问题是，我将这页选择的都删了，这页没有了，怎么显示回上一页 将整个项目推送到 gitee中Step1：首先初始你需要新建一个项目 Step2：在项目文件中打开 git bash 12345678910111213git initgit add .//在这之前，首次需要 注册邮箱和姓名git config --global user.email &quot;963561243@qq.com&quot;git config --global user.name &quot;JiangKaisheng&quot;//然后再git commit -m &quot;搭建项目&quot; // 初始第一次 远程一下git remote add origin https://gitee.com/kaikai-superman/vue2_-purchase-ego.git// push 到 master 分支上git push -u origin &quot;master&quot; 而后每一次提交 12// 先要 pull 一下保持更新git pull 在实际的开发中 肯定不会在 master 分支上的 所以我们可能需要自己建立分支 123// 可查看 本地和远端 分别由什么分支// 注意查看之前最好先 更新 git pull 一下git branch -a","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://example.com/tags/Vue/"}]},{"title":"网络安全篇章","slug":"前端网络安全面试题_凯凯超人版本","date":"2023-03-20T15:51:03.000Z","updated":"2023-03-20T10:52:58.000Z","comments":true,"path":"2023/03/20/前端网络安全面试题_凯凯超人版本/","link":"","permalink":"http://example.com/2023/03/20/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/","excerpt":"","text":"网络安全篇章考点1：网络劫持面试题：网络劫持分为哪两种DNS劫持： 例子：输入京东被强制跳转到淘宝，这就属于DNS劫持 方式有： DNS强制解析： 通过修改运营商的本地DNS记录，来引导用户流量到缓存服务器。 302跳转的方式： 通过监控网路出口的流量，分析判断哪些内容是可以进行劫持处理的，再对劫持的内存发起302跳转的回复，引导用户获取内容 HTTP劫持： 例子：访问谷歌，但是一直有贪玩蓝月的广告 **由于http明文传输，运营商会修改你的http响应内容（即加广告）** 总结 DNS劫持由于涉嫌违法，已经监管起来，现在很少有DNS劫持， 而http劫持依旧非常盛行，最有效的办法就是全站https，将http加密，这使得运营商无法获得明文，就无法劫持你的响应内容。 考点2：前端安全的 引起与 防御面试题：有哪些可能引起前端安全的问题？1.跨站脚本(Cross-Site Scripting, XSS)： 一种代码注入方式，为了与CSS区分，所以被称为 XSS。 早期常见于网络论坛，起因是网站没有对用户的输入进行严格的限制，使得攻击者可以将脚本上传到帖子，让其他人浏览到恶意脚本的页面，其注入方式很简单，包括但不限于javascript/css/flash等； 2. iframe的滥用： iframe中的内容是由第三方来提供的，默认情况下，他们不受控制，他们可以在iframe中运行javascript脚本、Flash插件、弹出对话框等等，这可能会破坏前端用户体验。 3.跨站点请求伪造（Cross-Site Request Forgeries，CSRF）: 指攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新，属于被动攻击。 4.恶意第三方库： 无论是后端服务器应用还是前端应用开发，绝大多数时候，都是在借助开发框架和各种类库进行快速开发，一旦第三方库被植入恶意代码很容易引起安全问题。 面试题：什么是 跨站脚本 XSS攻击？基本概念XSS 攻击指的是跨站脚本攻击，是一种代码注入攻击。攻击者通过在网站注入恶意脚本，使之在用户的浏览器上运行，从而盗取用户的信息如 cookie 等。 XSS 的本质是因为网站没有对恶意代码进行过滤，与正常的代码混合在一起了，浏览器没有办法分辨哪些脚本是可信的，从而导致了恶意代码的执行。 攻击者可以通过这种攻击方式可以进行以下操作： 获取页面的数据，如 DOM、cookie、localStorage； DOS 攻击，发送合理请求，占用服务器资源，从而使用户无法访问服务器； 破坏页面结构；流量劫持（将链接指向某网站）； 攻击类型 XSS 可以分为存储型、反射型和 DOM 型 存储型指的是恶意脚本会存储在目标服务器上，当浏览器请求数据时，脚本从服务器传回并执行。 反射型指的是攻击者诱导用户访问一个带有恶意代码的 URL 后，服务器端接收数据后处理，然后把带有恶意代码的数据发送到浏览器端，浏览器端解析这段带有 XSS 代码的数据后当做脚本执行，最终完成XSS 攻击。 DOM 型指的通过修改页面的 DOM 节点形成的 XSS。 三者的区别在于： DOM 型 XSS 攻击中，取出和执⾏恶意代码由浏览器端完成，属于前端JavaScript 自身的安全漏洞， 而其他两种 XSS 都属于服务端的安全漏洞。 面试题：如何防御 XSS 攻击？三种方式都可以： 在服务器端对用户输入的内容进行转义，例如使用HTML实体替换敏感字符，避免浏览器将其当作HTML代码解析执行。 在输出时对用户输入的内容进行过滤和转义，避免用户输入的恶意脚本被执行。 在网站中使用 HTTP头中的Content-Security-Policy（CSP）字段 CSP ，限制可以加载的资源，例如脚本、样式表、图片等。 通常有两种方式来开启 CSP， 一种是设置 HTTP 首部中的Content-Security-Policy， 一种是设置 meta 标签的方式 &lt;metahttp-equiv=&quot;Content-Security-Policy&quot;&gt;，对一些敏感信息进行保护，比如 cookie 使用 http-only，使得脚本无法获取。也可以使用验证码，避免脚本伪装成用户执行一些操作。 存储型XSS 存储型XSS是攻击者将恶意代码存储到服务器上，当用户访问包含恶意代码的页面时，恶意代码会被执行。攻击者通常会在论坛、留言板、博客等需要存储用户输入的地方进行攻击。 反射型XSS 反射型XSS是攻击者将恶意代码注入到URL中，当用户访问包含恶意代码的URL时，恶意代码会被执行。防御通常，攻击者会通过诱骗用户点击恶意链接、在搜索引擎中搜索恶意关键字等方式进行攻击。 在服务器端对URL进行过滤和验证，例如限制输入长度、过滤特殊字符等。 DOM型XSS ​ DOM型XSS是攻击者将恶意代码注入到网页的DOM节点中，当用户浏览网页时，恶意代码会被执行。防御 DOM型XSS的方法有： 避免使用eval()函数、innerHTML属性、document.write()等容易受到攻击的API。如果必须使用这些API，可以使用一些安全的编码方式来防止注入攻击，例如使用JSON.stringify()函数对变量进行编码，使用正则表达式进行过滤等。 面试题：什么是 CSRF 攻击？CSRF 攻击指的是跨站请求伪造攻击，攻击者诱导用户进入一个第三方网站，然后该网站向被攻击网站发送跨站请求。如果用户在被攻击网站中保存了登录状态，那么攻击者就可以利用这个登录状态，绕过后台的用户验证，冒充用户向服务器执行一些操作。 CSRF 攻击的本质是利用 cookie 会在同源请求中携带发送给服务器的特点，以此来实现用户的冒充。 常见的 CSRF 攻击有三种： GET 类型的 CSRF 攻击：比如在网站中的一个 img 标签里构建一个请求，当用户打开这个网站的时候就会自动发起提交。 POST 类型的 CSRF 攻击：比如构建一个表单，然后隐藏它，当用户进入页面时，自动提交这个表单。 链接类型的 CSRF 攻击：比如在 a 标签的 href 属性里构建一个请求，然后诱导用户去点击。 面试题：怎么预防 CSRF 的三种攻击1.进行同源检测服务器根据 http 请求头中 origin 或者 referer 信息 来判断请求是否为允许访问的站点，从而对请求进行过滤。 当origin 或者 referer 信息都不存在的时候，直接阻止请求。 这种方式的缺点是有些情况下 referer 可以被伪造，同时还会把搜索引擎的链接也给屏蔽了。 所以一般网站会允许搜索引擎的页面请求，但是相应的页面请求这种请求方式也可能被攻击者给利用。（Referer 字段会告诉服务器该网页是从哪个页面链接过来的） 2.使用 CSRF Token 进行验证，服务器向用户返回一个随机数 Token ， 当网站再次发起请求时，在请求参数中加入服务器端返回的 token ， 然后服务器对这个 token 进行验证。 这种方法解决了使用 cookie单一验证方式时，可能会被冒用的问题。 但是这种方法存在一个缺点就是，我们需要给网站中的所有请求都添加上这个 token，操作比较繁琐。 还有一个问题是一般不会只有一台网站服务器，如果请求经过负载平衡转移到了其他的服务器，但是这个服务器的 session 中没有保留这个 token 的话，就没有办法验证了。 这种情况可以通过改变 token 的构建方式来解决。 3. 对 Cookie 进行双重验证服务器在用户访问网站页面时，向请求域名注入一个 Cookie，内容为随机字符串， 然后当用户再次向服务器发送请求的时候，从 cookie 中取出这个字符串，添加到 URL 参数中， 然后服务器通过对 cookie 中的数据和参数中的数据进行比较，来进行验证。 使用这种方式是利用了攻击者只能利用 cookie，但是不能访问获取 cookie 的特点。 并且这种方法比 CSRF Token 的方法更加方便，并且不涉及到分布式访问的问题。 这种方法的缺点是如果网站存在 XSS 漏洞的，那么这种方式会失效。同时这种方式不能做到子域名的隔离。 4.在设置 cookie 属性的时候设置 Samesite ，限制 cookie 不能作为被第三方使用，从而可以避免被攻击者利用。 Samesite 一共有两种模式， 一种是严格模式，在严格模式下 cookie 在任何情况下都不可能作为第三方 Cookie 使用， 在宽松模式下，cookie 可以被请求是GET 请求，且会发生页面跳转的请求所使用。","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"前端（JS）代码编程题","slug":"前端（JS）代码编程题","date":"2023-03-20T15:51:03.000Z","updated":"2023-03-20T10:53:04.000Z","comments":true,"path":"2023/03/20/前端（JS）代码编程题/","link":"","permalink":"http://example.com/2023/03/20/%E5%89%8D%E7%AB%AF%EF%BC%88JS%EF%BC%89%E4%BB%A3%E7%A0%81%E7%BC%96%E7%A8%8B%E9%A2%98/","excerpt":"","text":"前端（JS）代码编程题JS 专属APIhttps://cloud.tencent.com/developer/chapter/13597 数值定义正数最小值 和 最大值 123// 表示无穷接近于0 的最小正数Number.MIN_VALUENumber,MAX_VALUE 负无穷大 和 正无穷大 123456// 负无穷大-InfinityNumber.NEGATIVE_INFINITY// 正无穷大InfinityNumber.POSITIVE_INFINITY 数组创建一个二维数组 1var dp = new Array(prices.length).fill(0).map(x =&gt; Array(2).fill(0)) 数组的两个索引值交换的 ES6写法 1[nums[i], nums[j]] = [nums[j], nums[i]]; 对象字符串字符串变字符串数组，再转Number类型 1let lineObj = line.toString().split(&#x27; &#x27;) 12// 使用 map 方法 映射成 Number类型let lineArray = lineStr.map(Number) 将字符串逆序 123sArray = s.split(&quot;&quot;)sReverseArray = sArray.reverse()sReverse = sReverseArray.join(&quot;&quot;) Number类型变字符串 1Number.toString() 单字符和 ASCCII码 在 JS 中 不像java 可以直接 ‘b’ -‘a’ = 1 因为JS不存在 char这个类型，所以我们需要利用 api charCodeAt(index) 来做，例如： 1&#x27;b&#x27;.charCodeAt(0) - &#x27;a&#x27;.charCodeAt(0) 哈希表 （任意类型均可） MapJS中不限制传入键和值的 类型 。 JS 使用的是 Map，与 Java 中的 HashMap 有所区别 12345678910111213141516171819202122// 创建一个哈希表const symbolValues = new Map()// 添加symbolValues.set(&quot;I&quot;, 1)// 读取const value = symbolValues.get(&quot;I&quot;)// 第一次添加 + 遍历值for(num of arr)&#123; //利用Map的数据结构统计次数 if (!map.has(num)) &#123; map.set(num, 1) &#125; else &#123; map.set(num, map.get(num) + 1) &#125;&#125;let values = [...map.values()] console.log(map.entries()) // 类似于 MapIterator &#123;&quot;name&quot; =&gt; &quot;An&quot;, &quot;des&quot; =&gt; &quot;JS&quot;&#125;console.log(map.keys()) // 类似于 MapIterator &#123;&quot;name&quot;, &quot;des&quot;&#125;size：返回字典中所包含的元素个数 Map 转 Array 123const map = new Map([[1, 1], [2, 2], [3, 3]])// ES6 的解构console.log([...map]) // [[1, 1], [2, 2], [3, 3]] Array 转 Map 12const map = new Map([[1, 1], [2, 2], [3, 3]])console.log(map) // Map &#123;1 =&gt; 1, 2 =&gt; 2, 3 =&gt; 3&#125; 将 map 形式 转化为 数组形式，并且按照 原来的 values 123// 首先将字典转成数组，然后对数组中的第二个元素（频度）从大到小排序const list = Array.from(map).sort((a, b) =&gt; b[1] - a[1]) sort 函数 针对数组1234567// 根据绝对值大小 nums.sort((a, b) =&gt; &#123; //从大到小 return Math.abs(b) - Math.abs(a) //从小到大 return Math.abs(a) - Math.abs(b)&#125;) join 函数可以将一个数组（什么类型都可以）按照某种分隔符进行拼接，拼接成字符串 例如我现在有一个 里面是Number类型的 数组 12345678var arr = [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;]// 映射成 Number类型var arrNumber = arr.map(Number)// ”123&quot; arr.join(arr)// 转成 Number类型Number(arr.join(&quot;&quot;))Number(arrNumber.join(&quot;&quot;)) reduce函数可以用于实现累加，代码最精简 123var result = candys.reduce((a, b) =&gt; &#123; return a + b&#125;) splice 函数其可以用于截取，也可用于在指定位置添加 123for(let i = 0; i &lt; people.length; i++) &#123; peopleNew.splice(people[i][1], 0, people[i])&#125; 达到下面的效果： slice 函数 数组和字符串的截取用于 字符串和 数组的截取均可 1234let str = &quot;kaikai&quot;str.slice(0,2) // &quot;ka&quot;const nums = [1,2,3]nums.slice(0,2) // [1,2] at 函数，取最后一个数组元素123let arr=[1,2,3];arr.at(-1) //3// arr[arr.length - 1] 也是可以的 正则表达式的使用字符串根据 &gt;= 1个空格 进行隔开 1let tokens = line.split(/\\s+/); 颜色分类（来自：小米 2022 秋招 卷1）问题描述: 给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排 列。 此题中，我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。 输入描述: 1输入：数组nums 输出描述: 1输出：数组nums 输入样例: （输入字符串） 12 0 2 1 1 0 输出样例: （输出字符串） 1[0,0,1,1,2,2] 答案做法：不适用 Array.sort() 方法的情况下 其实很简单，定义一个指针，就是碰到0，就与这个指针交换一下位置并且更新指针，这样最后所有的0都会再最左边。以此类推再来一次1。 力扣上我记得也是有这道题的，使用 Java 也非常容易实现。 12345678910111213141516171819202122function swap(nums, i, j) &#123; let t = nums[j]; nums[j] = nums[i]; nums[i] = t;&#125;function sortColors(nums) &#123; let ptr = 0; for(let i = 0; i &lt; nums.length; i++) &#123; if (nums[i] === 0) &#123; swap(nums, i, ptr); ptr++; &#125; &#125; for(let i = 0; i &lt; nums.length; i++) &#123; if (nums[i] === 1) &#123; swap(nums, i, ptr); ptr++; &#125; &#125; return nums;&#125; 罗马数字转整数（来自：小米 2022 秋招 卷1）问题描述: 罗马数字包含以下七种字符: I， V， X， L，C，D 和 M, 分别对应数字：1，5， 10， 50，100，500，1000。例如， 罗马数字 2 写做 II ，即 为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。 通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于 大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况： I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。 输入描述: 1XXVII 输出描述: 127 问题解决 这道题看起来好像要判断子问题，其实对于整体结果而言就是，特殊情况剪掉，其他正常加就ok。 一次循环即可，不过要判断当前位 和 下一位的大小，如果是小的在左边，那说明是总数要减去当前值的，否则就是加上当前值。 123456789101112131415161718192021var romanToInt = function(str) &#123; const symbolValues = new Map() symbolValues.set(&#x27;I&#x27;, 1) symbolValues.set(&#x27;V&#x27;, 5) symbolValues.set(&#x27;X&#x27;, 10) symbolValues.set(&#x27;L&#x27;, 50) symbolValues.set(&#x27;C&#x27;, 100) symbolValues.set(&#x27;D&#x27;, 500) symbolValues.set(&#x27;M&#x27;, 1000) let result = 0 let length = str.length for (let i = 0; i &lt; length; i++) &#123; const value = symbolValues.get(str[i]); if (i &lt; length - 1 &amp;&amp; value &lt; symbolValues.get(str[i + 1])) &#123; result -= value &#125; else &#123; result += value &#125; &#125; return result;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"","slug":"NodeJS笔记","date":"2023-03-20T10:12:35.928Z","updated":"2023-03-05T13:03:22.000Z","comments":true,"path":"2023/03/20/NodeJS笔记/","link":"","permalink":"http://example.com/2023/03/20/NodeJS%E7%AC%94%E8%AE%B0/","excerpt":"","text":"[toc] Node.js （最全）基础+全栈项目​ 作者：kerwin ​ 版本：QF1.0 ​ 版权：千锋HTML5大前端教研院 ​ 公众号: 大前端私房菜 一、Node.js基础1. 认识Node.js Node.js是一个javascript运行环境。它让javascript可以开发后端程序，实现几乎其他后端语言实现的所有功能，可以与PHP、Java、Python、.NET、Ruby等后端语言平起平坐。 Nodejs是基于V8引擎，V8是Google发布的开源JavaScript引擎，本身就是用于Chrome浏览器的js解释部分，但是Ryan Dahl 这哥们，鬼才般的，把这个V8搬到了服务器上，用于做服务器的软件。 01 nodejs的特性 Nodejs语法完全是js语法，只要你懂js基础就可以学会Nodejs后端开发 NodeJs超强的高并发能力,实现高性能服务器 开发周期短、开发成本低、学习成本低 02 使用 Node.js 需要了解多少 JavaScript http://nodejs.cn/learn/how-much-javascript-do-you-need-to-know-to-use-nodejs 03 浏览器环境vs node环境 Node.js 可以解析JS代码（没有浏览器安全级别的限制）提供很多系统级别的API，如： 文件的读写 (File System) 12345const fs = require(&#x27;fs&#x27;)fs.readFile(&#x27;./ajax.png&#x27;, &#x27;utf-8&#x27;, (err, content) =&gt; &#123; console.log(content)&#125;) 进程的管理 (Process) 123456function main(argv) &#123; console.log(argv)&#125;main(process.argv.slice(2)) 网络通信 (HTTP/HTTPS) 12345678910const http = require(&quot;http&quot;)http.createServer((req,res) =&gt; &#123; res.writeHead(200, &#123; &quot;content-type&quot;: &quot;text/plain&quot; &#125;) res.write(&quot;hello nodejs&quot;) res.end()&#125;).listen(3000) 2. 开发环境搭建 http://nodejs.cn/download/ 3. 模块、包、commonJS​ 02 CommonJS规范 03 modules模块化规范写法我们可以把公共的功能 抽离成为一个单独的 js 文件 作为一个模块，默认情况下面这个模块里面的方法或者属性，外面是没法访问的。如果要让外部可以访问模块里面的方法或者属性，就必须在模块里面通过 exports 或者 module.exports 暴露属性或者方法。 m1.js： 1234567891011121314151617181920const name = &#x27;gp19&#x27;const sayName = () =&gt; &#123; console.log(name)&#125;console.log(&#x27;module 1&#x27;)// 接口暴露方法一：module.exports = &#123; say: sayName&#125;// 接口暴露方法二：exports.say = sayName// 错误！exports = &#123; say: sayName&#125; main.js： 12const m1 = require(&#x27;./m1&#x27;)m1.say() 4. Npm&amp;Yarn01 npm的使用123456789101112131415npm initnpm install 包名 –g （uninstall,update）npm install 包名 --save-dev (uninstall,update)npm list -g (不加-g，列举当前目录下的安装包)npm info 包名（详细信息） npm info 包名 version(获取最新版本)npm install md5@1（安装指定版本）npm outdated( 检查包是否已经过时) &quot;dependencies&quot;: &#123; &quot;md5&quot;: &quot;^2.1.0&quot; &#125; ^ 表示 如果 直接npm install 将会 安md5 2.*.* 最新版本 &quot;dependencies&quot;: &#123; &quot;md5&quot;: &quot;~2.1.0&quot; &#125; ~ 表示 如果 直接npm install 将会 安装md5 2.1.* 最新版本 &quot;dependencies&quot;: &#123; &quot;md5&quot;: &quot;*&quot; &#125; * 表示 如果 直接npm install 将会 安装 md5 最新版本 02 全局安装 nrm NRM (npm registry manager)是npm的镜像源管理工具，有时候国外资源太慢，使用这个就可以快速地在 npm 源间切换。 手动切换方法： npm config set registry https://registry.npm.taobao.org 安装 nrm 在命令行执行命令，npm install -g nrm，全局安装nrm。 使用 nrm 执行命令 nrm ls 查看可选的源。 其中，带*的是当前使用的源，上面的输出表明当前源是官方源。 切换 nrm 如果要切换到taobao源，执行命令nrm use taobao。 测试速度 你还可以通过 nrm test 测试相应源的响应时间。 1nrm test 扩展： 1npm install -g cnpm --registry=https://registry.npmmirror.com 03 yarn使用1npm install -g yarn 1234567891011121314151617对比npm: 速度超快: Yarn 缓存了每个下载过的包，所以再次使用时无需重复下载。 同时利用并行下载以最大化资源利用率，因此安装速度更快。 超级安全: 在执行代码之前，Yarn 会通过算法校验每个安装包的完整性。开始新项目 yarn init 添加依赖包 yarn add [package] yarn add [package]@[version] yarn add [package] --dev 升级依赖包 yarn upgrade [package]@[version] 移除依赖包 yarn remove [package] 安装项目的全部依赖 yarn install 5. 内置模块01 http模块 要使用 HTTP 服务器和客户端，则必须 require(&#39;http&#39;)。 123456789101112const http = require(&#x27;http&#x27;);// 创建本地服务器来从其接收数据const server = http.createServer((req, res) =&gt; &#123; res.writeHead(200, &#123; &#x27;Content-Type&#x27;: &#x27;application/json&#x27; &#125;); res.end(JSON.stringify(&#123; data: &#x27;Hello World!&#x27; &#125;));&#125;);server.listen(8000); 1234567891011121314const http = require(&#x27;http&#x27;);// 创建本地服务器来从其接收数据const server = http.createServer();// 监听请求事件server.on(&#x27;request&#x27;, (request, res) =&gt; &#123; res.writeHead(200, &#123; &#x27;Content-Type&#x27;: &#x27;application/json&#x27; &#125;); res.end(JSON.stringify(&#123; data: &#x27;Hello World!&#x27; &#125;));&#125;);server.listen(8000); 02 url模块02.1 parse 1234const url = require(&#x27;url&#x27;)const urlString = &#x27;https://www.baidu.com:443/ad/index.html?id=8&amp;name=mouse#tag=110&#x27;const parsedStr = url.parse(urlString)console.log(parsedStr) 02.2 format 1234567891011121314151617const url = require(&#x27;url&#x27;)const urlObject = &#123; protocol: &#x27;https:&#x27;, slashes: true, auth: null, host: &#x27;www.baidu.com:443&#x27;, port: &#x27;443&#x27;, hostname: &#x27;www.baidu.com&#x27;, hash: &#x27;#tag=110&#x27;, search: &#x27;?id=8&amp;name=mouse&#x27;, query: &#123; id: &#x27;8&#x27;, name: &#x27;mouse&#x27; &#125;, pathname: &#x27;/ad/index.html&#x27;, path: &#x27;/ad/index.html?id=8&amp;name=mouse&#x27;&#125;const parsedObj = url.format(urlObject)console.log(parsedObj) 02.3 resolve 12345const url = require(&#x27;url&#x27;)var a = url.resolve(&#x27;/one/two/three&#x27;, &#x27;four&#x27;) ( 注意最后加/ ，不加/的区别 )var b = url.resolve(&#x27;http://example.com/&#x27;, &#x27;/one&#x27;)var c = url.resolve(&#x27;http://example.com/one&#x27;, &#x27;/two&#x27;)console.log(a + &quot;,&quot; + b + &quot;,&quot; + c) 03 querystring模块03.1 parse 12345const querystring = require(&#x27;querystring&#x27;)var qs = &#x27;x=3&amp;y=4&#x27;var parsed = querystring.parse(qs)console.log(parsed) 03.2 stringify 12345678const querystring = require(&#x27;querystring&#x27;)var qo = &#123; x: 3, y: 4&#125;var parsed = querystring.stringify(qo)console.log(parsed) 03.3 escape/unescape 12345const querystring = require(&#x27;querystring&#x27;)var str = &#x27;id=3&amp;city=北京&amp;url=https://www.baidu.com&#x27;var escaped = querystring.escape(str)console.log(escaped) 1234const querystring = require(&#x27;querystring&#x27;)var str = &#x27;id%3D3%26city%3D%E5%8C%97%E4%BA%AC%26url%3Dhttps%3A%2F%2Fwww.baidu.com&#x27;var unescaped = querystring.unescape(str)console.log(unescaped) 04 http模块补充04.1 接口：jsonp 12345678910111213141516171819const http = require(&#x27;http&#x27;)const url = require(&#x27;url&#x27;)const app = http.createServer((req, res) =&gt; &#123; let urlObj = url.parse(req.url, true) switch (urlObj.pathname) &#123; case &#x27;/api/user&#x27;: res.end(`$&#123;urlObj.query.cb&#125;(&#123;&quot;name&quot;: &quot;gp145&quot;&#125;)`) break default: res.end(&#x27;404.&#x27;) break &#125;&#125;)app.listen(8080, () =&gt; &#123; console.log(&#x27;localhost:8080&#x27;)&#125;) 04.2 跨域：CORS 1234567891011121314151617181920212223242526272829303132333435363738const http = require(&#x27;http&#x27;)const url = require(&#x27;url&#x27;)const querystring = require(&#x27;querystring&#x27;)const app = http.createServer((req, res) =&gt; &#123; let data = &#x27;&#x27; let urlObj = url.parse(req.url, true) res.writeHead(200, &#123; &#x27;content-type&#x27;: &#x27;application/json;charset=utf-8&#x27;, &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27; &#125;) req.on(&#x27;data&#x27;, (chunk) =&gt; &#123; data += chunk &#125;) req.on(&#x27;end&#x27;, () =&gt; &#123; responseResult(querystring.parse(data)) &#125;) function responseResult(data) &#123; switch (urlObj.pathname) &#123; case &#x27;/api/login&#x27;: res.end(JSON.stringify(&#123; message: data &#125;)) break default: res.end(&#x27;404.&#x27;) break &#125; &#125;&#125;)app.listen(8080, () =&gt; &#123; console.log(&#x27;localhost:8080&#x27;)&#125;) 04.3 模拟get 123456789101112131415161718192021222324252627282930313233var http = require(&#x27;http&#x27;)var https = require(&#x27;https&#x27;)// 1、接口 2、跨域const server = http.createServer((request, response) =&gt; &#123; var url = request.url.substr(1) var data = &#x27;&#x27; response.writeHeader(200, &#123; &#x27;content-type&#x27;: &#x27;application/json;charset=utf-8&#x27;, &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27; &#125;) https.get(`https://m.lagou.com/listmore.json$&#123;url&#125;`, (res) =&gt; &#123; res.on(&#x27;data&#x27;, (chunk) =&gt; &#123; data += chunk &#125;) res.on(&#x27;end&#x27;, () =&gt; &#123; response.end(JSON.stringify(&#123; ret: true, data &#125;)) &#125;) &#125;)&#125;)server.listen(8080, () =&gt; &#123; console.log(&#x27;localhost:8080&#x27;)&#125;) 04.4 模拟post：服务器提交（攻击） 123456789101112131415161718192021222324252627282930313233343536373839404142434445const https = require(&#x27;https&#x27;)const querystring = require(&#x27;querystring&#x27;)const postData = querystring.stringify(&#123; province: &#x27;上海&#x27;, city: &#x27;上海&#x27;, district: &#x27;宝山区&#x27;, address: &#x27;同济支路199号智慧七立方3号楼2-4层&#x27;, latitude: 43.0, longitude: 160.0, message: &#x27;求购一条小鱼&#x27;, contact: &#x27;13666666&#x27;, type: &#x27;sell&#x27;, time: 1571217561&#125;)const options = &#123; protocol: &#x27;https:&#x27;, hostname: &#x27;ik9hkddr.qcloud.la&#x27;, method: &#x27;POST&#x27;, port: 443, path: &#x27;/index.php/trade/add_item&#x27;, headers: &#123; &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;, &#x27;Content-Length&#x27;: Buffer.byteLength(postData) &#125;&#125;function doPost() &#123; let data let req = https.request(options, (res) =&gt; &#123; res.on(&#x27;data&#x27;, chunk =&gt; data += chunk) res.on(&#x27;end&#x27;, () =&gt; &#123; console.log(data) &#125;) &#125;) req.write(postData) req.end()&#125;// setInterval(() =&gt; &#123;// doPost()// &#125;, 1000) 04.5 爬虫 12345678910111213141516171819202122232425262728293031323334353637383940414243444546const https = require(&#x27;https&#x27;)const http = require(&#x27;http&#x27;)const cheerio = require(&#x27;cheerio&#x27;)http.createServer((request, response) =&gt; &#123; response.writeHead(200, &#123; &#x27;content-type&#x27;: &#x27;application/json;charset=utf-8&#x27; &#125;) const options = &#123; // protocol: &#x27;https:&#x27;, hostname: &#x27;i.maoyan.com&#x27;, port: 443, path: &#x27;/&#x27;, method: &#x27;GET&#x27; &#125; const req = https.request(options, (res) =&gt; &#123; let data = &#x27;&#x27; res.on(&#x27;data&#x27;, (chunk) =&gt; &#123; data += chunk &#125;) res.on(&#x27;end&#x27;, () =&gt; &#123; filterData(data) &#125;) &#125;) function filterData(data) &#123; // console.log(data) let $ = cheerio.load(data) let $movieList = $(&#x27;.column.content&#x27;) console.log($movieList) let movies = [] $movieList.each((index, value) =&gt; &#123; movies.push(&#123; title: $(value).find(&#x27;.movie-title .title&#x27;).text(), detail: $(value).find(&#x27;.detail .actor&#x27;).text(), &#125;) &#125;) response.end(JSON.stringify(movies)) &#125; req.end()&#125;).listen(3000) 05 event模块123456789101112const EventEmitter = require(&#x27;events&#x27;)class MyEventEmitter extends EventEmitter &#123;&#125;const event = new MyEventEmitter()event.on(&#x27;play&#x27;, (movie) =&gt; &#123; console.log(movie)&#125;)event.emit(&#x27;play&#x27;, &#x27;我和我的祖国&#x27;)event.emit(&#x27;play&#x27;, &#x27;中国机长&#x27;) 06 fs文件操作模块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485const fs = require(&#x27;fs&#x27;)// 创建文件夹fs.mkdir(&#x27;./logs&#x27;, (err) =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 文件夹改名fs.rename(&#x27;./logs&#x27;, &#x27;./log&#x27;, () =&gt; &#123; console.log(&#x27;done&#x27;)&#125;)// 删除文件夹fs.rmdir(&#x27;./log&#x27;, () =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 写内容到文件里fs.writeFile( &#x27;./logs/log1.txt&#x27;, &#x27;hello&#x27;, // 错误优先的回调函数 (err) =&gt; &#123; if (err) &#123; console.log(err.message) &#125; else &#123; console.log(&#x27;文件创建成功&#x27;) &#125; &#125;)// 给文件追加内容fs.appendFile(&#x27;./logs/log1.txt&#x27;, &#x27;\\nworld&#x27;, () =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 读取文件内容fs.readFile(&#x27;./logs/log1.txt&#x27;, &#x27;utf-8&#x27;, (err, data) =&gt; &#123; console.log(data)&#125;)// 删除文件fs.unlink(&#x27;./logs/log1.txt&#x27;, (err) =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 批量写文件for (var i = 0; i &lt; 10; i++) &#123; fs.writeFile(`./logs/log-$&#123;i&#125;.txt`, `log-$&#123;i&#125;`, (err) =&gt; &#123; console.log(&#x27;done.&#x27;) &#125;)&#125;// 读取文件/目录信息fs.readdir(&#x27;./&#x27;, (err, data) =&gt; &#123; data.forEach((value, index) =&gt; &#123; fs.stat(`./$&#123;value&#125;`, (err, stats) =&gt; &#123; // console.log(value + &#x27;:&#x27; + stats.size) console.log(value + &#x27; is &#x27; + (stats.isDirectory() ? &#x27;directory&#x27; : &#x27;file&#x27;)) &#125;) &#125;)&#125;)// 同步读取文件try &#123; const content = fs.readFileSync(&#x27;./logs/log-1.txt&#x27;, &#x27;utf-8&#x27;) console.log(content) console.log(0)&#125; catch (e) &#123; console.log(e.message)&#125;// 异步读取文件：方法一fs.readFile(&#x27;./logs/log-0.txt&#x27;, &#x27;utf-8&#x27;, (err, content) =&gt; &#123; console.log(content) console.log(0)&#125;)console.log(1)// 异步读取文件：方法二const fs = require(&quot;fs&quot;).promisesfs.readFile(&#x27;./logs/log-0.txt&#x27;, &#x27;utf-8&#x27;).then(result =&gt; &#123; console.log(result)&#125;) 在fs模块中，提供同步方法是为了方便使用。那我们到底是应该用异步方法还是同步方法呢？ 由于Node环境执行的JavaScript代码是服务器端代码，所以，绝大部分需要在服务器运行期反复执行业务逻辑的代码，必须使用异步代码，否则，同步代码在执行时期，服务器将停止响应，因为JavaScript只有一个执行线程。 服务器启动时如果需要读取配置文件，或者结束时需要写入到状态文件时，可以使用同步代码，因为这些代码只在启动和结束时执行一次，不影响服务器正常运行时的异步执行。 07 stream流模块stream是Node.js提供的又一个仅在服务区端可用的模块，目的是支持“流”这种数据结构。 什么是流？流是一种抽象的数据结构。想象水流，当在水管中流动时，就可以从某个地方（例如自来水厂）源源不断地到达另一个地方（比如你家的洗手池）。我们也可以把数据看成是数据流，比如你敲键盘的时候，就可以把每个字符依次连起来，看成字符流。这个流是从键盘输入到应用程序，实际上它还对应着一个名字：标准输入流（stdin）。 如果应用程序把字符一个一个输出到显示器上，这也可以看成是一个流，这个流也有名字：标准输出流（stdout）。流的特点是数据是有序的，而且必须依次读取，或者依次写入，不能像Array那样随机定位。 有些流用来读取数据，比如从文件读取数据时，可以打开一个文件流，然后从文件流中不断地读取数据。有些流用来写入数据，比如向文件写入数据时，只需要把数据不断地往文件流中写进去就可以了。 在Node.js中，流也是一个对象，我们只需要响应流的事件就可以了：data事件表示流的数据已经可以读取了，end事件表示这个流已经到末尾了，没有数据可以读取了，error事件表示出错了。 123456789101112131415161718var fs = require(&#x27;fs&#x27;);// 打开一个流:var rs = fs.createReadStream(&#x27;sample.txt&#x27;, &#x27;utf-8&#x27;);rs.on(&#x27;data&#x27;, function (chunk) &#123; console.log(&#x27;DATA:&#x27;) console.log(chunk);&#125;);rs.on(&#x27;end&#x27;, function () &#123; console.log(&#x27;END&#x27;);&#125;);rs.on(&#x27;error&#x27;, function (err) &#123; console.log(&#x27;ERROR: &#x27; + err);&#125;); 要注意，data事件可能会有多次，每次传递的chunk是流的一部分数据。 要以流的形式写入文件，只需要不断调用write()方法，最后以end()结束： 1234567var fs = require(&#x27;fs&#x27;);var ws1 = fs.createWriteStream(&#x27;output1.txt&#x27;, &#x27;utf-8&#x27;);ws1.write(&#x27;使用Stream写入文本数据...\\n&#x27;);ws1.write(&#x27;END.&#x27;);ws1.end(); pipe 就像可以把两个水管串成一个更长的水管一样，两个流也可以串起来。一个Readable流和一个Writable流串起来后，所有的数据自动从Readable流进入Writable流，这种操作叫pipe。 在Node.js中，Readable流有一个pipe()方法，就是用来干这件事的。 让我们用pipe()把一个文件流和另一个文件流串起来，这样源文件的所有数据就自动写入到目标文件里了，所以，这实际上是一个复制文件的程序： 123456const fs = require(&#x27;fs&#x27;)const readstream = fs.createReadStream(&#x27;./1.txt&#x27;)const writestream = fs.createWriteStream(&#x27;./2.txt&#x27;)readstream.pipe(writestream) 08 zlib 123456789101112const fs = require(&#x27;fs&#x27;)const zlib = require(&#x27;zlib&#x27;)const gzip = zlib.createGzip()const readstream = fs.createReadStream(&#x27;./note.txt&#x27;)const writestream = fs.createWriteStream(&#x27;./note2.txt&#x27;)readstream .pipe(gzip) .pipe(writestream) 09 cryptocrypto模块的目的是为了提供通用的加密和哈希算法。用纯JavaScript代码实现这些功能不是不可能，但速度会非常慢。Nodejs用C/C++实现这些算法后，通过cypto这个模块暴露为JavaScript接口，这样用起来方便，运行速度也快。 MD5是一种常用的哈希算法，用于给任意数据一个“签名”。这个签名通常用一个十六进制的字符串表示： 12345678910const crypto = require(&#x27;crypto&#x27;);const hash = crypto.createHash(&#x27;md5&#x27;);// 可任意多次调用update():hash.update(&#x27;Hello, world!&#x27;);hash.update(&#x27;Hello, nodejs!&#x27;);console.log(hash.digest(&#x27;hex&#x27;)); update()方法默认字符串编码为UTF-8，也可以传入Buffer。 如果要计算SHA1，只需要把&#39;md5&#39;改成&#39;sha1&#39;，就可以得到SHA1的结果1f32b9c9932c02227819a4151feed43e131aca40。 Hmac算法也是一种哈希算法，它可以利用MD5或SHA1等哈希算法。不同的是，Hmac还需要一个密钥： 123456789const crypto = require(&#x27;crypto&#x27;);const hmac = crypto.createHmac(&#x27;sha256&#x27;, &#x27;secret-key&#x27;);hmac.update(&#x27;Hello, world!&#x27;);hmac.update(&#x27;Hello, nodejs!&#x27;);console.log(hmac.digest(&#x27;hex&#x27;)); // 80f7e22570... 只要密钥发生了变化，那么同样的输入数据也会得到不同的签名，因此，可以把Hmac理解为用随机数“增强”的哈希算法。 AES是一种常用的对称加密算法，加解密都用同一个密钥。crypto模块提供了AES支持，但是需要自己封装好函数，便于使用： 123456789101112131415const crypto = require(&quot;crypto&quot;);function encrypt (key, iv, data) &#123; let decipher = crypto.createCipheriv(&#x27;aes-128-cbc&#x27;, key, iv); // decipher.setAutoPadding(true); return decipher.update(data, &#x27;binary&#x27;, &#x27;hex&#x27;) + decipher.final(&#x27;hex&#x27;);&#125;function decrypt (key, iv, crypted) &#123; crypted = Buffer.from(crypted, &#x27;hex&#x27;).toString(&#x27;binary&#x27;); let decipher = crypto.createDecipheriv(&#x27;aes-128-cbc&#x27;, key, iv); return decipher.update(crypted, &#x27;binary&#x27;, &#x27;utf8&#x27;) + decipher.final(&#x27;utf8&#x27;);&#125;key,iv必须是16个字节 可以看出，加密后的字符串通过解密又得到了原始内容。 6. 路由01 基础1234567891011121314151617181920212223242526272829/* * @作者: kerwin * @公众号: 大前端私房菜 */var fs = require(&quot;fs&quot;)var path = require(&quot;path&quot;)function render(res, path) &#123; res.writeHead(200, &#123; &quot;Content-Type&quot;: &quot;text/html;charset=utf8&quot; &#125;) res.write(fs.readFileSync(path, &quot;utf8&quot;)) res.end()&#125;const route = &#123; &quot;/login&quot;: (req, res) =&gt; &#123; render(res, &quot;./static/login.html&quot;) &#125;, &quot;/home&quot;: (req, res) =&gt; &#123; render(res, &quot;./static/home.html&quot;) &#125;, &quot;/404&quot;: (req, res) =&gt; &#123; res.writeHead(404, &#123; &quot;Content-Type&quot;: &quot;text/html;charset=utf8&quot; &#125;) res.write(fs.readFileSync(&quot;./static/404.html&quot;, &quot;utf8&quot;)) &#125;&#125; 02 获取参数get请求 12345&quot;/api/login&quot;:(req,res)=&gt;&#123; const myURL = new URL(req.url, &#x27;http://127.0.0.1:3000&#x27;); console.log(myURL.searchParams.get(&quot;username&quot;)) render(res,`&#123;ok:1&#125;`)&#125; post请求 12345678910111213&quot;/api/login&quot;: (req, res) =&gt; &#123; var post = &#x27;&#x27;; // 通过req的data事件监听函数，每当接受到请求体的数据，就累加到post变量中 req.on(&#x27;data&#x27;, function (chunk) &#123; post += chunk; &#125;); // 在end事件触发后，通过querystring.parse将post解析为真正的POST请求格式，然后向客户端返回。 req.on(&#x27;end&#x27;, function () &#123; post = JSON.parse(post); render(res, `&#123;ok:1&#125;`) &#125;); &#125; 03 静态资源处理1234567891011121314function readStaticFile(req, res) &#123; const myURL = new URL(req.url, &#x27;http://127.0.0.1:3000&#x27;) var filePathname = path.join(__dirname, &quot;/static&quot;, myURL.pathname); if (fs.existsSync(filePathname)) &#123; // console.log(1111) res.writeHead(200, &#123; &quot;Content-Type&quot;: `$&#123;mime.getType(myURL.pathname.split(&quot;.&quot;)[1])&#125;;charset=utf8` &#125;) res.write(fs.readFileSync(filePathname, &quot;utf8&quot;)) res.end() return true &#125; else &#123; return false &#125;&#125; 二、Express https://www.expressjs.com.cn/ 基于 Node.js 平台，快速、开放、极简的 web 开发框架。 1.特色 2.安装1$ npm install express --save 3.路由路由是指如何定义应用的端点（URIs）以及如何响应客户端的请求。 路由是由一个 URI、HTTP 请求（GET、POST等）和若干个句柄组成，它的结构如下： app.METHOD(path, [callback…], callback)， app 是 express 对象的一个实例， METHOD 是一个 HTTP 请求方法， path 是服务器上的路径， callback 是当路由匹配时要执行的函数。 下面是一个基本的路由示例： 1234567var express = require(&#x27;express&#x27;);var app = express();// respond with &quot;hello world&quot; when a GET request is made to the homepageapp.get(&#x27;/&#x27;, function(req, res) &#123; res.send(&#x27;hello world&#x27;);&#125;); 路由路径和请求方法一起定义了请求的端点，它可以是字符串、字符串模式或者正则表达式。 1234567891011121314// 匹配根路径的请求app.get(&#x27;/&#x27;, function (req, res) &#123; res.send(&#x27;root&#x27;);&#125;);// 匹配 /about 路径的请求app.get(&#x27;/about&#x27;, function (req, res) &#123; res.send(&#x27;about&#x27;);&#125;);// 匹配 /random.text 路径的请求app.get(&#x27;/random.text&#x27;, function (req, res) &#123; res.send(&#x27;random.text&#x27;);&#125;); 使用字符串模式的路由路径 （注意这个 不是 正则表达式）示例： 123456789101112131415161718192021222324// 匹配 acd 和 abcdapp.get(&#x27;/ab?cd&#x27;, function(req, res) &#123; res.send(&#x27;ab?cd&#x27;);&#125;);// 匹配 /ab/******app.get(&#x27;/ab/:id&#x27;, function(req, res) &#123; res.send(&#x27;aaaaaaa&#x27;);&#125;);// 匹配 abcd、abbcd、abbbcd等app.get(&#x27;/ab+cd&#x27;, function(req, res) &#123; res.send(&#x27;ab+cd&#x27;);&#125;);// 匹配 abcd、abxcd、abRABDOMcd、ab123cd等app.get(&#x27;/ab*cd&#x27;, function(req, res) &#123; res.send(&#x27;ab*cd&#x27;);&#125;);// 匹配 /abe 和 /abcdeapp.get(&#x27;/ab(cd)?e&#x27;, function(req, res) &#123; res.send(&#x27;ab(cd)?e&#x27;);&#125;); 使用正则表达式的路由路径示例： 123456789// 匹配任何路径中含有 a 的路径：app.get(/a/, function(req, res) &#123; res.send(&#x27;/a/&#x27;);&#125;);// 匹配 butterfly、dragonfly，不匹配 butterflyman、dragonfly man等app.get(/.*fly$/, function(req, res) &#123; res.send(&#x27;/.*fly$/&#x27;);&#125;); 可以为请求处理提供多个回调函数，其行为类似 中间件。唯一的区别是这些回调函数有可能调用 next(‘route’) 方法而略过其他路由回调函数。可以利用该机制为路由定义前提条件，如果在现有路径上继续执行没有意义，则可将控制权交给剩下的路径。 123app.get(&#x27;/example/a&#x27;, function (req, res) &#123; res.send(&#x27;Hello from A!&#x27;);&#125;); 使用多个回调函数处理路由（记得指定 next 对象）： 123456app.get(&#x27;/example/b&#x27;, function (req, res, next) &#123; console.log(&#x27;response will be sent by the next function ...&#x27;); next();&#125;, function (req, res) &#123; res.send(&#x27;Hello from B!&#x27;);&#125;); 使用回调函数数组处理路由： 12345678910111213141516var cb0 = function (req, res, next) &#123; console.log(&#x27;CB0&#x27;) next()&#125;var cb1 = function (req, res, next) &#123; console.log(&#x27;CB1&#x27;) next()&#125;var cb2 = function (req, res) &#123; res.send(&#x27;Hello from C!&#x27;)&#125;// 用数组形式 更加的优雅app.get(&#x27;/example/c&#x27;, [cb0, cb1, cb2]) 混合使用函数和函数数组处理路由： 12345678910111213141516var cb0 = function (req, res, next) &#123; console.log(&#x27;CB0&#x27;) next()&#125;var cb1 = function (req, res, next) &#123; console.log(&#x27;CB1&#x27;) next()&#125;app.get(&#x27;/example/d&#x27;, [cb0, cb1], function (req, res, next) &#123; console.log(&#x27;response will be sent by the next function ...&#x27;) next()&#125;, function (req, res) &#123; res.send(&#x27;Hello from D!&#x27;)&#125;) 4.中间件Express 是一个自身功能极简，完全是由路由和中间件构成一个的 web 开发框架：从本质上来说，一个 Express 应用就是在调用各种中间件。 中间件（Middleware） 是一个函数，它可以访问请求对象（request object (req)）, 响应对象（response object (res)）, 和 web 应用中处于请求-响应循环流程中的中间件，一般被命名为 next 的变量。 中间件的功能包括： 执行任何代码。 修改请求和响应对象。 终结请求-响应循环。 调用堆栈中的下一个中间件。 如果当前中间件没有终结请求-响应循环，则必须调用 next() 方法将控制权交给下一个中间件，否则请求就会挂起。 Express 应用可使用如下几种中间件： 应用级中间件 路由级中间件 错误处理中间件 内置中间件 第三方中间件 使用可选则挂载路径，可在应用级别或路由级别装载中间件。另外，你还可以同时装在一系列中间件函数，从而在一个挂载点上创建一个子中间件栈。 （1）应用级中间件应用级中间件绑定到 app 对象 使用 app.use() 和 app.METHOD()， 其中， METHOD 是需要处理的 HTTP 请求的方法，例如 GET, PUT, POST 等等，全部小写。例如： **不过他要注意 app.use 挂载的顺序，你不能一进来就 验证token吧，肯定要调用login 或者其他请求的时候，才开始 app.use挂载。** 12345678var app = express()// 没有挂载路径的中间件，应用的每个请求都会执行该中间件app.use(function (req, res, next) &#123; console.log(&#x27;Time:&#x27;, Date.now()) next()&#125;) （2）路由级中间件路由级中间件和应用级中间件一样，只是它绑定的对象为 express.Router()。 这个就是对需要挂载的路由，进行一定的拦截与验证。 1var router = express.Router() 12345678910111213141516171819202122232425262728293031323334353637var app = express()var router = express.Router()// 没有挂载路径的中间件，通过该路由的每个请求都会执行该中间件router.use(function (req, res, next) &#123; console.log(&#x27;Time:&#x27;, Date.now()) next()&#125;)// 一个中间件栈，显示任何指向 /user/:id 的 HTTP 请求的信息router.use(&#x27;/user/:id&#x27;, function(req, res, next) &#123; console.log(&#x27;Request URL:&#x27;, req.originalUrl) next()&#125;, function (req, res, next) &#123; console.log(&#x27;Request Type:&#x27;, req.method) next()&#125;)// 一个中间件栈，处理指向 /user/:id 的 GET 请求router.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; // 如果 user id 为 0, 跳到下一个路由 if (req.params.id == 0) next(&#x27;route&#x27;) // 负责将控制权交给栈中下一个中间件 else next() //&#125;, function (req, res, next) &#123; // 渲染常规页面 res.render(&#x27;regular&#x27;)&#125;)// 处理 /user/:id， 渲染一个特殊页面router.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; console.log(req.params.id) res.render(&#x27;special&#x27;)&#125;)// 将路由挂载至应用app.use(&#x27;/&#x27;, router) （3）错误处理中间件错误处理中间件和其他中间件定义类似，只是要使用 4 个参数，而不是 3 个，其签名如下： (err, req, res, next)。 其肯定是放在最后的，理论上算应用级中间件的后置。 1234app.use(function(err, req, res, next) &#123; console.error(err.stack) res.status(500).send(&#x27;Something broke!&#x27;)&#125;) （4）内置的中间件express.static 是 Express 唯一内置的中间件。它基于 serve-static，负责在 Express 应用中提托管静态资源。每个应用可有多个静态目录。 123app.use(express.static(&#x27;public&#x27;))app.use(express.static(&#x27;uploads&#x27;))app.use(express.static(&#x27;files&#x27;)) （5）第三方中间件安装所需功能的 node 模块，并在应用中加载，可以在应用级加载，也可以在路由级加载。 下面的例子安装并加载了一个解析 cookie 的中间件： cookie-parser 1$ npm install cookie-parser 123456var express = require(&#x27;express&#x27;)var app = express()var cookieParser = require(&#x27;cookie-parser&#x27;)// 加载用于解析 cookie 的中间件app.use(cookieParser()) 5. 获取请求参数get 1req.query post 123app.use(express.urlencoded(&#123;extended:false&#125;))app.use(express.json())req.body 6.利用 Express 托管静态文件通过 Express 内置的 express.static 可以方便地托管静态文件，例如图片、CSS、JavaScript 文件等。 将静态资源文件所在的目录作为参数传递给 express.static 中间件就可以提供静态资源文件的访问了。例如，假设在 public 目录放置了图片、CSS 和 JavaScript 文件，你就可以： 1app.use(express.static(&#x27;public&#x27;)) 现在，public 目录下面的文件就可以访问了。 12345http://localhost:3000/images/kitten.jpghttp://localhost:3000/css/style.csshttp://localhost:3000/js/app.jshttp://localhost:3000/images/bg.pnghttp://localhost:3000/hello.html 所有文件的路径都是相对于存放目录的，因此，存放静态文件的目录名不会出现在 URL 中。 如果你的静态资源存放在多个目录下面，你可以多次调用 express.static 中间件： 12app.use(express.static(&#x27;public&#x27;))app.use(express.static(&#x27;files&#x27;)) 访问静态资源文件时，express.static 中间件会根据目录添加的顺序查找所需的文件。 如果你希望所有通过 express.static 访问的文件都存放在一个“虚拟（virtual）”目录（即目录根本不存在）下面，可以通过为静态资源目录指定一个挂载路径的方式来实现，如下所示： 1app.use(&#x27;/static&#x27;, express.static(&#x27;public&#x27;)) 现在，你就可以通过带有 “/static” 前缀的地址来访问 public 目录下面的文件了。 12345http://localhost:3000/static/images/kitten.jpghttp://localhost:3000/static/css/style.csshttp://localhost:3000/static/js/app.jshttp://localhost:3000/static/images/bg.pnghttp://localhost:3000/static/hello.html 7.服务端渲染（模板引擎） 1npm i ejs 需要在应用中进行如下设置才能让 Express 渲染模板文件： views, 放模板文件的目录，比如： app.set(‘views’, ‘./views’) view engine, 模板引擎，比如： app.set(‘view engine’, ‘ejs’) 三、MongoDB1.关系型与非关系型数据库 2.安装数据库https://docs.mongodb.com/manual/administration/install-community/ 3.启动数据库（1）windows12mongod --dbpath d:/data/dbmongo （2）mac12mongod --config /usr/local/etc/mongod.confmongo 4.在命令行中操作数据库 5.可视化工具进行增删改查Robomongo Robo3T adminMongo 6.nodejs连接操作数据库连接数据库 123const mongoose = require(&quot;mongoose&quot;)mongoose.connect(&quot;mongodb://127.0.0.1:27017/company-system&quot;) 创建模型 1234567891011121314const mongoose = require(&quot;mongoose&quot;)const Schema = mongoose.Schemaconst UserType = &#123; username:String, password:String, gender:Number, introduction:String, avatar:String, role:Number&#125;const UserModel = mongoose.model(&quot;user&quot;,new Schema(UserType))module.exports = UserModel 增加数据 123UserModel.create(&#123; introduction,username,gender,avatar,password,role&#125;) 查询数据 1UserModel.find(&#123;username:&quot;kerwin&quot;&#125;,[&quot;username&quot;,&quot;role&quot;,&quot;introduction&quot;,&quot;password&quot;]).sort(&#123;createTime:-1&#125;).skip(10).limit(10) 更新数据 12345UserModel.updateOne(&#123; _id&#125;,&#123; introduction,username,gender,avatar&#125;) 删除数据 1UserModel.deleteOne(&#123;_id&#125;) 四、接口规范与业务分层1.接口规范 2.业务分层 五、登录鉴权1. Cookie&amp;Session「HTTP 无状态」我们知道，HTTP 是无状态的。也就是说，HTTP 请求方和响应方间无法维护状态，都是一次性的，它不知道前后的请求都发生了什么。但有的场景下，我们需要维护状态。最典型的，一个用户登陆微博，发布、关注、评论，都应是在登录后的用户状态下的。「标记」那解决办法是什么呢？ 12345678910111213141516171819202122232425262728293031323334353637const express = require(&quot;express&quot;);const session = require(&quot;express-session&quot;);const MongoStore = require(&quot;connect-mongo&quot;);const app = express();app.use( session(&#123; secret: &quot;this is session&quot;, // 服务器生成 session 的签名 resave: true, saveUninitialized: true, //强制将为初始化的 session 存储 cookie: &#123; maxAge: 1000 * 60 * 10,// 过期时间 secure: false, // 为 true 时候表示只有 https 协议才能访问cookie &#125;, rolling: true, //为 true 表示 超时前刷新，cookie 会重新计时； 为 false 表示在超时前刷新多少次，都是按照第一次刷新开始计时。 store: MongoStore.create(&#123; mongoUrl: &#x27;mongodb://127.0.0.1:27017/kerwin_session&#x27;, ttl: 1000 * 60 * 10 // 过期时间 &#125;), &#125;));app.use((req,res,next)=&gt;&#123; if(req.url===&quot;/login&quot;)&#123; next() return; &#125; if(req.session.user)&#123; req.session.garbage = Date(); next(); &#125;else&#123; res.redirect(&quot;/login&quot;) &#125;&#125;) 2. JSON Web Token (JWT)（1）介绍 我为什么要保存这可恶的session呢， 只让每个客户端去保存该多好？ 当然， 如果一个人的token 被别人偷走了， 那我也没办法， 我也会认为小偷就是合法用户， 这其实和一个人的session id 被别人偷走是一样的。 这样一来， 我就不保存session id 了， 我只是生成token , 然后验证token ， 我用我的CPU计算时间获取了我的session 存储空间 ！ 解除了session id这个负担， 可以说是无事一身轻， 我的机器集群现在可以轻松地做水平扩展， 用户访问量增大， 直接加机器就行。 这种无状态的感觉实在是太好了！ 缺点： 占带宽，正常情况下要比 session_id 更大，需要消耗更多流量，挤占更多带宽，假如你的网站每月有 10 万次的浏览器，就意味着要多开销几十兆的流量。听起来并不多，但日积月累也是不小一笔开销。实际上，许多人会在 JWT 中存储的信息会更多； 无法在服务端注销，那么久很难解决劫持问题； 性能问题，JWT 的卖点之一就是加密签名，由于这个特性，接收方得以验证 JWT 是否有效且被信任。对于有着严格性能要求的 Web 应用，这并不理想，尤其对于单线程环境。 注意： CSRF攻击的原因是浏览器会自动带上cookie，而不会带上token； 以CSRF攻击为例： cookie：用户点击了链接，cookie未失效，导致发起请求后后端以为是用户正常操作，于是进行扣款操作；token：用户点击链接，由于浏览器不会自动带上token，所以即使发了请求，后端的token验证不会通过，所以不会进行扣款操作； （2）实现1234567891011121314151617//jsonwebtoken 封装const jsonwebtoken = require(&quot;jsonwebtoken&quot;)const secret = &quot;kerwin&quot;const JWT = &#123; generate(value,exprires)&#123; return jsonwebtoken.sign(value,secret,&#123;expiresIn:exprires&#125;) &#125;, verify(token)&#123; try&#123; return jsonwebtoken.verify(token,secret) &#125;catch(e)&#123; return false &#125; &#125;&#125;module.exports = JWT 1234567891011121314151617181920212223242526//node中间件校验app.use((req,res,next)=&gt;&#123; // 如果token有效 ,next() // 如果token过期了, 返回401错误 if(req.url===&quot;/login&quot;)&#123; next() return; &#125; const token = req.headers[&quot;authorization&quot;].split(&quot; &quot;)[1] if(token)&#123; var payload = JWT.verify(token) // console.log(payload) if(payload)&#123; const newToken = JWT.generate(&#123; _id:payload._id, username:payload.username &#125;,&quot;1d&quot;) res.header(&quot;Authorization&quot;,newToken) next() &#125;else&#123; res.status(401).send(&#123;errCode:&quot;-1&quot;,errorInfo:&quot;token过期&quot;&#125;) &#125; &#125;&#125;) 1234567 //生成tokenconst token = JWT.generate(&#123; _id: result[0]._id, username: result[0].username&#125;, &quot;1d&quot;)res.header(&quot;Authorization&quot;, token) 1234567891011121314151617181920212223242526272829303132//前端拦截/* * @作者: kerwin * @公众号: 大前端私房菜 */import axios from &#x27;axios&#x27;// Add a request interceptoraxios.interceptors.request.use(function (config) &#123; const token = localStorage.getItem(&quot;token&quot;) config.headers.Authorization = `Bearer $&#123;token&#125;` return config; &#125;, function (error) &#123; return Promise.reject(error); &#125;);// Add a response interceptoraxios.interceptors.response.use(function (response) &#123; const &#123;authorization &#125; = response.headers authorization &amp;&amp; localStorage.setItem(&quot;token&quot;,authorization) return response; &#125;, function (error) &#123; const &#123;status&#125; = error.response if(status===401)&#123; localStorage.removeItem(&quot;token&quot;) window.location.href=&quot;/login&quot; &#125; return Promise.reject(error); &#125;); 六、文件上传管理Multer 是一个 node.js 中间件，用于处理 multipart/form-data 类型的表单数据，它主要用于上传文件。 注意: Multer 不会处理任何非 multipart/form-data 类型的表单数据。 1npm install --save multer 12345678910111213//前后端分离-前端const params = new FormData()params.append(&#x27;kerwinfile&#x27;, file.file)params.append(&#x27;username&#x27;, this.username)const config = &#123; headers: &#123; &quot;Content-Type&quot;:&quot;multipart/form-data&quot; &#125;&#125;http.post(&#x27;/api/upload&#x27;, params, config).then(res =&gt; &#123; this.imgpath = &#x27;http://localhost:3000&#x27; + res.data&#125;) Multer 会添加一个 body 对象 以及 file 或 files 对象 到 express 的 request 对象中。 body 对象包含表单的文本域信息，file 或 files 对象包含对象表单上传的文件信息。 12345//前后端分离-后端router.post(&#x27;/upload&#x27;, upload.single(&#x27;kerwinfile&#x27;),function(req, res, next) &#123; console.log(req.file)&#125;) 七、APIDOC - API 文档生成工具apidoc 是一个简单的 RESTful API 文档生成工具，它从代码注释中提取特定格式的内容生成文档。支持诸如 Go、Java、C++、Rust 等大部分开发语言，具体可使用 apidoc lang 命令行查看所有的支持列表。 apidoc 拥有以下特点： 跨平台，linux、windows、macOS 等都支持； 支持语言广泛，即使是不支持，也很方便扩展； 支持多个不同语言的多个项目生成一份文档； 输出模板可自定义； 根据文档生成 mock 数据； 1npm install -g apidoc 注意： (1) 在当前文件夹下 apidoc.json 123456&#123; &quot;name&quot;: &quot;****接口文档&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;关于****的接口文档描述&quot;, &quot;title&quot;: &quot;****&quot;&#125; （2）可以利用vscode apidoc snippets 插件创建api 八、Koa2 1.简介koa 是由 Express 原班人马打造的，致力于成为一个更小、更富有表现力、更健壮的 Web 框架。使用 koa 编写 web 应用，通过组合不同的 generator，可以免除重复繁琐的回调函数嵌套，并极大地提升错误处理的效率。koa 不在内核方法中绑定任何中间件，它仅仅提供了一个轻量优雅的函数库，使得编写 Web 应用变得得心应手。 2. 快速开始2.1 安装koa212345# 初始化package.jsonnpm init# 安装koa2 npm install koa 2.2 hello world 代码123456789const Koa = require(&#x27;koa&#x27;)const app = new Koa()app.use( async ( ctx ) =&gt; &#123; ctx.body = &#x27;hello koa2&#x27; //json数据&#125;)app.listen(3000) 2.3 启动demo1node index.js 3. koa vs express通常都会说 Koa 是洋葱模型，这重点在于中间件的设计。但是按照上面的分析，会发现 Express 也是类似的，不同的是Express 中间件机制使用了 Callback 实现，这样如果出现异步则可能会使你在执行顺序上感到困惑，因此如果我们想做接口耗时统计、错误处理 Koa 的这种中间件模式处理起来更方便些。最后一点响应机制也很重要，Koa 不是立即响应，是整个中间件处理完成在最外层进行了响应，而 Express 则是立即响应。 3.1更轻量 koa 不提供内置的中间件； koa 不提供路由，而是把路由这个库分离出来了（koa/router） 3.2 Context对象koa增加了一个Context的对象，作为这次请求的上下文对象（在koa2中作为中间件的第一个参数传入）。同时Context上也挂载了Request和Response两个对象。和Express类似，这两个对象都提供了大量的便捷方法辅助开发, 这样的话对于在保存一些公有的参数的话变得更加合情合理 3.3 异步流程控制​ express采用callback来处理异步， koa v1采用generator，koa v2 采用async/await。 ​ generator和async/await使用同步的写法来处理异步，明显好于callback和promise， 3.4 中间件模型​ express基于connect中间件，线性模型； ​ koa中间件采用洋葱模型（对于每个中间件，在完成了一些事情后，可以非常优雅的将控制权传递给下一个中间件，并能够等待它完成，当后续的中间件完成处理后，控制权又回到了自己） 123456789101112131415161718192021222324252627282930313233343536//同步var express = require(&quot;express&quot;)var app = express()app.use((req,res,next)=&gt;&#123; console.log(1) next() console.log(4) res.send(&quot;hello&quot;)&#125;)app.use(()=&gt;&#123; console.log(3)&#125;)app.listen(3000)//异步var express = require(&quot;express&quot;)var app = express()app.use(async (req,res,next)=&gt;&#123; console.log(1) await next() console.log(4) res.send(&quot;hello&quot;)&#125;)app.use(async ()=&gt;&#123; console.log(2) await delay(1) console.log(3)&#125;)function delay(time)&#123; return new Promise((resolve,reject)=&gt;&#123; setTimeout(resolve,1000) &#125;)&#125; 123456789101112131415161718192021222324252627282930313233343536373839//同步var koa = require(&quot;koa&quot;)var app = new koa()app.use((ctx,next)=&gt;&#123; console.log(1) next() console.log(4) ctx.body=&quot;hello&quot;&#125;)app.use(()=&gt;&#123; console.log(3)&#125;)app.listen(3000)//异步var koa = require(&quot;koa&quot;)var app = new koa()app.use(async (ctx,next)=&gt;&#123; console.log(1) await next() console.log(4) ctx.body=&quot;hello&quot;&#125;) app.use(async ()=&gt;&#123; console.log(2) await delay(1) console.log(3)&#125;)function delay(time)&#123; return new Promise((resolve,reject)=&gt;&#123; setTimeout(resolve,1000) &#125;)&#125;app.listen(3000) 4. 路由4.1基本用发1234567891011var Koa = require(&quot;koa&quot;)var Router = require(&quot;koa-router&quot;)var app = new Koa()var router = new Router()router.post(&quot;/list&quot;,(ctx)=&gt;&#123; ctx.body=[&quot;111&quot;,&quot;222&quot;,&quot;333&quot;]&#125;)app.use(router.routes()).use(router.allowedMethods())app.listen(3000) 4.2 router.allowedMethods作用 4.3 请求方式Koa-router 请求方式： get 、 put 、 post 、 patch 、 delete 、 del ，而使用方法就是 router.方式() ，比如 router.get() 和 router.post() 。而 router.all() 会匹配所有的请求方法。 12345678910111213141516171819202122var Koa = require(&quot;koa&quot;)var Router = require(&quot;koa-router&quot;)var app = new Koa()var router = new Router()router.get(&quot;/user&quot;,(ctx)=&gt;&#123; ctx.body=[&quot;aaa&quot;,&quot;bbb&quot;,&quot;ccc&quot;]&#125;).put(&quot;/user/:id&quot;,(ctx)=&gt;&#123; ctx.body=&#123;ok:1,info:&quot;user update&quot;&#125;&#125;).post(&quot;/user&quot;,(ctx)=&gt;&#123; ctx.body=&#123;ok:1,info:&quot;user post&quot;&#125;&#125;).del(&quot;/user/:id&quot;,(ctx)=&gt;&#123; ctx.body=&#123;ok:1,info:&quot;user del&quot;&#125;&#125;)app.use(router.routes()).use(router.allowedMethods())app.listen(3000) 4.4 拆分路由list.js 123456789101112131415var Router = require(&quot;koa-router&quot;)var router = new Router()router.get(&quot;/&quot;,(ctx)=&gt;&#123; ctx.body=[&quot;111&quot;,&quot;222&quot;,&quot;333&quot;]&#125;).put(&quot;/:id&quot;,(ctx)=&gt;&#123; ctx.body=&#123;ok:1,info:&quot;list update&quot;&#125;&#125;).post(&quot;/&quot;,(ctx)=&gt;&#123; ctx.body=&#123;ok:1,info:&quot;list post&quot;&#125;&#125;).del(&quot;/:id&quot;,(ctx)=&gt;&#123; ctx.body=&#123;ok:1,info:&quot;list del&quot;&#125;&#125;)module.exports = router index.js 12345678var Router = require(&quot;koa-router&quot;)var router = new Router()var user = require(&quot;./user&quot;)var list = require(&quot;./list&quot;)router.use(&#x27;/user&#x27;, user.routes(), user.allowedMethods())router.use(&#x27;/list&#x27;, list.routes(), list.allowedMethods())module.exports = router entry入口 123456var Koa = require(&quot;koa&quot;)var router = require(&quot;./router/index&quot;)var app = new Koa()app.use(router.routes()).use(router.allowedMethods())app.listen(3000) 4.5 路由前缀1router.prefix(&#x27;/api&#x27;) 4.6 路由重定向123456789router.get(&quot;/home&quot;,(ctx)=&gt;&#123; ctx.body=&quot;home页面&quot;&#125;)//写法1 router.redirect(&#x27;/&#x27;, &#x27;/home&#x27;);//写法2router.get(&quot;/&quot;,(ctx)=&gt;&#123; ctx.redirect(&quot;/home&quot;)&#125;) 5. 静态资源12345678910111213141516171819const Koa = require(&#x27;koa&#x27;)const path = require(&#x27;path&#x27;)const static = require(&#x27;koa-static&#x27;)const app = new Koa()app.use(static( path.join( __dirname, &quot;public&quot;)))app.use( async ( ctx ) =&gt; &#123; ctx.body = &#x27;hello world&#x27;&#125;)app.listen(3000, () =&gt; &#123; console.log(&#x27;[demo] static-use-middleware is starting at port 3000&#x27;)&#125;) 6. 获取请求参数6.1get参数在koa中，获取GET请求数据源头是koa中request对象中的query方法或querystring方法，query返回是格式化好的参数对象，querystring返回的是请求字符串，由于ctx对request的API有直接引用的方式，所以获取GET请求数据有两个途径。 是从上下文中直接获取 请求对象ctx.query，返回如 { a:1, b:2 } 请求字符串 ctx.querystring，返回如 a=1&amp;b=2 是从上下文的request对象中获取 请求对象ctx.request.query，返回如 { a:1, b:2 } 请求字符串 ctx.request.querystring，返回如 a=1&amp;b=2 6.2post参数对于POST请求的处理，koa-bodyparser中间件可以把koa2上下文的formData数据解析到ctx.request.body中 12345const bodyParser = require(&#x27;koa-bodyparser&#x27;)// 使用ctx.body解析中间件app.use(bodyParser()) 7. ejs模板7.1 安装模块123456# 安装koa模板使用中间件npm install --save koa-views# 安装ejs模板引擎npm install --save ejs 7.2 使用模板引擎文件目录 1234├── package.json├── index.js└── view └── index.ejs ./index.js文件 123456789101112131415161718const Koa = require(&#x27;koa&#x27;)const views = require(&#x27;koa-views&#x27;)const path = require(&#x27;path&#x27;)const app = new Koa()// 加载模板引擎app.use(views(path.join(__dirname, &#x27;./view&#x27;), &#123; extension: &#x27;ejs&#x27;&#125;))app.use( async ( ctx ) =&gt; &#123; let title = &#x27;hello koa2&#x27; await ctx.render(&#x27;index&#x27;, &#123; title, &#125;)&#125;)app.listen(3000) ./view/index.ejs 模板 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;%= title %&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;&lt;%= title %&gt;&lt;/h1&gt; &lt;p&gt;EJS Welcome to &lt;%= title %&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 8. cookie&amp;session8.1 cookiekoa提供了从上下文直接读取、写入cookie的方法 ctx.cookies.get(name, [options]) 读取上下文请求中的cookie ctx.cookies.set(name, value, [options]) 在上下文中写入cookie 8.2 session koa-session-minimal 适用于koa2 的session中间件，提供存储介质的读写接口 。 1234567const session = require(&#x27;koa-session-minimal&#x27;)app.use(session(&#123; key: &#x27;SESSION_ID&#x27;, cookie: &#123; maxAge:1000*60 &#125;&#125;)) 12345678910111213141516app.use(async (ctx, next) =&gt; &#123; //排除login相关的路由和接口 if (ctx.url.includes(&quot;login&quot;)) &#123; await next() return &#125; if (ctx.session.user) &#123; //重新设置以下sesssion ctx.session.mydate = Date.now() await next() &#125; else &#123; ctx.redirect(&quot;/login&quot;) &#125;&#125;) 9. JWT 123456789101112131415161718192021222324252627app.use(async(ctx, next) =&gt; &#123; //排除login相关的路由和接口 if (ctx.url.includes(&quot;login&quot;)) &#123; await next() return &#125; const token = ctx.headers[&quot;authorization&quot;]?.split(&quot; &quot;)[1] // console.log(req.headers[&quot;authorization&quot;]) if(token)&#123; const payload= JWT.verify(token) if(payload)&#123; //重新计算token过期时间 const newToken = JWT.generate(&#123; _id:payload._id, username:payload.username &#125;,&quot;10s&quot;) ctx.set(&quot;Authorization&quot;,newToken) await next() &#125;else&#123; ctx.status = 401 ctx.body = &#123;errCode:-1,errInfo:&quot;token过期&quot;&#125; &#125; &#125;else&#123; await next() &#125;&#125;) 10.上传文件 https://www.npmjs.com/package/@koa/multer 1npm install --save @koa/multer multer 123456789101112const multer = require(&#x27;@koa/multer&#x27;);const upload = multer(&#123; dest: &#x27;public/uploads/&#x27; &#125;)router.post(&quot;/&quot;,upload.single(&#x27;avatar&#x27;),(ctx,next)=&gt;&#123; console.log(ctx.request.body,ctx.file) ctx.body=&#123; ok:1, info:&quot;add user success&quot; &#125;&#125;) 11.操作MongoDB1234const mongoose = require(&quot;mongoose&quot;)mongoose.connect(&quot;mongodb://127.0.0.1:27017/kerwin_project&quot;)//插入集合和数据,数据库kerwin_project会自动创建 123456789101112const mongoose = require(&quot;mongoose&quot;)const Schema = mongoose.Schemaconst UserType = &#123; username:String, password:String, age:Number, avatar:String&#125;const UserModel = mongoose.model(&quot;user&quot;,new Schema(UserType))// 模型user 将会对应 users 集合, module.exports = UserModel 九、MySQL1.介绍付费的商用数据库： Oracle，典型的高富帅； SQL Server，微软自家产品，Windows定制专款； DB2，IBM的产品，听起来挺高端； Sybase，曾经跟微软是好基友，后来关系破裂，现在家境惨淡。 这些数据库都是不开源而且付费的，最大的好处是花了钱出了问题可以找厂家解决，不过在Web的世界里，常常需要部署成千上万的数据库服务器，当然不能把大把大把的银子扔给厂家，所以，无论是Google、Facebook，还是国内的BAT，无一例外都选择了免费的开源数据库： MySQL，大家都在用，一般错不了； PostgreSQL，学术气息有点重，其实挺不错，但知名度没有MySQL高； sqlite，嵌入式数据库，适合桌面和移动应用。 作为一个JavaScript全栈工程师，选择哪个免费数据库呢？当然是MySQL。因为MySQL普及率最高，出了错，可以很容易找到解决方法。而且，围绕MySQL有一大堆监控和运维的工具，安装和使用很方便。 2.与非关系数据库区别关系型和非关系型数据库的主要差异是数据存储的方式。关系型数据天然就是表格式的，因此存储在数据表的行和列中。数据表可以彼此关联协作存储，也很容易提取数据。 与其相反，非关系型数据不适合存储在数据表的行和列中，而是大块组合在一起。非关系型数据通常存储在数据集中，就像文档、键值对或者图结构。你的数据及其特性是选择数据存储和提取方式的首要影响因素。 关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织优点：1、易于维护：都是使用表结构，格式一致；2、使用方便：SQL语言通用，可用于复杂查询；3、复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。缺点：1、读写性能比较差，尤其是海量数据的高效率读写；2、固定的表结构，灵活度稍欠；3、高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。 非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，可以是文档或者键值对等。 优点： 1、格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。2、速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘；3、高扩展性；4、成本低：nosql数据库部署简单，基本都是开源软件。 缺点： 1、不提供sql支持；2、无事务处理；3、数据结构相对复杂，复杂查询方面稍欠。 3.sql语句 插入： 12INSERT INTO `students`(`id`, `name`, `score`, `gender`) VALUES (null,&#x27;kerwin&#x27;,100,1)//可以不设置id,create_time 更新：1UPDATE `students` SET `name`=&#x27;tiechui&#x27;,`score`=20,`gender`=0 WHERE id=2;删除：1DELETE FROM `students` WHERE id=2;查询：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253查所有的数据所有的字段SELECT * FROM `students` WHERE 1;查所有的数据某个字段SELECT `id`, `name`, `score`, `gender` FROM `students` WHERE 1;条件查询SELECT * FROM `students` WHERE score&gt;=80;SELECT * FROM `students` where score&gt;=80 AND gender=1模糊查询SELECT * FROM `students` where name like &#x27;%k%&#x27;排序SELECT id, name, gender, score FROM students ORDER BY score;SELECT id, name, gender, score FROM students ORDER BY score DESC;分页查询SELECT id, name, gender, score FROM students LIMIT 50 OFFSET 0记录条数SELECT COUNT(*) FROM students;SELECT COUNT(*) kerwinnum FROM students;多表查询SELECT * FROM students, classes;（这种多表查询又称笛卡尔查询，使用笛卡尔查询时要非常小心，由于结果集是目标表的行数乘积，对两个各自有100行记录的表进行笛卡尔查询将返回1万条记录，对两个各自有1万行记录的表进行笛卡尔查询将返回1亿条记录）SELECT students.id sid, students.name, students.gender, students.score, classes.id cid, classes.name cnameFROM students, classes; （要使用表名.列名这样的方式来引用列和设置别名，这样就避免了结果集的列名重复问题。）SELECT s.id sid, s.name, s.gender, s.score, c.id cid, c.name cnameFROM students s, classes c; （SQL还允许给表设置一个别名）联表查询SELECT s.id, s.name, s.class_id, c.name class_name, s.gender, s.scoreFROM students sINNER JOIN classes cON s.class_id = c.id; （连接查询对多个表进行JOIN运算，简单地说，就是先确定一个主表作为结果集，然后，把其他表的行有选择性地“连接”在主表结果集上。） 注意： InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败； 外键约束 CASCADE在父表上update/delete记录时，同步update/delete掉子表的匹配记录 SET NULL在父表上update/delete记录时，将子表上匹配记录的列设为null (要注意子表的外键列不能为not null) NO ACTION如果子表中有匹配的记录,则不允许对父表对应候选键进行update/delete操作 RESTRICT同no action, 都是立即检查外键约束 4.nodejs 操作数据库123456789101112131415161718192021222324252627282930313233343536373839const express = require(&#x27;express&#x27;)const app = express()const mysql2 = require(&#x27;mysql2&#x27;)const port = 9000app.get(&#x27;/&#x27;,async (req, res) =&gt; &#123; const config = getDBConfig() const promisePool = mysql2.createPool(config).promise(); // console.log(promisePool) let user = await promisePool.query(&#x27;select * from students&#x27;); console.log(user) if (user[0].length) &#123; //存在用户 res.send(user[0]) &#125; else &#123; //不存在 res.send( &#123; code: -2, msg: &#x27;user not exsit&#x27;, &#125;) &#125; &#125;)app.listen(port, () =&gt; &#123; console.log(`Example app listening at http://localhost:$&#123;port&#125;`)&#125;)function getDBConfig() &#123; return &#123; host: &#x27;127.0.0.1&#x27;, user: &#x27;root&#x27;, port: 3306, password: &#x27;&#x27;, database: &#x27;kerwin_test&#x27;, connectionLimit: 1 //创建一个连接池 &#125;&#125; 123456789101112查询：promisePool.query(&#x27;select * from users&#x27;);插入：promisePool.query(&#x27;INSERT INTO `users`(`id`,`name`,`age`, `password`) VALUES (?,?,?,?)&#x27;,[null,&quot;kerwin&quot;,100,&quot;123456&quot;]);更新：promisePool.query(`UPDATE users SET name = ? ,age=? WHERE id = ?`,[&quot;xiaoming2&quot;,20,1])删除：promisePool.query(`delete from users where id=?`,[1]) 十、Socket编程1.websocket介绍 应用场景： 弹幕 媒体聊天 协同编辑 基于位置的应用 体育实况更新 股票基金报价实时更新 WebSocket并不是全新的协议，而是利用了HTTP协议来建立连接。我们来看看WebSocket连接是如何创建的。 首先，WebSocket连接必须由浏览器发起，因为请求协议是一个标准的HTTP请求，格式如下： 1234567GET ws://localhost:3000/ws/chat HTTP/1.1Host: localhostUpgrade: websocketConnection: UpgradeOrigin: http://localhost:3000Sec-WebSocket-Key: client-random-stringSec-WebSocket-Version: 13 该请求和普通的HTTP请求有几点不同： GET请求的地址不是类似/path/，而是以ws://开头的地址； 请求头Upgrade: websocket和Connection: Upgrade表示这个连接将要被转换为WebSocket连接； Sec-WebSocket-Key是用于标识这个连接，并非用于加密数据； Sec-WebSocket-Version指定了WebSocket的协议版本。 随后，服务器如果接受该请求，就会返回如下响应： 1234HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: server-random-string 该响应代码101表示本次连接的HTTP协议即将被更改，更改后的协议就是Upgrade: websocket指定的WebSocket协议。 版本号和子协议规定了双方能理解的数据格式，以及是否支持压缩等等。如果仅使用WebSocket的API，就不需要关心这些。 现在，一个WebSocket连接就建立成功，浏览器和服务器就可以随时主动发送消息给对方。消息有两种，一种是文本，一种是二进制数据。通常，我们可以发送JSON格式的文本，这样，在浏览器处理起来就十分容易。 为什么WebSocket连接可以实现全双工通信而HTTP连接不行呢？实际上HTTP协议是建立在TCP协议之上的，TCP协议本身就实现了全双工通信，但是HTTP协议的请求－应答机制限制了全双工通信。WebSocket连接建立以后，其实只是简单规定了一下：接下来，咱们通信就不使用HTTP协议了，直接互相发数据吧。 安全的WebSocket连接机制和HTTPS类似。首先，浏览器用wss://xxx创建WebSocket连接时，会先通过HTTPS创建安全的连接，然后，该HTTPS连接升级为WebSocket连接，底层通信走的仍然是安全的SSL/TLS协议。 浏览器支持 很显然，要支持WebSocket通信，浏览器得支持这个协议，这样才能发出ws://xxx的请求。目前，支持WebSocket的主流浏览器如下： Chrome Firefox IE &gt;= 10 Sarafi &gt;= 6 Android &gt;= 4.4 iOS &gt;= 8 服务器支持 由于WebSocket是一个协议，服务器具体怎么实现，取决于所用编程语言和框架本身。Node.js本身支持的协议包括TCP协议和HTTP协议，要支持WebSocket协议，需要对Node.js提供的HTTPServer做额外的开发。已经有若干基于Node.js的稳定可靠的WebSocket实现，我们直接用npm安装使用即可。 2.ws模块服务器： 123456789101112131415const WebSocket = require(&quot;ws&quot;)WebSocketServer = WebSocket.WebSocketServerconst wss = new WebSocketServer(&#123; port: 8080 &#125;);wss.on(&#x27;connection&#x27;, function connection(ws) &#123; ws.on(&#x27;message&#x27;, function message(data, isBinary) &#123; wss.clients.forEach(function each(client) &#123; if (client !== ws &amp;&amp; client.readyState === WebSocket.OPEN) &#123; client.send(data, &#123; binary: isBinary &#125;); &#125; &#125;); &#125;); ws.send(&#x27;欢迎加入聊天室&#x27;);&#125;); 客户端： 1234567var ws = new WebSocket(&quot;ws://localhost:8080&quot;)ws.onopen = ()=&gt;&#123; console.log(&quot;open&quot;)&#125;ws.onmessage = (evt)=&gt;&#123; console.log(evt.data)&#125; 授权验证： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879//前端var ws = new WebSocket(`ws://localhost:8080?token=$&#123;localStorage.getItem(&quot;token&quot;)&#125;`)ws.onopen = () =&gt; &#123; console.log(&quot;open&quot;) ws.send(JSON.stringify(&#123; type: WebSocketType.GroupList &#125;)) &#125;ws.onmessage = (evt) =&gt; &#123; console.log(evt.data)&#125;//后端const WebSocket = require(&quot;ws&quot;);const JWT = require(&#x27;../util/JWT&#x27;);WebSocketServer = WebSocket.WebSocketServerconst wss = new WebSocketServer(&#123; port: 8080 &#125;);wss.on(&#x27;connection&#x27;, function connection(ws, req) &#123; const myURL = new URL(req.url, &#x27;http://127.0.0.1:3000&#x27;); const payload = JWT.verify(myURL.searchParams.get(&quot;token&quot;)) if (payload) &#123; ws.user = payload ws.send(createMessage(WebSocketType.GroupChat, ws.user, &quot;欢迎来到聊天室&quot;)) sendBroadList() //发送好友列表 &#125; else &#123; ws.send(createMessage(WebSocketType.Error, null, &quot;token过期&quot;)) &#125; // console.log(3333,url) ws.on(&#x27;message&#x27;, function message(data, isBinary) &#123; const messageObj = JSON.parse(data) switch (messageObj.type) &#123; case WebSocketType.GroupList: ws.send(createMessage(WebSocketType.GroupList, ws.user, JSON.stringify(Array.from(wss.clients).map(item =&gt; item.user)))) break; case WebSocketType.GroupChat: wss.clients.forEach(function each(client) &#123; if (client !== ws &amp;&amp; client.readyState === WebSocket.OPEN) &#123; client.send(createMessage(WebSocketType.GroupChat, ws.user, messageObj.data)); &#125; &#125;); break; case WebSocketType.SingleChat: wss.clients.forEach(function each(client) &#123; if (client.user.username === messageObj.to &amp;&amp; client.readyState === WebSocket.OPEN) &#123; client.send(createMessage(WebSocketType.SingleChat, ws.user, messageObj.data)); &#125; &#125;); break; &#125; ws.on(&quot;close&quot;,function()&#123; //删除当前用户 wss.clients.delete(ws.user) sendBroadList() //发送好用列表 &#125;) &#125;);&#125;);const WebSocketType = &#123; Error: 0, //错误 GroupList: 1,//群列表 GroupChat: 2,//群聊 SingleChat: 3//私聊&#125;function createMessage(type, user, data) &#123; return JSON.stringify(&#123; type: type, user: user, data: data &#125;);&#125;function sendBroadList()&#123; wss.clients.forEach(function each(client) &#123; if (client.readyState === WebSocket.OPEN) &#123; client.send(createMessage(WebSocketType.GroupList, client.user, JSON.stringify(Array.from(wss.clients).map(item =&gt; item.user)))) &#125; &#125;);&#125; 3.socket.io模块服务端： 1234567891011121314151617181920212223242526272829303132333435363738394041const io = require(&#x27;socket.io&#x27;)(server);io.on(&#x27;connection&#x27;, (socket) =&gt; &#123; const payload = JWT.verify(socket.handshake.query.token) if (payload) &#123; socket.user = payload socket.emit(WebSocketType.GroupChat, createMessage(socket.user, &quot;欢迎来到聊天室&quot;)) sendBroadList() //发送好友列表 &#125; else &#123; socket.emit(WebSocketType.Error, createMessage(null, &quot;token过期&quot;)) &#125; socket.on(WebSocketType.GroupList, () =&gt; &#123; socket.emit(WebSocketType.GroupList, createMessage(null, Array.from(io.sockets.sockets).map(item =&gt; item[1].user).filter(item=&gt;item))); &#125;) socket.on(WebSocketType.GroupChat, (messageObj) =&gt; &#123; socket.broadcast.emit(WebSocketType.GroupChat, createMessage(socket.user, messageObj.data)); &#125;) socket.on(WebSocketType.SingleChat, (messageObj) =&gt; &#123; Array.from(io.sockets.sockets).forEach(function (socket) &#123; if (socket[1].user.username === messageObj.to) &#123; socket[1].emit(WebSocketType.SingleChat, createMessage(socket[1].user, messageObj.data)); &#125; &#125;) &#125;) socket.on(&#x27;disconnect&#x27;, reason =&gt; &#123; sendBroadList() //发送好用列表 &#125;);&#125;);function sendBroadList() &#123; io.sockets.emit(WebSocketType.GroupList, createMessage(null, Array.from(io.sockets.sockets).map(item =&gt; item[1].user).filter(item=&gt;item)))&#125;//最后filter，是因为 有可能存在null的值 客户端： 12345678910111213141516171819202122232425262728293031323334353637383940414243const WebSocketType = &#123; Error: 0, //错误 GroupList: 1, //群列表 GroupChat: 2, //群聊 SingleChat: 3 //私聊&#125;const socket = io(`ws://localhost:3000?token=$&#123;localStorage.getItem(&quot;token&quot;)&#125;`);socket.on(&quot;connect&quot;,()=&gt;&#123; socket.emit(WebSocketType.GroupList)&#125;)socket.on(WebSocketType.GroupList, (messageObj) =&gt; &#123; select.innerHTML = &quot;&quot; select.innerHTML = `&lt;option value=&quot;all&quot;&gt;all&lt;/option&gt;` + messageObj.data.map(item =&gt; ` &lt;option value=&quot;$&#123;item.username&#125;&quot;&gt;$&#123;item.username&#125;&lt;/option&gt;`).join(&quot;&quot;)&#125;)socket.on(WebSocketType.GroupChat, (msg) =&gt; &#123; console.log(msg)&#125;)socket.on(WebSocketType.SingleChat, (msg) =&gt; &#123; console.log(msg)&#125;)socket.on(WebSocketType.Error, (msg) =&gt; &#123; localStorage.removeItem(&quot;token&quot;) location.href = &quot;/login&quot;&#125;)send.onclick = () =&gt; &#123; if (select.value === &quot;all&quot;) &#123; socket.emit(WebSocketType.GroupChat,&#123; data: text.value &#125;) &#125; else &#123; socket.emit(WebSocketType.SingleChat,&#123; data: text.value, to:select.value &#125;) &#125;&#125; 十一、mocha单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。 比如对函数abs()，我们可以编写出以下几个测试用例： 输入正数，比如1、1.2、0.99，期待返回值与输入相同； 输入负数，比如-1、-1.2、-0.99，期待返回值与输入相反； 输入0，期待返回0； 输入非数值类型，比如null、[]、{}，期待抛出Error。 把上面的测试用例放到一个测试模块里，就是一个完整的单元测试。 如果单元测试通过，说明我们测试的这个函数能够正常工作。如果单元测试不通过，要么函数有bug，要么测试条件输入不正确，总之，需要修复使单元测试能够通过。 单元测试通过后有什么意义呢？如果我们对abs()函数代码做了修改，只需要再跑一遍单元测试，如果通过，说明我们的修改不会对abs()函数原有的行为造成影响，如果测试不通过，说明我们的修改与原有行为不一致，要么修改代码，要么修改测试。 这种以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例。在将来修改的时候，可以极大程度地保证该模块行为仍然是正确的。 mocha是JavaScript的一种单元测试框架，既可以在浏览器环境下运行，也可以在Node.js环境下运行。 使用mocha，我们就只需要专注于编写单元测试本身，然后，让mocha去自动运行所有的测试，并给出测试结果。 mocha的特点主要有： 既可以测试简单的JavaScript函数，又可以测试异步代码，因为异步是JavaScript的特性之一； 可以自动运行所有测试，也可以只运行特定的测试； 可以支持before、after、beforeEach和afterEach来编写初始化代码。 1.编写测试12345678910111213141516171819202122const assert = require(&#x27;assert&#x27;);const sum = require(&#x27;../test&#x27;);describe(&#x27;#hello.js&#x27;, () =&gt; &#123; describe(&#x27;#sum()&#x27;, () =&gt; &#123; it(&#x27;sum() should return 0&#x27;, () =&gt; &#123; assert.strictEqual(sum(), 0); &#125;); it(&#x27;sum(1) should return 1&#x27;, () =&gt; &#123; assert.strictEqual(sum(1), 1); &#125;); it(&#x27;sum(1, 2) should return 3&#x27;, () =&gt; &#123; assert.strictEqual(sum(1, 2), 3); &#125;); it(&#x27;sum(1, 2, 3) should return 6&#x27;, () =&gt; &#123; assert.strictEqual(sum(1, 2, 3), 6); &#125;); &#125;);&#125;); 2.chai断言库 123456789101112var chai = require(&#x27;chai&#x27;)var assert = chai.assert;describe(&#x27;assert Demo&#x27;, function () &#123; it(&#x27;use assert lib&#x27;, function () &#123; var value = &quot;hello&quot;; assert.typeOf(value, &#x27;string&#x27;) assert.equal(value, &#x27;hello&#x27;) assert.lengthOf(value, 5) &#125;)&#125;) 1234567891011121314var chai = require(&#x27;chai&#x27;);chai.should();describe(&#x27;should Demo&#x27;, function()&#123; it(&#x27;use should lib&#x27;, function () &#123; var value = &#x27;hello&#x27; value.should.exist.and.equal(&#x27;hello&#x27;).and.have.length(5).and.be.a(&#x27;string&#x27;) // value.should.be.a(&#x27;string&#x27;) // value.should.equal(&#x27;hello&#x27;) // value.should.not.equal(&#x27;hello2&#x27;) // value.should.have.length(5); &#125;)&#125;); 1234567891011121314151617181920var chai = require(&#x27;chai&#x27;);var expect = chai.expect;describe(&#x27;expect Demo&#x27;, function() &#123; it(&#x27;use expect lib&#x27;, function () &#123; var value = &#x27;hello&#x27; var number = 3 expect(number).to.be.at.most(5) expect(number).to.be.at.least(3) expect(number).to.be.within(1, 4) expect(value).to.exist expect(value).to.be.a(&#x27;string&#x27;) expect(value).to.equal(&#x27;hello&#x27;) expect(value).to.not.equal(&#x27;您好&#x27;) expect(value).to.have.length(5) &#125;)&#125;); 3.异步测试1234567var fs =require(&quot;fs&quot;).promisesvar chai = require(&#x27;chai&#x27;);var expect = chai.expect;it(&#x27;test async function&#x27;,async function () &#123; const data =await fs.readFile(&#x27;./1.txt&#x27;,&quot;utf8&quot;); expect(data).to.equal(&#x27;hello&#x27;)&#125;); 4.http测试123456789101112131415161718const request = require(&#x27;supertest&#x27;)const app = require(&#x27;../app&#x27;);describe(&#x27;#test koa app&#x27;, () =&gt; &#123; let server = app.listen(3000); describe(&#x27;#test server&#x27;, () =&gt; &#123; it(&#x27;#test GET /&#x27;, async () =&gt; &#123; await request(server) .get(&#x27;/&#x27;) .expect(&#x27;Content-Type&#x27;, /text\\/html/) .expect(200, &#x27;&lt;h1&gt;hello world&lt;/h1&gt;&#x27;); &#125;); after(function () &#123; server.close() &#125;); &#125;);&#125;); 5.钩子函数12345678910111213141516171819describe(&#x27;#hello.js&#x27;, () =&gt; &#123; describe(&#x27;#sum()&#x27;, () =&gt; &#123; before(function () &#123; console.log(&#x27;before:&#x27;); &#125;); after(function () &#123; console.log(&#x27;after.&#x27;); &#125;); beforeEach(function () &#123; console.log(&#x27; beforeEach:&#x27;); &#125;); afterEach(function () &#123; console.log(&#x27; afterEach.&#x27;); &#125;); &#125;);&#125;);","categories":[],"tags":[]},{"title":"纯 Mock.js Vue中的操作","slug":"纯 Mock.js 操作_凯凯超人版本","date":"2023-03-20T05:52:01.000Z","updated":"2023-03-20T10:54:30.000Z","comments":true,"path":"2023/03/20/纯 Mock.js 操作_凯凯超人版本/","link":"","permalink":"http://example.com/2023/03/20/%E7%BA%AF%20Mock.js%20%E6%93%8D%E4%BD%9C_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/","excerpt":"","text":"纯 Mock.js Vue中的操作步骤1：首先在 src 中创建一个 mock文件夹里面创建一个 index.js (什么名称都可以) 比如我们创建如下的本地接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 引入 Mock 必须要import Mock from &#x27;mockjs&#x27;// 创建一个 数据库 假装是个数据库const &#123; newsList &#125; = Mock.mock(&#123; &#x27;newsList|50-100&#x27;: [ &#123; id: &#x27;@increment(1)&#x27;, title: &#x27;@ctitle&#x27;, content: &#x27;@cparagraph&#x27;, image: &quot;@image(&#x27;200x100&#x27;, &#x27;#894FC4&#x27;, &#x27;#FFF&#x27;, &#x27;png&#x27;, &#x27;Yusi&#x27;)&quot;, addtime: &quot;@date(&#x27;yyyy-MM-dd hh:mm:ss&#x27;)&quot; &#125; ]&#125;)// 一个post 接口 用于添加数据Mock.mock(&#x27;/api/add/news&#x27;, &#x27;post&#x27;, req =&gt; &#123; console.log(req) console.log(req.body) const item = JSON.parse(req.body) // 你看他这里其实模拟了 数据库的 添加操作 newsList.push( Mock.mock(&#123; id: &#x27;@increment(1)&#x27;, title: item.title, content: item.content, image: &quot;@image(&#x27;200x100&#x27;, &#x27;#894FC4&#x27;, &#x27;#FFF&#x27;, &#x27;png&#x27;, &#x27;Yusi&#x27;)&quot;, addtime: &quot;@date(&#x27;yyyy-MM-dd hh:mm:ss&#x27;)&quot; &#125;) ) // 返回一个添加成功的信息 return &#123; status: 201, message: &#x27;新闻创建成功&#x27;, list: newsList, total: newsList.length &#125;&#125;)// 一个 接口 用于删除数据Mock.mock(&#x27;/api/remove/news&#x27;, &#x27;post&#x27;, req =&gt; &#123; // console.log(req.body) const item = JSON.parse(req.body) const index = newsList.findIndex(x =&gt; x.id === item.id) if (index !== -1) &#123; newsList.splice(index, 1) &#125; return &#123; status: 200, message: &#x27;新闻删除成功&#x27;, list: newsList, total: newsList.length &#125;&#125;)// 模拟一个 get 接口Mock.mock(&quot;/api/feedPost&quot;,&quot;post&quot;,function()&#123; console.log(&quot;post 拦截&quot;) //返回10条随机数据 return Mock.mock(&#123; &quot;data|10&quot;:[ &#123; name:&quot;@cname&quot;,//随即中文名 msg:&quot;@cparagraph(2,3)&quot;,//随机段落 date:&quot;@datetime&quot;,//随机日期 &#125; ] &#125;)&#125;); 步骤2：配置 main.js在main.js 中你需要 引入刚才创建的文件，并且有引入 axios，我们才能进行访问 12345678910111213// 在main.js中导入自定义mock文件import &#x27;../mock/index.js&#x27;; // 导入axios 没有./ (axios网络请求工具:1不依赖dom,2.前后端都可以用,3. 丰富拦截,扩展功能,4可封装,复用性强)import axios from &#x27;axios&#x27;; // 挂载到vue的全局(原型上),在每个组件都可以使用 ,prototype是固定的,$axios是自定义的Vue.prototype.$axios = axios; //给每个请求拦截一下，添加请求Token信息axios.interceptors.request.use(function(config) &#123; config.headers.Authorization = &#x27;Bearer &#x27; + localStorage.getItem(&quot;token&quot;) return config&#125;) 步骤3：组件中使用你可以在组件中通过 axios 对象，调用接口，例如： 123456789101112131415161718created() &#123; this.getFeed()&#125;,methods: &#123; getFeed() &#123; // 调用挂载在 Vm 上的 $axios 使用get方法，返回一个promise对象 this.$axios.get(&quot;/api/feed&quot;) .then(res =&gt; &#123; console.log(res.data) console.log(res.data.data[0].name) this.test = res.data.data[0].name &#125;) .catch(err =&gt; &#123; console.error(err) &#125;) &#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://example.com/tags/Vue/"},{"name":"MockJS","slug":"MockJS","permalink":"http://example.com/tags/MockJS/"}]},{"title":"前端性能优化","slug":"前端性能优化面试题_凯凯超人版本","date":"2023-03-19T15:51:03.000Z","updated":"2023-03-20T10:52:28.000Z","comments":true,"path":"2023/03/19/前端性能优化面试题_凯凯超人版本/","link":"","permalink":"http://example.com/2023/03/19/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/","excerpt":"","text":"前端性能优化考点1： CND面试题：CND的原理CND的基本原理是 （其和 DSN 的过程 有点关系） 在用户访问相对集中的地区和网络设置一些缓存服务器。 当用户访问网站时，利用全局的负载均衡技术将用户的访问指向距离最近的缓存服务器，由缓存服务器代替源站响应用户的访问请求。 CNAME: 在域名解析中，实际上解析出来的指定域名对应的 IP 地址，或者该域名的一个 CNAME，然后再根据这个CNAME来查找对应的 IP 地址。 其一般使用的场景为： 使用第三方 CDN 服务，比如你想开源一些项目，给被人用 使用 CDN 进行静态资源的缓存，例如可以将自己网站的静态资源放在 CDN上。 直播传送：CDN是支持流媒体传送的 考点2：懒加载例如网页延迟加载图片数据，是一种优化网页性能的方式。 其具体表现为： 如果使用图片的懒加载，就是在滚动屏幕之前，可视化区域之外的图片是不会进行加载的，再滚动屏幕到下方的时候才会加载。 这样可以减少服务器返回数据的负担，并且可以一定的提高用户体验，另外防止加载过多的图片而影响其他资源文件的加载。 面试题：懒加载实现的原理 面试题：懒加载和预加载的区别都是可以提高网页性能的方式，两个主要的区别是。 懒加载指的是在 长网页中延迟加载图片的时机，当用户需要访问的时候，再去加载。实现的原理看上面。并且其一定程度上可以缓解服务器的响应负担。 预加载指的是 所需的资源提前请求加载到本地，这样后面在需要用到的时候就直接从缓存中获取资源。通过预加载可以减少用户等待的时间。 比较常见的案例有，使用 js 中的 image 对象，通过对 image 对象来设置 src 属性，来实现图片的预加载。 考点3：回流(重排)和重绘面试题：那些情况可能会导致回流**回流（重排）指的是 渲染树（dom树）部分或者全部元素的尺寸、结构或者属性发生变化的时候，浏览器会重新渲染部分或者全部文档的过程。**简单的说就是，你做出了一些改变影响页面元素布局的DOM操作。 引起回流的操作有： - 页面的首次渲染、浏览器窗口大小变化 - 某个元素内容变化、某个元素的尺寸或者位置发生变化、某个元素的字体变化 - 激活CSS伪类 - 查询某些属性或者调用某些方法 - 添加或删除可见（也就是 display 不是 none）的 DOM 元素 在触发回流的时候，由于浏览器渲染页面时基于**流式布局**的，**所以会导致周围的DOM元素重新排列**，他的影响分为全局和局部两种 - 全局范围：从根节点开始，对整个 渲染树 进行重新布局 - 局部范围：从渲染树的某个部分或者一个渲染对象进行重新布局 ### 面试题：那些情况可能会导致重绘 **页面中某些元素的样式发生了变化，但是不会影响到文档流中元素的位置。浏览器单独对发生样式变化的元素进行重新绘制。** 引起重绘的操作有： color、background 相关属性：background-color、background-image等 outline 相关属性：outline-color、outline-width、text-decoration 另外还有 border-radius、visibility、box-shadow等 所以，当触发回流时，重排一定触发。重排触发，回流不一定触发的。 面试题：如何避免回流和重绘，从程序员和浏览器本身两方面都说一说？程序员如何避免主要有： 不要使用 table 布局，一个改动可能整个重新布局 使用 CSS 表达式 使用absolute 或者 fixed，让元素脱离文档流，那他们发生变化并不会影响到其他的元素 这个操作非常适用于 的动画，因为动画会触发很多dom操作 避免频繁的操作dom，可以创建一个文档片段 documentFragment，在它上面应用所有 DOM 操作，最后添加到文档中 将元素先设置为 display:none，操作结束后再把它显示出来。 **因为 display 为none 的元素上进行的 DOM 操作不会引发回流和重绘。** 配合浏览器 的 渲染队列机制，将DOM的多个读操作放在一起，多个写操作放在一起，读写操作不穿插写。 浏览器做出的努力： 浏览器针对于页面的回流和重绘，做出了自身的优化 — 渲染队列 面试题：documentFragment是什么？和直接操作 DOM 有什么区别？ 考点4：节流和防抖面试题：什么是防抖和节流？有什么区别？ 防抖：把中间的处理函数全部过滤掉了，只执行在规定时间内的最后一个事件 比如我设置一个时间例如 200ms 如果在200ms内没有再次触发事件，那么就执行对应的处理函数 如果在200ms内再次触发事件，那么当前的计时取消，重新开始计时 一般是定义一个 debounce 函数，其是由闭包进行实现的： 1234567891011// 这里的 fn 也就是 我们的 事件对应的处理函数function debounce(fn,delay)&#123; let timer = null //借助闭包 return function() &#123; if(timer)&#123;//进入该分支语句，说明当前正在一个计时过程中，并且又触发了相同事件。所以要取消当前的计时，重新开始计时 clearTimeout(timer) &#125; timer = setTimeout(fn,delay) &#125;&#125; 节流：中间的处理函数被时间限制，只能在一段时间中执行一次。但是只是减少了频率 一般是定义一个 throttle函数，其也是由闭包进行实现的： 123456789101112131415function throttle(fn,delay)&#123; let valid = true return function() &#123; if(!valid)&#123; //休息时间 暂不工作 return false &#125; // 工作时间，执行函数并且在间隔期内把状态位设为无效 valid = false setTimeout(() =&gt; &#123; fn() valid = true; &#125;, delay) &#125;&#125; 考点5：图片优化面试题：如何对项目中的图片进行优化？ 面试题：常见的图片格式和使用场景 考点6： WebPack 优化面试题：如何使用 WebPack 来优化前端性能？ 面试题：如何提高 WebPack 的构建速度","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前端性能","slug":"前端性能","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD/"}]},{"title":"python 处理 nii 数据 保存为png图片","slug":"python 处理 nii 数据 保存为png图片","date":"2022-04-28T07:30:01.000Z","updated":"2022-04-28T17:28:34.511Z","comments":true,"path":"2022/04/28/python 处理 nii 数据 保存为png图片/","link":"","permalink":"http://example.com/2022/04/28/python%20%E5%A4%84%E7%90%86%20nii%20%E6%95%B0%E6%8D%AE%20%E4%BF%9D%E5%AD%98%E4%B8%BApng%E5%9B%BE%E7%89%87/","excerpt":"","text":"@TOC nii 文件处理代码如下： 处理代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import numpy as npimport os # 遍历文件夹import nibabel as nib # nii格式一般都会用到这个包import imageio # 转换成图像from PIL import Imagenp.set_printoptions(threshold=np.inf)def nii_to_image(niifile): return 0filepath = &#x27;F:\\ISIC-2017\\img.nii&#x27; # 读取本代码同个文件夹下所有的nii格式的文件filenames = os.listdir(filepath)imgfile = &#x27;./&#x27;slice_trans = []for f in filenames: # 开始读取nii文件 s = f[-4:] # 获取文件的后缀名称 print(s) if s != &#x27;.nii&#x27;: # 文件不是 .nii为结尾的就跳过 continue s1 = f[:-4] # 读取 .nii 文件的 文件名称 如：img print(s1) imgfile_path = imgfile + s1 # ./img print(&quot;imgfile_path:&quot; + imgfile_path) img_path = os.path.join(filepath, f) # ./img/img.nii img = nib.load(img_path) # 读取nii print(&quot;img:&quot;) # print(img) # 里面一大堆数据 img_fdata = img.get_fdata() print(&quot;**************&quot;) print(&quot;**************&quot;) print(img) print(&quot;**************&quot;) print(&quot;**************&quot;) fname = f.replace(&#x27;.nii&#x27;, &#x27;&#x27;) # 去掉nii的后缀名 img_f_path = os.path.join(imgfile, fname) # ./img if not os.path.exists(img_f_path): # 创建nii对应的图像的文件夹 os.mkdir(img_f_path) # #开始转换为图像 if &#x27;.gz&#x27; in s1: (x, y, z, _) = img.shape print(&quot;img2:&quot;) print(img.shape) else: (x, y, z) = img.shape # 里面没有 .gz的文件 z是图像的序列 一共 89张 print(&quot;img3:&quot;) print(img.shape) # 例如：(512, 512, 89) for i in range(z): # z是图像的序列 silce = img_fdata[:, :, i] # 选择哪个方向的切片都可以 imageio.imwrite(os.path.join(img_f_path, &#x27;&#123;&#125;_mask.png&#x27;.format(i)), silce) img = Image.open(os.path.join(img_f_path, &#x27;&#123;&#125;_mask.png&#x27;.format(i))) print(&quot;save&quot;) img.save(os.path.join(img_f_path, &#x27;&#123;&#125;_mask.png&#x27;.format(i))) 处理结果一共89张。","categories":[{"name":"医学图像","slug":"医学图像","permalink":"http://example.com/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/"}],"tags":[{"name":"医学图像处理","slug":"医学图像处理","permalink":"http://example.com/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"事件脉络第一次2.25","slug":"事件脉络第一次2.25","date":"2022-02-25T13:00:00.000Z","updated":"2022-02-25T12:09:04.233Z","comments":true,"path":"2022/02/25/事件脉络第一次2.25/","link":"","permalink":"http://example.com/2022/02/25/%E4%BA%8B%E4%BB%B6%E8%84%89%E7%BB%9C%E7%AC%AC%E4%B8%80%E6%AC%A12.25/","excerpt":"","text":"事件脉络介绍来源： 当今时代可以说是信息爆炸的时代，大大小小的事情都会引发人们的关注，而百度是我们获取新闻的第一途径，但各个事件往往展现出的信息都非常杂乱，因此就衍生出了百度事件脉络这一板块 实际： 通过对特定事件名称的检索，得到该事件的脉络，自动追溯事件的发展过程，根据时间线对热点事件的来龙去脉进行全面了解。 输入： 关于某一事件的相关新闻集合，应该是利用文本聚类(搜索等)得到的新闻簇。 输出： 事件的脉络信息，换句话说就是：给出一个重要新闻的列表，这些重要的新闻涵盖了该事件的各个重要阶段的重要信息。 如右边的图 就可以清晰的看到俄乌局势昨天的发展阶段，也就是这个方向应该做到的基本效果。 如果用于开发的话，真实的接口应该返回如图类似的json数据，包括新闻的时间、标题和链接。 时间片聚类算法其主要的办法是 从新闻的外部属性（主要是分布事件和转载情况）进行分析。 其前提假设为：在事件有重要进展的时候，一定会有一些高质量新闻的跟进报道，而且越是重要的进展情况，其报道也会越多越集中。 如何寻找事件发展的主要阶段？使用时间片聚类的方法 ，来发现事件发展的主要阶段 + 对每一篇新闻，抽取新闻的发布时间，按照新闻的发布时间将一个新闻事件集合内的新闻进行排列并投影到时间轴上。（根据之前的假设，时间轴上一定会有一段新闻密集的地方） + 利用凝聚层次聚类方法，将时间轴分成若干个片段。将新闻聚类而分，这样我们才能明确时间的发展过程。提取每个过程的 确切新闻内容。 + 凝聚层次聚类的基本做法：其不需要指定划分的个数（因为我也不知道到底有几次发展阶段），把每篇新闻看成一个时间片段（其实是一个点），然后**每次合并距离最近的两个片段**，直到任意两个片段之间的距离都大于一个预先设定的阈值。 + 获取到时间发展过程后，则要在每个进展的新闻集合中，抽取一篇代表新闻 + 其具体的策略，可以根据具体的产品需求来定。一般考虑例如：新闻来源站点是否权威，新闻的发布时间（在同一个聚类内），该新闻是否有更多的转载等等。 + 如果要求更多媒体化，还可以从新闻集合中，抽取出相应的图片，视频等相关资源。 #### 存在的问题一：自然时间距离问题？ 对于新闻来说，由于新闻发布并不是在24小时内均匀分布的，所以我们认为：在新闻发布高峰期间隔1个小时，要比在新闻发布的低谷期间隔一个小时，造成的时间跨度更长。 **改进为：按照每半小时为一个小时间片，统计每个时间段内的新闻发布数，求出各个时间段新闻数占所有时间片新闻总数的比值，这个比值可以用来重新分配24小时的时间长度，计算“新闻时间距离”。** 这样的效果得到了：在0点至6点之间的1个小时，在“新闻时间距离”中只有半个小时，甚至更少，而在9：00~11：00期间的一个小时，相当于2~3个小时。 #### 存在的问题二：新闻集合的去噪 各媒体对事件跟进报道的时效性不一，比如同样的新闻内容，新华网的报道更具时效性，在当前20:00就发布了，而一些小的新闻站点，则可能要等到第二天的9:00才发布，这样就导致描述同一阶段的新闻，往往会被分到不同的阶段中去，这样就影响了时间片聚类的效果。 所以我们在进行时间片聚类之前，还进行了相似新闻的去重。 去噪的方法对新闻集合内的新闻，进行一次相似度，如果碰到文本相似度很高的新闻，则归档在一起，以最早的那篇新闻为代表新闻，参加时间片聚类。具体的做法是：按照新闻的发布时间由远及近的顺序，计算每篇新闻与之前的新闻的文本相似度，如果相似度太高，则认为可能是重复的内容，则把这篇新闻标记为更早的新闻的转载或者相近报道。 该方法总结本方法利用了新闻媒体对新闻事件的报道行为，来挖掘出新闻事件的发展阶段以及代表新闻，从而给用户提供简单明了的新闻事件脉络。主要利用了时间片聚类算法来自动将事件划分成若干个进展阶段，然后从各个进展阶段中，抽取出代表新闻。为了改善算法，还提出了一种“新闻时间距离”的度量方法；同时，还结合了文本内容分析的手段，来对新闻集合进行精简，去噪，改善脉络抽取的效果。 基于图结构方法通过构建图的方法，将子事件之间的关系转换为图中结点的关系，寻找关键结点，连接关键结点得到最终的事件脉络。 事件感知对微博数据过滤分析后，根据热点事件的关键字搜索数据库，筛选包含该关键字的微博。 首先对其进行文本预处理，根据中英文使用不同的工具或方法。预处理过程大致可包括，分词，去除停用词。 而后计算每条微博的 中每个关键词 的 TF-IDF 得分，将所有关键词的 TF-IDF 得分之和作为这条微博的 TF-IDF 得分。 然后进行排序，得分越高的与事件的相关度也就越高，从得到最后处理的库。 事件脉络呈现分为3个子模块，构建图，寻找关键微博，连接关键微博。 整体思路是，在无向图中寻找关键结点，即关键微博。再在有向图中连接关键结点，最终得到事件脉络。 如何构建图结构需要构建两个图，一个有向图和一个无向图。每个结点的权值，为该结点微博与事件关键字集合Q的余弦相似度。无向图用来表示微博之间文本内容的关系，计算边时，2条微博文本之间的余弦相似度大于 一个阈值时。就用一条无向边将对应的2个结点连接起来。 有向图用来表示微博之间的时间关系，按时间顺序连接微博结点。 如何选择关键结点如何选择关键结点 就是 如何寻找关键微博 其采用 加权相似度的方法来寻找 无向图中的关键结点。当 加权相似度越大时，表明这个结点对应的微博更具代表性，能够表示其领接结点对应微博的内容，即这个结点就是 图中的一个关键结点。 计算无向图中所有结点的加权相似度，选取其中加权相似度最大的结点作为一个关键结点。 之后采用迭代的过程，找到关键结点集合。 如何链接关键结点在有向图中，对于任意2个关键结点，如果本来就是邻接结点，则直接连接。 如果不是的话，就需要添加过渡结点。其应该满足添加的过渡结点的加权相似度之和达到最小， 如右边的公式， 最后得到连接关键结点的边集合，即关键结点的连接结果。 给定一个过渡结点，可以体现事件一定程度的多样化，使得内容看起来更加的连贯。 实验数据结果该论文爬取的数据集是 2014年 巴西世界杯的 推特数据，事件为7月14日 阿根廷与德国的实时球赛事件推特记录。大致能说清楚事件发展情况，并且存在一定的趣味事件。 但这里的趣味事件和整个事件发展，关系不大。 并且这个数据由于本身太过于口语化，所以用户情感比较明显，对整体的事件脉络是有干扰的。 方法总结这个方法在事件感知，对微博的处理方法过于单一，仅仅依靠微博中是否出现关键字来判断，过于片面。可能会漏掉一些有潜在关系的数据。 另外图求解关键结点和连接结点的复杂度理论上非常的高，实时性应该是比较差的。 另外这里只考虑到了文本属性，其他一些值的参考的评论、微博博主的权威值等其实都可以引入。 甚至是多模态的多媒体也值的参考。 后续的一些问题第一 如何评价事件脉络实验结果好坏？ 之前看的有一篇中文文档，他是采用召回率和准确率来定量的描述。 他根据正确人工拟定的事件脉络，统计他的时间日期个数和 算法命中的日期个数 比值为召回率；同理也可以计算出准确率。 另外也有采用人调查评价是否能明白事件经过的打分情况，主观成分较大。 第二 就是这个方向的整体思路不够清晰 有之前提到的 时间片聚类的算法，构造图算法 也有后续的多模考虑的 基于关键字，基于概率，基于主题的方法。 主体上是偏向于机器学习，图论，数据挖掘。 第三就是 新闻数据集的获取问题。 做新闻类的话，可能需要爬取一些权威性较高的平台。 另外 存在多媒体，新浪微博、百度新闻等 的所谓的数据流特征不太类似，不确定使用同种方法是不是都试用。","categories":[{"name":"研究课题-事件脉络","slug":"研究课题-事件脉络","permalink":"http://example.com/categories/%E7%A0%94%E7%A9%B6%E8%AF%BE%E9%A2%98-%E4%BA%8B%E4%BB%B6%E8%84%89%E7%BB%9C/"}],"tags":[{"name":"事件脉络","slug":"事件脉络","permalink":"http://example.com/tags/%E4%BA%8B%E4%BB%B6%E8%84%89%E7%BB%9C/"}]},{"title":"ResNet迁移学习 之 花图像分类","slug":"ResNet迁移学习 之 花图像分类","date":"2021-11-23T15:52:01.000Z","updated":"2021-11-26T13:25:48.163Z","comments":true,"path":"2021/11/23/ResNet迁移学习 之 花图像分类/","link":"","permalink":"http://example.com/2021/11/23/ResNet%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%20%E4%B9%8B%20%E8%8A%B1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/","excerpt":"","text":"@TOC迁移学习 (Transfer Learning) 是把已学训练好的模型参数用作新训练模型的起始参数. 迁移学习是深度学习中非常重要和常用的一个策略. 为什么使用迁移学习迁移学习 (Transfer Learning) 可以帮助我们得到更好的结果. 当我们手上的数据比较少的时候,训练非常容易造成过拟合的现象。使用迁移学习可以帮助我们通过更少的训练数据达到更好的效果。使得模型的泛化能力更强, 训练过程更稳定。 迁移学习 (Transfer Learning) 可以帮助我们节省时间。通过迁移学习，利用前人花大量时间训练好的参数，能帮助我们在模型的训练上节省大把的时间。 常见的迁移学习 backbonePytorch 迁移学习官网 API VGG ResNet SqueezeNet DenseNet Inception GoogleNet 中的 Inception结构 GoogLeNet ShuffleNet MobileNet 冻层实现123456789101112def set_parameter_requires_grad(model, feature_extracting): &#x27;&#x27;&#x27; 是否保留梯度, 实现冻层 保留梯度也就是冻结层 :param model:模型 :param feature_extracting:是否冻层 :return:无返回值 &#x27;&#x27;&#x27; if feature_extracting: # 如果冻层 for param in model.parameters(): # 遍历每个权重参数 param.requires_grad = False # param.requires_grad = False的作用是: # 屏蔽预训练模型的权重。 模型初始化ResNet模型的初始化，是冻结全连接层之前所有的层参数，并将全连接层重写为符合自己数据集的输出。例如：花图像数据集一共有102个类，所以最后的输出为102个。12345678910111213141516171819202122232425262728293031323334353637def initialize_model(model_name, num_classes, feature_extract, use_pretrained_state=False): &quot;&quot;&quot; 初始化模型 :param model_name: 模型名字 :param num_classes: 类别数 :param feature_extract: 是否部冻层 :param use_pretrained_state: 是否下载模型 为True的话为自动下载加载到模型内 为False的话就自己加载模型 :return: 返回模型 &quot;&quot;&quot; model_ft = None input_size = 0 if model_name == &quot;resnet&quot;: &quot;&quot;&quot; 原来Resnet152模型结构中最后两层为： (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=2048, out_features=1000, bias=True) &quot;&quot;&quot; model_ft = models.resnet152(pretrained=use_pretrained_state) # 下载参数 False就不下载 需要下面手动加 model_ft.load_state_dict(torch.load(&#x27;./dataset/pth/resnet152-b121ed2d.pth&#x27;)) # 手动加 模型参数 set_parameter_requires_grad(model_ft, feature_extract) # 冻层 # 修改全连接层 num_ftrs = model_ft.fc.in_features # 获取resnet最后全连接层输入的维度 2048，默认解冻 model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes), nn.LogSoftmax(dim=1)) &quot;&quot;&quot; 经过修改线性层输出的维度之后变为： (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Sequential( (0): Linear(in_features=2048, out_features=102, bias=True) (1): LogSoftmax() ) &quot;&quot;&quot; input_size = 224 print(model_ft) return model_ft, input_size 获取需更新参数1234567891011121314151617181920def parameter_to_update(model): &#x27;&#x27;&#x27; 获取需要更新的参数 :param model: 模型 :return: 需要更新的参数列表 &#x27;&#x27;&#x27; # 是否训练所有层 params_to_update = model.parameters() print(&quot;Params to learn:&quot;) if feature_extract: params_to_update = [] for name, param in model.named_parameters(): if param.requires_grad: params_to_update.append(param) print(&quot;\\t&quot;, name) else: for name, param in model.named_parameters(): if param.requires_grad: print(&quot;\\t&quot;, name) return params_to_update 训练模型里面有一些API 不明白 torch.max(outputs, 1) optimizer.state_dict() model.load_state_dict(best_model_wts) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105def train_model(model, dataloaders, criterion, optimizer, filename, num_epochs): &#x27;&#x27;&#x27; 训练模型 :param model: 引入的权重模型 :param dataloaders: 导入数据 格式为dataloaders :param criterion: 损失函数 :param optimizer: 优化器 :param filename: 模型名称（地址） :param num_epochs: epoch数 :return:model, val_acc_history, train_acc_history, valid_losses, train_losses, LRs &#x27;&#x27;&#x27; # 获取起始时间 start = time.time() # 用于GPU model.to(device) # 初始化参数 best_acc = 0 val_acc_history = [] train_acc_history = [] train_loss = [] valid_loss = [] LRs = [optimizer.param_groups[0][&#x27;lr&#x27;]] ## ？？？ best_model_wts = copy.deepcopy(model.state_dict()) # 保存最好的模型权重参数 for epoch in tqdm(range(num_epochs)): print(&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;.format(epoch, num_epochs - 1)) print(&#x27;-&#x27; * 20) # 训练和验证 for phase in [&#x27;train&#x27;, &#x27;valid&#x27;]: if phase == &#x27;train&#x27;: model.train() # 训练 else: model.eval() # 验证 running_loss = 0.0 running_corrects = 0 # 遍历数据 for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) # inputs shape : torch.Size([16, 3, 224, 224]) labels = labels.to(device) # 梯度清零 optimizer.zero_grad() # 只有训练的时候计算和更新梯度 with torch.set_grad_enabled(phase == &#x27;train&#x27;): outputs = model(inputs) # torch.Size([16, 102]) # https://www.jianshu.com/p/3ed11362b54f _, preds = torch.max(outputs, 1) # dim是max函数索引的维度0/1，0是每列的最大值，1是每行的最大值 print(&quot;preds&quot;, preds) # 计算损失 loss = criterion(outputs, labels) # 训练阶段更新权重 if phase == &#x27;train&#x27;: loss.backward() optimizer.step() # 计算损失 running_loss += loss.item() * inputs.size(0) # size 表示 inputs 的形状的 第一个也就是 batch 16 running_corrects += torch.sum(preds == labels.data) # 预测和实际标签一样就算上 epoch_loss = running_loss / len(dataloaders[phase].dataset) # 这个loss的定义 ？？？ epoch_acc = running_corrects.double() / len( dataloaders[phase].dataset) # ??? dataloaders[phase].dataset 为什么有dataset属性 是啥呢 time_spend = time.time() - start # 所花费的时间 start是初始开始时间 print(&#x27;Time spend &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(time_spend // 60, time_spend % 60)) print(&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;.format(phase, epoch_loss, epoch_acc)) # 得到最好那次的模型 if phase == &#x27;valid&#x27; and epoch_acc &gt; best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) # copy当前最好模型的所有权重 state = &#123; &#x27;state_dict&#x27;: model.state_dict(), # 当前最好模型的所有权重 &#x27;best_acc&#x27;: best_acc, # 最好的准确率 （测试集上） &#x27;optimizer&#x27;: optimizer.state_dict(), # https://www.cnblogs.com/liujianing/p/13428387.html &#125; torch.save(state, filename) # filename 保存的模型名（其实是地址） if phase == &#x27;valid&#x27;: val_acc_history.append(epoch_acc) valid_loss.append(epoch_loss) scheduler.step(epoch_loss) # ??? 更新权重参数 if phase == &#x27;train&#x27;: train_acc_history.append(epoch_acc) train_loss.append(epoch_loss) print(&#x27;Optimizer learning rate : &#123;:.7f&#125;&#x27;.format(optimizer.param_groups[0][&#x27;lr&#x27;])) LRs.append(optimizer.param_groups[0][&#x27;lr&#x27;]) # 添加此时的学习率 time_spend_all = time.time() - start # 所花费的时间 start是初始开始时间 print(&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(time_spend_all // 60, time_spend_all % 60)) print(&#x27;Best val Acc: &#123;:4f&#125;&#x27;.format(best_acc)) # 训练完后用最好的一次当做模型最终的结果 model.load_state_dict(best_model_wts) # model加载 可以查看 https://www.jianshu.com/p/60fc57e19615 # 返回 return model, val_acc_history, train_acc_history, valid_loss, train_loss, LRs 如果是仅仅微调所有参数的话123456789101112131415161718192021222324252627# 有全体参数的情况下 微调训练全部层def train_all_layers(num_epochs): # 保存文件的名字 file_path = &#x27;./dataset/pth/resnet152_fc.pth&#x27; # 加载模型 checkpoint = torch.load(file_path) best_acc = checkpoint[&#x27;best_acc&#x27;] model_ft = models.resnet152(pretrained=False) model_ft.load_state_dict(checkpoint[&#x27;state_dict&#x27;]) # 将所有参数的requires_grad 设为True 微调 训练所有层 for param in model_ft.parameters(): param.requires_grad = True optimizer = torch.optim.Adam(model_ft.parameters(), lr=1e-4) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1) # 损失函数 criterion = nn.NLLLoss() optimizer.load_state_dict(checkpoint[&#x27;optimizer&#x27;]) model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(model_ft, dataloaders, criterion, optimizer, num_epoch=num_epochs, filename=&#x27;resnet152_all_layers.pth&#x27;) 用于最后模型测试1234567891011121314151617181920212223242526272829303132333435363738def fortest(): # 保存文件的名字 file_path = &#x27;./dataset/pth/resnet152_fc.pth&#x27; # 加载模型 model_ft = torch.load(file_path) # GPU模式 model_ft = model_ft.to(device) # 得到一个batch的测试数据 dataiter = iter(dataloaders[&#x27;valid&#x27;]) images, labels = dataiter.next() model_ft.eval() train_on_gpu = torch.cuda.is_available() if train_on_gpu: output = model_ft(images.cuda()) else: output = model_ft(images) _, preds_tensor = torch.max(output, 1) preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy()) print(preds) # 结果展示 fig = plt.figure(figsize=(20, 20)) columns = 4 rows = 4 for idx in range(columns * rows): ax = fig.add_subplot(rows, columns, idx + 1, xticks=[], yticks=[]) plt.imshow(im_convert(images[idx])) ax.set_title(&quot;&#123;&#125; (&#123;&#125;)&quot;.format(cat_to_name[str(preds[idx])], cat_to_name[str(labels[idx].item())]), color=(&quot;green&quot; if cat_to_name[str(preds[idx])] == cat_to_name[str(labels[idx].item())] else &quot;red&quot;)) plt.savefig(&#x27;./img_show.png&#x27;) plt.close(fig) 获取数据一般这个部分 不同数据集是不一样的。但我们需要的 数据一定是 一个 dataloader （同时其一般为 字典格式）例如： data_loader = {“train”: train_loader, “valid”: test_loader} 如上面所示，所以我们一般数据集是划分为 训练集、验证集、测试集的。（但训练一般前两者即可）。 在花朵任务内： 123# 创建数据image_datasets, dataloaders, dataset_sizes, class_names = create_dataset(batch_size=batch_size) 定义数据预处理 123456789101112131415161718192021222324252627# 图片路径data_dir = &#x27;./dataset/flower_data/&#x27;train_dir = data_dir + &#x27;/train&#x27;valid_dir = data_dir + &#x27;/valid&#x27;# 读取标签对应的实际名字with open(&#x27;./dataset/flower_data/cat_to_name.json&#x27;, &#x27;r&#x27;) as f: cat_to_name = json.load(f)# 数据预处理data_transforms = &#123; &#x27;train&#x27;: transforms.Compose([transforms.RandomRotation(45), # 随机旋转，-45到45度之间随机选 transforms.CenterCrop(224), # 从中心开始裁剪 transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转 选择一个概率概率 transforms.RandomVerticalFlip(p=0.5), # 随机垂直翻转 transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1), # 参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相 transforms.RandomGrayscale(p=0.025), # 概率转换成灰度率，3通道就是R=G=B transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 均值，标准差 ]), &#x27;valid&#x27;: transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),&#125; create_dataset方法 1234567891011121314151617181920212223242526# # 数据集创建初始化def create_dataset(batch_size): # 数据创建初始化 # 这就类似于一个字典 &#123;&#x27;train&#x27;:./dataset/flower_data/train....,&#x27;valid&#x27;:......&#125; image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [&#x27;train&#x27;, &#x27;valid&#x27;]&#125; # 查看一下 image_datasets 的内容 print(&quot;image_datasets&quot;, image_datasets) # torch.utils.data.DataLoader使用方法 # 数据加载器，结合了数据集和取样器，并且可以提供多个线程处理数据集。 # 在训练模型时使用到此函数，用来把训练数据分成多个小组，此函数每次抛出一组数据。直至把所有的数据都抛出。就是做一个数据的初始化。 # 这里同样是生成一个字典格式 dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in [&#x27;train&#x27;, &#x27;valid&#x27;]&#125; # 查看一下dataloaders 的内容 print(&quot;dataloaders&quot;, dataloaders) # 字典形式 dataset_sizes = &#123;x: len(image_datasets[x]) for x in [&#x27;train&#x27;, &#x27;valid&#x27;]&#125; # 查看一下 dataset_sizes 的内容 print(&quot;dataset_sizes&quot;, dataset_sizes) # 返回一个list类型 class_names = image_datasets[&#x27;train&#x27;].classes return image_datasets, dataloaders, dataset_sizes, class_names 最终Main调用顺序配置图片路径12345678# 图片路径data_dir = &#x27;./dataset/flower_data/&#x27;train_dir = data_dir + &#x27;/train&#x27;valid_dir = data_dir + &#x27;/valid&#x27;# 读取标签对应的实际名字with open(&#x27;./dataset/flower_data/cat_to_name.json&#x27;, &#x27;r&#x27;) as f: cat_to_name = json.load(f) 数据预处理划分训练集、验证集、测试集等。并做图像增强。 123456789101112131415161718# 数据预处理data_transforms = &#123; &#x27;train&#x27;: transforms.Compose([transforms.RandomRotation(45), # 随机旋转，-45到45度之间随机选 transforms.CenterCrop(224), # 从中心开始裁剪 transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转 选择一个概率概率 transforms.RandomVerticalFlip(p=0.5), # 随机垂直翻转 transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1), # 参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相 transforms.RandomGrayscale(p=0.025), # 概率转换成灰度率，3通道就是R=G=B transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 均值，标准差 ]), &#x27;valid&#x27;: transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),&#125; 配置超参数123456# 超参数配置# 是否用人家训练好的特征来做,True 为 不改变权重参数也就是冻层，False 为自己重新训练所有层的权重参数feature_extract = True # 冻层num_classes = 102 # 输出的类别数batch_size = 16 # 一次训练的样本数目num_epochs = 20 创建数据 DataLoader一般这都是一个整体方法。这里 分来开写了。 12# 创建数据image_datasets, dataloaders, dataset_sizes, class_names = create_dataset(batch_size=batch_size) 获取初始化ResNet模型冻结了最后一层全连接层外的所有层参数，并对最后一层线性层修改为自己的数据集样本个数输出。 12345678## 获取模型 模型冻结了部分层，最后一层线性层修改resnet152 = initialize_model( model_name=&#x27;resnet&#x27;, num_classes=num_classes, feature_extract=feature_extract, use_pretrained=False) 是否使用GPU训练1234567# 是否使用GPU训练if not torch.cuda.is_available(): print(&#x27;CUDA is not available. Training on CPU ...&#x27;)else: print(&#x27;CUDA is available! Training on GPU ...&#x27;)device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) 模型训练属性配置哪些参数需要被训练12# 训练参数params_to_update = parameter_to_update(resnet152) 优化器、衰减器、损失函数12345# 优化器设置optimizer = torch.optim.Adam(params_to_update, lr=0.01)scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1) # 学习率每7个epoch衰减成原来的1/10# 最后一层已经LogSoftmax()了，所以不能nn.CrossEntropyLoss()来计算了，nn.CrossEntropyLoss()相当于logSoftmax()和nn.NLLLoss()整合criterion = nn.NLLLoss() 开始ResNet预训练（最后一层线性训练）123456# # 开始训练model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(resnet152, dataloaders, criterion, optimizer, num_epoch=num_epochs, filename=&quot;resnet152_fc.pth&quot;) 微调所有ResNet参数训练1train_all_layers(num_epochs) 评估模型结果1fortest() 整体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436from tensorboard import summaryfrom torchvision import transforms, models, datasetsfrom torch.utils.data import DataLoaderimport osimport torch.nn as nnimport torchimport numpy as npimport jsonimport matplotlib.pyplot as pltimport timeimport copyimport jsonfrom PIL import Imageimport tqdmdef im_convert(tensor): # 展示数据 image = tensor.to(&quot;cpu&quot;).clone().detach() # 方法解读 https://zhuanlan.zhihu.com/p/148061684 # 结论：根据上述例1~3可知，np.squeeze（）函数可以删除数组形状中的单维度条目， # 即把shape中为1的维度去掉，但是对非单维的维度不起作用。 image = image.numpy().squeeze() # 方法解读 https://blog.csdn.net/qq_38675570/article/details/80048650 # 这里用np.transpose（img，(1,2,0)） # 将图片的格式由（channels,imagesize,imagesize）转化为（imagesize,imagesize,channels）,这样plt.show()就可以显示图片了。 # pytorch中 最开始的应该是 维度 image = image.transpose(1, 2, 0) # 乘以标准差 加上 均值 就是 原来的图片样本值 image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406)) # ？？？ image = image.clip(0, 1) return image# 展示图片效果def show_image(): fig = plt.figure(figsize=(20, 12)) columns = 4 rows = 2 # 为什么加了一个迭代器就这样了 dataiter = iter(dataloaders[&#x27;valid&#x27;]) inputs, classes = dataiter.next() for idx in range(columns * rows): ax = fig.add_subplot(rows, columns, idx + 1, xticks=[], yticks=[]) ax.set_title(cat_to_name[str(int(class_names[classes[idx]]))]) # 为什么还要 先转int类型？？？ plt.imshow(im_convert(inputs[idx])) # 图片转换显示 plt.show() # 显示整个图# 原版的数据获取 mnt# def get_data():# &quot;&quot;&quot;获取数据&quot;&quot;&quot;## # 获取测试集# train = torchvision.datasets.CIFAR100(root=&quot;./mnt&quot;, train=True, download=True,# transform=torchvision.transforms.Compose([# torchvision.transforms.ToTensor(), # 转换成张量# torchvision.transforms.Normalize((0.1307,), (0.3081,)) # 标准化# ]))# train_loader = DataLoader(train, batch_size=batch_size) # 分割测试集## # 获取测试集# test = torchvision.datasets.CIFAR100(root=&quot;./mnt&quot;, train=False, download=True,# transform=torchvision.transforms.Compose([# torchvision.transforms.ToTensor(), # 转换成张量# torchvision.transforms.Normalize((0.1307,), (0.3081,)) # 标准化# ]))# test_loader = DataLoader(test, batch_size=batch_size) # 分割训练## data_loader = &#123;&quot;train&quot;: train_loader, &quot;valid&quot;: test_loader&#125;## # 返回分割好的训练集和测试集# return data_loader# # 数据集创建初始化def create_dataset(batch_size): # 数据创建初始化 # 这就类似于一个字典 &#123;&#x27;train&#x27;:./dataset/flower_data/train....,&#x27;valid&#x27;:......&#125; image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [&#x27;train&#x27;, &#x27;valid&#x27;]&#125; # 查看一下 image_datasets 的内容 print(&quot;image_datasets&quot;, image_datasets) # torch.utils.data.DataLoader使用方法 # 数据加载器，结合了数据集和取样器，并且可以提供多个线程处理数据集。 # 在训练模型时使用到此函数，用来把训练数据分成多个小组，此函数每次抛出一组数据。直至把所有的数据都抛出。就是做一个数据的初始化。 # 这里同样是生成一个字典格式 dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in [&#x27;train&#x27;, &#x27;valid&#x27;]&#125; # 查看一下dataloaders 的内容 print(&quot;dataloaders&quot;, dataloaders) # 字典形式 dataset_sizes = &#123;x: len(image_datasets[x]) for x in [&#x27;train&#x27;, &#x27;valid&#x27;]&#125; # 查看一下 dataset_sizes 的内容 print(&quot;dataset_sizes&quot;, dataset_sizes) # 返回一个list类型 class_names = image_datasets[&#x27;train&#x27;].classes return image_datasets, dataloaders, dataset_sizes, class_namesdef set_parameter_requires_grad(model, feature_extracting): &#x27;&#x27;&#x27; 是否保留梯度, 实现冻层 保留梯度也就是冻结层 :param model:模型 :param feature_extracting:是否冻层 :return:无返回值 &#x27;&#x27;&#x27; if feature_extracting: # 如果冻层 for param in model.parameters(): # 遍历每个权重参数 param.requires_grad = False # param.requires_grad = False的作用是: # 屏蔽预训练模型的权重。def initialize_model(model_name, num_classes, feature_extract, use_pretrained_state=False): &quot;&quot;&quot; 初始化模型 :param model_name: 模型名字 :param num_classes: 类别数 :param feature_extract: 是否部冻层 :param use_pretrained_state: 是否下载模型 为True的话为自动下载加载到模型内 为False的话就自己加载模型 :return: 返回模型 &quot;&quot;&quot; model_ft = None input_size = 0 if model_name == &quot;resnet&quot;: &quot;&quot;&quot; 原来Resnet152模型结构中最后两层为： (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=2048, out_features=1000, bias=True) &quot;&quot;&quot; model_ft = models.resnet152(pretrained=use_pretrained_state) # 下载参数 False就不下载 需要下面手动加 model_ft.load_state_dict(torch.load(&#x27;./dataset/pth/resnet152-b121ed2d.pth&#x27;)) # 手动加 模型参数 set_parameter_requires_grad(model_ft, feature_extract) # 冻层 # 修改全连接层 num_ftrs = model_ft.fc.in_features # 获取resnet最后全连接层输入的维度 2048 model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes), nn.LogSoftmax(dim=1)) &quot;&quot;&quot; 经过修改线性层输出的维度之后变为： (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Sequential( (0): Linear(in_features=2048, out_features=102, bias=True) (1): LogSoftmax() ) &quot;&quot;&quot; input_size = 224 print(model_ft) return model_ft, input_sizedef parameter_to_update(model): &#x27;&#x27;&#x27; 获取需要更新的参数 :param model: 模型 :return: 需要更新的参数列表 &#x27;&#x27;&#x27; # 是否训练所有层 params_to_update = model.parameters() print(&quot;Params to learn:&quot;) if feature_extract: params_to_update = [] for name, param in model.named_parameters(): if param.requires_grad: params_to_update.append(param) print(&quot;\\t&quot;, name) else: for name, param in model.named_parameters(): if param.requires_grad: print(&quot;\\t&quot;, name) return params_to_updatedef train_model(model, dataloaders, criterion, optimizer, filename, num_epochs): &#x27;&#x27;&#x27; 训练模型 :param model: 引入的权重模型 :param dataloaders: 导入数据 格式为dataloaders :param criterion: 损失函数 :param optimizer: 优化器 :param filename: 模型名称（地址） :param num_epochs: epoch数 :return:model, val_acc_history, train_acc_history, valid_losses, train_losses, LRs &#x27;&#x27;&#x27; # 获取起始时间 start = time.time() # 用于GPU model.to(device) # 初始化参数 best_acc = 0 val_acc_history = [] train_acc_history = [] train_loss = [] valid_loss = [] LRs = [optimizer.param_groups[0][&#x27;lr&#x27;]] ## ？？？ best_model_wts = copy.deepcopy(model.state_dict()) # 保存最好的模型权重参数 for epoch in tqdm(range(num_epochs)): print(&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;.format(epoch, num_epochs - 1)) print(&#x27;-&#x27; * 20) # 训练和验证 for phase in [&#x27;train&#x27;, &#x27;valid&#x27;]: if phase == &#x27;train&#x27;: model.train() # 训练 else: model.eval() # 验证 running_loss = 0.0 running_corrects = 0 # 遍历数据 for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) # inputs shape : torch.Size([16, 3, 224, 224]) labels = labels.to(device) # 梯度清零 optimizer.zero_grad() # 只有训练的时候计算和更新梯度 with torch.set_grad_enabled(phase == &#x27;train&#x27;): outputs = model(inputs) # torch.Size([16, 102]) # https://www.jianshu.com/p/3ed11362b54f _, preds = torch.max(outputs, 1) # dim是max函数索引的维度0/1，0是每列的最大值，1是每行的最大值 print(&quot;preds&quot;, preds) # 计算损失 loss = criterion(outputs, labels) # 训练阶段更新权重 if phase == &#x27;train&#x27;: loss.backward() optimizer.step() # 计算损失 running_loss += loss.item() * inputs.size(0) # size 表示 inputs 的形状的 第一个也就是 batch 16 running_corrects += torch.sum(preds == labels.data) # 预测和实际标签一样就算上 epoch_loss = running_loss / len(dataloaders[phase].dataset) # 这个loss的定义 ？？？ epoch_acc = running_corrects.double() / len( dataloaders[phase].dataset) # ??? dataloaders[phase].dataset 为什么有dataset属性 是啥呢 time_spend = time.time() - start # 所花费的时间 start是初始开始时间 print(&#x27;Time spend &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(time_spend // 60, time_spend % 60)) print(&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;.format(phase, epoch_loss, epoch_acc)) # 得到最好那次的模型 if phase == &#x27;valid&#x27; and epoch_acc &gt; best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) # copy当前最好模型的所有权重 state = &#123; &#x27;state_dict&#x27;: model.state_dict(), # 当前最好模型的所有权重 &#x27;best_acc&#x27;: best_acc, # 最好的准确率 （测试集上） &#x27;optimizer&#x27;: optimizer.state_dict(), # https://www.cnblogs.com/liujianing/p/13428387.html &#125; torch.save(state, filename) # filename 保存的模型名（其实是地址） if phase == &#x27;valid&#x27;: val_acc_history.append(epoch_acc) valid_loss.append(epoch_loss) scheduler.step(epoch_loss) # ??? 更新权重参数 if phase == &#x27;train&#x27;: train_acc_history.append(epoch_acc) train_loss.append(epoch_loss) print(&#x27;Optimizer learning rate : &#123;:.7f&#125;&#x27;.format(optimizer.param_groups[0][&#x27;lr&#x27;])) LRs.append(optimizer.param_groups[0][&#x27;lr&#x27;]) # 添加此时的学习率 time_spend_all = time.time() - start # 所花费的时间 start是初始开始时间 print(&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(time_spend_all // 60, time_spend_all % 60)) print(&#x27;Best val Acc: &#123;:4f&#125;&#x27;.format(best_acc)) # 训练完后用最好的一次当做模型最终的结果 model.load_state_dict(best_model_wts) # model加载 可以查看 https://www.jianshu.com/p/60fc57e19615 # 返回 return model, val_acc_history, train_acc_history, valid_loss, train_loss, LRs# 有全体参数的情况下 微调训练全部层def train_all_layers(num_epochs): # 保存文件的名字 file_path = &#x27;./dataset/pth/resnet152_fc.pth&#x27; # 加载模型 checkpoint = torch.load(file_path) best_acc = checkpoint[&#x27;best_acc&#x27;] model_ft = models.resnet152(pretrained=False) model_ft.load_state_dict(checkpoint[&#x27;state_dict&#x27;]) # 将所有参数的requires_grad 设为True 微调 训练所有层 for param in model_ft.parameters(): param.requires_grad = True optimizer = torch.optim.Adam(model_ft.parameters(), lr=1e-4) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1) # 损失函数 criterion = nn.NLLLoss() optimizer.load_state_dict(checkpoint[&#x27;optimizer&#x27;]) model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(model_ft, dataloaders, criterion, optimizer, num_epoch=num_epochs, filename=&#x27;resnet152_all_layers.pth&#x27;)def fortest(): # 保存文件的名字 file_path = &#x27;./dataset/pth/resnet152_fc.pth&#x27; # 加载模型 model_ft = torch.load(file_path) # GPU模式 model_ft = model_ft.to(device) # 得到一个batch的测试数据 dataiter = iter(dataloaders[&#x27;valid&#x27;]) images, labels = dataiter.next() model_ft.eval() train_on_gpu = torch.cuda.is_available() if train_on_gpu: output = model_ft(images.cuda()) else: output = model_ft(images) _, preds_tensor = torch.max(output, 1) preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy()) print(preds) # 结果展示 fig = plt.figure(figsize=(20, 20)) columns = 4 rows = 4 for idx in range(columns * rows): ax = fig.add_subplot(rows, columns, idx + 1, xticks=[], yticks=[]) plt.imshow(im_convert(images[idx])) ax.set_title(&quot;&#123;&#125; (&#123;&#125;)&quot;.format(cat_to_name[str(preds[idx])], cat_to_name[str(labels[idx].item())]), color=(&quot;green&quot; if cat_to_name[str(preds[idx])] == cat_to_name[str(labels[idx].item())] else &quot;red&quot;)) plt.savefig(&#x27;./img_show.png&#x27;) plt.close(fig)if __name__ == &#x27;__main__&#x27;: plt.switch_backend(&#x27;agg&#x27;) &#x27;&#x27;&#x27; 配置图片路径以及数据预处理 &#x27;&#x27;&#x27; # 图片路径 data_dir = &#x27;./dataset/flower_data/&#x27; train_dir = data_dir + &#x27;/train&#x27; valid_dir = data_dir + &#x27;/valid&#x27; # 读取标签对应的实际名字 with open(&#x27;./dataset/flower_data/cat_to_name.json&#x27;, &#x27;r&#x27;) as f: cat_to_name = json.load(f) # 数据预处理 data_transforms = &#123; &#x27;train&#x27;: transforms.Compose([transforms.RandomRotation(45), # 随机旋转，-45到45度之间随机选 transforms.CenterCrop(224), # 从中心开始裁剪 transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转 选择一个概率概率 transforms.RandomVerticalFlip(p=0.5), # 随机垂直翻转 transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1), # 参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相 transforms.RandomGrayscale(p=0.025), # 概率转换成灰度率，3通道就是R=G=B transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 均值，标准差 ]), &#x27;valid&#x27;: transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), &#125; # 超参数配置 # 是否用人家训练好的特征来做,True 为 不改变权重参数也就是冻层，False 为自己重新训练所有层的权重参数 feature_extract = True # 冻层 num_classes = 102 # 输出的类别数 batch_size = 16 # 一次训练的样本数目 num_epochs = 20 # 创建数据 image_datasets, dataloaders, dataset_sizes, class_names = create_dataset(batch_size=batch_size) ## 获取模型 模型冻结了部分层，最后一层线性层修改 resnet152 = initialize_model( model_name=&#x27;resnet&#x27;, num_classes=num_classes, feature_extract=feature_extract, use_pretrained=False ) # 是否使用GPU训练 if not torch.cuda.is_available(): print(&#x27;CUDA is not available. Training on CPU ...&#x27;) else: print(&#x27;CUDA is available! Training on GPU ...&#x27;) device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) # 输出网络结构 print(summary(resnet152, (3, 32, 32))) # 训练参数 params_to_update = parameter_to_update(resnet152) # model_ft = model_ft.to(device) # 优化器设置 optimizer = torch.optim.Adam(params_to_update, lr=0.01) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1) # 学习率每7个epoch衰减成原来的1/10 # 最后一层已经LogSoftmax()了，所以不能nn.CrossEntropyLoss()来计算了，nn.CrossEntropyLoss()相当于logSoftmax()和nn.NLLLoss()整合 criterion = nn.NLLLoss() # # # 开始训练 model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(resnet152, dataloaders, criterion, optimizer, num_epoch=num_epochs, filename=&quot;resnet152_fc.pth&quot;) train_all_layers(num_epochs) # 评估模型结果 fortest() 博客参考PyTorch一小时掌握之ResNet迁移学习篇","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"ResNet","slug":"ResNet","permalink":"http://example.com/tags/ResNet/"},{"name":"迁移学习","slug":"迁移学习","permalink":"http://example.com/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"}]},{"title":"ResNet","slug":"ResNet","date":"2021-11-20T15:52:01.000Z","updated":"2021-11-26T13:26:02.431Z","comments":true,"path":"2021/11/20/ResNet/","link":"","permalink":"http://example.com/2021/11/20/ResNet/","excerpt":"","text":"@TOC ResNet解决 网络退化问题从经验来看，网络的深度对模型的性能至关重要，当增加网络层数后，网络可以进行更加复杂的特征模式的提取，所以当模型更深时理论上可以取得更好的结果。但研究表明，加深网络深度，会出现网络准确度 饱和甚至下降的情况，如下图1所示。 这个现象被称为 网络退化现象 那网络退化问题是过拟合导致的么？当然不是，因为网络越深理论上提取特征的能力越强，越不容易过拟合。如上图1所示，56层的网络误差整体都比26层的高。 所以其从本质上看，其实是模型深度越大，其训练不动的情况。换句话说他可能存在一定的梯度消失问题，导致高深度网络难以训练。也就是，现在的网络训练方式肯定有点问题，让深度网络很难的反向传播找到一组很好的参数。 ResNet 残差学习其实网络退化的现象可以通俗的理解为，一个小孩报了更多的班，然而成绩还下降了。我们的目的应该是最起码报的班可能没作用，但是不至于成绩还下降了。 基于这个想法，现在我们有一个浅层网络，我们想通过堆积更多的层次来建立深层网络，一个极端的情况就是这些新的层可能作用都不起，仅仅复制了浅层网络的特征（也就是不至于退步），这样的新层可以被称为 恒等映射 Identity mapping 在ResNet中，何大佬想到了利用之前的 机器学习的残差 和 跳跃（短路）连接 来实现一种新的结构。 机器学习的残差，其实就是预测值和标签值之间的距离。我们的目的其实是让预测毕竟真实的标签值。如下图2所示，大括号的部分就是所谓的残差。 何大佬的具体想法是，对于一个堆集层结构。当输入为 $x$ 时其学习到的特征记作 $H(x)$ ，而我们要 学习的部分为 残差 $F(x) = H(x)-x$，这样原始的学习特征为 $F(x)+x$。 为什么这么设计？ 因为残差学习相比原始特征的直接学习容易得多。 如下图3所示，为残差结构：当残差为0时，此时堆积层仅仅做了恒等映射，至少网络性能不会下降，实际上残差不会为0，这也会使得堆积层在输入特征基础上学习到新的特征，从而拥有更好的性能。 为什么残差学习更容易？ ResNet的网络结构ResNet网络是参考了 VGG19 网络，在其基础上进行了修改，并通过短路机制加入了残差单元，如图4所示。变化主要体现在 ResNet 直接使用 stride=2 的卷积做下采样，并且用 global average pool 层替换了全连接层。 ResNet 的一个重要设计原则是：当 feature map 大小降低一半时，feature map的数量增加一倍，这保持了网络层的复杂度。从图4中可以看到，ResNet相比普通网络每两层间增加了短路机制，这就形成了残差学习，其中虚线表示feature map数量发生了改变。图4展示的34-layer的ResNet，还可以构建更深的网络如表1所示。从表1中可以看到，对于18-layer和34-layer的ResNet，其进行的两层间的残差学习，当网络更深时，其进行的是三层间的残差学习，三层卷积核分别是1x1，3x3和1x1，一个值得注意的是隐含层的feature map数量是比较小的，并且是输出feature map数量的1/4。 为什么ResNet50 明明模型深很多但是 参数量却和ResNet34差不多呢？因为 ResNet50采用的为bottleneck残差模块。那为什么用这个模块呢？ 又因为通道数比较大，比如64直接通过变成256的。相当于4倍，如果我们还是使用3×3的卷积的话，那计算复杂度会高很多。 （这也是用到1×1的优势）可以看一下 Inception 里 描述 1×1的优势 Inception 下面我们再分析一下残差单元，ResNet使用两种残差单元，如图5所示。左图对应的是浅层网络普通残差模块，而右图对应的是深层网络bottleneck残差模块。 对于短路连接，当输入和输出维度一致时，可以直接将输入加到输出上。但是当维度不一致时（对应的是维度增加一倍），这就不能直接相加。 有2种策略： 采用zero-padding增加维度，此时一般要先做一个downsamp，可以采用strde=2的pooling，这样不会增加参数； 采用新的映射（projection shortcut），一般采用1x1的卷积，这样会增加参数，也会增加计算量。短路连接除了直接使用恒等映射，当然都可以采用projection shortcut。（所以这里有两种选择） 综上所述，理论上有3种方式A、B、C来用于增加维度：我们一般会选用B方案。 A 所有的短路连接升维度都采用 padding 补零方式。 其不增加参数量。 B 需要调整维度的 才有 projection shortcut 1×1卷积，其他的短路连接保持不变。 其参数量有一些。 C 所有的短路连接都采用 projection shortcut 1×1卷积。 引入参数量较大。 从实验结果看，如下图6所示。之所以我们选择B方法，是因为其效果相对A来说还不错，参数增加相比C方案来说少。 ResNet的迁移其在各个领域都有不错的效果。一般都可作为backbone，例如faster R-CNN 就是这么干的。作者在论文中做了很多实验，后续写。","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"ResNet","slug":"ResNet","permalink":"http://example.com/tags/ResNet/"}]},{"title":"浅谈 VGG","slug":"浅谈 VGG","date":"2021-11-01T15:52:01.000Z","updated":"2021-11-26T13:26:55.049Z","comments":true,"path":"2021/11/01/浅谈 VGG/","link":"","permalink":"http://example.com/2021/11/01/%E6%B5%85%E8%B0%88%20VGG/","excerpt":"","text":"@TOC《Very Deep Convolutional Networks for Large-Scale Image Recognition》 arXiv：[1409.1556] Very Deep Convolutional Networks for Large-Scale Image Recognitionintro：ICLR 2015homepage：Visual Geometry Group Home Page VGG 特点VGG 网络是在ILSVRC 2014上的相关工作，主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。VGG有两种结构，分别是VGG16和VGG19，两者并没有本质上的区别，只是网络深度不一样。 VGG16包含了16个隐藏层（13个卷积层和3个全连接层） 其特点为 卷积块的卷积层个数为 2 2 3 3 3 VGG19包含了19个隐藏层（16个卷积层和3个全连接层） 的特点为 卷积块的卷积层个数为 2 2 4 4 4 全连接转卷积（测试阶段）这也是VGG的一个特点，在网络测试阶段将训练阶段的三个全连接替换为三个卷积，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入，这在测试阶段很重要。例如，输入图像是224x224x3，如果后面三个层都是全连接，那么在测试阶段就只能将测试的图像全部都要缩放大小到224x224x3，才能符合后面全连接层的输入数量要求，这样就不便于测试工作的开展。 VGG 原理VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（如11x11，7x7，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。 为什么2个3×3的卷积核 可以 代替 1个5×5的卷积核？因为我们知道 例如输入图片大小为C 卷积核大小为k 步长为d 那输出图片大小就是 $\\lfloor \\frac{C+2 * padding-k}{d} \\rfloor +1$那pad=0 d=1 对于2个3×3的而言 计算得到的 输出图片大小为 C-4同理 一个5×5的 也为 C-4 总结的来说优势有3点： 分成多个层的小卷积核来代替大卷积核，可以增加网络深度。而每一层都会引入非线性的激活函数，所以其非线性表达的能力会更好，模型的分类性能更好。 计算参数减少了。举个例子比如输入维度是C(也就是卷积核通道维度)，输出维度是C(也就是卷积核个数)，如果使用2层3×3的卷积层来代替一层5×5的，3×3的参数总量为 3×3×C×C×2 = $18C^{2}$；对应的 5×5的 为 5×5×C×C×1 = $25C^{2}$ 使用多个层的小卷积核，相当于将一个大的感受野分成多个小感受野来学习，是一种正则化的思想。注意：正则化是一种思想方式，其目的为防止过拟合。其具体方法有：BN、dropout、L1和L2正则化项等。 VGG优缺点VGG优点 VGG16和VGG19 的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。 几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好： 验证了通过不断加深网络结构可以提升性能。 VGG 是传统的串行结构，输出的内容例如左上角提取的就是原图像左上角的特征。 VGG 的迁移学习能力很强，一般都用来做基础模型。我们只需要修改最后1层的输出结构，冻结前面所有在ImageNet上训练VGG后的参数，再拿自己的数据集来训练最后4096神经元和最后一层输出的参数即可。 采用多尺度训练方式，训练的数据可以有 224、256、384、[256，512] 作者提出的 在test上改进的方法，将最后的全连接层改为全卷积层，但是作者训练的时候并没有这么用。这个方法可以实现多尺度输入，原始的 全神经网络的话 他层次的神经元是定死的 所以我没办法换个尺度的图片输入。 VGG缺点参数非常庞大。庞大在卷积层输出压平后与第一层全神经网络之间的参数。首先看第二行，所谓的内存就是输出图片大小 而参数就是卷积核×通道数×卷积核个数64个。注意这里是没有算上偏置量的，算的话就是每个卷积核一个偏置项，会增广成矩阵加上去的。 VGG的训练和测试 论文首先将训练图像缩放到最小边长度的方形，设缩放后的训练图像的尺寸为S×S。网络训练时对训练图像进行随机裁剪，裁剪尺寸为网络的输入尺寸224×224。如果S=224，则输入网络的图像就是整个训练图像；如果S&gt;224，则随机裁剪训练图像包含目标的部分。 对于训练集图像的尺寸设置，论文中使用了两种方法： 固定尺寸训练，设置 S=256 和 S=384多尺度训练，每个训练图像从一定范围内 [Smin,Smax],(Smin=256,Smax=512) 进行随机采样。由于图像中的目标可能具有不同的大小，因此在训练期间考虑到这一点是有益的。这也可以看作是通过尺度抖动进行训练集增强，其中单个模型被训练在一定尺度范围内识别对象。 网络性能评估 单尺度评估，测试图像固定尺度。结果如下表通过评估结果，可以看出： 局部归一化（A-LRN）网络，对网络A的结果并没有很大的提升。 网络的性能随着网络的加深而提高。应该注意到B，C，D这个网络的性能。C网络好于B网络，说明额外添加的非线性激活函数，确实是有好处的；但是，D网络好于C网络，这说明也可以使用非平凡的感受野来捕获更多的信息更有用。 当网络层数达到19层时，使用VGG架构的错误率就不再随着层数加深而提高了。更深的网络应该需要更多的数据集。 论文还将网络B与具有5×5卷积层的浅层网络进行了比较，浅层网络可以通过用单个5×5卷积层替换B中每对3×3卷积层得到。测量的浅层网络top-1错误率比网络B的top-1错误率（在中心裁剪图像上）高7％，这证实了具有小滤波器的深层网络优于具有较大滤波器的浅层网络。 训练时的尺寸抖动（训练图像大小S∈[256,512])得到的结果好于固定尺寸，这证实了通过尺度抖动进行的训练集增强确实有助于捕获多尺度图像统计。 多尺度评估，测试图像的尺度抖动对性能的影响 对同一张测试图像，将其缩放到不同的尺寸进行测试，然后取这几个测试结果的平均值，作为最终的结果（有点像集成学习，所不同的是，这里是测试图像的尺寸不同）。使用了三种尺寸的测试图像：Q表示测试图像，S表示训练是图像尺寸：Q=S−32，Q=S+32，前面两种是针对训练图像是固定大小的，对于训练时图像尺寸在一定范围内抖动的，则可以使用更大的测试图像尺寸。 Q={Smin,0.5(Smin+Smax),Smax}.评估结果如下：评估结果表明，训练图像尺度抖动优于使用固定最小边S。 稠密和多裁剪图像评估Dense（密集评估），即指全连接层替换为卷积层（第一FC层转换到7×7卷积层，最后两个FC层转换到1×1卷积层），最后得出一个预测的score map，再对结果求平均。multi-crop，即对图像进行多样本的随机裁剪，将得到多张裁剪得到的图像输入到网络中，最终对所有结果平均.从上图可以看出，多裁剪的结果是好于密集估计的。而且这两种方法确实是互补的，因为它们的组合优于其中的每一种。由于不同的卷积边界条件，多裁剪图像评估是密集评估的补充：当将ConvNet应用于裁剪图像时，卷积特征图用零填充，而在密集评估的情况下，相同裁剪图像的填充自然会来自于图像的相邻部分（由于卷积和空间池化），这大大增加了整个网络的感受野，因此捕获了更多的图像内容信息。 结论 在训练时，可以使用多尺度抖动的训练图像，其精度好于固定尺寸的训练集。 测试时，使用多裁剪和密集评估（卷积层替换全连接层）像结合的方法","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"针对 VOC2007和VOC2012 的具体用法","slug":"针对 VOC2007、VOC2012和COCO 的具体用法","date":"2021-11-01T14:52:01.000Z","updated":"2021-11-26T13:26:49.930Z","comments":true,"path":"2021/11/01/针对 VOC2007、VOC2012和COCO 的具体用法/","link":"","permalink":"http://example.com/2021/11/01/%E9%92%88%E5%AF%B9%20VOC2007%E3%80%81VOC2012%E5%92%8CCOCO%20%E7%9A%84%E5%85%B7%E4%BD%93%E7%94%A8%E6%B3%95/","excerpt":"","text":"@TOC 目前广大研究者们普遍使用的是 VOC2007和VOC2012数据集，因为二者是互斥的，不相容的。 论文中针对 VOC2007和VOC2012 的具体用法有以下几种： 只用VOC2007的trainval 训练，使用VOC2007的test测试。 只用VOC2012的trainval 训练，使用VOC2012的test测试，这种用法很少使用，因为大家都会结合VOC2007使用。 使用 VOC2007 的 train+val 和 VOC2012的 train+val 训练，然后使用 VOC2007的test测试，这个用法是论文中经常看到的 07+12 ，研究者可以自己测试在VOC2007上的结果，因为VOC2007的test是公开的。 使用 VOC2007 的 train+val+test 和 VOC2012的 train+val训练，然后使用 VOC2012的test测试，这个用法是论文中经常看到的 07++12 ，这种方法需提交到VOC官方服务器上评估结果，因为VOC2012 test没有公布。 先在 MS COCO 的 trainval 上预训练，再使用 VOC2007 的 train+val、 VOC2012的 train+val 微调训练，然后使用 VOC2007的test测试，这个用法是论文中经常看到的 07+12+COCO 。 先在 MS COCO 的 trainval 上预训练，再使用 VOC2007 的 train+val+test 、 VOC2012的 train+val 微调训练，然后使用 VOC2012的test测试 ，这个用法是论文中经常看到的 07++12+COCO，这种方法需提交到VOC官方服务器上评估结果，因为VOC2012 test没有公布。 代码分离 VOC训练集 的 val 和 train 数据1234567891011121314import numpy as npanchors =[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]anchors = np.array(anchors).reshape(-1, 2) #(5,2)input_shape = (416, 416)batch_size = 10epochs = 100colors = [[255,0,255],[218,112,214],[100,149,237],[95,158,160],[0,255,255],[0,255,127],[107,142,35], [255,255,0],[184,134,11],[255,165,0],[255,0,0],[224,255,255],[70,130,180],[255,192,203],[255,240,245],[0,255,0], [240,128,128],[220,220,220],[0,0,0],[169,169,169]]VOCdevkit_path = &#x27;./VOCdevkit&#x27;classes = [&#x27;aeroplane&#x27;,&#x27;bicycle&#x27;,&#x27;bird&#x27;,&#x27;boat&#x27;,&#x27;bottle&#x27;,&#x27;bus&#x27;,&#x27;car&#x27;,&#x27;cat&#x27;, &#x27;chair&#x27;,&#x27;cow&#x27;,&#x27;diningtable&#x27;,&#x27;dog&#x27;,&#x27;horse&#x27;,&#x27;motorbike&#x27;,&#x27;person&#x27;, &#x27;pottedplant&#x27;,&#x27;sheep&#x27;,&#x27;sofa&#x27;,&#x27;train&#x27;,&#x27;tvmonitor&#x27;] 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 把数据集拆分成训练和测试集两部分# 分别保存在 train.txt 和 val.txt 中# 把数据集拆分成训练和测试集两部分# 分别保存在val.txt和train.txt中import osimport randomimport xml.etree.ElementTree as ETfrom config import classes,VOCdevkit_pathVOCdevkit_sets = [(&#x27;2012&#x27;, &#x27;train&#x27;), (&#x27;2012&#x27;, &#x27;val&#x27;)]def convert_annotation(year, image_id, list_file): in_file = open(os.path.join(VOCdevkit_path, &#x27;VOC%s/Annotations/%s.xml&#x27; % (year, image_id)), encoding=&#x27;utf-8&#x27;) tree = ET.parse(in_file) root = tree.getroot() for obj in root.iter(&#x27;object&#x27;): difficult = 0 if obj.find(&#x27;difficult&#x27;) != None: difficult = obj.find(&#x27;difficult&#x27;).text cls = obj.find(&#x27;name&#x27;).text if cls not in classes or int(difficult) == 1: continue cls_id = classes.index(cls) xmlbox = obj.find(&#x27;bndbox&#x27;) b = (int(float(xmlbox.find(&#x27;xmin&#x27;).text)), int(float(xmlbox.find(&#x27;ymin&#x27;).text)), int(float(xmlbox.find(&#x27;xmax&#x27;).text)), int(float(xmlbox.find(&#x27;ymax&#x27;).text))) list_file.write(&quot; &quot; + &quot;,&quot;.join([str(a) for a in b]) + &#x27;,&#x27; + str(cls_id))if __name__ == &quot;__main__&quot;: random.seed(0) for year, image_set in VOCdevkit_sets: #[(&#x27;2012&#x27;, &#x27;train&#x27;), (&#x27;2012&#x27;, &#x27;val&#x27;)] image_ids = open(os.path.join(VOCdevkit_path, &#x27;VOC%s/ImageSets/Main/%s.txt&#x27; % (year, image_set)), encoding=&#x27;utf-8&#x27;).read().strip().split() print(image_ids) list_file = open(&#x27;%s_%s.txt&#x27; % (year, image_set), &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) for image_id in image_ids: list_file.write(&#x27;%s/VOC%s/JPEGImages/%s.jpg&#x27; % (os.path.abspath(VOCdevkit_path), year, image_id)) convert_annotation(year, image_id, list_file) list_file.write(&#x27;\\n&#x27;) list_file.close()","categories":[{"name":"数据集","slug":"数据集","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E9%9B%86/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"数据集","slug":"数据集","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"}]},{"title":"Python数据处理篇之Matplotlib系列","slug":"Python数据处理篇之Matplotlib系列","date":"2021-10-30T14:52:01.000Z","updated":"2021-11-26T13:26:44.207Z","comments":true,"path":"2021/10/30/Python数据处理篇之Matplotlib系列/","link":"","permalink":"http://example.com/2021/10/30/Python%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AF%87%E4%B9%8BMatplotlib%E7%B3%BB%E5%88%97/","excerpt":"","text":"@TOC 创建画布与显示Python数据处理篇之Matplotlib系列(一)—-初识Matplotlib plt.scatter()散点图Python数据处理篇之Matplotlib系列(二)—-plt.scatter()散点图 plt.plot()折线图Python数据处理篇之Matplotlib系列(三)—-plt.plot()折线图 plt.bar()与plt.barh条形图Python数据处理篇之Matplotlib系列(四)—-plt.bar()与plt.barh条形图 plt.pie()饼状图Python数据处理篇之Matplotlib系列(五)—-plt.pie()饼状图 plt.hist()与plt.hist2d()直方图Python数据处理篇之Matplotlib系列(六)—-plt.hist()与plt.hist2d()直方图 matplotlib原理分析Python数据处理篇之Matplotlib系列(七)—-matplotlib原理分析","categories":[{"name":"python工具包类","slug":"python工具包类","permalink":"http://example.com/categories/python%E5%B7%A5%E5%85%B7%E5%8C%85%E7%B1%BB/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"http://example.com/tags/Matplotlib/"}]},{"title":"AlexNet 元老 开创的创新点","slug":"AlexNet 元老 开创的创新点","date":"2021-10-29T14:52:01.000Z","updated":"2021-10-29T14:58:11.730Z","comments":true,"path":"2021/10/29/AlexNet 元老 开创的创新点/","link":"","permalink":"http://example.com/2021/10/29/AlexNet%20%E5%85%83%E8%80%81%20%E5%BC%80%E5%88%9B%E7%9A%84%E5%88%9B%E6%96%B0%E7%82%B9/","excerpt":"","text":"@TOC 创新点1：CNN 卷积神经网络这个就不用说了 CNN 都懂的啊 创新点2：relu激活函数relu 是一个 非饱和的激活函数。用公式来说就是： f(x) = max (0 , x )饱和函数最大的问题在，他左右两边随自变量的变化，应变量变化缓慢。换句话就是说，他的梯度变化基本没有，甚至有可能是0。这就有可能导致梯度消失（如果是0的话），或者训练时间很长，且收敛效果不佳。 创新点3：双GPU模型并行作者使用这个完全是因为当年的GPU的内存实在太小了。那对于现在来说这并不是什么问题，但是这个思想可以参考。 创新点4：LRN局部响应归一化其提出的目的，是作者认为，每个通道的像素点不应该过高的激活，过高的激活可能就会导致 其他通道的对应像素点激活被抑制。这就好像，生物学上，你过分的激活了对顶芽的生长，就会抑制其侧芽的生长一样。 其作用在AlexNet的前两个卷积层，顺序为 Relu之后为LRN再 MaxPooling 他整体的思路如下图所示： 上面相当于其查看了其附近两个通道的，公式就是上面红色的部分。其具体的计算公式如右图所示（其参数意思看下图） 但这个方法 被后来的VGG证实没有啥用，就是其根本就不起作用。用了还占内存其实想想看确实没啥用，Relu函数作为一个非饱和激活函数，其压根不需要normalization啊。normalization的意思是将数据统一在中间区域内，本质的含义其实就是为了让他避免饱和区啦。 创新点5：重叠池化 overlapping pooling作者认为可以 防止过拟合。 现在没人用了。 创新点6：防止过拟合之数据增强其提供了两种数据增强的方式。 注意：这个完全可以由CPU来做，所以作者在训练上一个batch的时候，已经准备好了下一次batch所需要的图像数据。 第一种就是图像翻转，裁剪等（平移和水平翻转） 颜色变换。 其使用了PCA的方式先提取了一下他的主成分。他的意思是我在其主成分的基础上进行一定的调整颜色和光照强度和亮度，这样的话可以使我生成的图片更加的自然。具体可以看下面的公式： 创新点7：防止过拟合之Dropout这个非常有用。现在还在用。其大致的意思就是，训练阶段每一个batch随机掐死一半的神经元（也就是将神经元的输出设置为0 即其在前向和反向传播中均不起作用）。在预测阶段，保留所有神经元。这里还是要具体了解一下，暂时我还不知道具体原理啥的。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"如何评价目标检测的性能 MAP如何计算等","slug":"如何评价目标检测的性能 MAP如何计算等","date":"2021-10-26T14:35:01.000Z","updated":"2021-10-29T15:03:55.678Z","comments":true,"path":"2021/10/26/如何评价目标检测的性能 MAP如何计算等/","link":"","permalink":"http://example.com/2021/10/26/%E5%A6%82%E4%BD%95%E8%AF%84%E4%BB%B7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E6%80%A7%E8%83%BD%20MAP%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E7%AD%89/","excerpt":"","text":"@TOC目标检测模型的性能指标分为速度指标和准确度指标。速度指标通常用每秒推断帧数 FPS （Frames Per Second）衡量，但受硬件影响较大。 目标检测输入图像，输出图像中各个目标预测框的矩形坐标及各类别预测置信度Conf。 采用交并比 IOU 衡量预测框和标注框的重合程度，即预测框的定位是否准确。 IOU=\\frac{area(B_{p}∩B_{gt})}{area(B_{p}∪B_{gt})}式子中，$B{p}$为预测框，$B{gt}$为标准框 根据与标注框的关系，可将某一预测框划分为下式四类中的某一类 真正例（TP）：样本的预测与实际标签相同 假正例（FP）：样本实际标签不是C，但模型预测成C了 假负例（FN）：样本实际标签为C，模型预测错了 真负例（TN）：样本实际为其他类，模型也预测为其他类 TP： $Conf &gt; P{thresh}$ 且 $IOU &gt; IOU{thresh}$ FP： $Conf &gt; P{thresh}$ 且 $IOU &lt; IOU{thresh}$ FN： $Conf &lt; P{thresh}$ 且 $IOU &gt; IOU{thresh}$ TN： $Conf &lt; P{thresh}$ 且 $IOU &lt; IOU{thresh}$ 式子中，$IOU_{thresh}$为0-1之间的常数，需人工指定。对于某一特定类别，TP、FP、FN、TN 四种预测框的个数构成混淆矩阵（Confusion Matrix）。例如这边用 同济子豪兄大哥的 毕设波磨检测为例。（这里的其他类别指的是背景）进一步定义以下参数： Precison(查准率) 是指所有预测框中预测正确的比例，反应了模型“不把背景冤枉成目标”的准确性。 Recall(查全率、敏感性、召回率)是指所有 应该被预测出来的标准框 中被正确预测的比例，反应了模型“不把目标放过为背景”的敏感性。 Average Precision（平均精度，简称AP）：将 $P{thrshold}$ 阈值从0到1变化，计算每个 $P{threshold}$ 阈值对应的Precision和Recall，绘制成某类别的PR性能曲线，其围成的面积为该类别的AP。 取所有类别的AP和不同的 $IOU{thresh}$ ，可分别计算 mAP@0.5 和 mAP@0.5:0.95 。 mAP@0.5为 $IOU{thresh}$ 取0.5时，各类别AP的平均值。 mAP@0.5:0.95为 $IOU_{thresh}$ 分别取以0.05为步长，从0.5增大到0.95的10个数时，各类别AP的平均值。如下式所示，j分别取 0.5、0.55、0.6、0.65、0.7、0.75、0.8、0.85、0.9、0.95，N为类别总数20（类别总数）。 AP = \\int_{0}^{1}P_{thresh}(r) drmAP@0.5=\\frac{1}{N}\\sum_{i=1}^{N}AP_{i}(IOU_{thresh}=0.5)mAP@0.5:0.95=\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j}AP_{i}(IOU_{thresh}=j)","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"目标检测","slug":"目标检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}]},{"title":"cv2 各类函数 详解","slug":"cv2 各类函数 详解","date":"2021-10-25T14:09:01.000Z","updated":"2021-10-29T15:03:40.074Z","comments":true,"path":"2021/10/25/cv2 各类函数 详解/","link":"","permalink":"http://example.com/2021/10/25/cv2%20%E5%90%84%E7%B1%BB%E5%87%BD%E6%95%B0%20%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"@TOC cv2.rectangle 在任何图像上绘制矩形用法： cv2.rectangle(image, start_point, end_point, color, thickness) 参数： image:它是要在其上绘制矩形的图像。 start_point：它是矩形的起始坐标。坐标表示为两个值的元组，即(X坐标值，Y坐标值)。end_point：它是矩形的结束坐标。坐标表示为两个值的元组，即(X坐标值ÿ坐标值)。color:它是要绘制的矩形的边界线的颜色。对于BGR，我们通过一个元组。例如：(255，0，0)为蓝色。thickness:它是矩形边框线的粗细像素。厚度-1像素将以指定的颜色填充矩形形状。 返回值：它返回一个图像。 1cv2.rectangle(img,(x,y),(x+w,y+h),color,8) cv2.putText 在图像上加字12string = &#x27;&#123;&#125;&#123;&#125;&#x27;.format(class_names[i],confidence)cv2.putText(img,string,(x,y+20),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),5) 各参数依次为：图片，添加的文字，左上角坐标，字体，字体大小，颜色，字体粗细 其中字体可以选择：FONT_HERSHEY_SIMPLEX 、 FONT_HERSHEY_PLAIN、 FONT_HERSHEY_DUPLEX 等 cv2.dnn.readNet 用于读取网络参数并构建网络注意 cv2的dnn 网络库集合了多种网络具体可以查看这个 博客 OpenCV中DNN支持的网络架构如：读取 yolov3的配置文件与网络参数 1net = cv2.dnn.readNet(&#x27;yolov3.weights&#x27;,&#x27;yolov3.cfg&#x27;) cv2.imread 用于读取图片文件imread函数有两个参数。第一个参数是图片路径，第二个参数表示读取图片的形式，有三种： cv2.IMREAD_COLOR：加载彩色图片，这个是默认参数，可以直接写1。cv2.IMREAD_GRAYSCALE：以灰度模式加载图片，可以直接写0。cv2.IMREAD_UNCHANGED：包括alpha，可以直接写-1 cv2.imread()读取图片后已多维数组的形式保存图片信息，前两维表示图片的像素坐标，最后一维表示图片的通道索引，具体图像的通道数由图片的格式来决定 12# 导入图像 默认彩色img = cv2.imread(&#x27;guoge_and_ shark.jpg&#x27;) cv2.imwrite 保存图像cv2.imwrite(file，img，num)保存一个图像。 第一个参数是要保存的文件名，第二个参数是要保存的图像。可选的第三个参数，它针对特定的格式：对于JPEG，其表示的是图像的质量，用0 -100的整数表示，默认95;对于png ,第三个参数表示的是压缩级别。默认为3. 12# 保存图片cv2.imwrite(&#x27;result-guoge.jpg&#x27;,img) cv2.imshow() 显示图像cv2.imshow(窗口名字，图像名称) 显示图像。窗口会自动调整为图像大小。第一个参数是窗口的名字，其次才是我们的图像。你可以创建多个窗口，只要你喜欢，但是必须给他们不同的名字。 1cv2.imwrite(&#x27;lena.png&#x27;,img) cv2.dnn.blobFromImage 对图像进行预处理，包括减均值，比例缩放，裁剪，交换通道等 参数：image:输入图像（1、3或者4通道）———————————————可选参数 ：scalefactor:图像各通道数值的缩放比例size:输出图像的空间尺寸,如size=(200,300)表示高h=300,宽w=200mean:用于各通道减去的值，以降低光照的影响 swapRB:交换RB通道，默认为False.(cv2.imread读取的是彩图是BGR通道，正常图片都为RGB)crop:图像裁剪,默认为False.当值为True时，先按比例缩放，然后从中心裁剪成size尺寸ddepth:输出的图像深度，可选CV_32F 或者 CV_8U. 1234# 对图像预处理# 1/255把所有像素归一化 除以255 （0，0，0）表示对每个像素RGB减去常数 这里不减# 因为opencv读入的为BGR 所以我们这里要反一下 swapRB=True crop不对图片进行裁剪blob = cv2.dnn.blobFromImage(img,1/255,(416,416),(0,0,0),swapRB=True,crop=False) cv2.dnn.NMSBoxes 非极大值抑制法1234CONF_THRES = 0.1 #指定置信度阈值，阈值越大，置信度过滤越强NMS_THRES = 0.4 #指定NMS阈值，阈值越小，NMS越强indexes = cv2.dnn.NMSBoxes(boxes,confidences,CONF_THRES,NMS_THRES)","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"目标检测，OpenCv","slug":"目标检测，OpenCv","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%8COpenCv/"}]},{"title":"yolov3 详解","slug":"yolov3 详解","date":"2021-10-23T14:52:01.000Z","updated":"2021-10-29T15:04:08.518Z","comments":true,"path":"2021/10/23/yolov3 详解/","link":"","permalink":"http://example.com/2021/10/23/yolov3%20%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"@TOC yolov1v2v3系列的区别 yolov3 存在的问题 与 改进 如何评判目标检测的效果好坏，以及AP如何计算？ 请看另一文章评判目标检测性能以及如何计算AP等 yolov3 在 IoU 阈值为0.5的情况下，AP值较好（也就是框框并不需要和 Ground Truth 贴合的很准，条件比较宽松）。但 IoU 阈值在0.5-0.95，以0.05作为步长的1 0个阶段，得到的 AP平均值 就不佳， 也就是说明 yolov3在精准定位对象的性能上仍然是比较差的，但是换来的FPS是比较不错的。 在检测 小目标或密集目标 能力上有所改进。 grid cell 个数增加（v2 和 v3 都可以兼容任意图片大小的输入） 能检测对象的预测框多了。v2和v3 你输入的图像越大，那能用于检测对象的 预测框也就越多 Anchor 预先设置了一些比较小的anchor。 v1中直接生成小目标的预测框是比较难的，但在小anchor的基础上计算预测框容易的多 多尺度预测（FPN） 例如 52×52这个大尺度的，感受野就对应于小目标。FPN 既提取了深层网络中特化语义信息，并结合了浅层细粒度像素结构信息（边缘轮廓转角等）。对于小目标而言，边缘和轮廓等细粒度信息是很重要的。 损失函数 含有 惩罚小框项 网络结构（骨干网络 跨层链接 残差链接） yolov3 相较于 v2 的改进 （即细节）yolov2 存在的问题是,对小物体的检测精度还是不高。毕竟，一张图片经过卷积层（特征提取）到最后的特征图，包含小物体的信息是会有损失的。 多尺度输出在 yolov3 中，共设置9个宽高不同的anchor（同样是通过 K-means 聚类获取得到），每个 grid cell 的 anchor 的数量为 9/3=3 个，因为 yolov3 有3个feature_map，不同feature_map的size和感受野是不一样的，较小size的feature_map具有较大的感受野，所以负责检测较大的物体，同理，较大size的feature_map有较小的感受野，负责检测较小的物体。如下图举个例子： 上面的就是 yolov3 的整个网络模型，输出的一共有3种尺度（255 = 3×(5+80) 因为用的COCO数据集）。对于第一个 13×13×255 的输出来说，416（输入尺寸）÷ 13(输出尺寸) = 32（也就是 下采样 32），换句话说就是 对于13×13的特征图，单元网格1×1×255的特征向量 对应 输入原图 32×32×3 的信息 （感受野最大，所以负责检测较大的物体）用如上图的例子可以看出，小特征图有大的anchor box，适合检测大物体（你可以这么理解，对于大物体我们其实只要很粗糙的像素内容就可以认出来，比如我们把一张小马图片用切片机去掉几行几列，我们还是认得出来这是匹马；而对于小物体，我们确实需要更大的特征图，因为其更能保留细度的特征，你也可以这么理解就是我裁剪的太过分了，小物体主体都快被我裁完了怎么可能认得出来） 输入图片 等比例变化v2的时候采取了多尺度训练的方式，并且使用了一个GAP层来帮助解决输入图片尺寸不一样的情况。v3对输入图片本身做了一定的处理。一般对图形的处理有两种方式： 第一种就是把图片不管比例直接变成这边的 416×416 分辨率； 第二种就是先设定一个 416×416 的黑框，然后将图片等比例变化后放入黑框中，在训练和预测的时候黑色的部分会被当做成背景，不会对结果有什么影响。 在实际操作中这两种方法都是可行的。 yolov3的 预测框计算机制 未变yolov3的预测框，预测出来的方法与yolov2是一致的。 训练过程中，都是看实际框中心点落在哪个grid cell，拿出这个grid cell 的所有anchor box 看实际框与哪个anchor box 的IoU最大 （注意：是两个框中心点对其后的IoU），就选择这个anchor box 作为模板。 然后根据这个anchor box 进行校准。 注意： $t{x}$ 这些才是我们网络的输出，也就是这边的 $b{x}$ 我们是命令一个新的函数对其操作得到的。所以ground truth 也要将 长宽中心点这些 $b{i}$ 调整成 $t{i}$ 来进行计算损失如下图所示： 其中 $c{x}$ 和 $c{y}$ 表示单元格长度（分别为 +2 和 +1）注意：在实际运算中，为了运算方便，$b{x}$ 与 $b{x}^{‘}$ 都指的是预测框中心点到图像边界的距离，而不是相对于到单元格的距离。另外 因为 $c{x}$和$c{y}$都是以1为单位的（也就是下采样过），所以我们计算得到的 $b{x}$ 与 $b{y}$ 其实都是相对量，（$b{h}$与$b{w}$是正确尺寸的值）所以我们在最后将框还原到原图尺寸的时候，中心点需乘以grid cell 的下采样倍数，得到原始图像输入图像上预测框 中心点 的坐标。 yolov3 Anchor box对应机制注： yolov3 中使用的 anchor box 的数量是3个如下图所示，每个 grid cell 都可以有3个 anchor box，那样就可以达到如下满满当当的效果，也就是可以检测出更多的物体对象。 yolov3 在置信度上与yolov1和v2的区别 在 yolov1和v2中使用IoU作为置信度标签有何不好的地方？ v1和v2中 $P(object)* IoU$ 来计算置信度标签 ，对于ground truth $P{object}=1$ 所以 就是使用 IoU最为置信度标签。这样的坏处在：1.很多预测框与 ground truth 的IoU最高只有0.7（最好的只有70分）也就是置信度最高只有0.7. 换句话就是我最高就0.7了，我网络怎么学也很难超过0.7.2.COCO中的小目标，IoU对像素偏移很敏感，无法有效学习 yolov3 中使用逻辑回归来计算每个预测框的置信度，每个预测框标签的置信度均为1 （告诉网络我这个就是正样本，你得给我好好学。）正样本(也就是和GT IoU最大的那个anchor 校准得到的预测框)的置信度规定为1，负样本的置信度规定为0。下面可以参考一下什么是正负样本：正样本：与ground truth IoU最大的anchor 校准的预测框不参与（不负责预测）：anchor与ground truth IoU大于阈值（论文是0.5）但是 不是最大的 就什么也不是 。 其实本来就没考虑它，你也不是最大的。负样本：anchor 与ground truth IoU 小于阈值（论文是0.5） 的 或者完全就不重叠的anchor。 其实本来也就没考虑它。 具体 如何预测 预测框yolov3的预测框，预测出来的方法与yolov2是一致的。 每个GT仅仅分配一个anchor（也就是一个预测框）负责预测，这个是相对于 训练过程中，都是看实际框中心点落在哪个grid cell，拿出这个grid cell 的所有anchor box 看实际框与哪个anchor box 的IoU最大（注意：是两个框中心点对其后的IoU），就选择这个anchor box 作为模板。&lt;/font&gt; 然后对其进行训练修正（上面讲的计算偏移机制），注意：$t{x}$ 这些才是我们网络的输出，也就是这边的 $b{x}$我们是命令一个新的函数对其操作得到的。所以ground truth 也要将 长宽中心点这些 $b{i}$调整成 $t{i}$ 来进行计算损失，调整模型参数后 得到最佳的预测框。 yolov3的网络结构 变化最后 应该是 255维度（用的COCO） 注意 Backbone Darknet-53 53的由来步长为2的卷积层有5个 图中蓝色的部分 步长为1的卷积层有47个 （47=1+1×2+2×2+8×2+8×2+4×2 ）图中绿色的部分最后 的全连接网络层 为1层 含有参数所以一共53层 红色的部分 是残差层 和全连接层之前的下采样层一样都是没有参数的 所以不参与网络层的统计 作者构建了darknet-53，在ImageNet数据集上，进行分类测试。发现精度和Resnet-101和Resnet-152 精度都差不多，但计算速度比这两者快很多，而且网络层数少很多。 其中里面的每一个 Convolution 都是由 卷积层+BN层+Leakyrelu激活函数层。 这边统一叫做 CBL 换句话说的 Darknet-53分类模型结构包括之前说的各种结构部分 Res4也就是上上图中框出来的那部分。 Neck 层注意 这里的 21 其实是 255 （这个作者 定义的是两种类别 实际是 80种即COCO （1+4+80）×3）在主干网络提取出图像特征之后，为了能更好的融合提取的特征，还是用了Neck结构。不过因为最后的输出层有3种特征图（13×13，26×26以及52×52），而主干网络输出的矩阵尺寸为 13×13。所以要经过Neck结构中的 FPN结构 和前面的 26×26，52×52 特征图进行多尺度融合。 这里我们对上图种框出的 上采样结构 做分析： 上面那条支路 为 骨干网络 最后的输出维度 13×13 通过CBL 再 上采样一下 变为了 26×26 下面那条支路 为 骨干网络种 中途输出的维度 26×26 所以整合Concat操作 得到还是 26×26的维度 注意他是通道相叠 同理后面几次操作： 最后输出的 类别的条件概率 理解yolov3与v1和v2在 输出的类别条件概率的想法是一致的，都采用的是 各类别独立的逻辑回归（即多分类标签），每个类别的最大概率都为1，不互相干扰都互相独立。 也就是不适用softmax，因为softmax的话，输出的结果就是每个类别条件概率之和为1。 对于yolov3 每个预测框的每个类别逐一用逻辑回归输出概率，可有多个类别输出高概率。 拿分类误差，使用的损失函数，那肯定也是 二分类交叉熵损失函数（因为我每个类是分开单独考虑的 逻辑回归） yolov3的训练过程 输入416×416大小的图像，在经过主干网络darknet-53的卷积网络以及Neck中的FPN结构。可以得到输出层(P0、P1、P2)三种特征图，P0的尺寸最大为52×52，P1是中间尺寸为26×26，P2尺寸最小为13×13。 特征图上每个单元格的特征向量都可以对应416×416图像上的一块感受野区域，而每个区域都会生成三个初始anchor box，因此网络输出的 $t{x} 、t{y}、t{h}、t{w}$ 可以利用anchor，计算得到预测框。再加上前景背景的概率obj以及类别概率cls，就可以汇总得到，目标检测网络输出的预测信息。 但从监督学习的角度，我们会对训练的样本进行标注，因此我们可以知道，图片上每一个物体，它实际框的位置和类别。所以可以根据，前面讲的anchor的对应机制，分别对应到各自anchor上，并打上类别的标签。这样，就可以将预测框和 ground truth 的信息，对应关联起来。 从P0、P1、P2，三个特征图的角度，对前景和背景的概率以及Location位置信息，和class类别信息。从这三个方面，来计算预测框和ground truth 之间的偏差即损失函数，而总体的损失函数，等于三个特征图的损失函数之和。 当有了损失函数，就可以利用网络的梯度更新方式，来进行反向传播了，从而不断迭代，更新网络中的参数。使得损失函数的值，越来越小，从而越来越准确。 详细 损失函数 介绍yolov3的损失函数主要分为3部分： 分类误差，定位误差，置信度误差 正样本对 分类误差、定位误差、置信度误差 学习产生贡献 对不负责预测的框（其实本来就不考虑） 置信度为0 所以 它啥也不算 负样本只对置信度误差 学习产生贡献 为什么呢？ 负样本的置信度不是 规定为0了么？ 为什么会对置信度误差产生贡献呢？？？ yolov3的测试过程 yolov3的测试过程主要分为两步。 第一步，先通过网络的$t{x}、t{y}、t_{h}、t{w}$等输出向量，计算处预测框的位置和所属的类别信息。注意预测框的得分应该为 前景和背景的概率 × class 类别的得分。 并设置阈值分数 例如为0.3。将预测框分数，大于0.3的都保留下来。而分数比较低的都过滤掉，这样的好处是保留的框既是前景即目标的框，同时也是类别分数，比较大的目标。 第一步如上，得到了三个特征图预测框的信息 但现在的框，还是太多了。因此我们需要在一定的标准下去评判这些目标框信息。所以第二步 我们需要将三个特征图上的结果，全部映射回416×416输入图像上。这时，在416×416的图片上，就有多种类别很多的框了。 这时需要针对每个类别，做一个NMS，即非极大值抑制处理，消除重叠度很高的框。这样到了最后，我们就可以得到最终的预测框的信息，以及得分，从而完成目标的检测和定位。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"yolo","slug":"yolo","permalink":"http://example.com/tags/yolo/"},{"name":"目标检测","slug":"目标检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}]},{"title":"同济子豪兄 之 yolov2 详解","slug":"同济子豪兄 之 yolov2 详解","date":"2021-10-08T07:09:01.000Z","updated":"2021-10-29T15:04:20.352Z","comments":true,"path":"2021/10/08/同济子豪兄 之 yolov2 详解/","link":"","permalink":"http://example.com/2021/10/08/%E5%90%8C%E6%B5%8E%E5%AD%90%E8%B1%AA%E5%85%84%20%E4%B9%8B%20yolov2%20%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"@TOC 蓝色： 表示还不明白什么意思 v1存在 一些性能和原理上的问题： mAP相比 R-CNN 系列比较低 定位性能比较差，定位错误占总错误的比例很大 Recall比较低，就是把全部目标全部检测出来的能力比较差 检测密集和小目标的能力比较差 这篇文章其实主要有两个模型，即Yolov2 和 Yolo9000. 9000这个只是一个想法，不太实用。Yolov2 是在此基础上做了很多的 tricks，作者分别归为了三个类，分别是Better（更准确），Faster（更快的），Stronger（类别更多的）。其中Stronger这块 作者说他可以预测9000种，但其实效果不好的，他只是提供一个想法。我们的重点在 前面的Better（更准确）和Faster（更快）（换用了Darknet-19网络）上。 总结来看，虽然YOLOv2做的改进，基本都是借鉴其它论文的一些tricks，比如Faster R-CNN的anchor box，YOLOv2采用anchor box和卷积做预测，这基本上与SSD模型（单尺度特征图的SSD）非常类似了，而且SSD也是借鉴了Faster R-CNN的RPN网络。从某种意义上来说，YOLOv2和SSD这两个one-stage模型与RPN网络本质上无异，只不过RPN不做类别的预测，只是简单地区分物体与背景。在two-stage方法中，RPN起到的作用是给出region proposals，其实就是作出粗糙的检测，所以另外增加了一个stage，即采用R-CNN网络来进一步提升检测的准确度（包括给出类别预测）。而对于one-stage方法，它们想要一步到位，直接采用“RPN”网络作出精确的预测，要因此要在网络设计上做很多的tricks。YOLOv2的一大创新是采用Multi-Scale Training策略，这样同一个模型其实就可以适应多种大小的图片了。 提问：他的模型是 首先是个分类模型（带 global average pooling）可以实现输入多维尺度 这个网络不是用来检测的但他又调整 这个网络，去掉了GAP 然后加了3个卷积 和 passthrough 来做检测 ？？== 那我之前分类的意义在哪？ 答：它相当于就是分类对模型做了个预训练，先大致确定好参数。然后再去检测训练的时候fine-tune，可以加快训练的速度，并且提升实际效果（实际上这个就是有用，但不知道为什么有用呢） Better（更准确）作者为使yolo的精度更高，使用了很多个tricks。包括Batch Normalization、High Resolution Classifer、Anchor、Dimension Cluster、Direct location prediction、Fine-Graind Features、Muti-Scale Training Batch NormalizationBatch Normalization可以提升模型收敛速度，而且可以起到一定正则化效果，降低模型的过拟合。在YOLOv2中，每个卷积层后面都添加了Batch Normalization层，并且不再使用droput。使用Batch Normalization后，YOLOv2的mAP提升了2.4%。 Batch Normalization 的详细内容请看一只柴犬 深度学习基础 - Batch Normalization High Resolution Classifier目前大部分的检测模型都会在先在ImageNet分类数据集上预训练模型的主体部分（CNN特征提取器），由于历史原因，ImageNet分类模型基本采用大小为 224×224 的图片作为输入，分辨率相对较低，不利于检测模型。 Yolov1中 所以 YOLOv1 在采用 224×224 分类模型预训练后，将分辨率增加至448×448，并使用这个高分辨率在检测数据集上finetune。但是直接切换分辨率，检测模型可能难以快速适应高分辨率。 Yolov2中 YOLOv2增加了在ImageNet数据集上使用 448×448 输入来finetune分类网络这一中间过程（10 epochs）（也就是他先是224×224 分辨率训练了一会，再用 448×448分辨率上训练了10个epoch，），这可以使得模型在检测数据集上finetune之前已经适用高分辨率输入。使用高分辨率分类器后，YOLOv2的mAP提升了约4%。 Convolutional With Anchor Boxes Yolov1中 在YOLOv1中，输入图片最终被划分为 7×7 个 grid cell，每个grid cell预测2个边界框（bounding box）。YOLOv1最后采用的是全连接层直接对边界框进行预测，其中边界框的宽与高是相对整张图片大小的，而由于各个图片中存在不同尺度和长宽比（scales and ratios）的物体，YOLOv1在训练过程中学习适应不同物体的形状是比较困难的，这也导致YOLOv1在精确定位方面表现较差。In another word, v1中并没有对框和对象的关系做匹配，也就是我的框可能都是长的或者都是宽的没个标准，这样匹配起来就比较麻烦。另外Yolov1 左上角的bounding box 有可能预测在右下角，这就导致了训练起来非常不稳定，需要加以限制。比如上图所示，长的那个符合人这个物体，但对车就不太符合了。 对于YOLOv1，每个grid cell都预测2个 bounding box，每个box包含5个值： (中心点横坐标，中心店纵坐标，框宽度，框高度，置信度)，最后一个置信度（confidence scores，包含两部分：含有物体的概率以及预测框与ground truth的IOU）。但是每个cell只预测一套分类概率值（class predictions，其实是置信度下的条件概率值）,供2个boxes共享。 Yolov2 v2中引入了先验参考框这个概念。（其实可以理解为一个公共的模板bounding box集合，生成的bounding box 都是这个集合里的）所有的预测框其实都是 先验参考框的偏移。每个anchor都对应一个预测框，每个预测框只要 预测出 其相对于Anchor的偏移量。例如下图所示，就是5个先验参考框： 所以YOLOv2移除了YOLOv1中的全连接层而采用了卷积和anchor boxes来预测边界框(bounding box)。为了使检测所用的特征图分辨率更高，移除其中的一个pool层。在检测模型中，YOLOv2不是采用 448×448 图片作为输入，而是采用 416×416 大小。因为YOLOv2模型下采样的总步长为 32，对于 416×416 大小的图片，最终得到的特征图大小为 13×13 ，维度是奇数，这样特征图恰好只有一个中心位置。对于一些大物体，它们中心点往往落入图片中心位置，此时使用特征图的一个中心点去预测这些物体的边界框相对容易些。所以在YOLOv2设计中要保证最终的特征图有奇数个位置。 YOLOv2使用了anchor box之后，每个位置的各个anchor box都单独预测一套分类概率值，这和SSD比较类似（但SSD没有预测置信度，而是把background作为一个类别来处理）。 在YOLOv2中，每个grid cell 预测 5个bounding box （也就是对应的 5个anchor box）。为什么选5呢后面会说（用的聚类）。所以网络结构输出的特征结果 变为了 13×13×（5+20）× 5 = 13×13×125 ，不是一个grid cell 的bounding box 共享一套分类概率值（条件概率），现在是每个bounding box 都要有自己单独的一套。如下图所示： anchor box 在v2的效果使用anchor boxes之后，YOLOv2的mAP有稍微下降（这里下降的原因，有博主猜想是YOLOv2虽然使用了anchor boxes，但是依然采用YOLOv1的训练方法）。YOLOv1只能预测98个边界框（ 7×7×2 ），而YOLOv2使用anchor box之后可以预测更多个边界框（ 13×13×5 ）。所以使用anchor box之后，YOLOv2的召回率recall大大提升，由原来的81%升至88%。也就是说yolo检测出物体的能力更强了，但准确性下降了一些。 Dimension Clusters 在Faster R-CNN和SSD中，先验框的维度（长和宽）都是手动设定的，带有一定的主观性。如果选取的先验框维度比较合适，那么模型更容易学习，从而做出更好的预测。 这里的这个功能就是 为了选取 对于所训练的数据集，我选择anchor box 为几个？ 才能最好的效果。 那这里 总结一下 v2为什么选择 anchor box =5 呢？答：所谓的anchor box 的数量 说白了 就是 你的数据集到底有多少个类，把物体对象框大小差不多的归为一类。v2 采用 的是k-means聚类方法（我们用这个方法确定了anchor的数量以及长宽比）对训练集中的边界框标签做了聚类分析。因为设置先验框的主要目的是为了使得预测框与ground truth的IOU更好，所以聚类分析时选用box与聚类中心box之间的IOU值作为距离指标： d(box,centroid) = 1 - IoU(box,centroid)IoU这部分表示数据集中的某个ground truth框和他所在的聚类中心框的IoU 这个越大说明我的聚类中心选的越好（接近于1 刚好把所有样本分散的好） 在**VOC 2007 和COCO数据集上的聚类分析结果**，随着聚类中心数目的增加，平均IOU值（各个边界框与聚类中心的IOU的平均值）是增加的，但是综合考虑模型复杂度和召回率，作者最终选取**5个聚类中心作为先验框** (也就是 anchor box = 5) 但是这里先验框的大小具体指什么作者并没有说明，但肯定不是像素点，从代码实现上看，应该是相对于预测的特征图大小（ 13×13）。对比两个数据集，也可以看到COCO数据集上的物体相对小点。这个策略作者并没有单独做实验，但是作者对比了采用聚类分析得到的先验框与手动设置的先验框在平均IOU上的差异，发现前者的平均IOU值更高，因此模型更容易训练学习。 ![数据集VOC和COCO上的边界框聚类分析结果 右侧中 黑框是voc2007 的 长宽比聚类 蓝色的是 coco 的长宽比聚类](https://img-blog.csdnimg.cn/img_convert/5f91f5d74220601c5e3f6d7cb34b81c1.png#pic_center) 注：anchor 的长宽比才有意义，至于图上所示，其位置在哪无所谓，其位置没有任何的意义（这里作者调整过了，怕叠在一起不好看） 聚类中心怎么看的呢？这边的先验框大小到底是什么意思呢？ Direct location prediction 直接位置预测Direct location prediction 可以解决v1中bounding box 乱窜野蛮生长的问题（比如：左上角的grid cell 的bounding box 在右下角 偏移量有点大。。） **已知 YOLOv2借鉴RPN网络使用anchor box来预测边界框bounding box相对先验框anchor box的偏移量offsets。** 预测边界框 bounding box 的中心位置 $(x,y)$ ，需要根据预测的坐标偏移量（感觉是个比例） $(t_{x},t_{y})$，先验框 anchor box 的宽高 $(w_{a},h_{a})$ 以及Anchor 中心坐标 $(x_{a},y_{a})$ （特征图（边长是奇数）每个位置的中心点）来计算： ![faster R-CNN 中计算预测框的中心坐标的方法](https://img-blog.csdnimg.cn/img_convert/fda3e2548e0e8778e2506eb6bbbdbe56.png#pic_center) 这个公式是**无约束的，预测的边界框很容易向任何方向偏移**，如当 $t_{x}=1$ 时边界框将向右偏移先验框的一个宽度大小，而当 $t_{x}=-1$ 时边界框将向左偏移先验框的一个宽度大小，因此每个位置**预测的边界框可以落在图片任何位置**，$t_{x},t_{y}$没有约束而可能移动幅度过大，这导致模型的**不稳定性**，在训练时需要很长时间来预测出正确的offsets。 所以，YOLOv2弃用了这种预测方式，而是沿用YOLOv1的方法，就是**预测边界框中心点相对于对应grid cell左上角位置$(c_{x},c_{y})$的相对偏移值**，为了将边界框 bounding box 中心点约束在当前cell中 ，使用sigmoid函数处理偏移值，这样预测的偏移值在(0,1)范围内（每个cell的尺度看做1）。总结来看，根据边界框预测的4个offsets $t_{x},t_{y},t_{w},t_{h}$ ，可以按如下公式计算出边界框实际位置和大小$(b_{x},b_{y},b_{w},b_{h})$： ![](https://img-blog.csdnimg.cn/img_convert/920c51b2db6727365725e3fb831d027e.png#pic_center) 其中 $(c_{x},c_{y})$ 为grid cell的左上角坐标，如下图所示。 ![边界框位置与大小的计算示例图](https://img-blog.csdnimg.cn/img_convert/9a65ac9119d2ed7d3c1af623efd34b76.png) 在计算时每个grid cell的尺度为1，所以当前grid cell的左上角坐标为$(0,0)$。由于 sigmoid函数 的处理 **边界框的中心位置会约束在当前grid cell内部，防止偏移过多**。而 $p_{w}$ 和 $p_{h}$ 是先验框 anchor box 的宽度与长度，前面说过它们的值也是相对于特征图大小的，在特征图中每个cell的长和宽均为1。这里记特征图的大小为 $(W,H)$ （v2中为 (13,13) )，这样我们可以将边界框相对于整张图片的位置和大小计算出来 。 ![得到的四个 尺度值](https://img-blog.csdnimg.cn/img_convert/92cbcacaeb84e01c3ecde7db7fe3a155.png) **如果再将上面的4个值分别乘以图片的宽度和长度（像素点值）就可以得到边界框的最终位置和大小了**。这就是YOLOv2边界框的整个解码过程。约束了边界框的位置预测值使得模型更容易稳定训练，结合聚类分析得到先验框与这种预测方法，YOLOv2的mAP值提升了约5%。 ## Fine-Grained Features 细粒度特征图 Fine-Grained Features 细粒度特征图 用于帮助检测小目标以及密集目标 YOLOv2的输入图片大小为 416×416 ，经过5次maxpooling之后得到 13×13大小的特征图，并以此特征图采用卷积做预测。 13×13大小的特征图对检测大物体是足够了，但是**对于小物体还需要更精细的特征图（Fine-Grained Features）**。因此SSD使用了多尺度的特征图来分别检测不同大小的物体，前面更精细的特征图可以用来预测小物体。YOLOv2提出了一种pass through层来利用更精细的特征图。如下图为整体的网络结构： ![Darknet19检测模型+passthrough操作](https://img-blog.csdnimg.cn/img_convert/989dde6af769da5bd9ba6012e8bef92e.png#pic_center) passthrough层与ResNet网络的shortcut类似，以前面**更高分辨率的特征图为输入**，然后将其**连接到后面的低分辨率特征图**上。 前面的特征图维度是后面的特征图的2倍，passthrough层抽取前面层的每个 2×2 的局部区域，然后将其转化为channel维度，对于26×26×512 的特征图，经passthrough层处理之后就变成了 13×13×2048 的新特征图（特征图大小降低4倍，而channles增加4倍。操作如下图所示： ![passthrough 增加通道数的操作栗子](https://img-blog.csdnimg.cn/img_convert/4051f9f715281e7658ab01fb6557807b.png#pic_center) 这样也就得到了 13×13×2048 的输出，可以与后面的 13×13×1024 低分辨率特征图连接在一起形成 13×13×3072 大小的特征图，然后在此特征图基础上卷积做预测。 ![就是这样](https://img-blog.csdnimg.cn/img_convert/8a808bf40d6b819b196d7d348c755dca.png) 在TensorFlow中，可以使用tf.extract_image_patches或者tf.space_to_depth来实现passthrough层： 123out = tf.extract_image_patches(in, [1, stride, stride, 1], [1, stride, stride, 1], [1,1,1,1], padding=&quot;VALID&quot;)// or use tf.space_to_depthout = tf.space_to_depth(in, 2) 这是v2论文中刚开始的想法，作者后期借鉴了ResNet网络，**不是直接对高分辨特征图处理**，而是增加了一个**中间1×1卷积层**，先采用64个1×1 卷积核进行卷积，然后再进行passthrough处理，这样 26×26×512的特征图得到 13×13×256 的特征图。最后再高和低分辨率合并，得到13×13×1280的特征图做预测。这算是实现上的一个trick。使用Fine-Grained Features之后YOLOv2的性能有1%的提升。 ![作者改进后的 也就是真实的代码设计](https://img-blog.csdnimg.cn/img_convert/cd777947365d746debcde922ad285dfb.png#pic_center) ## Multi-Scale Training 多尺度训练 YOLOv2的一大创新是采用Multi-Scale Training策略，**这样同一个模型其实就可以适应多种大小的图片**。 由于YOLOv2模型中采用了global average pooling 全局平均池化层 ，所以YOLOv2的输入可以不限于 416×416 大小的图片。为了增强模型的鲁棒性，YOLOv2采用了多尺度输入训练策略，具体来说就是在训练过程中每间隔10个 iterations 之后改变模型的输入图片大小。由于YOLOv2的下采样总步长为32，输入图片大小选择一系列为32倍数的值：{320,352，...608}。在训练过程，每隔10个iterations随机选择一种输入图片大小，然后只需要修改对最后检测层的处理就可以重新训练。 ![Multi-Scale Training 多尺度输入训练](https://img-blog.csdnimg.cn/img_convert/8a03850706857e9f5a4cd666bae33301.png#pic_center) YOLOv2在 VOC2007和2012的训练集上，可以看到采用较小分辨率时，YOLOv2的mAP值略低，但是速度更快，而采用高分辨输入时，mAP值更高，但是速度略有下降，对于 544×544 ，mAP高达78.6%。**注意，这只是训练时输入图片大小不同，而实际上用的是同一个模型（采用Multi-Scale Training训练）。** 这里也可以看出，多尺度训练的一个副作用：如果你输入的是一个高分辨率的大图片 yolo会预测的比较慢但是比较准 如果你输入的是低分辨率的小图片，yolo会预测的非常快但是精度没有那么高。因此yolo可以通过输入图片的大小尺度，来做到精度和速度的权衡。 # Faster ## New Network: Darknet-19 YOLOv2采用了一个新的基础模型（特征提取器），称为Darknet-19，包括19个卷积层和5个maxpooling层，如下图所示。下面这个是 用于分类的模型， 就是预训练模型啦。 ![Darknet-19 的分类模型 预训练输入的为 224×224](https://img-blog.csdnimg.cn/img_convert/10c9041bf90f9c2d7a3de23f4b571706.png) Darknet-19与VGG16模型设计原则是一致的，主要采用 3×3 卷积，采用 2×2 的maxpooling层之后，特征图维度降低2倍，而同时将特征图的channles增加两倍。与NIN(Network in Network)类似，Darknet-19最终采用**global avgpooling做预测**，并且在 3×3 卷积之间使用 1×1 卷积来压缩特征图channles以降低模型计算量和参数。Darkxnet-19每个卷积层后面同样使用了Batch Normalization层以加快收敛速度，降低模型过拟合。在ImageNet分类数据集上，Darknet-19的top-1准确度为72.9%，top-5准确度为91.2%，但是模型参数相对小一些。使用Darknet-19之后，YOLOv2的mAP值没有显著提升，但是计算量却可以减少约33%。 # YOLOv2的训练 YOLOv2的训练主要包括三个阶段。 1. 第一阶段就是先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为 224×224 ，共训练160个epochs。 2. 第二阶段将网络的输入调整为 448×448 ，继续在ImageNet数据集上finetune分类模型，训练10个epochs，此时分类模型的top-1准确度为76.5%，而top-5准确度为93.3%。 3. **第三个阶段就是修改Darknet-19分类模型为检测模型**，并在检测数据集上继续finetune网络。网络修改包括（网路结构可视化）：移除最后一个卷积层、global average pooling层以及softmax层，并且新增了三个 3×3×1024 卷积层，同时增加了一个passthrough层，最后使用 1×1 卷积层输出预测结果，输出的channels数为： $anchor个数 × (5+类别个数)$（在v2中 为 5×（5+20）） ，和训练采用的数据集有关系。由于anchors数为5，对于VOC数据集输出的channels数就是125，而对于COCO数据集则为425（因为COCO是80个分类）。 这里以VOC数据集为例，最终的预测矩阵为 $T$（shape为 （batch_size,13,13,125）），可以先将其reshape为 （batch_size,13,13,5,25），其中 $T[:,:,:,:,0:4]$ 为边界框的位置和大小 $t_x,t_y,t_w,t_h$， $T[:,:,:,:,4]$ 为边界框的置信度，而 $T[:,:,:,:,5:]$为类别预测值。 ![YOLOv2训练的三个阶段](https://img-blog.csdnimg.cn/img_convert/533f8c8dcc9da79ea03a5ca90bd00f4a.png#pic_center) ![YOLOv2 检测网络结构示意图](https://img-blog.csdnimg.cn/img_convert/89c0c117e6648f93753cc6416d0bbadf.png#pic_center) ## YOLOv2的损失函数 v2的预测框和类别的想法其实与v1是一致的，对于训练图片中的ground truth，若其中心点落在某个grid cell内，那么该grid cell内的5个先验框 anchor box 所对应的预测框 bounding box 负责预测它，具体是哪个bounding box预测它，需要在训练中确定，即由那个与ground truth的IoU最大的 bounding box 预测它，而剩余的4个 bounding box 不与该ground truth匹配。 ![YOLOv2的损失函数](https://img-blog.csdnimg.cn/img_convert/68b2ccd52bf5d18fd4a234ac07c12057.png#pic_center) 1. 首先 $W、H$分别指的是特征图（ 13×13 ）的宽13与高13，而 $A$ 指的是先验框anchor box数目（这里是5），各个 $λ$ 值是各个 loss 部分的权重系数（即超参数）。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/2b4666868ab3c549bf793cfa3acf9e59.png#pic_center) 2. 第一项loss是计算 该预测框不负责检测物体(background) 的置信度误差(越小越好)，但是哪些预测框不负责检测物体对象而预测背景呢，需要先计算各个预测框和**所有ground truth的IOU值**，并且取**最大值Max_IOU**，如果该值**小于**一定的**阈值**（YOLOv2使用的是0.6），那么这个预测框就标记为background，需要计算$λ_{noobj}$ 的置信度误差。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/b0b4307ec6cdad8bde6ec679a55b6d8b.png#pic_center) 3. 第二项是计算先验框anchor box与预测框bounding box的坐标误差，但是只在前12800个iterations间计算，该博客博主认为 这项应该是在训练前期使预测框快速学习到先验框的位置和形状。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/fdd54195cbe12c0fc17d3ac02a61a179.png#pic_center) > Q1: 为什么是 前12800个iterations？ 4. 第三大项计算与某个ground truth匹配的预测框各部分loss值，包括定位（坐标）误差、置信度误差以及分类误差。先说一下匹配原则，对于某个ground truth，首先要确定其中心点要落在哪个grid cell上，然后计算这个grid cell的5个先验框 anchor box 与ground truth的IoU值（YOLOv2中bias_match=1），**计算IoU值时不考虑坐标，只考虑形状**，所以先将先验框与ground truth的中心点都偏移到同一位置（原点），然后计算出对应的IoU值，IoU值最大的那个先验框与ground truth匹配，对应形状的预测框用来预测这个ground truth。 说白了就是 我先看看 anchorbox 模板里面哪个和 ground truth形状比较像，这样我的框比较对嘛。然后选出这个框 找到 这个grid cell 里面 5个bounding box 和这个anchor 形状一样的那个框 去匹配ground truth。 说白了就是 弄了个中间商去选 形状 匹配。 在计算obj置信度时，target=1，但与YOLOv1一样而增加了一个控制参数rescore，当其为1时，target取预测框与ground truth的真实IOU值（cfg文件中默认采用这种方式）。 ???什么意思 对于那些没有与ground truth匹配的先验框（与预测框对应），除去那些Max_IOU低于阈值的，其它的就全部忽略，不计算任何误差。这点在YOLOv3论文中也有相关说明：**YOLO中一个ground truth只会与一个先验框匹配（IOU值最好的）**，对于那些IOU值超过一定阈值的先验框，其预测结果就忽略了。 尽管YOLOv2和YOLOv1计算loss处理上有不同，但都是采用均方差来计算loss。另外需要注意的一点是，在计算boxes的 $w$ 和 $h$ 误差时，YOLOv1中采用的是平方根以降低boxes的大小对误差的影响，而YOLOv2是直接计算，但是根据ground truth的大小对权重系数进行修正：l.coord_scale * (2 - truth.w*truth.h)（这里w和h都归一化到(0,1))，这样对于尺度较小的boxes其权重系数会更大一些，可以放大误差，起到和YOLOv1计算平方根相似的效果（参考[YOLO v2 损失函数源码分析](https://www.cnblogs.com/YiXiaoZhou/p/7429481.html)）。 最终的YOLOv2模型在速度上比YOLOv1还快（采用了计算量更少的Darknet-19模型），而且模型的准确度比YOLOv1有显著提升，详情见paper。 # Yolov2的预测 同Yolov1 的预测 同样是消除多余的框。可以看一下Yolov1 是怎么 在网络提取出特征图 后 如何 消除多余的框的。 [Yololv1的详解](https://jks88995656.github.io/2021/09/26/%E5%90%8C%E6%B5%8E%E5%AD%90%E8%B1%AA%E5%85%84%20%E4%B9%8B%20yolov1%20%E8%AF%A6%E8%A7%A3/) # Yolo9000 YOLO9000是在YOLOv2的基础上提出的一种可以检测超过9000个类别的模型，其主要贡献点在于提出了一种分类和检测的联合训练策略。 ImageNet分类数据集比VOC等检测数据集高出几个数量级。在YOLO中，边界框的预测其实并不依赖于物体的标签，所以YOLO可以实现在分类和检测数据集上的联合训练。对于检测数据集，可以用来学习预测物体的边界框、置信度以及为物体分类，而对于分类数据集可以仅用来学习分类，但是其可以大大扩充模型所能检测的物体种类。 # Yolo9000 的训练 ## WordTree与联合训练 这个装逼不成的作者 **选择在COCO检测数据集和ImageNet分类数据集上进行联合训练**，但是遇到的第一问题是两者的类别并不是完全互斥的（而常规的softmax方法认定各神经元是互斥的），比如\"Norfolk terrier\"明显属于\"dog\"，所以作者提出了一种层级分类方法（Hierarchical classification），主要思路是根据各个类别之间的从属关系（根据WordNet）建立一种树结构WordTree，结合COCO和ImageNet建立的WordTree如下图所示： ![基于COCO和ImageNet数据集建立的WordTree](https://img-blog.csdnimg.cn/img_convert/e081b98313870f03c620f2d8fb0ddb7e.png#pic_center) WordTree中的根节点为\"physical object\"，每个节点的子节点都属于同一子类，可以对它们进行softmax处理。在给出某个类别的预测概率时，需要找到其所在的位置，遍历这个path，然后计算path上各个节点的概率之积。计算某个节点的概率，比如说 Norfolk terrier 节点（根据他的物种从上到下遍历），计算步骤如下所示（分层概率计算完整概率）： ![计算Norfolk terrier结点概率](https://img-blog.csdnimg.cn/img_convert/802124190e6b707e7cd21def3a0f0cd7.png#pic_center) 上面是 做 分类的时候，概率的计算方式。他用了 ImageNet1000个类别构建的WordTree，当然中间需要一些中间层结点（比如 并不代表物种的 hunting dog这个类等）一共1369个结点。 按同层次的类别softmax的方法如下图，**计算结果其实不如 全部互斥的分类结果。** ![ImageNet与WordTree预测的对比](https://img-blog.csdnimg.cn/img_convert/63cf274736bb7b43970301aa7d192431.png#pic_center) ![Yolo9000](https://img-blog.csdnimg.cn/img_convert/e6f7edd74a243934d58718fd27e46d23.png#pic_center) 当其是应用于 图像检测上时，需要将上面的 Pr(physical object)替换成 v2的置信度预测。 实际训练与损失函数Yolo9000 使用 ImageNet的分类数据集的前9000个类别和COCO的检测数据集构建WordTree 进行训练，测试用的是 ImageNet检测竞赛数据。 其用v2输出的 Tensor应该为 （13,13,3,5+9418），做Yolo9000时，作者将anchor box 变成了3个，因为5个的话张量实在太大了。5+9418 也就是 bounding box预测的4个左边偏移量和含有对象置信度，以及9418个分类。 在训练时，如果是检测样本，按照YOLOv2的loss计算误差，而对于分类样本，只计算分类误差。在预测时，YOLOv2给出的置信度就是 $Pr(physical -object)$ ，同时会给出边界框位置以及一个树状概率图。在这个概率图中找到概率最高的路径，当达到某一个阈值时停止，就用当前节点表示预测的类别（也就是只会有1个）。而其他与Ground Truth 的IoU 高于0.3的预测框，本不应该具有这么高的置信度（IoU),通通都作为负样本。 Yolo9000 检测上的实验效果通过联合训练策略，YOLO9000可以快速检测出超过9000个类别的物体，总体mAP值为19.7%。事实上，ImageNet检测类别中大部分类别仅在ImageNet分类数据集上见过，并不是检测数据集，（这里可以看做迁移效果）。所以效果一般般，很多类别检测不出来，特别是物体类；但动物类尚可。估计原因就是，COCO检测数据集中大部分都是动物，所以迁移过来的对动物的效果当然也会比较好的。作者提出的 yolo9000 算是一个开创的想法，但是效果不佳（不然他早就在youtube上装逼了） 参考论文和博客参考博客： 转载来源 目标检测|YOLOv2原理与实现 YOLO v2 损失函数源码分析 源码c版的 Batch Normalization的通俗解释 参考视频： 同济子豪兄v2算法讲解 同济子豪兄v2论文精讲 keras代码 github：YAD2K-master参考论文：YOLO9000 Better, Faster, Stronger","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"yolo","slug":"yolo","permalink":"http://example.com/tags/yolo/"},{"name":"目标检测","slug":"目标检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}]},{"title":"深度学习基础 - Batch Normalization","slug":"深度学习基础 - Batch Normalization","date":"2021-10-05T07:29:01.000Z","updated":"2021-10-29T15:03:24.311Z","comments":true,"path":"2021/10/05/深度学习基础 - Batch Normalization/","link":"","permalink":"http://example.com/2021/10/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%20-%20Batch%20Normalization/","excerpt":"","text":"@TOC 在计算机的眼光里，对具有统一规格的数据，更能学习到其数据之间的规律特征。也就是下图所看的的这样，将杂乱的数据标准归一化。 首先我们之前有Normalization（普通数据标准化），一般用作输入数据的样本归一化操作。那Batch Normalization 则可用在 每个层上包括隐藏层。 机器学习中的Feature Scaling如果特征大小差的比较远的话，loss function会很扁平，数值更大的feature的参数会对结果的影响更大，这样在训练过程中，不同的方向需要设定不同的学习率，这样子会不太方便，这不是我们想看到的，所以我们通常会去做feature scaling。 具体的操作很简单，对每一维特征，我们对每一个数据减去这维特征的均值，再除以这位特征的标准差，得到缩放后的新的特征值，此时它的均值为0，方差为1。一般经过feature scaling之后，收敛速度会变快。 那么在神经网络中又是什么情况呢？ 我们可以看到，其实在深度网络中，后一层的输入其实是前一层的输出。那么我们在做feature scaling的时候，应该对每一层的输入都去做一个feature scaling, 但是又不像传统的机器学习，由于神经网络每一层的参数都在不断变化，直接使用前面的feature scaling是不太合适的。所以我们需要一个新的技术，就是Batch Normalization了 Batch Normalization 放在神经网络的哪个部位？Batch Normalization 放在 线性层的后面，激活函数的前面。如下图所示： Batch Normalization 基本原理现在一般采用批梯度下降方法对深度学习进行优化，这种方法把数据分为若干组，按组来更新参数，一组中的数据共同决定了本次梯度的方向，下降时减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也下降了很多。 Batch Normalization(简称BN)中的batch就是批量数据，即每一次优化时的样本数目，通常BN网络层用在卷积层后，用于重新调整数据分布。假设神经网络某层一个batch的输入为X=[x1,x2,…,xn]，其中xi代表一个样本，n为batch size。 首先，我们需要求得mini-batch里元素的均值：μ_{B}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i} 接下来，求取mini-batch的方差：\\sigma _{B}^{2} = \\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-μ_{B})^{2} 这样我们就可以对每个元素进行归一化\\hat{x_{i}}=\\frac{x_{i}-μ_{B}}{\\sqrt{\\sigma _{B}^{2}+\\varepsilon}}这里的分母本来应该是 $\\sigma$,但为了防止它为0，我们加上一个$\\varepsilon$。 最后进行尺度缩放和偏移操作，这样可以变换回原始的分布，实现恒等变换，这样的目的是为了补偿网络的非线性表达能力，因为经过标准化之后，偏移量丢失。具体的表达如下，$y_{i}$就是网络的最终输出。$γ$与$β$是神经网络的参数，是网络自己学习的。y_{i}=γ\\hat{x_{i}}+β 从某种意义上来说，方差和均值代表的其实是输入数据分布的方差和偏移。对于没有BN的网络，这两个值与前一层网络带来的非线性性质有关，而经过变换后，就跟前面一层无关，变成了当前层的一个学习参数，这更加有利于优化并且不会降低网络的能力。 举个 Batch Normaliztion 计算栗子他分为训练（训练 $γ$与$β$）和测试阶段（使用训练后得到的参数）。如下图 这个的 batch_size=8，也就是说输入的图像有8张，即8个输入；看第一个0.9 表示的是 第一张神经元对第4张图片的响应；后面的1.7就是 第一张神经元对第5张图片的响应；26.7 也就是最后一个神经元对 第4张图片的响应。 就是先算出 平均值 再计算 均方差，按公式得到标准化的结果。 Batch Normaliztion 的效果 因为BN可以把输入都规整化在非饱和区内，所以他可以加快收敛（因为梯度变化的大，不缓慢）比如 sigmoid 和 tanh 函数 非饱和区和饱和区。 减少了训练时间，而且可以进行深层网络的训练，同时可以使用更大的学习率。 减轻了对参数初始化的依赖，这是利于调参的 可以起到正则化的作用 可以防止过拟合 BN一定程度上增加了泛化能力，dropout等技术可以去掉。 注意：BN与Dropout不能一起使用。 为什么有待于补充。 可以看一下 效果 参考论文与博客Batch Normalization论文：Batch Normalization论文参考的博客：什么是批标准化？知乎第一个留言 深度学习中 Batch Normalization为什么效果好？精选 写的很好 Batch Normalization的通俗解释","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"目标检测的中的指标的含义及其实现","slug":"目标检测的中的指标的含义及其实现","date":"2021-10-04T14:01:01.000Z","updated":"2021-10-29T15:03:28.966Z","comments":true,"path":"2021/10/04/目标检测的中的指标的含义及其实现/","link":"","permalink":"http://example.com/2021/10/04/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E4%B8%AD%E7%9A%84%E6%8C%87%E6%A0%87%E7%9A%84%E5%90%AB%E4%B9%89%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"@TOC Precision和Recall Precision是查准率、精确率的意思。预测为正的结果中，有多少真正是正样本。 Recall是查全率、召回率的意思。对所有正样本有多少预测出来了。 用另一个图理解快速记忆 左边这个是TF表示这个结果预测的对不对 右边那个PN表示我预测的是正的还是负的（比如二分类 正的：是这个东西 负的：不是这个东西）注意：这两个量都是：第一是你告诉我是正的里面有多少是对的，第二是关注我对ground truth是正的 也就是实际上就是正的的能力。这两个是相反的关系，一个高另一个就低。比如如下图所示：提升门槛值，那么也就是对的会越对。门槛值高了嘛，那我正样本预测的就越准的，那么我将负样本预测错误成正样本的概率就低了。所以我的 Precison上升了，但Recall 下降了。 IoU (Intersection over Union) 1234567891011121314151617181920212223242526def calculateIoU(candidateBound, groundTruthBound): cx1 = candidateBound[0] cy1 = candidateBound[1] cx2 = candidateBound[2] cy2 = candidateBound[3] gx1 = groundTruthBound[0] gy1 = groundTruthBound[1] gx2 = groundTruthBound[2] gy2 = groundTruthBound[3] carea = (cx2 - cx1) * (cy2 - cy1) #C的面积 garea = (gx2 - gx1) * (gy2 - gy1) #G的面积 x1 = max(cx1, gx1) y1 = max(cy1, gy1) x2 = min(cx2, gx2) y2 = min(cy2, gy2) w = max(0, x2 - x1) h = max(0, y2 - y1) area = w * h #C∩G的面积 iou = area / (carea + garea - area) return iou top1、top5 的含义在图像分类中： Top-1 error的意思是：假如模型预测某张动物图片（一只猫）的类别，且模型只输出1个预测结果，那么这一个结果正好能猜出来这个动物是只猫的概率就是Top-1正确率。猜出来的结果不是猫的概率则成为Top-1错误率。简单来说就是模型猜错的概率。 Top-5 error的意思是：假如模型预测某张动物图片（还是刚才那只猫），但模型会输出来5个预测结果，那么这五个结果中有猫这个分类的概率成为Top-5正确率，相反，预测输出的这五个结果里没有猫这个分类的概率则成为Top-5错误率。 一般来说，Top-1和Top-5错误率越低，模型的性能也就越好。且Top-5 error 在数值上会比Top-1 error 的数值要小，毕竟从1个结果猜对的几率总会比从5个结果里猜对的几率要小嘛！ 在目标检测中： top-1正确率，就是你预测的label取最后概率向量里面最大的那一个作为预测结果，如过你的预测结果中概率最大的那个分类正确，则预测正确，否则预测错误。 top5就是最后概率向量最大的前五名中，只要出现了正确概率即为预测正确。否则预测错误。 Average Precision (AP)与 mAP多个类别目标检测中，每个类别都可以根据recall（召回率）和 percision（准确率）绘制一条曲线。AP就是该曲线下的面积，mAP意思是对每一类的AP再求平均。mAP计算方法：首先我们要先搞明白AP。AP表示 整个的面积我们一般用F1的值来 找到最适合的点 来均衡 Precison 和 Recall。那什么是mAP呢，我们现在讨论的都是 比如预测有1和0，我们是针对1这个正样本。也可以反过来看0作为正样本呢。所以要加起来一起除以总体 数。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"同济子豪兄 之 yolov1 详解","slug":"同济子豪兄 之 yolov1 详解","date":"2021-09-26T14:01:01.000Z","updated":"2021-10-29T15:03:50.667Z","comments":true,"path":"2021/09/26/同济子豪兄 之 yolov1 详解/","link":"","permalink":"http://example.com/2021/09/26/%E5%90%8C%E6%B5%8E%E5%AD%90%E8%B1%AA%E5%85%84%20%E4%B9%8B%20yolov1%20%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"@TOCyolov1 的主旨是 You Only Look Once：Unified，Real-Time Object Detection。yolo 是一个典型的 将 目标检测 转化为 回归问题的方法。yolo与其他网络不同在，他的测试与训练方法不同，所以接下来我们主要 分预测以及训练两个阶段去介绍yolov1。 包括 预测阶段（以及后处理），训练阶段来讲。 将输入的图片 划分为 S×S个 grid cell训练阶段： 将标签 Ground truth 的 框 中心点落在哪个grid cell 中 就由 哪个 grid cell 来预测这个物体对象 每个 grid cell 可以 预测 B 个 bounding box， 与 Ground truth 的 框 IoU 最大的bounding box 负责预测 这个物体对象。 每个 grid cell 只能 检测一个物体 包含和不包含 ground truth 标签的 grid cell 和 bounding box 都要依照损失函数 分别处理 测试阶段： 直接获得 S × S ×（S×B+C）向量 进行 NMS 后处理 得到目标检测结果。 目标检测的基础知识目标检测是什么？在计算机视觉领域，图像任务主要分为：图像分类，图像检测 和 图像分割（语义分割和实例分割）等语义分割和实例分割的区别在于：语义分割是我对每个像素分类，我不管这个像素是属于哪几个物体的，只管他是属于什么类别的（也就是我只分类，同一个类别的不同实例不区分）；而实例分割是要把同一个类别的不同实例给区分开来 目标检测主流的数据集来源yolo 是在 PASCAL-2007 和 MS-COCO上做的评测 目标检测的发展目前这个主要的流派由两种，上面是单阶段模型 yolo 系列 下面是两阶段模型 RCNN系列。 两阶段就是先从图像中提取若干候选框，再逐一的对这些候选框进行分类、甄别以及调整它们的坐标最后得出结果。 单阶段就是 我不提取候选框，我直接把全图喂到算法里面，能直接输出出来目标检测的结果。是一个统一的端到端的系统 对于 RCNN系列的话，他比较慢但是 正确率比较高 R-CNN 使用region proposal先提取候选框，再使用卷积神经网络逐一的对每个候选款进行甄别，对 bouning box 位置调整和回归和分类 Fast R -CNN 是把所有的图片用卷积神经网络过一遍，在生成的feature map上找候选框 投影到 feature map 上面，再进行甄别 Faster R-CNN 使用了 RPN 网络，也就是找候选框这个事情由 RPN 这个专业户干了 对于 yolo系列的话，他的优势在于速度，正确率相比没有那么高（待补充） yolov1 的缺点在于，单个grid cell 只能识别一种类别。识别小目标或者密集目标 能力不足，例如羊群、人群这种。 yolov2 是在 yolov1 的基础上 加了Batch Normalization、High Resolution Classifer、Anchor、Dimension Cluster、Direct location prediction、Fine-Graind Features、Muti-Scale Training yolov3 yolov4 从v4开始 作者变了，前面的大作因为感慨yolo技术被用来干坏事而退出了计算机视觉领域。 yolov5 yolo v1 的 预测阶段yolo v1 网络架构输出的 7×7×30 这个tensor 就是我们预测阶段所需要的我们来分析一下网络结构并写出各层次的padding。计算公式为 outputsize =\\lfloor {\\frac{inputsize + 2padding -filtersize}{步长}}\\rfloor +1之后最后两个全连接层。他是怎么转为 4096个输入的呢。也就是输入的为7×7×1024 我们全连接层输出的 是 4096 的一维向量。我们采用 4096个 7×7×1024 的卷积核，然后 变成 1×1×4096 再使用降维 变为 一维的4096。然后我们再将这个 reshap 成 4096×1的列向量 中间的 参数矩阵为 4096×1470 根据 线性回归的公式： y=w^{T}x可以计算得到 1470×4096×4096×1 = 1470×1 然后我们在 reshape 一下变成三维 （7,7,30） yolo v1 预测阶段 内容详解 Q：为什么 输出的是 7×7×30 呢？因为在 yolo v1 中图像被划分成了7×7的网格。每个格子叫做 grid cell ，也就是由49个grid cell。 这里的 每个 grid cell 又能预测 B个 bounding box （也就是预测框） yolo v1中 B=2 也就是每个 grid cell 可以预测 2个 bounding box。这两个预测框可能很大也可能很小 也就是这个框是啥样的不一定。（注意这个框是由前面的网络结构得到的 就是这么神奇）。这个框覆盖其他的grid cell 是很正常的，只要这个 bounding box 的中心点 是落在这个 grid cell 里就ok。 每个grid cell 预测 B 个 bounding box。 在yolo v1 的实验中 B=2，也就是 每个 grid cell 由 2 个 bounding box。bounding box 的由 5个 数值来表示 （x,y,h,w,c） x，y 表示中心点的位置 h，w表示这个 bounding box 的 高 和 宽 c 表示这个 bounding box 框的置信度。在图像中 一般用 框线的粗细来表示置信度的大小。置信度的意思是，这个bounding box 对自己含有物体对象的自信程度。（注意是识别的对象，而不是具体的类别） 在yolo v1的实验中，因为由 49 个 grid cell，所以 有 98 个 bounding box 如下图所示（粗细表示置信度高低） grid cell 输出所有类别的条件概率每个 grid cell 还能生成所有类别的 条件概率，并且选择最高的一个概率表明，预测的是这个类别。这也就是 yolo v1 最大的弊端，每个 grid cell 只能预测一个类别，那一个 49个cell 最大只能预测 49个类别；并且如果类别对象很密集，一个 grid cell 中有多个不同的小对象的话，识别效果会很差。 注意这里的概率是 条件概率 比如 p(cat|object) 是在有存在类别对象的情况下 是 猫的概率。下图可以表示 49个cell 预测的类别情况（也就是各cell 选择的最高类别的 条件概率） 7×7×30 这个30是怎么来的呢每个grid cell 有 2个bounding box。1个bounding box 中有5个数值 那就是10个数值，然后 yolo v1 预测了20个类别的物体，所以有20个类别的概率 所以是 30个输出。然后有 7×7个 grid cell 所以 输出的 是 7×7×30 的 tensor。 Q：那 类别真正的概率怎么算出来呢？只有将 对应的 bounding box 置信度 × 这个grid cell 的类别条件概率才是 这个类别真正的概率值 $全概率 = bounding box 置信度 × $ 将这个grid cell 的两个 bouding box 都赋予 这个grid cell 选择的最高类别。再进行一系列的后处理（指的是 置信度很低的先给过滤掉，非极大值抑制（NMS））选择最佳 bounding box 7×7×30这个tensor中包含了 98个bounding box 49个grid cell 每个grid cell 的类别 bounding box的 5个数值 进行解析和后处理 最后得到了结果以上我们说的都是 预测阶段 也就是 参数啥的已经调好了 我只要跑一跑 拿到个结果。 预测阶段 的后处理部分一个 grid cell 可以得到 下图右侧中两列向量。每个向量 都表示 这个 grid cell 在其一个 bounding box 中 20个类别的全概率。一个98个bounding box。 这个是由 每个bounding box 的置信度 乘以 tensor 中 输出的 该 grid cell 对20个类别的条件概率得到的。 现在我们得到如下的框框图像，一共有 98个 bounding box。不同颜色表示不同类别。（因为每个 grid cell 只会预测概率最高的那个类别 比如狗是黄色的 那他的两个bounding box 都是黄色的） 每个 bounding box 把他对20个分类的条件概率拿出来，乘以对应的置信度。得到20个分类的全概率向量。我们把刚才 每个bounding box 输出的 20个分类的全概率向量拿出来。 假如第一行的是对狗的预测。我们要把98个列向量按狗的概率，从大到小排列。（他的意思就是 我按排列之后 每一个类别都按 NMS一遍 ） 整个的过程如下图所示。 NMS方法详解假如 我们比较下图中 98个bounding box 狗这一行 的 前两个值， 也就是左边橙色和绿色连的bounding box ，我们计算一下 IoU 这边要预先设定一个门槛值（他这里是0.5，越小排异性越高），如果IoU超过0.5的话，表明这两个框预测的都是同一类别（这里也就是狗）。这样的话，保留值高的那个，低的那个全概率改为0，把这个bounding box 干掉。 下图这个就是 IoU不到门槛值 说明两个 bounding box 预测的不是一个类别 两者都保留不动。 然后第一个和所有比完了 再从剩下里面最高的 再比。最后我们可以得到一个稀疏的 98 列，选择有值的 列向量，找到其最大的概率的那一项，返回他的索引（也就是类别），以及他对于的概率值。然后在图片上打上对应的 bounding box。 注意奥 我们讲的是只是对预测阶段 需要 。在训练阶段是不需要NMS的。 因为每个框不管他是要被打入冷宫的还是负责预测物体的有用框 都要在损失函数中占据一席之地。里面的所有框的一举一动都会影响损失函数。所以不能随随便便在训练阶段 用NMS 把没用的框去掉，或者把概率抹零。 训练阶段首先奥这是个典型的 监督学习。所以我们是需要 ground truth。比如下图就是一个正确的标签： 这里有个问题 每个grid cell 都有两个 bounding box 谁来 拟合 ground truth 做损失函数呢? 答：看谁和 ground truth的 IoU 更大。比如这里 就是由 外面这个大框 负责拟合 ground truth，让其尽量的逼近 调整成 ground truth 的样子，那么另外一个框就被打入冷宫了 ，它什么都不用做，尽量让他置信度降为0。 如果没有ground truth 中心点落下 的 grid cell 的两个 bounding box 全部打入冷宫。 yolo v1 的 损失函数 (待补充与推理)下面介绍一下 yolov1损失函数误差。主要分为5个部分。现在有一个问题就是 我损失函数要去调整的参数到底是谁。是为了让选中的那个bounding box 框更加拟合 ground truth ，那我们要调整的岂不是 网络结构输出的东西，那也就是改的网络了？所以到底是在调整什么呢？ 没毛病 就是返回框的参数 然后反向传播调整网络的参数 总结yolov1的缺点 mAP相比 R-CNN 系列比较低 定位性能比较差，定位错误占总错误的比例很大 Recall比较低，就是把全部目标全部检测出来的能力比较差 检测密集和小目标的能力比较差 参考文献 牛逼的子豪兄 yolo v1详解 yolo 损失函数的详解 yolo 置信度的概念","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"yolo","slug":"yolo","permalink":"http://example.com/tags/yolo/"},{"name":"目标检测","slug":"目标检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}]},{"title":"吴恩达deeplearning.ai学习  之 目标检测","slug":"吴恩达deeplearning.ai学习  之 目标检测","date":"2021-09-25T08:37:01.000Z","updated":"2021-10-29T15:03:19.509Z","comments":true,"path":"2021/09/25/吴恩达deeplearning.ai学习  之 目标检测/","link":"","permalink":"http://example.com/2021/09/25/%E5%90%B4%E6%81%A9%E8%BE%BEdeeplearning.ai%E5%AD%A6%E4%B9%A0%20%20%E4%B9%8B%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","excerpt":"","text":"@TOC 目标定位我们对图像的学习过程应该由 图像分类 -&gt; 图像单目标定位 -&gt; 图像多目标检测。 图像分类在图像分类中，例如，输入一张图片到多层卷积神经网络，它会输出一个特征向量，并反馈给 softmax 单元来预测图片类型。比如你正在构建汽车自动驾驶系统，你面前的对象可能包括以下4类：行人、汽车、摩托车和背景，这时 softmax 单元有四个输出（概率高的为判断的类）。如果图片里没有前三类的话，输出结果会是背景。 图像分类基础上 发展图像内的单目标定位在图像分类的基础上，我们可以对图像内的单目标定位（注意：这边的基础是图像里只有一个目标可以被检测，例如上图的车）。实现定位，需要让神经网络多输出4个数字，标记为$b{x},b{y},b{h},b{w}$用于表示输出的边界框。前两者表示边界框的中心点，后两者表示的为边界框的高度和宽度。注意：我们定义左上角为坐标原点(0,0)，右下角为终点(1,1) 例如下图所示：还是这个例子，神经网络的输出改变为四个边界框描述数字$b{x},b{y},b{h},b{w}$ ，是否含有对象 $p{c}$ ，含有对象属于哪个类标签。可以定义输出 $y$ 为 $[p{c},b{x},b{y},b{h},b{w},c{1},c{2},c_{3}]^{T}$ 注意我们此时假设的图片中只含有一个对象，是单目标的分类定位问题。 损失函数神经网络的损失函数，其参数为类别$\\hat{y}$ 和网络输出 $y$ ，如果采用MSE损失函数，则 L(\\hat{y},y)==(\\hat{y_{1}} - y_{1})^{2}+(\\hat{y_{2}} - y_{2})^{2}+...+(\\hat{y_{8}} - y_{8})^{2}损失值等于每个元素相应差值的平方和。​ 如果图片内有对象（即 $p_{c}=1$），损失值就是不同元素的平方和 如果图片内没有对象（即 $p{c}=0$），我们不用考虑其它元素，只需要关注神经网络输出 $p{c}$ 的准确度。 图像内的单目标定位基础上 发展多目标定位yolo 将图像拆分成多个子图 特征点检测（Landmark detection）例如我想做人脸的情感识别，可以根据眼睛的特征点，根据嘴部的关键点输出值来确定嘴的形状，从而判断人物是在微笑还是皱眉，也可以提取鼻子周围的关键特征点。为了便于说明，你可以设定特征点的个数，假设脸部有64个特征点，有些点甚至可以帮助你定义脸部轮廓或下颌轮廓。选定特征点个数，并生成包含这些特征点的标签训练集，然后利用神经网络输出脸部关键特征点的位置。具体的想法是，准备一个卷积网络和一些特征点集，将人脸图片输入到卷积网络，输出1或0（1表示有人脸，0表示没有人脸），然后输出 64个特征点坐标位置 $(l{1x},l{1y})$ … $(l{64x},l{64y})$。理论上应该有129个输出（64个特征点 64×2+ 1（表示是否有人脸））。另外在人体姿态检测上也可以使用这样的特征点方法。 Q：注意点 特征点1的特性在所有图片中必须保持一致特征点1始终是右眼的外眼角，特征点2是右眼的内眼角，特征点3是左眼内眼角，特征点4是左眼外眼角等等。所以标签在所有图片中必须保持一致，假如你雇用他人或自己标记了一个足够大的数据集，那么神经网络便可以输出上述所有特征点，你可以利用它们实现其他有趣的效果，比如判断人物的动作姿态，识别图片中的人物表情等等。 滑动窗口目标检测法 （复杂过时）这个方法简单的说就两步 先构建一个卷积神经网络，能够识别出这个对象 滑动窗口（每次扩大窗口），选定合适的步长，从左上角开始裁剪，将其输入该卷积网络，输出是否为该对象。这样从左上角开始滑动窗口遍历整个图像。这个方法有很明显的缺点就是。如果步长太大，误差会很大，不够精细。单如果步长太精细的话，因为我每滑动一次窗口即裁剪一次图像就要输入卷积网络输出是否是车。卷积网络时间代价很高，这么多次输入，那这个方法需要的时间成本就非常的高。 Q：那为什么这个办法之前是可用的？因为之前神经网络还没兴起，每个裁剪对象判断都是由SVM来完成的。线性分类器速度比较快一些。 解决的办法是不要使用滑动窗口，使用卷积来实现滑动窗口的效果。详见下章节。 滑动窗口的卷积实现（Convolutional implementation of sliding windows）首先你要了解，如何将全神经网络转化为用卷积网络来实现，如下图：那我们现在来看 为什么要可以使用卷积来简化滑动窗口呢？如上图所示，假如输入给卷积网络的图像大小为14×14×3，测试集图片是16×16×3。现在给这个输入图片加上黄色条块（padding = 2），在最初的滑动窗口算法中，设置窗口大小为14×14，步长为2，可以滑出4个窗口，对应输入到卷积网络中，输出4个标签。 可以发现，这4次卷积操作中由很多像素点的计算都是重复的。 所以执行滑动窗口的卷积时使得卷积网络在这4次前向传播过程中共享很多计算。如果我们使用如上的卷积方式的话，最后输出的4个方块，刚好就对应我们的4个窗口。如上面绿色的小框框，假设你剪切出这块区域（编号1），传递给卷积网络，第一层的激活值就是这块区域（编号2），最大池化后的下一层的激活值是这块区域（编号3），这块区域对应着后面几层输出的右上角方块（编号4，5，6）。但是正如在前一页所看到的，我们不能依靠连续的卷积操作来识别图片中的汽车，比如，我们可以对大小为28×28的整张图片进行卷积操作，一次得到所有预测值，如果足够幸运，神经网络便可以识别出汽车的位置。28×28的图像按照 图像14×14的来划定窗口，那么将有 64个窗口（行列均为8 8×8）所以最后输出的也是个 8×8。说白了这个办法，就是用卷积，将最后的输出每个格子表示当初划定的一个窗口。这个算法，效率是提高了，但是仍然存在一个缺点，就是边界框的位置可能不够准确。可以Bounding Box预测解决，详见下一章。 Bounding Box预测（Bounding box predictions）如何能精准边界框呢。比较出名的一个算法就是 Yolo 算法。Yolo 算法是这样的，简单的说就是 （如下图）比如你输入的图像是100×100的，然后在图像上放一个3×3网格（自己定应该更精细一点）。一共9个网格，每个网格都采取我们之前说的图像分类再定位的算法。 对于9个格子中的每一个指定一个标签 $y$ ，$y$ 是8维的。$y=[p{c},b{x},b{y},b{h},b{w},c{1},c{2},c{3}]^{T}$。 看这个九宫格的第一个格子，里面没有检测的目标（也就是只有背景），所以左上格子的标签向量 $y=[0,?,?,?,?,?,?,?]^{T}$，同样右边的两个格子也是一样的。 再看第二层，有两辆车，也就是有2个对象。YOLO算法做的就是，取两个对象的中点，然后将这个对象分配给包含对象中点的格子。所以左边的汽车就分配到左边这个格子上（编号4），然后这辆长条车中点在这里，分配给右侧这个格子（编号6）。所以即使中心格子（编号5）同时有两辆车的一部分，我们就假装中心格子没有任何我们感兴趣的对象，所以对于中心格子，的输出标签向量 就是$y=[0,?,?,?,?,?,?,?]^{T}$。而左右编号为4和6的格子，输出标签向量均为$y=[1,b{x},b{y},b{h},b{w},0,1,0]^{T}$ 由此得到，最后这张图片的目标输出为 3×3×8 （因为这里有3×3格子，然后对于每个格子，你都有一个8维向量，所以目标输出尺寸是3×3×8。） 怎么得到框的精确位置呢？因为我们是将每个样本格子都作为考虑对象，所以每个格子的左上角均为（0，0），右下角为（1，1）。如下图所示，右侧长条车为栗子： 可以看到橙色为对象的中点处，而后$b{x},b{y},b{h},b{w}$单位是相对于格子尺寸的比例，所以$b{x},b{y}$必须在0和1之间；$b{h},b{w}$ 可能会大于1，特别是如果有一辆汽车的边界框是这样的（左下大红框），那么边界框的宽度和高度有可能大于1。 交并比（Intersection over union）业界都用交并比（IOU）来衡量 框框打的对不对。如下图所示： IOU = \\frac{∩ size}{∪size}一般规定≥0.5即可，这个是人为定的，你也可以严格一点，选0.6及其以上。 非极大值抑制（NMS）减少同一对象的 多个检测结果到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。 非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。 就比如上面这个图。在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。实践中当你运行对象分类和定位算法时，对于每个格子都运行一次，所以这个格子（编号1）可能会认为这辆车中点应该在格子内部，这几个格子（编号2、3）也会这么认为。对于左边的车子也一样，所以不仅仅是这个格子，如果这是你们以前见过的图像，不仅这个格子（编号4）会认为它里面有车，也许这个格子（编号5）和这个格子（编号6）也会，也许其他格子也会这么认为，觉得它们格子内有车。 我们分步介绍一下非极大抑制是怎么起效的，因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的 $p_{c}$ ，我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。所以当你运行算法的时候，最后可能会对同一个对象做出多次检测，所以非极大值抑制做的就是清理这些检测结果。这样一辆车只检测一次，而不是每辆车都触发多次检测。 所以具体上，这个算法做的是，首先看看每次报告每个检测结果相关的概率$p{c}$，实际上$p{c}$ 是 $p{c}=1$ 乘以 $c{1}、c{2}$或 $c{3}$得到的。首先看概率最大的那个，这个例子（右边车辆）中是0.9，然后就说这是最可靠的检测，所以我们就用高亮标记，就说我这里找到了一辆车。这么做之后，非极大值抑制就会逐一审视剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框，那么这些输出就会被抑制。因为其他两个矩形 $p_{c}$ 分别是0.6和0.7，这两个矩形和 0.9矩形重叠程度很高，所以会被抑制而变暗。接下来，逐一审视剩下的矩形，找出概率最高，最高的一个，在这种情况下是0.8，我们就认为这里检测出一辆车（左边车辆），然后非极大值抑制算法就会去掉其他 loU 值很高的矩形。所以现在每个矩形都会被高亮显示或者变暗，如果你直接抛弃变暗的矩形，那就剩下高亮显示的那些，这就是最后得到的两个预测结果。 简单的说就是：先消除$p_{c} ≤ 0.6$的框，当多个检测框重叠面积IOU占据最大框面积的比例超过了这个设定的非最大值抑制这个值的时候，那么就只保留置信度（概率）最高的那个框，冗余的框都去掉。 Anchor Boxes为什么要使用 anchor box到目前为止，对象检测中存在一个问题就是每个格子只能预测一个对象，如果想让一个格子检测出多个对象，你可以这么做，就是使用anchor box这个概念。 假设我们有这样一张图片，对于这个例子，我们使用3x3的网格，可以观察到，行人和汽车的中心几乎在同一个网格，然而我们以前的方法一个格子只能预测一个对象，而且对于 y 输出的向量 $y=[p{c},b{x},b{y},b{h},b{w},c{1},c{2},c{3}]^{T}$ ，你可以检测这三个类别，行人、汽车和摩托车，它将无法输出检测结果，所以我必须从两个检测结果中选一个，这便影响了模型性能，导致一些对象被丢弃无法检测出来。 anchor box 的引入和使用我们按以下图片的方式，重新定义输出即可：（右边的话是因为 anchor box2 的IoU更高）所以，总的来说，anchor box是这么来做的，现在每个对象和以前一样根据中心点分配到一个格子中，然后看和每个anchor box的IoU（交并比），选择IoU最高的那个，用这个anchor box来进行预测。 如何选择 anchor box？ 一般手工指定anchor box形状，根据要检测的对象，指定有针对性地anchor box，可选择5-10个anchor box，使其尽可能覆盖到不同形状。 使用K-means聚类算法获得anchor box。 anchor box + NMS 的总过程","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"argparse模块用法实例详解","slug":"argparse模块用法实例详解","date":"2021-09-22T15:31:01.000Z","updated":"2021-10-29T15:03:15.083Z","comments":true,"path":"2021/09/22/argparse模块用法实例详解/","link":"","permalink":"http://example.com/2021/09/22/argparse%E6%A8%A1%E5%9D%97%E7%94%A8%E6%B3%95%E5%AE%9E%E4%BE%8B%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"@TOC argparse是python的命令行解析的标准模块，内置于python，不需要安装。这个库可以让我们直接在命令行（这边指的是 python的命令行 或者是 Anaconda Prompt）中就可以向程序中传入参数并让程序运行。其实 argparse 就是一个键值对存储的方式。 栗子一：传入一个参数并输出新建一个文件（如叫：arg_study），在该文件夹中新建一个python文件（如：demo.py） 1234567891011import argparseparser = argparse.ArgumentParser(description=&#x27;命令行中传入一个数字&#x27;)# type是要传入的参数的数据类型 help是该参数的提示信息# integers 相当于键parser.add_argument(&#x27;integers&#x27;, type=str, help=&#x27;传入的数字&#x27;)args = parser.parse_args()#获得传入的参数print(args) 查看帮助提示命令行中输入python demo.py -h或者 python demo.py --help 12python demo.py -hpython demo.py --help 运行结果如下： 123456789usage: demo.py [-h] integers命令行中传入数字positional arguments: integers 传入的数字optional arguments: -h, --help show this help message and exit 输入参数并输出如输入51python demo.py 5得到的结果print(args)为 1Namespace(integers=&#x27;5&#x27;) 如何获取其中的数据呢？Namespace(integers=&#39;5&#39;) 其实是一个类似于python字典的数据类型。我们可以是哟个 arg.参数名 来提取这个参数 12#获得integers参数print(args.integers) 栗子二：传入多个参数并输出nargs是用来说明传入的参数个数，’+’ 表示传入至少一个参数。这时候再重新在命令行中运行。 12345678import argparseparser = argparse.ArgumentParser(description=&#x27;命令行中传入一个数字&#x27;)# nargs是用来说明传入的参数个数，&#x27;+&#x27; 表示传入至少一个参数。parser.add_argument(&#x27;integers&#x27;, type=str, nargs=&#x27;+&#x27;,help=&#x27;传入的数字&#x27;)args = parser.parse_args()print(args.integers) 这时候再重新在命令行中运行python demo.py 1 2 3 4得到1[&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;] 栗子三：改变数据类型add_argument中有type参数可以设置传入参数的数据类型。我们看到代码中有type这个关键词，该关键词可以传入list, str, tuple, set, dict等。例如我们把上面的type=str，改成type=int,这时候我们就可以进行四则运算。 12345678import argparseparser = argparse.ArgumentParser(description=&#x27;命令行中传入一个数字&#x27;)parser.add_argument(&#x27;integers&#x27;, type=int, nargs=&#x27;+&#x27;,help=&#x27;传入的数字&#x27;)args = parser.parse_args()#对传入的数据进行加总print(sum(args.integers)) 在命令行中输入 python demo.py 1 2 3 4, 运行结果为 110 栗子四：位置参数在命令行中传入参数时候，传入的参数的先后顺序不同，运行结果往往会不同，这是因为采用了位置参数,例如： 123456789import argparseparser = argparse.ArgumentParser(description=&#x27;姓名&#x27;)parser.add_argument(&#x27;param1&#x27;, type=str,help=&#x27;姓&#x27;)parser.add_argument(&#x27;param2&#x27;, type=str,help=&#x27;名&#x27;)args = parser.parse_args()#打印姓名print(args.param1+args.param2) 输出 张三 ：在命令行中分别输入 1python demo.py 张 三 使用可选参数为了在命令行中避免上述位置参数的bug（容易忘了顺序），可以使用可选参数，这个有点像关键词传参，但是需要在关键词前面加—，例如： 123456789import argparseparser = argparse.ArgumentParser(description=&#x27;姓名&#x27;)parser.add_argument(&#x27;--family&#x27;, type=str,help=&#x27;姓&#x27;)parser.add_argument(&#x27;--name&#x27;, type=str,help=&#x27;名&#x27;)args = parser.parse_args()#打印姓名print(args.family+args.name) 在命令行中输入： 1python demo.py --family=张 --name=三 结果为 张三 。可选参数虽然写法比较繁琐，但是增加了命令行中的可读性，不容易因为参数传入顺序导致数据错乱。 设置默认值add_argument中有一个default参数。有的时候需要对某个参数设置默认值，即如果命令行中没有传入该参数的值，程序使用默认值。如果命令行传入该参数，则程序使用传入的值。具体请看下面的例子： 123456789import argparseparser = argparse.ArgumentParser(description=&#x27;姓名&#x27;)parser.add_argument(&#x27;--family&#x27;, type=str, default=&#x27;张&#x27;,help=&#x27;姓&#x27;)parser.add_argument(&#x27;--name&#x27;, type=str, default=&#x27;三&#x27;, help=&#x27;名&#x27;)args = parser.parse_args()#打印姓名print(args.family+args.name) 设置该参数一定要传入add_argument有一个required参数可以设置该参数是否必需。 12345678910import argparseparser = argparse.ArgumentParser(description=&#x27;姓名&#x27;)parser.add_argument(&#x27;--family&#x27;, type=str, help=&#x27;姓&#x27;)# name 必须传入parser.add_argument(&#x27;--name&#x27;, type=str, required=True, default=&#x27;&#x27;, help=&#x27;名&#x27;)args = parser.parse_args()#打印姓名print(args.family+args.name) 参考博客argparse模块用法实例详解 【非常的详细】python中argparse模块用法实例详解 【比较粗糙】","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"argparse","slug":"argparse","permalink":"http://example.com/tags/argparse/"}]},{"title":"Pytorch GoogleNet中的Inception","slug":"Pytorch GoogleNet中的Inception","date":"2021-09-21T15:40:01.000Z","updated":"2021-10-29T15:03:09.686Z","comments":true,"path":"2021/09/21/Pytorch GoogleNet中的Inception/","link":"","permalink":"http://example.com/2021/09/21/Pytorch%20GoogleNet%E4%B8%AD%E7%9A%84Inception/","excerpt":"","text":"@TOC GoogleNet 的概念是基于AlexNet，VGG 后的模型 特殊点：Inception为什么要提出 Inception一般来说，提升网络性能最直接的办法是增加网络深度和宽度，但一味地增加，会带来诸多问题： 参数太多，如果训练数据集有限，很容易产生过拟合； 网络越大、参数越多，计算复杂度越大，难以应用； 网络越深，容易出现梯度消失问题（梯度越往后穿越容易消失），难以优化模型。 梯度消失和梯度爆炸 是什么？查看文章 如何理解梯度消失和梯度爆炸以及本博客文章 梯度消失和梯度爆炸的理解 我们希望在增加网络深度和宽度的同时减少参数，为了减少参数，自然就想到将全连接变成稀疏连接。但是在实现上，全连接变成稀疏连接后实际计算量并不会有质的提升，因为大部分硬件是针对密集矩阵计算优化的，稀疏矩阵虽然数据量少，但是计算所消耗的时间却很难减少。在这种需求和形势下，Google研究人员提出了Inception的方法。 Inception 模块的结构Inception 模块 是GoogleNet 重复使用的重要部分。其最大的特点是 引入了 1×1 的卷积核。其目的是用于 缩小通道数，将像素信息融合，也叫做 通道压缩。同时其可以减少卷积核的参数数量 例如:如下的操作数对比（28×28表示 卷积的时候图片像素点也要乘的啊）Inception 模块的内容如下图所示： Pytorch 实现 Inception 模块下图中为每个部分的代码模块。 每个部分的 上侧是 pytorch中网络初始化部分，下侧是 pytorch中网络前馈实现的部分。 123456789101112131415161718192021222324252627282930313233343536373839404142434445import torchimport torch.nn.functional as Fclass InceptionA(torch.nn.Module): def __init__(self, in_channels): super(InceptionA, self).__init__() # 第一个部分 self.branch_pool = torch.nn.Conv2d(in_channels, 24, kernel_size=1) # 第二个部分 self.branch1x1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1) # 第三个部分 self.branch5x5_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1) self.branch5x5_2 = torch.nn.Conv2d(16, 24, kernel_size=5, padding=2) # 第四个部分 self.branch3x3_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1) self.branch3x3_2 = torch.nn.Conv2d(16, 24, kernel_size=3, padding=1) self.branch3x3_3 = torch.nn.Conv2d(24, 24, kernel_size=3, padding=1) def forward(self, x): # 第一个部分 branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1) branch_pool = self.branch_pool(branch_pool) # 第二个部分 branch1x1 = self.branch1x1(x) # 第三个部分 branch5x5 = self.branch5x5_1(x) branch5x5 = self.branch5x5_2(branch5x5) # 第四个部分 branch3x3 = self.branch3x3_1(x) branch3x3 = self.branch3x3_2(branch3x3) branch3x3 = self.branch3x3_3(branch3x3) # 通道整合 outputs = [branch_pool, branch1x1, branch5x5, branch3x3] # 整合通道 通道的位置在1处 （batch,通道,宽度,长度） return torch.cat(outputs, dim=1) GoogleNet 网络的整体模型 使用Mnist 使用Inception构建网络123456789101112131415161718192021class Net(torch.Module): def __init__(self): super(Net, self).__init__() self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5) self.conv2 = torch.nn.Conv2d(88, 20, kernel_size=5) self.incep1 = InceptionA(in_channels=10) self.incep2 = InceptionA(in_channels=20) self.mp = torch.nn.MaxPool2d(2) self.fc = torch.nn.Linear(1408, 10) def forward(self, x): in_size = x.size(0) x = F.relu(self.mp(self.conv1(x))) x = self.incep1(x) x = F.relu(self.mp(self.conv2(x))) x = self.incep2(x) # 变成列向量 x = x.view(in_size, -1) x = self.fc(x) return x Mnist 数据集 训练 整体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143import torchimport torch.nn.functional as Ffrom torchvision import transformsfrom torchvision import datasetsfrom torch.utils.data import DataLoaderimport torch.optim as optim# 第一步 准备数据batch_size = 64transform = transforms.Compose([ transforms.ToTensor(), # 用均值和方差进行归一化 transforms.Normalize((0.1307,), (0.3081,))])train_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=True, download=True, transform=transform)test_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=False, download=True, transform=transform)train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)class InceptionA(torch.nn.Module): def __init__(self, in_channels): super(InceptionA, self).__init__() # 第一个部分 self.branch_pool = torch.nn.Conv2d(in_channels, 24, kernel_size=1) # 第二个部分 self.branch1x1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1) # 第三个部分 self.branch5x5_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1) self.branch5x5_2 = torch.nn.Conv2d(16, 24, kernel_size=5, padding=2) # 第四个部分 self.branch3x3_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1) self.branch3x3_2 = torch.nn.Conv2d(16, 24, kernel_size=3, padding=1) self.branch3x3_3 = torch.nn.Conv2d(24, 24, kernel_size=3, padding=1) def forward(self, x): # 第一个部分 branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1) branch_pool = self.branch_pool(branch_pool) # 第二个部分 branch1x1 = self.branch1x1(x) # 第三个部分 branch5x5 = self.branch5x5_1(x) branch5x5 = self.branch5x5_2(branch5x5) # 第四个部分 branch3x3 = self.branch3x3_1(x) branch3x3 = self.branch3x3_2(branch3x3) branch3x3 = self.branch3x3_3(branch3x3) # 通道整合 outputs = [branch_pool, branch1x1, branch5x5, branch3x3] return torch.cat(outputs, dim=1)class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5) self.conv2 = torch.nn.Conv2d(88, 20, kernel_size=5) self.incep1 = InceptionA(in_channels=10) self.incep2 = InceptionA(in_channels=20) self.mp = torch.nn.MaxPool2d(2) self.fc = torch.nn.Linear(1408, 10) def forward(self, x): in_size = x.size(0) x = F.relu(self.mp(self.conv1(x))) x = self.incep1(x) x = F.relu(self.mp(self.conv2(x))) x = self.incep2(x) # 变成列向量 x = x.view(in_size, -1) x = self.fc(x) return x# 实例化这个网络模型model = Net()# 第三步 定义损失函数和优化器criterion = torch.nn.CrossEntropyLoss()optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)# 定义测试函数def test(): test_loss = 0 correct = 0 with torch.no_grad(): for data, target in test_loader: outputs = model(data) _, predicted = torch.max(outputs, dim=1) correct += predicted.eq(target.view_as(predicted)).sum().item() test_loss /= len(test_loader.dataset) print(&quot;\\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%) \\n&quot;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset) )) \\ \\ def train(epochs): for epoch in range(epochs): for batch_idx, data in enumerate(train_loader, 0): # prepare data inputs, labels = data # 前馈 y_predict = model(inputs) loss = criterion(y_predict, labels) # 反馈 optimizer.zero_grad() loss.backward() # 更新 optimizer.step() if (batch_idx + 1) % 30 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))if __name__ == &#x27;__main__&#x27;: for epoch in range(10): train(epoch) test() 参考博客深度学习|经典网络：GoogLeNet（一）GoogLeNet","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"},{"name":"GoogleNet","slug":"GoogleNet","permalink":"http://example.com/tags/GoogleNet/"}]},{"title":"梯度消失和梯度爆炸的理解","slug":"梯度消失和梯度爆炸的理解","date":"2021-09-20T11:31:01.000Z","updated":"2021-10-29T15:03:05.247Z","comments":true,"path":"2021/09/20/梯度消失和梯度爆炸的理解/","link":"","permalink":"http://example.com/2021/09/20/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"","text":"@TOC 根本原因梯度消失和梯度爆炸的根本原因是由于深度神经网络过长的链，在反向传播通过链式法则求导过程中产生的。 换句话说，就是反向传播先天就有一定的毛病。 根本原因的理解左上角为 正向反馈的步骤（σ 表示 激活函数 $sigmoid$ ）。 Loss 使用的是 MSE损失函数。 根据反向传播，我们可以看到最后 loss 对 b1 参数的梯度。 可以看到 连乘的情况。 看这个式子里的 $w{i}$ 中，一般我们初始化权重参数 $w{i}$ 时，通常都小于1。 激活函数 $sigmoid$ 的求导如下所示 激活函数的导数 图像如下图所示： 所以$|σ’(z) × w| ≤ 0.25$，多个小于1的数连乘之后，那将会越来越小，导致靠近输入层的层的权重的偏导几乎为0，也就是说梯度几乎为0，导致参数基本不更新，这就是梯度消失的根本原因。梯度爆炸的原因，也就是说如果$|σ’(z) × w| ≥ 1$，连乘下来就会导致梯度过大，导致梯度更新幅度特别大，可能会溢出，导致模型无法收敛。但 $sigmoid$ 的函数是不可能大于1了，上图看的很清楚，那只能是参数 $w{i}$了，故只有当 $abs(w)&gt;4$ 时才可能出现梯度爆炸，这也就是经常看到别人博客里的一句话，初始权重过大。但梯度爆炸的情况一般不会发生，对于$sigmoid$ 函数来说，$σ’(z)$的大小也与 $w{i}$ 有关。其实梯度爆炸和梯度消失问题都是因为网络太深，网络权值更新不稳定造成的，本质上是因为梯度反向传播中的连乘效应。 如何解决梯度消失的问题（待补充） 用 $ReLU、LeakyRelu、Elu$ 等激活函数激活函数取代 $sigmoid$ 激活函数。将输出不要固定在0-1之间。$sigmoid$函数的梯度随着 $x$ 的增大或减小和消失，而 $ReLU$ 不会。 Batch Normalization 就是通过对每一层的输出规范为均值和方差一致的方法，消除了$w$带来的放大缩小的影响，进而解决梯度消失和爆炸的问题。 ResNet残差结构具体待补充完善，查看 ResNet LSTM结构LSTM不太容易发生梯度消失，主要原因在于LSTM内部复杂的“门（gates）”，具体看LSTM基本原理解析 预训练加finetunning此方法来自Hinton在06年发表的论文上，其基本思想是每次训练一层隐藏层节点，将上一层隐藏层的输出作为输入，而本层的输出作为下一层的输入，这就是逐层预训练。训练完成后，再对整个网络进行“微调（fine-tunning）”。此方法相当于是找全局最优，然后整合起来寻找全局最优，但是现在基本都是直接拿imagenet的预训练模型直接进行finetunning。 梯度剪切、正则这个方案主要是针对梯度爆炸提出的，其思想是设值一个剪切阈值，如果更新梯度时，梯度超过了这个阈值，那么就将其强制限制在这个范围之内。这样可以防止梯度爆炸。另一种防止梯度爆炸的手段是采用权重正则化，正则化主要是通过对网络权重做正则来限制过拟合，但是根据正则项在损失函数中的形式：可以看出，如果发生梯度爆炸，那么权值的范数就会变的非常大，反过来，通过限制正则化项的大小，也可以在一定程度上限制梯度爆炸的发生。 参考博客 神经网络训练中的梯度消失与梯度爆炸 梯度消失和梯度爆炸问题详解","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"Keras 实现 Kaggle 数据集 Titanic 预测","slug":"Keras 实现 Kaggle 数据集 Titanic 预测","date":"2021-09-17T12:24:01.000Z","updated":"2021-10-29T15:02:16.646Z","comments":true,"path":"2021/09/17/Keras 实现 Kaggle 数据集 Titanic 预测/","link":"","permalink":"http://example.com/2021/09/17/Keras%20%E5%AE%9E%E7%8E%B0%20Kaggle%20%E6%95%B0%E6%8D%AE%E9%9B%86%20Titanic%20%E9%A2%84%E6%B5%8B/","excerpt":"","text":"@TOC 问题描述 使用乘客数据(如姓名、年龄、性别、社会经济阶层等)，建立一个模型预测泰坦尼克号沉船上哪些乘客能够幸存。数据被分成训练集和测试集两组，它们分别在train.csv和test.csv文档中。我们的模型将基于训练集的乘客的性别和阶级等特征建立。在测试集中每个乘客是否幸存的信息是缺省的，其将由我们模型预测出来作为答案提交。 加载本地下载的 Titanic 数据集这里使用的 是 pandas 的 read_csv() 方法。 读取的格式为 DataFrame。12345# xlsx训练数据导入train_filepath = r&quot;../dataset/Titanic/train.csv&quot;train_data = pd.read_csv(train_filepath)test_filepath = r&quot;../dataset/Titanic/test.csv&quot;test_data = pd.read_csv(test_filepath)同样可以用 shape函数查看 12#(891,12)print(train_data.shape) 数据分析与预处理在预处理数据前，首先整体分析各项数据对预测模型的重要性 （1）PassengerID：乘客的ID（2）Survived：乘客是否幸存，取值为0或1，是我们预测/分类的目标。（3）Pclass：客舱等级，可能蕴含着乘客的阶层、乘客客舱的位置等信息，比较重要。（4）Name： 姓名，是无关信息。（5）Sex：性别。灾难来临时常让妇女儿童先走，而同等条件女性体力普遍弱于男性，这些因素都会影响到一名乘客幸存的可能性，因此比较重要。（6）Age：年龄，较为重要，理由同上。（7）Parch：直系亲友数目，比较重要。（8）SibSp：旁系亲友数目，比较重要。（9）Ticket：票编号，是无关信息。（10）Fare：票价，可能会反映乘客的社会阶层等。（11）Cabin：客舱编号，可能会反映客舱位置等，但由于缺省太多，数据量很小不具有代表性，可以视为噪音剔除。（12）Embarked：上船的港口编号。 在剔除了一些数据后，是否会因信息损失而降低模型的准确度？例如乘客的姓名可能暗含船上乘客之间家庭的关系。实际上我们的模型本来就是建立在不完全观测上（比如我们不知道船上的一对男女乘客有没有发生像Jack和Rose那样的故事），不确定性是必然存在的。把握主要矛盾，舍弃噪音信息是建立模型的一个好思路。 训练数据预处理方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 数据预处理# 训练数据预处理def PreprocessTrainData(train_data): # 预处理1：筛除无关特征 # 无关的有 乘客的ID 姓名 票编号客舱编号（数据量太少，当噪声剔除） # 是否幸存 客舱等级 性别 年龄 旁系亲友数目 直系亲友数目 票价 上船港口编号 cols=[&#x27;Survived&#x27;, &#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;, &#x27;Embarked&#x27;] # colums表示列名 index 表示行名 train_data = pd.DataFrame(train_data, columns=cols) #(891,8) print(train_data.shape) # 预处理2：填充缺失特征并标准化特征 age_mean = train_data[&#x27;Age&#x27;].mean() # fillna 为 无值的数据填充 train_data[&#x27;Age&#x27;] = train_data[&#x27;Age&#x27;].fillna(age_mean) fare_mean = train_data[&#x27;Fare&#x27;].mean() train_data[&#x27;Fare&#x27;] = train_data[&#x27;Fare&#x27;].fillna(fare_mean) # 预处理3：性别编码0-1 将&#123;&#x27;female&#x27;: 0, &#x27;male&#x27;: 1&#125; train_data[&#x27;Sex&#x27;]= train_data[&#x27;Sex&#x27;].map(&#123;&#x27;female&#x27;: 0, &#x27;male&#x27;: 1&#125;).astype(int) # 预处理4：登港地点转换为one-hot编码 # 这是将 Embarked这一列 分成 one-hot形式 共有三个港口 所以分成了3列 x_OneHot_df = pd.get_dummies(data=train_data,columns=[&quot;Embarked&quot;]) ndarray = x_OneHot_df.values print(&#x27;ndarray&#x27;,ndarray) #(891,10) print(ndarray.shape) # 预处理5：全体特征标准化，标签向量化 # &#x27;Survived&#x27; label = ndarray[:,:1] # label的shape： (891,1) print(&quot;label的shape：&quot;,label.shape) # 除了&#x27;Survived&#x27; 其他全部特征 features = ndarray[:,1:] # features的shape： (891, 9) print(&quot;features的shape：&quot;, features.shape) # 求一个所有列的平均值 mean = features.mean(axis=0) features -= mean # 求一个所有列的方差 std = features.std(axis=0) features /= std return features,label 测试数据预处理方法本质上与训练数据相同，只是少了一列 标签 12345678910111213141516171819202122232425262728# 测试数据预处理def PreprocessTestData(test_data): # 预处理1：筛除无关特征 # 客舱等级 性别 年龄 旁系亲友数目 直系亲友数目 票价 上船港口编号 cols=[ &#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;, &#x27;Embarked&#x27;] test_data = test_data[cols] # 预处理2：填充缺失特征并标准化特征 age_mean = test_data[&#x27;Age&#x27;].mean() test_data[&#x27;Age&#x27;] = test_data[&#x27;Age&#x27;].fillna(age_mean) fare_mean = test_data[&#x27;Fare&#x27;].mean() test_data[&#x27;Fare&#x27;] = test_data[&#x27;Fare&#x27;].fillna(fare_mean) # 预处理3：性别编码0-1 test_data[&#x27;Sex&#x27;]= test_data[&#x27;Sex&#x27;].map(&#123;&#x27;female&#x27;: 0, &#x27;male&#x27;: 1&#125;).astype(int) # 预处理4：登港地点转换为one-hot编码 x_OneHot_df = pd.get_dummies(data=test_data,columns=[&quot;Embarked&quot;]) ndarray = x_OneHot_df.values # 预处理5：全体特征标准化，标签向量化 features = ndarray mean = features.mean(axis=0) features -= mean std = features.std(axis=0) features /= std return features 拿到处理后的数据12x_train, y_train = PreprocessTrainData(train_data)x_test = PreprocessTestData(test_data) 构建网络模型构建网络时需要注意控制网络的大小。模型中容量（模型可学习的参数）不足可能导致欠拟合；但模型也不是越大越好，因为模型过大可能导致过拟合，泛化能力下降。其他降低过拟合的方法包括添加dropout正则化、权重正则化等。此外还需要在评估模型（将在下文阐述）的过程中尝试不同的超参数（学习率等）以找到最佳配置。123456789101112131415# 第三步 构建网络def TitanicModel(): # 构建网络-模型定义 model = models.Sequential() model.add(layers.Dense(input_dim=9,units=64, kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001), activation=&#x27;relu&#x27;)) model.add(layers.Dropout(0.5)) model.add(layers.Dense(units=64, kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001), activation=&#x27;relu&#x27;)) model.add(layers.Dropout(0.5)) model.add(layers.Dense(units=1, activation=&#x27;sigmoid&#x27;)) # 构建网络-编译模型 model.compile(optimizer=&#x27;rmsprop&#x27;, loss=&#x27;binary_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;]) return model 训练模型（带验证集）划分测试集和验证集12345678910111213# 留出验证集num_val = 300# 将训练集样本顺序 随机打乱np.random.shuffle([x_train,y_train])# 取出 前300个 训练样本作为 验证集x_val = x_train[:num_val]# 其他的部分作为 真实的训练集partial_x_train = x_train[num_val:]# 取出前三百个的标签 作为 验证集y_val = y_train[:num_val]# 其他的 作为真实的训练集partial_y_train = y_train[num_val:] 训练模型123# 训练模型model = TitanicModel()model.fit(partial_x_train, partial_y_train, epochs = 150, batch_size=16, validation_data=(x_val, y_val)) 预测测试样本并评估预测测试样本12y_test2 = model.predict_classes(x_test)print(y_test2) 读取正确答案123456789real_label_filepath = r&quot;../dataset/Titanic/gender_submission.csv&quot;real_label = pd.read_csv(real_label_filepath)# 读取正确数值一列onehot = pd.get_dummies(data=real_label)xarray = onehot.valuesreal = xarray[:,1:]print(real.shape,y_test2.shape) 输出正确率与保存预测答案123456789101112count = 0for (y_pre,y_rel) in zip(y_test2,real): if y_pre == y_rel: count = count+1print(&quot;count:&quot;,count)print(&quot;这个模型的正确率是：&quot; ,count/y_test2.shape[0])with open(r&quot;../dataset/Titanic/gender_submission_predict.csv&quot;,&#x27;w+&#x27;,newline=&#x27;&#x27;) as f: csv_file = csv.writer(f) csv_file.writerows(y_test2) 这个模型的优点这个模型 来自 [https://zhuanlan.zhihu.com/p/278057962?utm_source=wechat_session&amp;ivk_sa=1024320u]此模型在kaggle上排名前12%。总结其优点如下： （1）几乎完全没有人工干预。我们并不需要深入理解和分析每种因素对乘客幸存可能性的影响，而只需将数据几乎交由机器自己来学习便能得到准确度极高的预测结果。 （2）几乎没有引入数据集以外的新信息。引入新信息的行为包括将已知的乘客生存信息填入预测结果（kaggle上实现100%准确率的来源）等。此模型仅在数据处理阶段，引入部分常识判断的信息。 （3）模型泛化能力强。这里的“泛化”是指在模型建立过程中没有对该问题“过拟合”。实质上一味追求此问题的预测准确率是没有意义的。过度分析并设计复杂的特征工程也许可以提高测试集的准确率，但实质上很可能是对该问题的过拟合，不能在其他类似问题上泛化。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"},{"name":"刘二","slug":"刘二","permalink":"http://example.com/tags/%E5%88%98%E4%BA%8C/"},{"name":"Kaggle","slug":"Kaggle","permalink":"http://example.com/tags/Kaggle/"}]},{"title":"Pytorch 封装函数","slug":"Pytorch 封装函数","date":"2021-09-17T11:40:01.000Z","updated":"2021-10-29T15:02:10.088Z","comments":true,"path":"2021/09/17/Pytorch 封装函数/","link":"","permalink":"http://example.com/2021/09/17/Pytorch%20%E5%B0%81%E8%A3%85%E5%87%BD%E6%95%B0/","excerpt":"","text":"@TOC torch.tensor.viewTensor.view(*shape) → Tensor view()的作用相当于numpy中的reshape，重新定义矩阵的形状。 示例： 1234567891011121314151617181920a = torch.range(1,30)print(a)&gt;&gt;a:tensor([ 1., 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30.])b = a.view(2,3,5)print(b)&gt;&gt;b:tensor([[[ 1., 2., 3., 4., 5.], [ 6., 7., 8., 9., 10.], [11., 12., 13., 14., 15.]], [[16., 17., 18., 19., 20.], [21., 22., 23., 24., 25.], [26., 27., 28., 29., 30.]]])print(b.view(b.size(0),-1))print(b.view(b.size(1),-1))print(b.view(b.size(2),-1)) b是一个2组3行5列，b.size(0)就是留下2组，后面3行5列拉直成15个数，行成2行15列；b.size(1)就是留下3行，2组5列拉成10个数，行成3行10列；b.size(2)就是留下5列，2组3行拉成6个数，行成5行6列","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"}]},{"title":"数据集加载的各种方式方法","slug":"数据加载的各种方式方法","date":"2021-09-17T11:37:01.000Z","updated":"2021-10-29T15:02:04.635Z","comments":true,"path":"2021/09/17/数据加载的各种方式方法/","link":"","permalink":"http://example.com/2021/09/17/%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E7%9A%84%E5%90%84%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%96%B9%E6%B3%95/","excerpt":"","text":"@TOC np.loadtxt 读取本地 csv 文件读入本地 csv 文件内容。 12345678# 读取数据&#x27;&#x27;&#x27; numpy读取本地文件 delimiter 数据的分割号 dtype 读取数据类型 一般机器学习类的都是float32 因为显卡一般他内核里面是按32位工作的&#x27;&#x27;&#x27;xy = np.loadtxt(&#x27;./dataset/diabetes.csv&#x27;,delimiter=&quot;,&quot;,dtype=np.float32) 用Pytorch使用1234# numpy 转 张量 最后一组样本我们当测试样本吧 其余的当训练样本x_train = torch.from_numpy(xy[:-1,:-1])print(x_train.shape)y_train = torch.from_numpy(xy[:-1,[-1]]) 批次读取 本地 csv 文件使用 DataLoader+Dataset Step1：引入包1234# Dataset 是个抽象类，所以其不可以被实例化# Dataset 可以为其他的子类所继承的from torch.utils.data import Datasetfrom torch.utils.data import DataLoader Step2：定义一个自己的Dataset类 并继承原有的抽象类Dataset1234567891011121314151617181920212223# DiabetesDataset 继承 Datasetclass DiabetesDataset(Dataset): def __init__(self, filepath): xy = np.loadtxt(filepath, delimiter=&#x27;,&#x27;, dtype=np.float32) # 一共有几个样本 self.len = xy.shape[0] # numpy 转 张量 最后一组样本我们当测试样本吧 其余的当训练样本 self.x_train = torch.from_numpy(xy[:, :-1]) self.y_train = torch.from_numpy(xy[:, [-1]]) # 继承Dataset的方法并重写 # 其实用来帮助找索引位置的 dataset[index] # 函数功能是根据index索引去返回数据样本以及标签label def __getitem__(self, index): return self.x_train[index], self.y_train[index] # 函数功能是用来查看数据的长度，也就是 dataset 样本的数量 def __len__(self): return self.len# 实例化这个类diabetesdataset = DiabetesDataset(&#x27;../dataset/diabetes.csv&#x27;) Step3：使用DataLoader其返回的是 对应索引的数据123456789# 定义一个 loader&#x27;&#x27;&#x27; batch_size 就是批次大小 shuffle True的话就表示要打乱数据 num_workers 读取Mni-batch的时候要多进程 2就表示由2个进程进行读取&#x27;&#x27;&#x27;# 返回 （x,y）train_loader = DataLoader(dataset=diabetesdataset, batch_size=32, num_workers=2, shuffle=True, drop_last=False) Step4：用迭代的方式拿到数据12345678910111213if __name__ == &#x27;__main__&#x27;: for epoch in range(100): for i, data in enumerate(train_loader, 0): # 1. Prepare data inputs, labels = data # 2. Forward y_pred = FullLeanerModel(inputs) loss = criterion(y_pred, labels) # 3. Backward optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 # 4. Update optimizer.step() # 更新参数 用 pandas 的 read_csv 方法12train_filepath = r&quot;../dataset/Titanic/train.csv&quot;train_data = pd.read_csv(train_filepath) pandas需要使用 DataFrame 的形式可用 pandas.DataFrame()来转换成 DataFrame 格式 1234# 是否幸存 客舱等级 性别 年龄 旁系亲友数目 直系亲友数目 票价 上船港口编号cols=[&#x27;Survived&#x27;, &#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;, &#x27;Embarked&#x27;]# colums表示列名 index 表示行名 选择需要的列train_data = pd.DataFrame(train_data, columns=cols) 可以用 ndarray 将DataFrame 转为 普通的numpy 读取出来。如下： 1234# &#x27;Survived&#x27;label = ndarray[:,:1]# 除了&#x27;Survived&#x27; 其他全部特征features = ndarray[:,1:]","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"数据集","slug":"数据集","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"}]},{"title":"Pytorch CNN概念性解决","slug":"Pytorch CNN概念性解决","date":"2021-09-16T12:40:01.000Z","updated":"2021-10-29T15:01:50.601Z","comments":true,"path":"2021/09/16/Pytorch CNN概念性解决/","link":"","permalink":"http://example.com/2021/09/16/Pytorch%20CNN%E6%A6%82%E5%BF%B5%E6%80%A7%E8%A7%A3%E5%86%B3/","excerpt":"","text":"@TOC需要知道的几点 卷积核里的参数都是超参数，是通过训练进行调整的 CNN的流程input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten（压平）——&gt;fully connected network——&gt;output CNN的卷积操作运算单通道图像 多通道图像 如三通道RGB用三个卷积核，分别对3个通道各自卷积，然后再相加整合输出。 如何看待卷积核的个数和通道数记住两条规律就好： 卷积核通道数 = 输入通道数 卷积核个数 = 输出通道数 注意卷积层一般都是4维的 包括：批次，输入通道数，卷积核大小（宽，高）可以参考下面的卷积程序 1234567891011121314151617181920212223242526import torch# 输入通道数为5 输出通道数为10in_channels,out_channels = 5, 10# 初始化图像高度width,height = 100,100# 卷积核的大小kernel_size = 3# 批次batch_size = 1# 随机生成100×100的 图像input = torch.randn(batch_size,in_channels,width,height)# 设置卷积层 输入维度，输出维度，卷积核大小conv_layer = torch.nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size)# 将图片放入卷积层 输出结果output = conv_layer(input)# torch.Size([1, 5, 100, 100])# 分别为 batch_size,图片通道数，图像宽100，图像高100print(input.shape)# torch.Size([1, 10, 98, 98])# 分别为 batch_size,输出通道数10（其实就是卷积核的个数），图像卷积后（由于卷积核是3×3 所以减去2）print(output.shape)# torch.Size([10, 5, 3, 3])# 输出通道（卷积核数量） 输入通道（卷积核通道数） 卷积核大小print(conv_layer.weight.shape) 如何看待 paddingpadding的目的是，为了规定输出图像的大小。例如 原来是 5×5 的原图，通过卷积核为 3×3 那 输出的图 是 3×3 的但如果设置 padding 为1，那么相当于把原图扩充为 7×7 了。可以参考一下如下的代码： 1234567891011121314151617181920212223242526272829303132import torch# 假设的灰度图片像素值 图片为5×5input = [3,4,6,5,7, 2,4,6,8,2, 1,6,7,8,4, 9,7,4,6,2, 3,7,5,4,1]# 将输入的图片变成Tensor类型，并且reshape一下&#x27;&#x27;&#x27; 参数从左到右分别为 batch_size,in_channels,width,height&#x27;&#x27;&#x27;input = torch.Tensor(input).view(1,1,5,5)# 卷积核的大小kernel_size = 3&#x27;&#x27;&#x27; 从左到右分别为 in_channels,out_channels,kernel_size&#x27;&#x27;&#x27;conv_layer = torch.nn.Conv2d(1,1,3,padding=1,bias=False)&#x27;&#x27;&#x27; 自定义一个tensor向量 再将其 reshape batch_size,in_channels,width,height&#x27;&#x27;&#x27;kernel = torch.Tensor([1,2,3,4,5,6,7,8,9]).view(1,1,3,3)# 初始化卷积层conv_layer.weight.data = kernel.dataoutput = conv_layer(input)# torch.Size([1, 1, 5, 5])print(output.shape)print(output) 如何看待步长 stride设置一下 stride就可以了1conv_layer = torch.nn.Conv2d(1, 1, kernel_size=3, stride=2, bias=False)改变步长的意义，其实就是为了缩小输出尺寸 如何看待Max Pooling可以参考如下的代码: 1234567891011121314151617181920212223242526import torchinput = [ 3,4,6,5, 2,4,6,8, 1,6,7,8, 9,7,4,6]# 输入的 batch_size为1 通道数为1 也就是灰度图像 大小是4×4input = torch.Tensor(input).view(1,1,4,4)# 默认的步长 stride也是2maxpooling_layer = torch.nn.MaxPool2d(kernel_size=2)output = maxpooling_layer(input)print(output.shape)print(output)&#x27;&#x27;&#x27; 这里只进行了一个 maxpooling操作 input = [ 3,4,6,5, 2,4,6,8, 1,6,7,8, 9,7,4,6] 变为 [4,8 9,8]&#x27;&#x27;&#x27; 设计一个网络并实现如图所示为 要设计的网络模型 转换成流程图 Pytorch 代码实现这个网络12345678910111213141516171819202122# 设计网络class CNNNet(torch.nn.Module): def __init__(self): super(CNNNet, self).__init__() self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5) self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5) self.pooling = torch.nn.MaxPool2d(2) self.fc = torch.nn.Linear(320, 10) def forward(self, x): # Flatten data from (n, 1, 28, 28) to (n, 784) batch_size = x.size(0) x = self.pooling(torch.relu(self.conv1(x))) x = self.pooling(torch.relu(self.conv2(x))) # flatten (n,320) x = x.view(batch_size, -1) x = self.fc(x) return x # 实例化这个网络CNNmodel = CNNNet()","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"CNN","slug":"CNN","permalink":"http://example.com/tags/CNN/"},{"name":"刘二","slug":"刘二","permalink":"http://example.com/tags/%E5%88%98%E4%BA%8C/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"}]},{"title":"Pytorch 多分类问题的解决","slug":"Pytorch 多分类问题的解决","date":"2021-09-15T11:40:01.000Z","updated":"2021-10-29T15:01:59.056Z","comments":true,"path":"2021/09/15/Pytorch 多分类问题的解决/","link":"","permalink":"http://example.com/2021/09/15/Pytorch%20%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3/","excerpt":"","text":"@TOC 多分类问题 激活函数的选择 Softmax选择 Softmax 函数的关键点是： 确保输出的每一个概率都是 ≥ 0 的 所有的概率之和应该为 1 Softmax 激活函数完美解决了这个问题： 举个简单的例子 CrossEntropyLoss 和 NLLLoss区别NLLLoss全称是Negative Log Likelyhood Loss，负对数似然损失函数。softmax + NLLLoss = CrossEntropyLoss 在Pytorch中 CrossEntropyLoss可以直接接到模型结果之后，直接得出交叉熵损失。 NLLLoss需要在模型结果后先接一个Softmax，将模型结果变成概率，再用NLLLoss求预测损失。 实现梯度下降Step1：准备数据12x_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0] Step2：初始化参数w12# 初始值w为1w = 1.0 Step3：定义模型12def forward(x_data): return x_data * w Step4：定义损失函数 123456def loss(x_data, y_data): loss = 0 for x, y in zip(x_data, y_data): y_pred = forward(x) loss = loss + (y_pred - y) ** 2 return loss / len(x_data) Step5：定义梯度 12345678910111213# 求梯度 也就是 损失函数对w的偏导def gradient(x_data, y_data): grad = 0 &#x27;&#x27;&#x27; x = [1, 2, 3] y = [4, 5, 6, 7] xy = zip(x, y) print xy 运行的结果是： [(1, 4), (2, 5), (3, 6)] &#x27;&#x27;&#x27; for x, y in zip(x_data, y_data): grad = grad + 2 * x * (x * w - y) return grad / len(x_data) Step6：训练并更新参数 w 1234567891011# 没训练过的时候 w是初始值print(&#x27;Predict (before training)&#x27;, 4, forward(4))# 这批数据样本 训练 99次for epoch in range(100): # 每次都是计算一整个数据集的 平均loss loss_val = loss(x_data, y_data) grad_val = gradient(x_data, y_data) w = w - 0.01 * grad_val print(&#x27;Epoch:&#x27;, epoch, &#x27;w=&#x27;, w, &#x27;loss=&#x27;, loss_val)print(&#x27;Predict (after training)&#x27;, 4, forward(4)) 实现多分类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899import torchfrom torchvision import transformsfrom torchvision import datasetsfrom torch.utils.data import DataLoaderimport torch.nn.functional as Fimport torch.optim as optim# 第一步 准备数据batch_size = 64transform = transforms.Compose([ transforms.ToTensor(), # 用均值和方差进行归一化 transforms.Normalize((0.1307,), (0.3081,))])train_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=True, download=True, transform=transform)test_dataset = datasets.MNIST(root=&#x27;../dataset/mnist/&#x27;, train=False, download=True, transform=transform)train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)# 第二步 设计模型class Net(torch.nn.Module): def __init__(self): # 这个是必须写的 super(Net, self).__init__() # 构建层次模型 self.l1 = torch.nn.Linear(784, 512) self.l2 = torch.nn.Linear(512, 256) self.l3 = torch.nn.Linear(256, 128) self.l4 = torch.nn.Linear(128, 64) self.l5 = torch.nn.Linear(64, 10) def forward(self, x): x = x.view(-1,784) x = F.relu(self.l1(x)) x = F.relu(self.l2(x)) x = F.relu(self.l3(x)) x = F.relu(self.l4(x)) return self.l5(x)# 实例化这个网络模型model = Net()# 第三步 定义损失函数和优化器criterion = torch.nn.CrossEntropyLoss()optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)# 第四步 训练模型def train(epoch): running_loss = 0.0 # 这个0 的意思表示 索引从0开始计 for batch_idx, data in enumerate(train_loader, 0): inputs, target = data optimizer.zero_grad() # forward + backward + update outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 300 == 299: print(&#x27;[%d, %5d] loss: %.3f&#x27; % (epoch + 1, batch_idx + 1, running_loss / 300)) running_loss = 0.0# 第五步 测试并检验def test(): correct = 0 total = 0 with torch.no_grad(): for data in test_loader: images, labels = data outputs = model(images) #输出每行最大的那个 _, predicted = torch.max(outputs.data, dim=1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#x27;Accuracy on test set: %d %%&#x27; % (100 * correct / total))if __name__ == &#x27;__main__&#x27;: for epoch in range(10): train(epoch) test()","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"}]},{"title":"Pytorch 数据读取 DataLoader与Dataset 概念","slug":"Pytorch 数据读取 DataLoader与Dataset 概念","date":"2021-09-13T13:17:01.000Z","updated":"2021-10-29T15:01:20.391Z","comments":true,"path":"2021/09/13/Pytorch 数据读取 DataLoader与Dataset 概念/","link":"","permalink":"http://example.com/2021/09/13/Pytorch%20%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%20DataLoader%E4%B8%8EDataset%20%E6%A6%82%E5%BF%B5/","excerpt":"","text":"@TOC 在机器学习中，我们对数据的处理主要分为4个阶段，如下图所示： 第一步，收集需要的数据，数据包括原始样本 和 对应标签； 第二步，对数据集进行划分，把数据集划分为 训练集、验证集和测试集 ；训练集用于训练模型，验证集用于验证模型是否过拟合（也可以理解为用验证集挑选模型的超参数），测试集用于测试模型的性能，测试模型的泛化能力； 第三步，从本地读取数据，要按 Mini-batch 分批训练。一起训练，内存不够。使用的方法为 DataLoader ，其又分为两个部分： Sample 用于生成索引，即样本的序号； Dataset 是根据索引去读取图片以及对应的标签； 第四步，数据预处理，把数据读取进来往往还需要对数据进行一系列的图像预处理，比如说数据的中心化，标准化，旋转或者翻转等等。Pytorch 中数据预处理是通过 transforms 进行处理的； DataLoader 和 DatasetDataLoader torch.utils.data.DataLoader 功能：构建可迭代的数据装载器；dataset: Dataset类，决定数据从哪里读取及如何读取；batchsize：批次样本数量大小；num_works:是否多进程读取数据； 可以设置为几个进程shuffle：每个epoch是否乱序；drop_last：当样本数不能被 batchsize 整除时，是否舍弃最后一批数据； Epoch，Iteration，Batchsize的区别 Epoch：所有训练样本都已输入到模型中，称为一个EpochIteration：一批样本输入到模型中，称之为一个Iteration；Batchsize：批次样本数量大小，决定一个Epoch中有多少个Iteration； Iteration = Epoch ➗ Batchsize123样本总数：87，Batchsize=8 （样本不能被Batchsize整除）1 Epoch = 10 Iteration，drop_last = True1 Epoch = 11 Iteration， drop_last = False用法例如： 1train_loader = DataLoader(dataset=diabetesdataset,batch_size=32,num_workers=2,shuffle=True,drop_last=False) Dataset torch.utils.data.DatasetDataset是用来定义数据从哪里读取，以及如何读取的问题； 功能：Dataset抽象类，所有自定义的Dataset需要继承它，并且重写getitem()； getitem ()：接收一个索引，返回一个样本 例如： 123456789101112131415161718# DiabetesDataset 继承 Datasetclass DiabetesDataset(Dataset): def __init__(self,filepath): xy = np.loadtxt(filepath,delimiter=&#x27;,&#x27;,dtype=np.float32) # 一共有几个样本 self.len = xy.shape[0] # numpy 转 张量 最后一组样本我们当测试样本吧 其余的当训练样本 self.x_train = torch.from_numpy(xy[:, :-1]) self.y_train = torch.from_numpy(xy[:, [-1]]) # 继承Dataset的方法并重写 # 其实用来帮助找索引位置的 dataset[index] # 函数功能是根据index索引去返回数据样本以及标签label def __getitem__(self, index): return self.x_train[index],self.y_train[index] # 函数功能是用来查看数据的长度，也就是 dataset 样本的数量 def __len__(self): return self.len Dataloader的运行机制数据读取的三个问题：1、读哪些数据；2、从哪读数据；3、怎么读数据？ 从代码中可以发现，index 是从 sampler.py 中输出的，所以读哪些数据是由sampler得到的； 从代码中看，是从Dataset中的 文件地址参数 告诉我们 Pytorch 是从硬盘中的哪一个文件夹获取数据； 从代码中可以发现，Pytorch是从Dataset的getitem()中具体实现的，根据索引去读取数据； DataLoader数据读取流程简单描述一下流程图，首先在for循环中去使用DataLoader，进入DataLoader之后是否采用多进程进入DataLoaderlter，进入DataLoaderIter之后会使用sampler去获取Index，拿到索引之后传输到DatasetFetcher，在DatasetFetcher中会调用Dataset，Dataset根据给定的Index，在getitem中从硬盘里面去读取实际的Img和Label，读取了一个batch_size的数据之后，通过一个collate_fn将数据进行整理，整理成batch_Data的形式，接着就可以输入到模型中训练； 读哪些是由Sampler决定的，从哪读是由Dataset决定的，怎么读是由getitem决定的 详细原文转载https://blog.csdn.net/qq_37388085/article/details/102663166 实验代码糖尿病案例。 数据读取采用 批处理 DataLoader。理论上 测试集和训练集 都应该分别有一个 DataLoader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import torchimport numpy as np# Dataset 是个抽象类，所以其不可以被实例化# Dataset 可以为其他的子类所继承的from torch.utils.data import Datasetfrom torch.utils.data import DataLoaderxy = np.loadtxt(&#x27;../dataset/diabetes.csv&#x27;, delimiter=&quot;,&quot;, dtype=np.float32)# (759,9) 759行 9列# 当测试样本 的 一组数据x_test = torch.from_numpy(xy[-1:, :-1])y_test = torch.from_numpy(xy[-1:, [-1]])# DiabetesDataset 继承 Datasetclass DiabetesDataset(Dataset): def __init__(self, filepath): xy = np.loadtxt(filepath, delimiter=&#x27;,&#x27;, dtype=np.float32) # 一共有几个样本 self.len = xy.shape[0] # numpy 转 张量 最后一组样本我们当测试样本吧 其余的当训练样本 self.x_train = torch.from_numpy(xy[:, :-1]) self.y_train = torch.from_numpy(xy[:, [-1]]) # 继承Dataset的方法并重写 # 其实用来帮助找索引位置的 dataset[index] # 函数功能是根据index索引去返回数据样本以及标签label def __getitem__(self, index): return self.x_train[index], self.y_train[index] # 函数功能是用来查看数据的长度，也就是 dataset 样本的数量 def __len__(self): return self.len# 实例化这个类diabetesdataset = DiabetesDataset(&#x27;../dataset/diabetes.csv&#x27;)# 定义一个 loader&#x27;&#x27;&#x27; batch_size 就是批次大小 shuffle True的话就表示要打乱数据 num_workers 读取Mni-batch的时候要多线程 2就表示由2个线程进行读取&#x27;&#x27;&#x27;# 返回 （x,y）train_loader = DataLoader(dataset=diabetesdataset, batch_size=32, num_workers=2, shuffle=True, drop_last=False)# 第二部 定义模型# 这个其实有点类似与 神经网络的结构了 每个线性层后面都加了一个sigmoid函数 做了次非线性变换class FullLeanerModel(torch.nn.Module): # 定义多层线性模型的结构 def __init__(self): super(FullLeanerModel, self).__init__() # 第一个线性转换 将8维转换为6维 self.linear1 = torch.nn.Linear(8, 6) self.linear2 = torch.nn.Linear(6, 4) self.linear3 = torch.nn.Linear(4, 1) self.sigmoid = torch.nn.Sigmoid() # 前馈 运行 def forward(self, x): # 用一个变量比较 简单 x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) x = self.sigmoid(self.linear3(x)) return x# 实例化模型FullLeanerModel = FullLeanerModel()# 第三步 定义 损失函数和优化器criterion = torch.nn.BCELoss(reduction=&#x27;mean&#x27;)optimizer = torch.optim.SGD(FullLeanerModel.parameters(), lr=0.1)# 第四步 训练&#x27;&#x27;&#x27; 前两步 就是正向传播 forward 1. 预测 标签 2. 预测 与 实际 算出损失值 3. 反向传播 backward 优化参数 4. 更新参数&#x27;&#x27;&#x27;#if __name__ == &#x27;__main__&#x27;: for epoch in range(100): for i, data in enumerate(train_loader, 0): # 1. Prepare data inputs, labels = data # 2. Forward y_pred = FullLeanerModel(inputs) loss = criterion(y_pred, labels) # 3. Backward optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 # 4. Update optimizer.step() # 更新参数 # 第五步 评估模型 # 输出各层 权重w 和 偏置b for weight, bias in FullLeanerModel.state_dict().items(): # param is weight or bias(Tensor) print(weight, bias) # 预测 y_yuce = FullLeanerModel(x_test) print(&quot;测试样本的预测值为&quot;, y_yuce.data, &quot;实际样本的标签值为&quot;, y_test.data) 实验结果","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"刘二","slug":"刘二","permalink":"http://example.com/tags/%E5%88%98%E4%BA%8C/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"},{"name":"DataLoader","slug":"DataLoader","permalink":"http://example.com/tags/DataLoader/"}]},{"title":"Pytorch 实现 多维特征的输入——糖尿病预测","slug":"Pytorch 实现 多维特征的输入——糖尿病预测","date":"2021-09-13T03:30:01.000Z","updated":"2021-10-29T15:01:32.015Z","comments":true,"path":"2021/09/13/Pytorch 实现 多维特征的输入——糖尿病预测/","link":"","permalink":"http://example.com/2021/09/13/Pytorch%20%E5%AE%9E%E7%8E%B0%20%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5%E2%80%94%E2%80%94%E7%B3%96%E5%B0%BF%E7%97%85%E9%A2%84%E6%B5%8B/","excerpt":"","text":"@TOC 整体的设计思路大致的设计步骤 分为5步 如下所示：第五步：是进行 评估模型并预测 12import torchimport numpy as np Step1：准备数据数据格式包含759个样本，其中有8个特征已经其是否会加剧糖尿病的预测标签（1或0）。我们将759个样本，分为758个训练样本以及1个测试样本。 先读入本地 csv 文件内容 12345678# 读取数据&#x27;&#x27;&#x27; numpy读取本地文件 delimiter 分割号 dtype 读取数据类型 一般机器学习类的都是float32 因为显卡一般他内核里面是按32位工作的&#x27;&#x27;&#x27;xy = np.loadtxt(&#x27;./dataset/diabetes.csv&#x27;,delimiter=&quot;,&quot;,dtype=np.float32) 可以查看一下 读入的数据维度情况 12# (759,9) 759行 9列print(xy.shape) 其中758个样本作为测试集 1234# numpy 转 张量 最后一组样本我们当测试样本吧 其余的当训练样本x_train = torch.from_numpy(xy[:-1,:-1])print(x_train.shape)y_train = torch.from_numpy(xy[:-1,[-1]]) 最后一个样本作为训练集，用于预测结果 1234# 当测试样本 的 一组数据x_test = torch.from_numpy(xy[-1:,:-1])print(x_test.shape)y_test = torch.from_numpy(xy[-1:,[-1]]) Step2：定义模型同样每一层都为 逻辑回归模型。但这边有8个特征，所以导入的应该是个矩阵。 torch.nn.Linear(in_features,out_features,bias=True) 方法下面这个函数 使得8维度线性变换为6维度注：1.整个模型都是以 列向量为操作单位的（这么做其实是为了利用计算机的并行计算能力加快训练速度），所以维度指的是有多少列，比如左下角这个维度就是8。2.激活函数的引入，其实就是为了引入非线性的因素。这样就可以使得我们可以非线性的变换矩阵维度。下面是我们 构建的整体的 线性网络模型 1234567891011121314151617181920# 第二部 定义模型# 这个其实有点类似与 神经网络的结构了 每个线性层后面都加了一个sigmoid函数 做了次非线性变换class FullLeanerModel(torch.nn.Module): # 定义多层线性模型的结构 def __init__(self): super(FullLeanerModel,self).__init__() # 第一个线性转换 将8维转换为6维 self.linear1 = torch.nn.Linear(8,6) self.linear2 = torch.nn.Linear(6,4) self.linear3 = torch.nn.Linear(4,1) self.sigmoid = torch.nn.Sigmoid() # 前馈 运行输出结果 # 会被自动调用 是方法的重写 def forward(self,x): # 用一个变量比较 简单 x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) x = self.sigmoid(self.linear3(x)) return x 实例化这个模型 12# 实例化模型FullLeanerModel = FullLeanerModel() Step3：定义损失函数和优化器123# 第三步 定义 损失函数和优化器criterion = torch.nn.BCELoss(reduction=&#x27;mean&#x27;)optimizer = torch.optim.SGD(FullLeanerModel.parameters(),lr=0.1) Step4：训练模型训练模型100次 12345678910111213141516# 第四步 训练&#x27;&#x27;&#x27; 前两步 就是正向传播 forward 1. 预测 标签 2. 预测 与 实际 算出损失值 3. 反向传播 backward 优化参数 4. 更新参数&#x27;&#x27;&#x27;for epoch in range(101): y_pred = FullLeanerModel(x_train) loss = criterion(y_pred,y_train) print(&#x27;迭代次数:&#x27;,epoch,&quot; 损失值:&quot;,loss.item()) optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 optimizer.step() #更新参数 评估模型并预测输出所有层次的 权重和偏置123 # 输出各层 权重w 和 偏置bfor weight, bias in FullLeanerModel.state_dict().items(): # param is weight or bias(Tensor)print( weight,bias) 预测123# 预测y_yuce = FullLeanerModel(x_test)print(&quot;测试样本的预测值为&quot;,y_yuce.data,&quot;实际样本的标签值为&quot;,y_test.data) 完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import numpy as npimport torch# 读取数据&#x27;&#x27;&#x27; numpy读取本地文件 delimiter 分割号 dtype 读取数据类型 一般机器学习类的都是float32 因为显卡一般他内核里面是按32位工作的&#x27;&#x27;&#x27;xy = np.loadtxt(&#x27;./dataset/diabetes.csv&#x27;,delimiter=&quot;,&quot;,dtype=np.float32)# (759,9) 759行 9列print(xy.shape)# numpy 转 张量 最后一组样本我们当测试样本吧 其余的当训练样本x_train = torch.from_numpy(xy[:-1,:-1])print(x_train.shape)y_train = torch.from_numpy(xy[:-1,[-1]])# 当测试样本 的 一组数据x_test = torch.from_numpy(xy[-1:,:-1])print(x_test.shape)y_test = torch.from_numpy(xy[-1:,[-1]])# 第二部 定义模型# 这个其实有点类似与 神经网络的结构了 每个线性层后面都加了一个sigmoid函数 做了次非线性变换class FullLeanerModel(torch.nn.Module): # 定义多层线性模型的结构 def __init__(self): super(FullLeanerModel,self).__init__() # 第一个线性转换 将8维转换为6维 self.linear1 = torch.nn.Linear(8,6) self.linear2 = torch.nn.Linear(6,4) self.linear3 = torch.nn.Linear(4,1) self.sigmoid = torch.nn.Sigmoid() # 前馈 运行 def forward(self,x): # 用一个变量比较 简单 x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) x = self.sigmoid(self.linear3(x)) return x# 实例化模型FullLeanerModel = FullLeanerModel()# 第三步 定义 损失函数和优化器criterion = torch.nn.BCELoss(reduction=&#x27;mean&#x27;)optimizer = torch.optim.SGD(FullLeanerModel.parameters(),lr=0.1)# 第四步 训练&#x27;&#x27;&#x27; 前两步 就是正向传播 forward 1. 预测 标签 2. 预测 与 实际 算出损失值 3. 反向传播 backward 优化参数 4. 更新参数&#x27;&#x27;&#x27;for epoch in range(101): y_pred = FullLeanerModel(x_train) loss = criterion(y_pred,y_train) print(&#x27;迭代次数:&#x27;,epoch,&quot; 损失值:&quot;,loss.item())![在这里插入图片描述](https://img-blog.csdnimg.cn/f600a0b6fbe24b60b35a0f2bc26f9444.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center) optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 optimizer.step() #更新参数# 第五步 评估模型 # 输出各层 权重w 和 偏置bfor weight, bias in FullLeanerModel.state_dict().items(): # param is weight or bias(Tensor) print( weight,bias)# 预测y_yuce = FullLeanerModel(x_test)print(&quot;测试样本的预测值为&quot;,y_yuce.data,&quot;实际样本的标签值为&quot;,y_test.data) 实验结果可以看到 最后一个样本模型预测概率是 0.6529 。&gt;0.5 我们可以推测其标签就是1，而实际标签也是1，所以这个模型预测结果目前看是正确的。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"刘二","slug":"刘二","permalink":"http://example.com/tags/%E5%88%98%E4%BA%8C/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"},{"name":"多维度特征","slug":"多维度特征","permalink":"http://example.com/tags/%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%89%B9%E5%BE%81/"}]},{"title":"Pytorch 实现 简易逻辑回归模型 —— 刘二","slug":"Pytorch 实现 简易逻辑回归模型 —— 刘二","date":"2021-09-12T03:30:01.000Z","updated":"2021-10-29T15:01:39.736Z","comments":true,"path":"2021/09/12/Pytorch 实现 简易逻辑回归模型 —— 刘二/","link":"","permalink":"http://example.com/2021/09/12/Pytorch%20%E5%AE%9E%E7%8E%B0%20%E7%AE%80%E6%98%93%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%20%E2%80%94%E2%80%94%20%E5%88%98%E4%BA%8C/","excerpt":"","text":"@TOC 用Pytorch 实现 简单的逻辑回归。整个流程图可以如下图所示： 大致的设计步骤 分为5步 如下所示：第五步：是进行 评估模型并预测 1import torch Step1：准备数据 123# 准备数据x_data = torch.Tensor([[1.0], [2.0], [3.0]])y_data = torch.Tensor([[0], [0], [1]]) Step2：设计模型内涵的线性模型比较简单 为 $y=Wx+b$ 只有两个超参数 W 和 b 1234567891011121314# 第二步 设计模型# 构建一个线性模型类 所有的模型类都必须继承torch.nn.Moduleclass LogisticRegressionModel(torch.nn.Module): def __init__(self): # 调用父类的构造 这步必须得有 super(LogisticRegressionModel, self).__init__() # Linear 是一个模型类 这边实例化他给 linear # w 权重 = 1 b 偏置 = 1 self.linear = torch.nn.Linear(1, 1) def forward(self, x): # 线性模型之后 在外套sigmoid激活函数 y_pred = torch.sigmoid(self.linear(x)) return y_pred torch.nn.Linear(in_features,out_features,bias=True) 方法 实例化这个模型为 model 12# 实例化这个模型model = LogisticRegressionModel() Step3：构建损失函数和优化器12345# 第三步 构建损失函数和优化器# BCELoss Binary Cross Entropycriterion = torch.nn.BCELoss(reduction=&#x27;mean&#x27;) # size_average = True 的话 就 乘以 1/N 默认为true#model.parameters() 可以找到模型所有需要训练的参数optimizer = torch.optim.SGD(model.parameters(),lr=0.01) torch.nn.BCELoss(size_average=False) 方法用于创建一个 BCE 损失函数 torch.optim.SGD(…) 方法优化器选择 SGD 可调整学习率$w^{*} = w - α\\frac{\\partial L}{\\partial W}$ Step4: 训练模型 前两步 就是正向传播 forward 预测 标签 预测 与 实际 算出损失值 反向传播 backward 优化参数 更新参数 123456789# 第四步 训练for epoch in range(100): y_pred = model(x_data) loss = criterion(y_pred,y_data) print(&#x27;迭代次数:&#x27;,epoch,&quot; 损失值:&quot;,loss.item() ) optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 optimizer.step() #更新参数 Step5: 评估模型并预测这边没有准备 测试集及其标签 输出 超参数 权重w 和 偏置b1234# 输出 超参数 权重w 和 偏置bprint(&#x27;w = &#x27;,model.linear.weight.item() )print(&#x27;b = &#x27;,model.linear.bias.item()) 预测 1234# 预测 x_test = torch.Tensor([[4.0]])y_test = model(x_test)print(&#x27;x为4.0 预测的 y值为：&#x27;,y_test.data) 实验结果 这边少了 怎么输出 准确率？ 可以画一下图12345678910111213import numpy as npimport matplotlib.pyplot as pltx = np.linspace(0, 10, 200)x_t = torch.Tensor(x).view((200, 1))y_t = model(x_t)y = y_t.data.numpy()plt.plot(x, y)plt.plot([0, 10], [0.5, 0.5], c=&#x27;r&#x27;)plt.xlabel(&#x27;Hours&#x27;)plt.ylabel(&#x27;Probability of Pass&#x27;)plt.grid()plt.show() 实现源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import torch# 第一步 载入数据x_data = torch.Tensor([[1.0], [2.0], [3.0]])y_data = torch.Tensor([[0], [0], [1]])# 第二步 设计模型# 构建一个线性模型类 所有的模型类都必须继承torch.nn.Moduleclass LogisticRegressionModel(torch.nn.Module): def __init__(self): # 调用父类的构造 这步必须得有 super(LogisticRegressionModel, self).__init__() # Linear 是一个模型类 这边实例化他给 linear # w 权重 = 1 b 偏置 = 1 self.linear = torch.nn.Linear(1, 1) def forward(self, x): # 线性模型之后 在外套sigmoid激活函数 y_pred = torch.sigmoid(self.linear(x)) return y_pred# 实例化这个模型model = LogisticRegressionModel()# 第三步 构建损失函数和优化器# BCELoss Binary Cross Entropycriterion = torch.nn.BCELoss(reduction=&#x27;mean&#x27;) # size_average = True 的话 就 乘以 1/N 默认为trueoptimizer = torch.optim.SGD(model.parameters(),lr=0.01) #model.parameters() 可以找到# 模型所有需要训练的参数# 第四步 训练&#x27;&#x27;&#x27; 前两步 就是正向传播 forward 1. 预测 标签 2. 预测 与 实际 算出损失值 3. 反向传播 backward 优化参数 4. 更新参数&#x27;&#x27;&#x27;for epoch in range(100): y_pred = model(x_data) loss = criterion(y_pred,y_data) print(&#x27;迭代次数:&#x27;,epoch,&quot; 损失值:&quot;,loss.item() ) optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 optimizer.step() #更新参数# 第五步 评估模型# 输出 超参数 权重w 和 偏置bprint(&#x27;w = &#x27;,model.linear.weight.item() )print(&#x27;b = &#x27;,model.linear.bias.item())# 预测x_test = torch.Tensor([[4.0]])y_test = model(x_test)print(&#x27;x为4.0 预测的 y值为：&#x27;,y_test.data)import numpy as npimport matplotlib.pyplot as pltx = np.linspace(0, 10, 200)x_t = torch.Tensor(x).view((200, 1))y_t = model(x_t)y = y_t.data.numpy()plt.plot(x, y)plt.plot([0, 10], [0.5, 0.5], c=&#x27;r&#x27;)plt.xlabel(&#x27;Hours&#x27;)plt.ylabel(&#x27;Probability of Pass&#x27;)plt.grid()plt.show()","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"刘二","slug":"刘二","permalink":"http://example.com/tags/%E5%88%98%E4%BA%8C/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"http://example.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"}]},{"title":"神经网络与深度学习 邱锡鹏 学习笔记（机器学习）","slug":"神经网络与深度学习 邱锡鹏 学习笔记（机器学习）","date":"2021-09-11T07:46:01.000Z","updated":"2021-10-29T15:01:14.919Z","comments":true,"path":"2021/09/11/神经网络与深度学习 邱锡鹏 学习笔记（机器学习）/","link":"","permalink":"http://example.com/2021/09/11/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E9%82%B1%E9%94%A1%E9%B9%8F%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%89/","excerpt":"","text":"@TOC 机器学习机器学习看作一个从有限、高维、有噪声的数据上得到更一般性规律的泛化问题． 机器学习的三个基本要素 模型 学习准则 优化算法 模型我们不知道 输入和输出是如何对应联系的，也就是数学函数究竟是什么。 我们假设一个可能的函数集合 $ℱ$ ，称为 假设空间 。 我们根据 观测 各函数在测试集 $𝒟$ 的表现，从中选择更理想的假设模型。常用的假设空间分为 线性和非线性 两种 学习准则令训练集 是由 $𝑁$ 个独立同分布的样本组成，即每个样本 (𝒙, 𝑦) ∈ 𝒳 × 𝒴 是从 𝒳 和 𝒴 的联合空间中按照某个未知分布 $𝑝_{r}(𝒙, 𝑦)$ 独立地随机产生的 。 学习准则包括： 经验风险最小化 结构风险最小化 最大似然估计 最大后验估计 损失函数用来量化模型预测和真实标签之间的差异 0-1损失函数平方损失函数经常用在预测标签 $𝑦$ 为实数值的任务中 L(y,f(x;θ)) = \\frac{1}{2}(y-f(x;θ))平方损失函数一般不适用于分类问题 交叉熵损失函数一般用于分类问题 L(y,f(x;θ)) =-\\sum_{c=1}^{C}y_{c}\\log f_{c}(x;θ)例如，对于一个三分类的问题，一个样本的标签向量为 $𝒚 = [0, 0, 1]^{T}$，模型预测的标签分布为 $f(x;θ) = [0.3, 0.3, 0.4]^{T}$。则它们的交叉熵为 $−(0 × log(0.3) + 0 ×log(0.3) + 1 × log(0.4)) = − log(0.4)$ 过拟合和欠拟合 过拟合模型在训练集上错误率 很低，但是在未知数据上错误率很高，这就是所谓的过拟合。过拟合的 3种 方法： 参数在过拟合之前就停止更新；正则化Regularization；dropout 欠拟合模型不能很好地拟合训练数据，在训练集上的错误率比较高．欠拟合一般是由于模型能力不足造成的。 优化算法参数与超参数 参数：模型 𝑓(𝒙; 𝜃)中的 𝜃 称为模型的参数，可以通过优化算法进行学习 超参数：用来定义模型结构或优化策略的。 常见的超参数有：聚类算法中的类别个数、梯度下降法中的步长、正则化项的系数、神经网络的层数、支持向量机中的核函数等 参数的优化一般都是由优化器优化，而超参数优化是机器学习的 一个经验性很强的技术 ，通常是按照人的经验设定，或者通过搜索的方法对一组超参数组合进行不断试错调整。 批量梯度下降法缺点在于 局部最优问题用下面的迭代公式来计算计算训练集 𝒟 上风险函数的最小值：𝛼 一般称为学习率（Learning Rate）． 批量梯度下降法在 每次迭代时需要计算每个样本（也就是所有样本）上损失函数的梯度并求和。当训练集中的样本数量 𝑁 很大时，空间复杂度比较高，每次迭代的计算开销也很大． 随机梯度下降法缺点在于 局部最优问题，但相比于批量，更容易脱离局部最优 为了减少每次迭代的计算复杂度，我们也可以在每次迭代时只采集一个样本，计算这个样本损失函数的梯度并更新参数，即随机梯度下降法。当经过足够次数的迭代时，随机梯度下降 也可以收敛到局部最优解。 小批量梯度下降法现在 大规模的机器学习 常用这个。利用了计算机的并行计算能力每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率。 机器学习的简单示例——线性回归自变量数量 为1时称为 简单回归， 自变量数量大于1时称为 多元回归． 𝑓(𝒙; 𝒘) = 𝒘^{T}𝒙 不明白 先跳过偏差- 方差分解其用在，对如何对模型的拟合能力和复杂度之间取得一个良好的平衡，偏差与方差起这很好的分析和指导作用。 对于单个样本 𝒙，不同训练集 𝒟 得到模型 $𝑓_{D}(𝒙)$ 和最优模型 $𝑓^{*}(𝒙)$ 的期望 差距为： 偏差：指一个模型在 不同训练集 上的平均性能和最优模型的差异，可以用来衡量一个模型的拟合能力 方差：一个模型在不同训练集上的差异 ，可以用来衡量一个模型是否容易过拟合 ． 每个图的中心点为最优模型 $𝑓^{*}(𝒙)$，黑点为不同训练集𝐷 上得到的模型 $𝑓_{D}(𝒙)$ 高偏差低方差的情况，表示模型的泛化能力很好，但拟合能力不足 低偏差高方差的情况，表示模型的拟合能力很好，但泛化能力比较差．当训练数据比较少时会导致过拟合 总结的来看：模型在训练集上的错误率比较高时，说明模型的拟合能力不够，偏差比较高。这种情况可以通过 增加数据特征 提高模型复杂度 减小正则化系数 模型在训练集上的错误率比较低，但验证集上的错误率比较高时，说明模型过拟合，方差比较高．这种情况可以通过 降低模型复杂度 加大正则化系数 引入先验 此外，还有一种有效降低方差的方法为集成模型，即通过多个高方差模型的平均来降低方差． 学习算法分类按照训练样本提供的信息以及反馈方式的不同，将机器学习算法分为以下几类： 监督学习机器学习的特征 𝒙 和标签 𝑦 之间可以用 数学模型表示出来，并且训练集中每个样本都有标签。（数据集标签一般都需要由人工进行标注，成本很高）根据标签的类型还可以分为： 回归。 标签 𝑦 与 模型的输出 都是连续值 分类。 标签 𝑦 是离散的类别（符号）。这种模型又叫做 分类器 。 分类问题可以分为 二分类 多分类。 结构化学习。 特殊的分类问题。标签 𝒚 通常是结构化的对象，比如序列、树或图等。 由于结构化学习的输出空间比较大，因此我们一般定义一个联合特征空间，将 𝒙 , 𝒚 映射为该空间中的联合特征向量 𝜙(𝒙, 𝒚)，预测模型可以写为 其中 Gen(𝒙) 表示输入 𝒙 的所有可能的输出目标集合．计算 arg max 的过程也称为解码（Decoding）过程，一般通过动态规划的方法来计算。 无监督学习 是指从不包含目标标签的训练样本中自动学习到一些有价值的信息。典型的无监督学习问题有 聚类 密度估计 特征学习 降维 强化学习 是一类通过交互来学习的机器学习算法．在强化学习中，智能体根据环境的状态做出一个动作，并得到即时或延时的奖励．智能体在和环境的交互中不断学习并调整策略，以取得最大化的期望总回报． 弱监督和半监督弱监督学习和半监督学习的方法，希望从大规模的无标注数据中充分挖掘有用的信息，降低对标注样本数量的要求。 强化学习和监督学习的不同在于，强化学习不需要显式地以“输入/输出对”的方式给出训练样本，是一种在线的学习机制。 数据的特征表示 需要将这些不同类型的数据转换为向量表示 。 如何选取有效的特征，具体可分为两种：特征选择和特征抽取。 传统的是和预测模型的学习分离的。 特征选择特征选择就是保留有用特征，移除冗余或无关的特征。方法包括 子集搜索和 L1正则化 子集搜索 过滤式方法：不依赖具体机器学习模型的特征选择方法。每次增加最有信息量的特征，或删除最没有信息量的特征。 包裹式方法（Wrapper Method）是使用后续机器学习模型的准确率作为评价来选择一个特征子集的方法．每次增加对后续机器学习模型最有用的特征，或删除对后续机器学习任务最无用的特征。 L1正则化由于 L1 正则化会导致稀疏特征，因此间接实现了特征选择． 特征抽取 构造一个新的特征空间，并将原始特征投影在新的空间中得到新的表示。 其方法分为 有监督和无监督两类。 监督的特征学习的目标是抽取对一个特定的预测任务最有用的特征，比如线性判别分析。 无监督的特征学习和具体任务无关，其目标通常是减少冗余信息和噪声，比如主成分分析PCA和自编码器 AE。 总结特征选择和特征抽取的优点是可以用较少的特征来表示原始特征中的大部分相关信息，去掉噪声信息，并进而提高计算效率和减小维度灾难。对于很多没有正则化的模型，特征选择和特征抽取非常必要。 经过特征选择或特征抽取后，特征的数量一般会减少，因此特征选择和特征抽取。 也经常称为维数约减或降维。 模型的评价指标 准确率（Accuracy） 错误率（Error Rate）： 1 - 准确率 查准率（Precision） 查全率（Recall） F值（F Measure） 如何理解 精确率、召回率和F值模型在测试集上的结果可以分为以下四种情况：比如我们现在 预测标签 C 真正例（TP）：样本的预测与实际标签相同 假负例（FN）：样本实际标签为C，模型预测错了 假正例（FP）：样本实际标签不是C，但模型预测成C了 真负例（TN）：样本实际为其他类，模型也预测为其他类 查准率类别 𝑐 的查准率 是所有预测为 类别C 的样本中 预测正确 的比例精确率 $P_{C}$ 的计算 公式为： P_{C} = \\frac{TP_{c}}{TP_{c}+FP_{c}}查全率类别𝑐的查全率 是所有真实标签为 类别𝑐 的样本中预测正确的比例： R_{C} = \\frac{TP_{c}}{TP_{c}+FN_{c}}F值F值（F Measure）是一个综合指标，为精确率和召回率的调和平均： F_{C} = \\frac{(1+β^{2})×P_{C}×R_{C}}{β^{2}×P_{C}+R_{C}}其中 𝛽 用于平衡精确率和召回率的重要性，一般取值为1．𝛽 = 1时的F值称为 F1 值，是精确率和召回率的调和平均． 宏平均和微平均为了计算分类算法在所有类别上的总体查准率、查全率和 F1值，经常使用两种平均方法，分别称为 宏平均 和 微平均 宏平均是每一类的性能指标的算术平均值 微平均是每一个样本的性能指标的算术平均值 理论和定理PAC学习理论：指该学习算法能够在多项式时间内从合理数量的训练数据中学习到一个近似正确的𝑓(𝒙)． 没有免费午餐定理没有免费午餐定理 就是不存在一种机器学习算法适合于任何领域或任务。 奥卡姆剃刀原理简单的模型泛化能力更好．如果有两个性能相近的模型，我们应该选择更简单的模型。因此，在机器学习的学习准则上，我们经常会引入参数正则化来限制模型能力，避免过拟合． 丑小鸭定理世界上不存在相似性的客观标准，一切相似性的标准都是主观的 归纳偏置预测模型前，先假设。比如在最近邻分类器中，我们会假设在特征空间中，一个小的局部区域中的大部分样本同属一类。在朴素贝叶斯分类器中，我们会假设每个特征的条件概率是互相独立的。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"邱锡鹏","slug":"邱锡鹏","permalink":"http://example.com/tags/%E9%82%B1%E9%94%A1%E9%B9%8F/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}]},{"title":"神经网络与深度学习 学习笔记（第一章）","slug":"神经网络与深度学习 学习笔记（第一章）","date":"2021-09-10T08:42:01.000Z","updated":"2021-10-29T15:01:08.210Z","comments":true,"path":"2021/09/10/神经网络与深度学习 学习笔记（第一章）/","link":"","permalink":"http://example.com/2021/09/10/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%89/","excerpt":"","text":"@TOC 机器学习浅层学习 学习一个预测模型．一般需要首先将数据表示为一组特征（Feature），特征的表示形式可以是连续的数值、离散的符号或其他形式．然后将这些特征输入到预测模型，并输出预测结果．这类机器学习可以看作浅层学习（Shallow Learning） 机器学习的步骤 数据预处理：对数据的原始形式进行初步的数据清理（比如去掉一些有缺失特征的样本，或去掉一些冗余的数据特征等）和加工（对数值特征进行缩放和归一化等），并构建成可用于训练机器学习模型的数据集． 特征提取：从数据的原始特征中提取一些对特定机器学习任务有用的高质量特征．比如在图像分类中提取边缘、尺度不变特征变换（Scale InvariantFeature Transform，SIFT）特征，在文本分类中去除停用词等． 特征转换：对特征进行进一步的加工，比如降维和升维． 很多特征转换方法也都是机器学习方法．降维包括特征抽取（Feature Extraction）和特征选择（FeatureSelection）两种途径．常用的特征转换方法有主成分分析（Principal Components Analysis，PCA）、 线性判别分析（Linear Discriminant Analysis，LDA）等． 预测：机器学习的核心部分，学习一个函数并进行预测． 注：很多的机器学习问题变成了特征工程（Feature Engineering）问题．开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。 表示学习在表示学习中，有两个核心问题： 一是“什么是一个好的表示”；即表示 需要包含更高层的语义信息 二是“如何学习到好的表示”． 传统的特征学习一般是通过人为地设计一些准则，然后根据这些准则来选取有效的特征。 所以 特征的学习是和最终预测模型的学习分开进行的，因此学习到的特征不一定可以提升最终模型的性能． 概念将输入信息转换为有效的特征。如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫作表示学习（Representation Learning）． 语义鸿沟语义鸿沟问题是指输入数据的底层特征和高层语义信息之间的不一致性和差异性。 比如车，图片中每辆车的颜色和形状等属性都不尽相同，因此不同图片在像素级别上的表示（即底层特征）差异性也会非常大．但是我们理解这些图片是建立在比较抽象的高层语义概念上的 表示特征的方式 局部表示：例如，one-hot向量 表示颜色。 缺点在于多个颜色就多个列或者行 分布式表示：RGB 表示颜色 嵌入嵌入通常指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系．比如自然语言中词的分布式表示，也经常叫作词嵌入 例如：3维one-hot向量空间和一个2维嵌入空间的对比在低维的嵌入空间中，每个样本都不在坐标轴上，样本之间可以计算相似度． 深度学习什么是深度“深度”是指原始数据进行非线性特征转换的次数 深度学习的优点深度学习，其主要目的是从数据中自动学习到有效的特征表示 其抽象在 数据通过多层的特征转换，学习到的表示可以代替人工设计的特征，从而避免“特征工程”其是 一种 端到端的学习方式 在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标．在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预 深度学习的关键问题深度学习需要解决的关键问题是 贡献度分配问题，即一个系统中不同的 组件 或其 参数 对最终系统输出结果的贡献或影响 目前，深度学习采用的模型主要是神经网络模型，其主要原因是神经网络模型可以使用 误差反向传播算法 ，从而可以比较好地解决贡献度分配问题 深度学习相关的学术会议 国际表示学习会议 ICLR ：主要聚焦于深度学习 神经信息处理系统年会 NeurIPS ：交叉学科会议，但偏重于机器学习 国际机器学习会议 ICML：机器学习顶级会议 国际人工智能联合会议 IJCAI ：人工智能领域最顶尖的综合性会议 美国人工智能协会年会 AAAI ：人工智能领域的顶级会议 计算机视觉领域 计算机视觉与模式识别大会 CVPR 国际计算机视觉会议 ICCV 自然语言处理领域 计算语言学年会 ACL 自然语言处理实证方法大会 EMNLP","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"邱锡鹏","slug":"邱锡鹏","permalink":"http://example.com/tags/%E9%82%B1%E9%94%A1%E9%B9%8F/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}]},{"title":"Pytorch 实现 线性回归模型 —— 刘二","slug":"Pytorch 实现 线性回归模型 —— 刘二","date":"2021-09-08T02:40:01.000Z","updated":"2021-10-29T15:03:00.269Z","comments":true,"path":"2021/09/08/Pytorch 实现 线性回归模型 —— 刘二/","link":"","permalink":"http://example.com/2021/09/08/Pytorch%20%E5%AE%9E%E7%8E%B0%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%20%E2%80%94%E2%80%94%20%E5%88%98%E4%BA%8C/","excerpt":"","text":"@TOC 用Pytorch 实现 线性模型。整个流程图可以如下图所示：大致的设计步骤 分为5步 如下所示：第五步：是进行 评估模型并预测 1import torch Step1：准备数据 123# 准备数据x_data = torch.Tensor([[1.0],[2.0],[3.0]])y_data = torch.Tensor([[2.0],[4.0],[6.0]]) Step2：设计模型这边的线性模型比较简单 为 $y=Wx+b$ 只有两个超参数 W 和 b要通过输入的维度和 输出的维度，才能明确 $W$ 和 $b$ 的维度 1234567891011121314# 构建一个线性模型类 所有的模型类都必须继承torch.nn.Moduleclass LinearModel(torch.nn.Module): # 构造方法 def __init__(self): # 调用父类的构造 这步必须得有 super(LinearModel,self).__init__() # Linear 是一个模型类 这边实例化他给 对象linear # w 权重 = 1 b 偏执 = 1 self.linear = torch.nn.Linear(1,1) # 方法重写 def forward(self,x): # 预测值 y_pred = self.linear(x) return y_pred torch.nn.Linear(in_features,out_features,bias=True) 方法 实例化这个模型为 model 12# 实例化这个模型model = LinearModel() Step3：构建损失函数和优化器1234# 损失函数：mean squared errorcriterion = torch.nn.MSELoss(reduction=&#x27;sum&#x27;) # size_average = True 的话 就 乘以 1/N 默认为true# model.parameters() 可以找到模型所有需要训练的参数 优化器：SGDoptimizer = torch.optim.SGD(model.parameters(),lr=0.01) torch.nn.MSELoss(size_average=False) 方法用于创建一个MSE损失函数 torch.optim.SGD(…) 方法优化器选择 SGD 可调整学习率$w^{*} = w - α\\frac{\\partial L}{\\partial W}$ Step4: 训练模型 前两步 就是正向传播 forward 预测 标签 预测 与 实际 算出损失值 反向传播 backward 优化参数 更新参数 123456789for epoch in range(100): #数据跑 99次 range是不到那个数字的 y_pred = model(x_data) loss = criterion(y_pred,y_data) print(&#x27;迭代次数:&#x27;,epoch,&quot; 损失值:&quot;,loss) optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 optimizer.step() #更新参数 Step5: 评估模型并预测这边没有准备 测试集及其标签 输出 超参数 权重w 和 偏置b1234# 输出 超参数 权重w 和 偏置bprint(&#x27;w = &#x27;,model.linear.weight.item() )print(&#x27;b = &#x27;,model.linear.bias.item()) 预测 1234# 预测 x_test = torch.Tensor([[4.0]])y_test = model(x_test)print(&#x27;x为4.0 预测的 y值为：&#x27;,y_test.data) 实验结果 这边少了 怎么输出 准确率？ 实现源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import torch# 准备数据x_data = torch.Tensor([[1.0],[2.0],[3.0]])y_data = torch.Tensor([[2.0],[4.0],[6.0]])# 第二步 设计模型class LinearModel(torch.nn.Module): def __init__(self): # 调用父类的构造 这步必须得有 super(LinearModel,self).__init__() # Linear 是一个模型类 这边实例化他给 linear # w 权重 = 1 b 偏执 = 1 self.linear = torch.nn.Linear(1,1) def forward(self,x): y_pred = self.linear(x) return y_pred# 实例化这个模型model = LinearModel()# 第三步 构建损失函数和优化器# mean squared errorcriterion = torch.nn.MSELoss(reduction=&#x27;sum&#x27;) # size_average = True 的话 就 乘以 1/N 默认为trueoptimizer = torch.optim.SGD(model.parameters(),lr=0.01) #model.parameters() 可以找到# 模型所有需要训练的参数# 第四步 训练&#x27;&#x27;&#x27; 前两步 就是正向传播 forward 1. 预测 标签 2. 预测 与 实际 算出损失值 3. 反向传播 backward 优化参数 4. 更新参数&#x27;&#x27;&#x27;for epoch in range(100): y_pred = model(x_data) loss = criterion(y_pred,y_data) print(&#x27;迭代次数:&#x27;,epoch,&quot; 损失值:&quot;,loss) optimizer.zero_grad() # 梯度清零 loss.backward() # 反向传播 optimizer.step() #更新参数# 第五步 评估模型# 输出 超参数 权重w 和 偏置bprint(&#x27;w = &#x27;,model.linear.weight.item() )print(&#x27;b = &#x27;,model.linear.bias.item())# 预测x_test = torch.Tensor([[4.0]])y_test = model(x_test)print(&#x27;x为4.0 预测的 y值为：&#x27;,y_test.data)","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"刘二","slug":"刘二","permalink":"http://example.com/tags/%E5%88%98%E4%BA%8C/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"}]},{"title":"Keras  RNN 实现 MNIST 手写数字识别","slug":"Keras  RNN 实现 MNIST 手写数字识别","date":"2021-09-04T02:40:01.000Z","updated":"2021-10-29T15:02:20.877Z","comments":true,"path":"2021/09/04/Keras  RNN 实现 MNIST 手写数字识别/","link":"","permalink":"http://example.com/2021/09/04/Keras%20%20RNN%20%E5%AE%9E%E7%8E%B0%20MNIST%20%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/","excerpt":"","text":"@TOC 我们就以 MNIST数据集的手写识别 为例子 导入需要的包首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便） 1234567891011import numpy as npfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.layers.recurrent import SimpleRNNfrom tensorflow.keras.optimizers import Adamimport matplotlib.pyplot as pltimport matplotlibmatplotlib.use(&#x27;TkAgg&#x27;)print(matplotlib.get_backend()) 载入MNIST 数据该数据集一共有训练集 6w 张，测试集 1w 张1(train_images,train_labels),(test_images,test_labels)= mnist.load_data() 可以查看一下图像和标签 是什么 12345678# 数字5print(train_images[0])# 标签5print(train_labels[0])# 数字7print(test_images[0])# 标签7print(test_labels[0]) 可以 打印 一下图片 看看是什么样子1234plt.imshow(train_images[0])plt.show()plt.imshow(test_images[0])plt.show() 图片数据处理查看图片原有 shape1234# train_images (60000, 28, 28)print(&#x27;train_images&#x27;, train_images.shape)# train_labels (60000,)print(&#x27;train_labels&#x27;, train_labels.shape) 图片数据处理：归一化除以255.0 是为了归一化，使得元素点 全部变为在 0-1 之间123456789# 数据处理# (60000, 28, 28) train_images_scale = train_images/255.0test_images_scale = test_images/255.0# train_images变换后 (60000, 28, 28)print(&#x27;train_images变换后&#x27;, train_images_scale.shape)# test_images变换后 (10000, 28, 28)print(&#x27;test_images变换后&#x27;, test_images_scale.shape) 标签数据处理：转换成 one hot 格式12345678910# 换 one hot 格式 共十个分类# np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。train_labels_hot = np_utils.to_categorical(train_labels,num_classes=10)test_labels_hot = np_utils.to_categorical(test_labels,num_classes=10)# train_labels (60000, 10)print(&#x27;train_labels&#x27;,train_labels_hot.shape)# test_labels (10000, 10)print(&#x27;test_labels&#x27;,test_labels_hot.shape) 构建模型先定义 RNN 所需的参数 12345678# 定义rnn 的参数# 数据长度 一行一共有28个元素input_size = 28# 序列长度 一共有28个序列 也就是28行time_steps = 28# 隐藏层cell个数cell_size = 50 再定义 RNN 模型123456789model = Sequential()#循环神经网络model.add(SimpleRNN( units=cell_size, #输出 input_shape=(time_steps,input_size) #输入))# 输出层model.add(Dense(input_dim=cell_size,units=10,activation=&quot;softmax&quot;))优化器使用 Adam， 损失函数 选择 交叉熵 并编译 1234# 定义优化器 10的 -4次方adam = Adam(learning_rate=1e-4)model.compile(optimizer= adam,loss=&#x27;categorical_crossentropy&#x27;,metrics=&quot;accuracy&quot;) 训练模型 一共 60000张训练图片 按批次训练 一批次64张 一共6w/64 个批次训练完一轮6w张，表示一个epoch123# 一共 60000张训练图片 按批次训练 一批次64张 # 训练完一轮6w张，表示一个epochmodel.fit(train_images_scale,train_labels_hot,batch_size=64,epochs=1) 评估模型就是在 测试集上的表现1loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)也可以看一下 在训练集上的表现 1loss,accuracy = model.evaluate(train_images_scale,train_labels_hot) 下面是 结果（上训练集 下测试集） 预测数据**有问题 输入的 数据维度不对 不知道错哪了？？？** 123456# 看下输入的形状# # 预测数据print(test_images_scale[0].shape)print(model.predict((test_images_scale[0]/255.0)))print(np.argmax(model.predict((test_images_scale[0]/255.0))))print(test_labels[0]) 输入的图像 变换后形状模型预测 数据 输出的概率分类结果选出其中最大的 以及 实际图片标签 均为 数字7","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://example.com/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"}]},{"title":"Keras  CNN 实现 MNIST 手写数字识别","slug":"Keras  CNN 实现 MNIST 手写数字识别","date":"2021-09-03T02:40:01.000Z","updated":"2021-10-29T15:02:27.512Z","comments":true,"path":"2021/09/03/Keras  CNN 实现 MNIST 手写数字识别/","link":"","permalink":"http://example.com/2021/09/03/Keras%20%20CNN%20%E5%AE%9E%E7%8E%B0%20MNIST%20%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/","excerpt":"","text":"@TOC 我们就以 MNIST数据集的手写识别 为例子 导入需要的包首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便） 12345678910import numpy as npfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flattenfrom tensorflow.keras.optimizers import Adamimport matplotlib.pyplot as pltimport matplotlibmatplotlib.use(&#x27;TkAgg&#x27;)print(matplotlib.get_backend()) 载入MNIST 数据该数据集一共有训练集 6w 张，测试集 1w 张1(train_images,train_labels),(test_images,test_labels)= mnist.load_data() 可以查看一下图像和标签 是什么 12345678# 数字5print(train_images[0])# 标签5print(train_labels[0])# 数字7print(test_images[0])# 标签7print(test_labels[0]) 可以 打印 一下图片 看看是什么样子1234plt.imshow(train_images[0])plt.show()plt.imshow(test_images[0])plt.show() 图片数据处理查看图片原有 shape1234# train_images (60000, 28, 28)print(&#x27;train_images&#x27;, train_images.shape)# train_labels (60000,)print(&#x27;train_labels&#x27;, train_labels.shape) 图片数据处理：变成四维 ，并归一化变维度的 -1 是个通配符，系统会自动完成应该变成多少除以255.0 是为了归一化，使得元素点 全部变为在 0-1 之间1234567891011# 数据处理# CNN 输入的是一张图片# 将 (60000, 28, 28) -&gt; (60000, 28, 28, 1) 变成四维# 第四个 1 表示的为深度 黑白图像为 1 彩色图像为 3train_images_scale = train_images.reshape(-1, train_images.shape[1] ,train_images.shape[2],1)/255.0test_images_scale = test_images.reshape(-1,test_images.shape[1], test_images.shape[2],1)/255.0# train_images变换后 (60000, 28, 28, 1)print(&#x27;train_images变换后&#x27;, train_images_scale.shape)# test_images变换后 (10000, 28, 28, 1)print(&#x27;test_images变换后&#x27;, test_images_scale.shape) 标签数据处理：转换成 one hot 格式12345678910# 换 one hot 格式 共十个分类# np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。train_labels_hot = np_utils.to_categorical(train_labels,num_classes=10)test_labels_hot = np_utils.to_categorical(test_labels,num_classes=10)# train_labels (60000, 10)print(&#x27;train_labels&#x27;,train_labels_hot.shape)# test_labels (10000, 10)print(&#x27;test_labels&#x27;,test_labels_hot.shape) 构建模型思路是 卷积 再池化 重复步骤 再压平给 全身神经网络12345678910111213141516171819202122232425262728293031model = Sequential()#第一个卷积层&#x27;&#x27;&#x27; input shape 激入平面 filters 卷积核/过滤器 个数 kernel_size 卷积窗口大小 strides 步长 padding（边界填充）padding方式 same/valid activation 激活函数&#x27;&#x27;&#x27;# 用same 保持整个还是 28 × 28model.add(Convolution2D( input_shape=(28,28,1),filters=32,kernel_size=5,strides=1,padding=&#x27;same&#x27;,activation=&#x27;relu&#x27;))#第一个池化层model.add(MaxPooling2D( pool_size=2,strides=2,padding=&#x27;same&#x27;))#第二卷积层model.add(Convolution2D(64,5,strides=1,padding=&#x27;same&#x27;,activation=&#x27;relu&#x27;))#第二个池化层model.add(MaxPooling2D( pool_size=2,strides=2,padding=&#x27;same&#x27;))#把第二个池化层的前出扁平化为1维model.add(Flatten())#第一个全连接层model.add(Dense(units=1024,activation=&#x27;relu&#x27;))#Dropoutmodel.add(Dropout(0.5))#第二个全连接层model.add(Dense(units=10,input_dim=1024,activation=&#x27;softmax&#x27;)) 优化器使用 Adam， 损失函数 选择 交叉熵 并编译 1234# 定义优化器 10的 -4次方adam = Adam(learning_rate=1e-4)model.compile(optimizer= adam,loss=&#x27;categorical_crossentropy&#x27;,metrics=&quot;accuracy&quot;) 训练模型 一共 60000张训练图片 按批次训练 一批次64张 一共6w/64 个批次训练完一轮6w张，表示一个epoch123# 一共 60000张训练图片 按批次训练 一批次64张 # 训练完一轮6w张，表示一个epochmodel.fit(train_images_scale,train_labels_hot,batch_size=64,epochs=1)上图只跑了一次 epoch，因为笔记本太慢了注意： 最好用 GPU 来跑 ，不然笔记本非常的慢 评估模型就是在 测试集上的表现1loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)也可以看一下 在训练集上的表现 1loss,accuracy = model.evaluate(train_images_scale,train_labels_hot) 下面是 结果（上训练集 下测试集） 预测数据12345# 看下输入的形状print(test_images_scale[0].reshape(-1,28,28,1).shape)print(model.predict((test_images_scale[0].reshape(-1,28,28,1))))print(np.argmax(model.predict((test_images_scale[0].reshape(-1,28,28,1)))))print(test_labels[0]) 输入的图像 变换后形状模型预测 数据 输出的概率分类结果选出其中最大的 以及 实际图片标签 均为 数字7","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://example.com/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"},{"name":"CNN","slug":"CNN","permalink":"http://example.com/tags/CNN/"}]},{"title":"Keras MNIST 过拟合问题解决：Dropout 与 正则化","slug":"Keras MNIST 过拟合问题解决：Dropout 与 正则化","date":"2021-09-02T02:40:01.000Z","updated":"2021-10-29T15:02:32.298Z","comments":true,"path":"2021/09/02/Keras MNIST 过拟合问题解决：Dropout 与 正则化/","link":"","permalink":"http://example.com/2021/09/02/Keras%20MNIST%20%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%EF%BC%9ADropout%20%E4%B8%8E%20%E6%AD%A3%E5%88%99%E5%8C%96/","excerpt":"","text":"@TOC 我们就以 MNIST数据集的手写识别 为例子做 过拟合问题的应用 包括 Dropout 和 正则化 导入需要的包首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便） 使用Dropout 需要导入的包需要 导入 另一个包 keras.12345678910import numpy as npfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Densefrom tensorflow.keras.optimizers import SGDimport matplotlib.pyplot as pltimport matplotlibmatplotlib.use(&#x27;TkAgg&#x27;)print(matplotlib.get_backend()) 使用 正则化 需要导入的包layers 层中 引入 keras.regularizers 中 l2 范式1234567891011import numpy as npfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Densefrom tensorflow.keras.optimizers import SGDfrom tensorflow.keras.regularizers import l2import matplotlib.pyplot as pltimport matplotlibmatplotlib.use(&#x27;TkAgg&#x27;)print(matplotlib.get_backend()) 载入MNIST 数据该数据集一共有训练集 6w 张，测试集 1w 张1(train_images,train_labels),(test_images,test_labels)= mnist.load_data() 可以查看一下图像和标签 是什么 12345678# 数字5print(train_images[0])# 标签5print(train_labels[0])# 数字7print(test_images[0])# 标签7print(test_labels[0]) 可以 打印 一下图片 看看是什么样子1234plt.imshow(train_images[0])plt.show()plt.imshow(test_images[0])plt.show() 图片数据处理查看图片原有 shape1234# train_images (60000, 28, 28)print(&#x27;train_images&#x27;, train_images.shape)# train_labels (60000,)print(&#x27;train_labels&#x27;, train_labels.shape) 图片数据处理：将图片压平123456789# 数据处理# 将 (60000, 28, 28) -&gt; (60000, 784) 压平图片train_images_scale = train_images.reshape(train_images.shape[0], train_images.shape[1] * train_images.shape[2])/255.0test_images_scale = test_images.reshape(test_images.shape[0], test_images.shape[1] * test_images.shape[2])/255.0# train_images变换后 (60000, 784)print(&#x27;train_images变换后&#x27;, train_images_scale.shape)# test_images变换后 (10000, 784)print(&#x27;test_images变换后&#x27;, test_images_scale.shape) 标签数据处理：转换成 one hot 格式12345678910# 换 one hot 格式 共十个分类# np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。train_labels_hot = np_utils.to_categorical(train_labels,num_classes=10)test_labels_hot = np_utils.to_categorical(test_labels,num_classes=10)# train_labels (60000, 10)print(&#x27;train_labels&#x27;,train_labels_hot.shape)# test_labels (10000, 10)print(&#x27;test_labels&#x27;,test_labels_hot.shape) 构建模型添加 Dropout12345678910model = Sequential()# 输入压平图像 维度为784 输出为 10分类# 加个隐层model.add(Dense(units=200,input_dim=784,bias_initializer=&quot;one&quot;,activation=&quot;tanh&quot;))# 上层40%的神经元不工作model.add(Dropout(0.4))model.add(Dense(units=100,input_dim=200,bias_initializer=&quot;one&quot;,activation=&quot;tanh&quot;))# 上层40%的神经元不工作model.add(Dropout(0.4))model.add(Dense(units=10,input_dim=100,bias_initializer=&quot;one&quot;,activation=&quot;softmax&quot;)) 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵 1234# 重新定义 sgd 优化器 加速一下学习率sgd = SGD(learning_rate=0.2)# 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵model.compile(optimizer= sgd,loss=&#x27;categorical_crossentropy&#x27;,metrics=&quot;accuracy&quot;) 添加 正则化项123456model = Sequential()# 输入压平图像 维度为784 输出为 10分类# 加个隐层model.add(Dense(units=200,input_dim=784,bias_initializer=&quot;one&quot;,activation=&quot;tanh&quot;,kernel_initializer=l2(0.003)))model.add(Dense(units=100,input_dim=200,bias_initializer=&quot;one&quot;,activation=&quot;tanh&quot;,kernel_initializer=l2(0.003)))model.add(Dense(units=10,input_dim=100,bias_initializer=&quot;one&quot;,activation=&quot;softmax&quot;,kernel_initializer=l2(0.003))) 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵 1234# 重新定义 sgd 优化器 加速一下学习率sgd = SGD(learning_rate=0.2)# 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵model.compile(optimizer= sgd,loss=&#x27;categorical_crossentropy&#x27;,metrics=&quot;accuracy&quot;) 训练模型 一共 60000张训练图片 按批次训练 一批次32张 一共6w/32 = 1875 个批次训练完一轮6w张，表示一个epoch123# 一共 60000张训练图片 按批次训练 一批次32张 一共6w/32 = 1875 个批次# 训练完一轮6w张，表示一个epochmodel.fit(train_images_scale,train_labels_hot,batch_size=32,epochs=10) 评估模型Dropout的结果就是在 测试集上的表现1loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)也可以看一下 在训练集上的表现 1loss,accuracy = model.evaluate(train_images_scale,train_labels_hot) 下面是 结果（上训练集 下测试集） 正则化的结果就是在 测试集上的表现1loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)也可以看一下 在训练集上的表现 1loss,accuracy = model.evaluate(train_images_scale,train_labels_hot) 下面是 结果（上训练集 下测试集） 出现了错误 不知道是哪里的问题哎？ 1TypeError: __call__() got an unexpected keyword argument &#x27;dtype&#x27; 预测数据12345678# 看下输入的形状print(test_images_scale[0].reshape(-1,784).shape)# 模型预测 输出每个分类的 概率print(model.predict((test_images_scale[0].reshape(-1,784))))# 选取最大的那个 就是预测的标签print(np.argmax(model.predict((test_images_scale[0].reshape(-1,784)))))# 实际该图片的 标签print(test_labels[0]) 输入的图像 变换后形状模型预测 数据 输出的概率分类结果选出其中最大的 以及 实际图片标签 均为 数字7","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://example.com/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"}]},{"title":"Keras  MNIST（数字识别）数据集分类（普通全神经网络）","slug":"Keras  MNIST（数字识别）数据集分类（普通全神经网络）","date":"2021-08-30T02:40:01.000Z","updated":"2021-10-29T15:02:40.534Z","comments":true,"path":"2021/08/30/Keras  MNIST（数字识别）数据集分类（普通全神经网络）/","link":"","permalink":"http://example.com/2021/08/30/Keras%20%20MNIST%EF%BC%88%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%89%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E7%B1%BB%EF%BC%88%E6%99%AE%E9%80%9A%E5%85%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%89/","excerpt":"","text":"@TOC 导入需要的包首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便） 12345678910import numpy as npfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Densefrom tensorflow.keras.optimizers import SGDimport matplotlib.pyplot as pltimport matplotlibmatplotlib.use(&#x27;TkAgg&#x27;)print(matplotlib.get_backend()) 载入MNIST 数据该数据集一共有训练集 6w 张，测试集 1w 张1(train_images,train_labels),(test_images,test_labels)= mnist.load_data() 可以查看一下图像和标签 是什么 12345678# 数字5print(train_images[0])# 标签5print(train_labels[0])# 数字7print(test_images[0])# 标签7print(test_labels[0]) 可以 打印 一下图片 看看是什么样子1234plt.imshow(train_images[0])plt.show()plt.imshow(test_images[0])plt.show() 图片数据处理查看图片原有 shape1234# train_images (60000, 28, 28)print(&#x27;train_images&#x27;, train_images.shape)# train_labels (60000,)print(&#x27;train_labels&#x27;, train_labels.shape) 图片数据处理：将图片压平123456789# 数据处理# 将 (60000, 28, 28) -&gt; (60000, 784) 压平图片train_images_scale = train_images.reshape(train_images.shape[0], train_images.shape[1] * train_images.shape[2])/255.0test_images_scale = test_images.reshape(test_images.shape[0], test_images.shape[1] * test_images.shape[2])/255.0# train_images变换后 (60000, 784)print(&#x27;train_images变换后&#x27;, train_images_scale.shape)# test_images变换后 (10000, 784)print(&#x27;test_images变换后&#x27;, test_images_scale.shape) 标签数据处理：转换成 one hot 格式12345678910# 换 one hot 格式 共十个分类# np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。train_labels_hot = np_utils.to_categorical(train_labels,num_classes=10)test_labels_hot = np_utils.to_categorical(test_labels,num_classes=10)# train_labels (60000, 10)print(&#x27;train_labels&#x27;,train_labels_hot.shape)# test_labels (10000, 10)print(&#x27;test_labels&#x27;,test_labels_hot.shape) 构建模型只有输入和输出层， 输入压平图像 维度为784 输出为 10分类123model = Sequential()# 输入压平图像 维度为784 输出为 10分类model.add(Dense(units=10,input_dim=784,bias_initializer=&quot;one&quot;,activation=&quot;softmax&quot;))优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵 1234# 重新定义 sgd 优化器 加速一下学习率sgd = SGD(learning_rate=0.2)# 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵model.compile(optimizer= sgd,loss=&#x27;categorical_crossentropy&#x27;,metrics=&quot;accuracy&quot;) 训练模型 一共 60000张训练图片 按批次训练 一批次32张 一共6w/32 = 1875 个批次训练完一轮6w张，表示一个epoch123# 一共 60000张训练图片 按批次训练 一批次32张 一共6w/32 = 1875 个批次# 训练完一轮6w张，表示一个epochmodel.fit(train_images_scale,train_labels_hot,batch_size=32,epochs=10) 评估模型就是在 测试集上的表现1loss,accuracy = model.evaluate(test_images_scale,test_labels_hot) 预测数据12345678# 看下输入的形状print(test_images_scale[0].reshape(-1,784).shape)# 模型预测 输出每个分类的 概率print(model.predict((test_images_scale[0].reshape(-1,784))))# 选取最大的那个 就是预测的标签print(np.argmax(model.predict((test_images_scale[0].reshape(-1,784)))))# 实际该图片的 标签print(test_labels[0]) 输入的图像 变换后形状模型预测 数据 输出的概率分类结果选出其中最大的 以及 实际图片标签 均为 数字7","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://example.com/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"}]},{"title":"keras 包方法集合","slug":"keras 包方法集合","date":"2021-08-29T02:18:01.000Z","updated":"2021-10-29T15:02:36.222Z","comments":true,"path":"2021/08/29/keras 包方法集合/","link":"","permalink":"http://example.com/2021/08/29/keras%20%E5%8C%85%E6%96%B9%E6%B3%95%E9%9B%86%E5%90%88/","excerpt":"","text":"@TOC keras.util 库 np_utilsnp_utils.to_categoricalnp_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。 1train_labels_hot = np_utils.to_categorical(train_labels,num_classes=10) 如将 $[1,2,3,……4]$ 转化成：这样的形态。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"}]},{"title":"各类 优化器(调参工具) 详解与选择","slug":"各类 优化器(调参工具) 详解与选择","date":"2021-08-28T02:40:01.000Z","updated":"2021-10-29T15:00:52.017Z","comments":true,"path":"2021/08/28/各类 优化器(调参工具) 详解与选择/","link":"","permalink":"http://example.com/2021/08/28/%E5%90%84%E7%B1%BB%20%E4%BC%98%E5%8C%96%E5%99%A8(%E8%B0%83%E5%8F%82%E5%B7%A5%E5%85%B7)%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E9%80%89%E6%8B%A9/","excerpt":"","text":"@TOC sgdadam","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"优化器","slug":"优化器","permalink":"http://example.com/tags/%E4%BC%98%E5%8C%96%E5%99%A8/"}]},{"title":"深度学习 Deep Learning 后续优化","slug":"深度学习 Deep Learning 后续优化","date":"2021-08-27T14:52:01.000Z","updated":"2021-10-29T15:05:19.772Z","comments":true,"path":"2021/08/27/深度学习 Deep Learning 后续优化/","link":"","permalink":"http://example.com/2021/08/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E5%90%8E%E7%BB%AD%E4%BC%98%E5%8C%96/","excerpt":"","text":"@TOC 深度学习 怎么评价效果与改进？ 先检查 训练阶段 是否有比较好的结果training优化方法： 换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax） 优化器——优化梯度下降和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam） training没问题了，再检查testing是否有比较好的结果 testing（过拟合）优化： 参数在过拟合之前就停止更新 正则化Regularization dropout 如何优化模型谈什么才是overfitting？首先我们在明确一下，深度学习的流程，其与机器学习基本一致。如下图所示：判断 过拟合 需要看两个数据集上的结果（training set → good， testing set → bad）。在试图解决overfitting之后仍要再看一下training set上的结果！ 误区：不能看见所有不好的 performance 都归因到 overfitting。如只看下右图，不能断言56-layer有 overfitting，要看模型在training set上的表现。根据下左图，可以发现原因是训练的时候没有训练好，即这个层次设计可能本身就是有问题的，不然为啥20层的挺好，56层没道理差啊（这不能叫 underfitting，underfitting：参数不够多，模型能力不足）。 对症下药：训练error，测试error分别用什么方法在读到深度学习的方法时，要思考该方法是解决什么问题。是解决training set上的performance不好，还是解决testing set上的performance不好。比如，Dropout是为了解决testing set上结果不好的问题，如果是training set上结果不好而用Dropout，不会有好的结果。下图是 分别解决各问题，可以采用的方法： 模型Train阶段Error 具体解决如下图是，MNIST手写数字识别，激活函数用sigmoid，training data上的accuracy与层数的关系曲线：层数&gt;7时，performance下降，原因不是 overfitting! 因为train的时候就没train好。那模型压根没有训练好，可以采用的方法上面也给出了包括：换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax）。激活函数可能会带来什么样的问题？以sigmoid为例说：会出现梯度消失。 方法一：换激活函数的问题 —— 梯度消失什么是梯度消失 有梯度时，参数才会往梯度最小的地方改变；没有梯度了，参数就停止更新了。前面层的学习速率明显低于后面层（后向传播），这就是梯度消失。 为什么会有梯度消失？ 角度一： 用sigmoid会出现梯度消失的问题（参数的变化经过sigmoid会逐层衰减，对最后的loss影响很小）如上图所示，我刚开始增加的△w，由于 sigmoid函数 ，自变量越大，改变量越小的缘故。数的变化经过sigmoid会逐层衰减，对最后的loss影响很小。也就是对C的偏导会越来越小，导致梯度接近于0，而消失。 角度二：假设现在存在一个网络结构：其整个数学模型可以表示为：若要对于 w1求梯度，根据链式求导法则，得到的解为：这明显数学模型的值，随着隐层的增加，越来越小。不过这个前提是 原先的w（权重）并不是很大，原本相乘就是小于1的。如果w太大的话，第一项相乘就大于1，这就会导致最后的梯度爆炸。 如何解决梯度消失问题 —— 换ReLU激活函数ReLU 与 MaxOut梯度消失是因为 sigmoid 引起的，要解决当然要换一个激活函数。采用的方法是换 ReLU激活函数（原型 input0,输出为原值；可变型）ReLU输出0或x，输出0的ReLU神经元相当于不存在，网络变得瘦长，但是整个网络仍然是非线性的，只有当input改变十分微小的时候才是线性的，因为input不同，输出为0的ReLU神经元也不同。 Q : 为什么ReLU是非线性？明明两端都是线性直线啊？因为ReLU在0点没有导数定义，线性讲究的是在整个定义域内。而在0点处，不可微，所以整体是非线性的。 ReLU是Maxout的特例，Maxout可以学出激活函数。 MaxOut 的训练是怎样的？好在哪？下面是一个神经网络的栗子，我们将激活函数换成 MaxOut激活函数。上面的图 可以删除不需要的边和点，变为如下的神经网络： Q ：如果和上图所示，那我去掉的那些边不是啥用没有？也就是这个权值压根和神经网络没关系呢，不是吗？答 ：当然有关系，因为我们的任务是调参，每个权值和偏值得变化，都会导致 MaxOut激活函数 选择的不同。比如说改变一下 w，他可能会选择 z2呢。 方法二：优化器 —— 优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）寻找最佳参数的方法，调节学习率的方法有（SGD、Adagrad、RMSProp、Momentum、Adam）SGD、Adagrad 可以看之前关于 梯度算法进阶的部分 Post not found: 梯度下降算法 进阶这边主要讲解一下 RMSProp 和 Momentum 关于 RMSProp为什么要使用RMSProp 在 Adagrad 中，学习率是跟损失函数对 w 的二次微分有关。那么对于图中蓝绿相交的一点来说，因为 w1 所在的曲率相对于 w2 要小，所以 w1 的学习率会比 w2 大。现在单考虑 w1（只看横向），那么二次微分是固定的（碗状），也就是说 w1是根据固定的规则去自动调整 η 的。但是现实中同一方向的二次微分是不固定的，因此对于同一方向去 w1，需要不同的规则去调 η。 对于一个参数来说，*Adagrad* 是用固定的规则去调 *η*，*RMSProp* 是用变化的规则去调 *η*![在这里插入图片描述](https://img-blog.csdnimg.cn/cc6becd55c104daaa6f8eddadc55eb9d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) ##### 如何实现RMSProp 在原来分母这一项中，在过去梯度平方和前面加上权值 *a*，现有的梯度平方加上 *1-a*。 其在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小），并且能够使得**陡峭的方向变得平缓**，从而加快训练速度） ![在这里插入图片描述](https://img-blog.csdnimg.cn/1377f4da7b564c9a89ede8f17577f241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### 关于 Momentum ##### Momentum（动量）是用来解决什么问题的？ **这个是用来解决局部最优解的问题的** 说白了就是要延续他的惯性 如何实现Momentum考虑他此时的方向，并保留他的惯性。来调整下一步，最大可能的避免局部最优解。 关于 Adam他其实是一种 Momentum + RMSProp 结合的方法。其具体算法可以看如下图所示： 模型Train阶段OK Test阶段Error，即过拟合方法一 ：参数在过拟合之前就停止更新（Early Stopping）这里的testing set指的是有label的testing set（即validation set ）。 如果learning rate设得对的话，training set的loss会逐渐降低，而testing set与training set可能分布不同，所以testing set的loss可能先降后升，这时就不要一直train下去，而是要在testing loss最小的地方停止train。这里的testing set 实际指的是**validation set**。 ### 方法二 ：正则化Regularization **Q ： 首先理解什么是范数，L1（范数为1）和L2（范数为2）是什么？** 范数：向量在不同空间中“长度”的计算公式 L1：绝对值之和 L2：平方和 #### L2正则化（权值衰减） ![](https://img-blog.csdnimg.cn/8a8facf4f6bf42ebb56f4f657102b5ed.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) > **Q ： 为什么通常 不考虑 bias？** > L2正则化让function更平滑，而bias与函数平滑程度没有关系。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/35cbdf14ab7049bd9967fcabc1223ae2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 参数更新： 因为η、λ、n都是正的，**所以 *1−ηλ*小于1，它的效果是减小w，这也就是权重衰减（weight decay）的由来**。**当然考虑到后面的导数项，w最终的值可能增大也可能减小**。 正则化在NN中虽有用但不明显。 NN参数初始值一般接近0，update参数即是要参数原理0。L2正则化（让参数接近0）的作用可能与early stopping类似。 > **Q : 为什么参数w衰减能防止过拟合?** > 答 ：模型过于复杂会导致过拟合。那么越小的w（可以想象成0理解），表示网络复杂度低，越简单的网络结构，就越不会过拟合。比如模型 *y=w1×w1 + w2×w2* 的平方 中把 *w2=0* 代入，模型就会简化，就不会引起过拟合。![在这里插入图片描述](https://img-blog.csdnimg.cn/c8fc90454614466ebee4a2d5a549a25e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) > **Q : 对正则化解决过拟合问题的一些本质理解？** > 正则化防止过拟合的本质：减少“没用参数”的权值（防止过拟合），同时也减少“有用参数”的权值（会增加bias误差） > **Q : 什么是有用参数，什么是没用参数？如上图中，怎么就把 *x2* 删去，不把 *x1* 删去呢？** > 我们姑且假设 *w1* 是有用参数， *w2* 是无用参数，由公式知参数更新值跟权值、梯度值两个因素有关，实际上，无论是 *x1* 还是 *x2* ，权值都会衰减，每update一次参数，权值 *w* 就会衰减一次，但如果是下图的情况，*损失函数Loss* 的减少跟 *w2* 没关系的，所以对其偏导为0，那么 *w2* 的参数更新只跟权值有关了，随着更新次数叠加，权值就会逐渐衰减接近0；对于***有用参数 w1*** ，虽然它权值衰减，但是它其作用的是后面的偏导值，所以它还是不会变成0的。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/50e060cb7bc24fbe896ef111e287092b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### L1正则化 L1是在Loss函数加上绝对值之和，求偏导后比原始的更新规则多出了η ×λ ×sgn(w)这一项。**当w为正时，更新后的w变小。当w为负时，更新后的w变大（一加一减）——因此它的效果就是让w往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合** ![在这里插入图片描述](https://img-blog.csdnimg.cn/113c9ac61f5946c783a434a07f8d52e9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### L1和L2相比 L1 update的速度是*|ηλ||ηλ|* （划横线那项每次改变量是一定的）。而 L2 update 的速度与w的t有关（如果wt 很大，那么改变量也很大）。 用L1做training，结果比较sparse(稀疏的)，参数中有很多接近0的值，也有很多很大的值。 L2 learn的结果：参数值平均来讲比较小。 ### Dropout **Dropout也是为了简化神经网络结构的目的**，但L1、L2正则化是通过修改代价函数来实现的，而Dropout则是通过修改神经网络本身来实现的。 #### dropout是如何实现的 在training的时候，每次update参数之前，对每一个Neuron（包括input_layer）做sampling，决定这个Neuron按一定几率p丢掉，跟它相连的weight也被丢掉，结果得到一个细长的Network。（每一次update一个mini-batch之前，拿来traing的Network structure是不一样的）。 换句话说input layer中每个element也算是一个neuron. 每次更新参数之前都要resample. **用dropout，在training上的结果会变差，但在testing上的结果会变好。** ![在这里插入图片描述](https://img-blog.csdnimg.cn/196bfc65730b4cb6b5877bcbc0a40729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 在**testing的时候不做dropout，所有neuron都要用**。 如果training时的删除神经元的概率为p%，则在testing时，所有的weight都要乘以（1-p）% ![在这里插入图片描述](https://img-blog.csdnimg.cn/2c2491b39cef4452b88c9c465a8a1cbe.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### Dropout的原理 ![在这里插入图片描述](https://img-blog.csdnimg.cn/27c81c02d95847c2a5776da769696c54.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) > **Q : 为什么当在做 *testing* 的时候，weights需要都乘以 *(1-p)%* (p是Dropout的概率)？** > > 答：如下图所示，左侧是在 *Traing* 阶段，*w2* 与 *w4* 由于丢失几率和丢掉(几率是这里是0.5)，假设神经元此时都是1，这时输出的应该是 *w1+w3*；右侧是在 *Testing* 阶段，在这个阶段要保证所有的神经元都不做 *Dropout* 。所以变成了w1+w2+w3+w4，约等于变成了左侧的两倍；所有取所有weight都要乘以（1-0.5）。 实际上，dropout是利用ensemble思想，把一个复杂神经网络的训练转化为，训练很多个简单的神经网络，然后再把多个简单神经网络训练出来的参数做平均。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/96b24fb760ee4d65b18862bc7bcf4ee0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 一个复杂model, bias准，但variance大，把多个复杂model ensemble起来，variance变小。 每个dropout后的结构由一个batch来train，但是权重是共享的，每个权重是由多个batch 来train的。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/32d269be253c4f1790664d3b5c88caca.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) **在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的。** **Dropout用在ReLU、Maxout上效果较好。** Q : 为什么 Dropout 在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的？ 而不是相同答：因为神经元之间的层次，使用的激活函数不一定都是线性的，只有线性的情况下才会是相同的。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"Keras 构建 线性模型和非线性模型","slug":"Keras 构建 线性模型和非线性模型","date":"2021-08-24T09:22:01.000Z","updated":"2021-10-29T15:02:49.324Z","comments":true,"path":"2021/08/24/Keras 构建 线性模型和非线性模型/","link":"","permalink":"http://example.com/2021/08/24/Keras%20%E6%9E%84%E5%BB%BA%20%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"@TOC 预测线性模型使用的数据 是我们随机生成的、首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便） 12345678910import kerasimport numpy as npimport matplotlibimport matplotlib.pyplot as plt# matplotlib.use(&#x27;TkAgg&#x27;)# print(matplotlib.get_backend())# Sequential按顺序构成的模型from keras.models import Sequential# Dense全连接层from keras.layers import Dense 先准备我们需要的数据。随机生成100个随机值x，并随机产生100个噪声值。我们按 $y=0.1x+0.2$ 的公式，得到对应的y标签值。 1234567# 使用numpy 生成100个 随机点x_data = np.random.rand(100)# 测试集，但其实都是随机的 用x_data 也可以x_pre = np.random.rand(100)# 噪声 使得每个点不是 均匀在一条直线上noise = np.random.normal(0,0.01,x_data.shape)y_data = x_data * 0.1 + 0.2 + noise 可以将 100个点的分布图画出。 注意图的显示可能有问题，自行解决一下哦。12plt.scatter(x_data,y_data)plt.show() Q：为什么我们要引入 噪声呢？答：引入噪声可以让我们的数据更加的离散分布 在 我们设计的线性模型上。 使得假设的数据更加的合理。 如下图所示 。 橙色的是我们设定的线性模型，蓝色的是 加入噪声以后的数据分布 使用 keras 中的 Sequential （顺序构成的模型） 构建模型 123456789# 构建一个顺序模型model = Sequential()# 在模型中添加一个全连接层# units 输出的维度# input_dim 输入的维度model.add(Dense(units=1,input_dim=1))# sgd 随机梯度下降法# mse Mean Squared Error 均方误差model.compile(optimizer=&#x27;sgd&#x27;,loss=&#x27;mse&#x27;) 之后我们就按照批次训练。 共训练3001个批次。有两种写法。方法一：用一个循环体，循环3001次； 每500次 打印一次 损失值。1234567# 训练3001个批次for step in range(3001): #每次训练一个批次 cost = model.train_on_batch(x_data,y_data) # 每500个 batch 打印一次 cost值 if step % 500 == 0: print(&quot;cost:&quot;,cost)方法二： 直接使用 model.fit () 函数 1model.fit(x_data,y_data,epochs=3001) 可以查看 参数值 W （权重）和 b（偏置值） 12W,b = model.layers[0].get_weights()print(&#x27;W：&#x27;,W,&#x27;b:&#x27;,b) 预测 测试集的 结果 使用 model.predict () 函数 12# 测试集 输入网络中，得到预测值 y_predy_pred = model.predict(x_pre) 可以再 把预测的 图打出来 12plt.scatter(x_pre,y_pred)plt.show() 我们的训练 使用方法二 结果如图所示： 预测非线性模型使用的数据 也是我们随机生成的 首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便） 注意SGD 需要 tensorflow.keras.optimizers 导入 123456789import numpy as npimport matplotlibimport matplotlib.pyplot as pltmatplotlib.use(&#x27;TkAgg&#x27;)# Sequential按顺序构成的模型from keras.models import Sequential# Dense全连接层from keras.layers import Dense,Activationfrom tensorflow.keras.optimizers import SGD 先准备我们需要的数据。用等差数列生成200个值x，并随机产生200个噪声值。我们按 $y=x^{2}$ 的公式，得到对应的y标签值。 123456# 使用numpy 生成 200 个随机点x_data = np.linspace(-0.5,0.5,200)# 测试集x_pre = np.linspace(-0.5,0.5,200)noise = np.random.normal(0,0.02,x_data.shape)y_data = np.square(x_data) + noise 可以将 200个点的分布图画出。 注意图的显示可能有问题，自行解决一下哦。12plt.scatter(x_data,y_data)plt.show() 使用 keras 中的 Sequential （顺序构成的模型） 构建模型。 与线性模型的区别在，我们需要 增加激活函数，并且增加一个 中间层（含有10个神经元）。 并且增加一点 sgd 的学习率，不然学习度太慢，需要的训练次数就会非常大。 1234567891011121314# 构建一个顺序模型model = Sequential()# 在模型中添加一个全连接层# units 输出的维度 维度就是神经元个数# input_dim 输入的维度# 需要的神经模型为 1-10-1model.add(Dense(units=10,input_dim=1,activation=&#x27;tanh&#x27;))model.add(Dense(units=1,input_dim=10,activation=&#x27;tanh&#x27;))# sgd 随机梯度下降法# mse Mean Squared Error 均方误差# sgd 的学习率太小 训练次数可能非常多# 需要修改一下 sgd的学习率sgd = SGD(lr=0.3)model.compile(optimizer= sgd,loss=&#x27;mse&#x27;) 之后我们就按照批次训练。 共训练3001个批次。有两种写法。方法一：用一个循环体，循环3001次； 每500次 打印一次 损失值。1234567# 训练3001个批次for step in range(3001): #每次训练一个批次 cost = model.train_on_batch(x_data,y_data) # 每500个 batch 打印一次 cost值 if step % 500 == 0: print(&quot;cost:&quot;,cost)方法二： 直接使用 model.fit () 函数 1model.fit(x_data,y_data,epochs=3001) 可以查看 参数值 W （权重）和 b（偏置值） 12W,b = model.layers[0].get_weights()print(&#x27;W：&#x27;,W,&#x27;b:&#x27;,b) 预测 测试集的 结果 使用 model.predict () 函数 12# 测试集 输入网络中，得到预测值 y_predy_pred = model.predict(x_pre) 可以再 把预测的 图打出来 12plt.scatter(x_pre,y_pred)plt.show() 我们的训练 使用方法二 结果如图所示：","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://example.com/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"},{"name":"线性模型","slug":"线性模型","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"},{"name":"非线性模型","slug":"非线性模型","permalink":"http://example.com/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"}]},{"title":"各类 激活函数 详解与选择","slug":"各类 激活函数 详解与选择","date":"2021-08-24T09:22:01.000Z","updated":"2021-10-29T15:00:35.325Z","comments":true,"path":"2021/08/24/各类 激活函数 详解与选择/","link":"","permalink":"http://example.com/2021/08/24/%E5%90%84%E7%B1%BB%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E9%80%89%E6%8B%A9/","excerpt":"","text":"@TOC Relutanhsigmiodsoftmax","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"激活函数","slug":"激活函数","permalink":"http://example.com/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"}]},{"title":"各类 损失函数 详解与选择","slug":"各类 损失函数 详解与选择","date":"2021-08-23T09:22:01.000Z","updated":"2021-10-29T15:00:40.017Z","comments":true,"path":"2021/08/23/各类 损失函数 详解与选择/","link":"","permalink":"http://example.com/2021/08/23/%E5%90%84%E7%B1%BB%20%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E9%80%89%E6%8B%A9/","excerpt":"","text":"@TOC mean_squared_error 均方误差","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"激活函数","slug":"激活函数","permalink":"http://example.com/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"}]},{"title":"Tensorflow 代码学习","slug":"Tensorflow 代码学习","date":"2021-08-22T06:05:01.000Z","updated":"2021-10-29T15:02:55.154Z","comments":true,"path":"2021/08/22/Tensorflow 代码学习/","link":"","permalink":"http://example.com/2021/08/22/Tensorflow%20%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"@TOC 机器学习的整体思路为： 用TensorFlow 预测线性模型我们以这个做最简单的栗子，题目描述如下图所示：这就是一个 最简单的数据模型。 首先我们要引入需要的包，这边使用的是 keras API包12from tensorflow import kerasimport numpy as np先构建模型，构建的为一层的神经网络，输入只有一个变量x1model = keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])再设置 优化器 和 损失函数1model.compile(optimizer=&#x27;sgd&#x27;,loss=&#x27;mean_squared_error&#x27;)准备训练数据12xs = np.array([-1.0,0.0,1.0,2.0,3.0,4.0],dtype=float)ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0],dtype=float)训练模型 迭代500次1model.fit(xs,ys,epochs=500)使用模型，对一个 测试集 x 进行预测 y 并输出1print(model.predict([10.0])) 总体代码如下：1234567891011121314151617from tensorflow import kerasimport numpy as np#构建模型#构建一层的神经网络，并且输入只有1个值model = keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])model.compile(optimizer=&#x27;sgd&#x27;,loss=&#x27;mean_squared_error&#x27;)#准备训练数据xs = np.array([-1.0,0.0,1.0,2.0,3.0,4.0],dtype=float)ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0],dtype=float)#训练模型model.fit(xs,ys,epochs=500)#使用模型，对一个x 进行预测 yprint(model.predict([10.0]))结果如下所示：预测的结果是 18.977886 按照 正确的数学模型 $y = 2x - 1$ 结果应该是 19 。但深度学习不可能完美预测这个值，只能是近似。 需要理解的几个点 Q1 ：请问 model.fit(xs,ys,epochs=500) 的 epochs 500 是什么意思？就是针对同一批数据，利用各类算法（比如梯度下降算法），优化训练的次数，理论上训练次数越多，损失函数越小，准确度越高。 Q2：如何看待这个模型是不是正确的？ 第一，需要看输出的 loss 是不是越来越小 ，accuracy 越来越高。 如果loss不是越来越小，那就说明有问题 第二，你可以看看在测试集 上表现怎么样。 Q3：请问 这个 epochs 越多越好么？ 当然不是，正常来说 模型在测试集上的表现 是不如训练集的。 要选取一个合适的 epochs 值，不然会出现 过拟合的现象。 注意：过拟合 是在测试集上的概念。是训练集上表现不错，但测试集表现不尽人意，叫做过拟合 用TensorFlow 做全神经网络的图像识别分类对 Fashion MNIST 进行图像分类 类别包括0 T-shirt/top(体恤) 1 Trouser(裤子) 2 Pullover(套头衫) 3 Dress(连衣裙) 4 Coat(外套) 5 Sandal(凉鞋) 6 Shirt(衬衫) 7 Sneaker(运动鞋) 8 Bag(袋子) 9 Ankle boot(短靴） 总体代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546import numpy as npimport tensorflow as tffrom tensorflow import kerasfashion_mnist = keras.datasets.fashion_mnist(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()#具体值 每一个数字都是灰度值print(train_images[0])#可以可视化的 查看其中的图片import matplotlib.pyplot as pltplt.imshow(train_images[0])plt.show()#构建一个全连接的神经网络model = keras.Sequential()#输入层model.add(keras.layers.Flatten(input_shape=(28,28)))#中间层 128个神经元 激活函数使用relumodel.add(keras.layers.Dense(128,activation=tf.nn.relu))#输出层 10个神经元 激活函数使用softmaxmodel.add(keras.layers.Dense(10,activation=tf.nn.softmax))# 中间层 参数共有 100480个#为 784 × 128 = 100352 还要再加上 每个神经元都有的 bias 100352+128=100480# 输出层 参数共有 1290个# 同理 为 128 × 10 + 10 = 1290model.summary()# optimizer 优化器 loss：损失函数# 当标签是除了0，1以外有其他数字的 用sparse_categorical_crossentropy#为 one-hot 只有一个1 如： [0,0,0,1]用 categorical_crossentropytrain_images_scaled = train_images/255model.compile(optimizer=tf.optimizers.Adam(),loss=tf.losses.sparse_categorical_crossentropy,metrics=[&#x27;accuracy&#x27;])model.fit(train_images_scaled,train_labels,epochs=5)test_images_scaled = test_images/255# # 输出 loss 和 accuracy# model.evaluate(test_images_scaled,test_labels)print(np.shape(test_images[0]/255))# 要满足输入的维度, 并从print(model.predict((test_images[0]/255).reshape(1,28,28,1)))print(np.argmax(model.predict((test_images[0]/255).reshape(1,28,28,1))))print(test_labels[0]) 先引入 需要的包 123import numpy as npimport tensorflow as tffrom tensorflow import keras 加载Fashion MNIST数据集12fashion_mnist = keras.datasets.fashion_mnist(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data() 可以查看一下 图片内容是什么 是个 28 × 28 的二维数组 12#具体值 每一个数字都是灰度值print(train_images[0]) 可以可视化的 查看一下 这张图片 1234#可以可视化的 查看其中的图片import matplotlib.pyplot as pltplt.imshow(train_images[0])plt.show() 构造神经元网络模型有两种表达方式方式一 ：12345678#构建一个全连接的神经网络model = keras.Sequential()#输入层model.add(keras.layers.Flatten(input_shape=(28,28)))#中间层 128个神经元 激活函数使用relumodel.add(keras.layers.Dense(128,activation=tf.nn.relu))#输出层 10个神经元 激活函数使用softmaxmodel.add(keras.layers.Dense(10,activation=tf.nn.softmax))方式二 ： 12345model=tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28,28)), tf.keras.layers.Dense(512, activation=tf.nn.relu), tf.keras.layers.Dense(10, activation=tf.nn.softmax)]) 可以 用summary 函数 查看各层的信息 包括参数等; 1model.summary() Q： 中间层参数 100480 怎么来的？ 中间层 参数共有 100480个 ：为 784 × 128 = 100352 还要再加上 每个神经元都有的 bias 100352+128=100480 输出层 参数共有 1290个 ： 同理 为 128 × 10 + 10 = 1290 归一化与训练数据123train_images_scaled = train_images/255 #归一化model.compile(optimizer=tf.optimizers.Adam(),loss=tf.losses.sparse_categorical_crossentropy,metrics=[&#x27;accuracy&#x27;])model.fit(train_images_scaled,train_labels,epochs=5) Q：为什么只对 1875个 进行训练？ epoch 5 的 含义是什么？ 训练没有问题。正在对1875批次（每批次32张图像）而不是1875张图像进行模型训练。 1875 × 32 = 60000张图像 评估模型 与 测试数据评估模型的 loss 和 accuracy 使用 evaluate (测试集全体数据，测试集全体标签) 方法1234test_images_scaled = test_images/255# # 输出 loss 和 accuracymodel.evaluate(test_images_scaled,test_labels)如果要对 测试集图像 进行预测 需要使用 predict (测试集数据) 方法 输出最后的输出内容为 10维向量（因为一共0-9 10个分类 输出层已经设定好了） 然后再用 numpy的 argmax 取得向量中 值最大的那个 就是对应 预测的标签。要注意输入的维度 必须要与 输入层设定的维度 保持一致123456# 要满足输入的维度, 并从print(model.predict((test_images[0]/255).reshape(1,28,28,1)))#输出预测的标签print(np.argmax(model.predict((test_images[0]/255).reshape(1,28,28,1))))#对比一下 真实的标签是什么print(test_labels[0]) 可以设定自动终止训练当损失值 小于 0.4 就终止 批次训练123456789101112131415161718192021222324import numpy as npimport tensorflow as tffrom tensorflow import kerasclass myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self,epoch,logs=&#123;&#125;): if(logs. get(&#x27;loss&#x27;)&lt; 0.4): print(&quot;\\ nLoss is low so cancelling training!&quot;) self.model.stop_training=True print(model.predict((test_images[0] / 255).reshape(1, 28, 28, 1))) print(np.argmax(model.predict((test_images[0] / 255).reshape(1, 28, 28, 1)))) print(test_labels[0])callbacks=myCallback()mnist=tf.keras.datasets.fashion_mnist(training_images, training_labels),(test_images, test_labels)=mnist.load_data()training_images_scaled=training_images/255.0test_images_scaled=test_images/255.0model=tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28,28)), tf.keras.layers.Dense(512, activation=tf.nn.relu), tf.keras.layers.Dense(10, activation=tf.nn.softmax)])model.compile(optimizer=&#x27;adam&#x27;,loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])model.fit(training_images_scaled, training_labels, epochs=5, callbacks=[callbacks])","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://example.com/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"}]},{"title":"Numpy、Pandas、Matplotlib  常用代码","slug":"Numpy、Pandas、Matplotlib 常用代码","date":"2021-08-21T02:18:01.000Z","updated":"2021-10-29T15:00:45.607Z","comments":true,"path":"2021/08/21/Numpy、Pandas、Matplotlib 常用代码/","link":"","permalink":"http://example.com/2021/08/21/Numpy%E3%80%81Pandas%E3%80%81Matplotlib%20%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81/","excerpt":"","text":"@TOC Numpy 常用代码1234567891011121314151617181920212223242526272829303132333435363738# !/usr/bin/python# -*- coding: UTF-8 -*-import numpy# 生成数组n = numpy.arange(10)print(n)print(&quot;*&quot;*20)# 生成数组，并做2行3列的分隔m = numpy.array([0,1,2,3,4,5]).reshape(2, 3)print(m)print(&quot;*&quot;*20)# 生成数据，分隔成3位数组t = numpy.arange(27).reshape(3, 3, 3)print(t)print(&quot;*&quot;*20)# 加载文本，为int方式tx1 = numpy.loadtxt(&quot;numpy.txt&quot;, delimiter=&quot;,&quot;, dtype=&quot;int&quot;)# 横列替换tx2 = numpy.loadtxt(&quot;numpy.txt&quot;, delimiter=&quot;,&quot;, dtype=&quot;int&quot;, unpack=True)print(tx1)print(tx2)# 1:2横截取，[1,2]为选取tx3 = tx1[1:2,[1,2]]print(tx3)print(&quot;*&quot;*20)# 竖拼接tx4 = numpy.vstack((tx1, tx2))print(tx4)# 横拼接tx5 = numpy.hstack((tx1, tx2))print(tx5)print(&quot;*&quot;*20) 函数简介arrange 函数：用于创建数值范围并返回数组对象1numpy.arrange([1,3,5,7],dtype=numpy.int6或dtype=&#x27;i8&#x27;) linspace 函数： 用于创建等差数组numpy.linspace(start,stop,num,endpoint,retstep,dtype) dtype：默认为 float64num：设置生成的元素个数endpoint：设置是否包含结束值（stop），False为不包含，默认为Trueretstep：设置是否返回步长（即公差），False表示返回，默认为False。当值为 True时，返回值为 二元组，包括数组与步长。 logspace 函数： 用于创建等比数组numpy.logspace(start,stop,num,endpoint,base,dtype) start：开始值，值为$base^{start}$ =》 base为底的 start次幂stop：结束值，值为$base^{stop}$ =》base为底的 stop次幂base：底数dtype：默认数据类型 float64endpoint：True为包含结束值，默认为True numpy 练习题一numpy 的基本用法1.导入numpy库1import numpy as np2.建立一个一维数组 a 初始化为[4,5,6],(1)输出a 的类型（type）(2)输出a的各维度的大小（shape）(3)输出 a的第一个元素（值为4）1234a = np.array([4,5,6])print(a.dtype)print(a.shape)print(a[0])3.建立一个二维数组 b,初始化为 [ [4, 5, 6],[1, 2, 3]] (1)输出各维度的大小（shape） (2)输出 b(0,0)，b(0,1),b(1,1) 这三个元素（对应值分别为4,5,2）12345b = np.array([[4,5,6],[1,2,3]])print(b[0].shape)print(b[1].shape)print(b.shape)print(b[0][0],b[0][1],b[1,1]) 4 (1)建立一个全0矩阵 a, 大小为 3x3; 类型为整型（提示: dtype = int）(2)建立一个全1矩阵b,大小为4x5; (3)建立一个单位矩阵c ,大小为4x4; (4)生成一个随机数矩阵d,大小为 3x2.12345678c = np.zeros([3,3],dtype=int)d = np.ones([4,5],dtype=int)e = np.identity(4,dtype=int)f = np.random.rand(3,2)print(c)print(d)print(e)print(f)5 建立一个数组 a,(值为[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]] ) ,(1)打印a; (2)输出 下标为(2,3),(0,0) 这两个数组元素的值123a = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])print(a)print(a[2][3],a[0][0])6.把上一题的 a数组的 0到1行 2到3列，放到b里面去，（此处不需要从新建立a,直接调用即可）(1),输出b;(2) 输出b 的（0,0）这个元素的值1234b = a[0:2,2:4]print(b)print(b[0][0]) #？？？ 用ndarray不会7 把第5题中数组a的最后两行所有元素放到 c中，（提示： a[1:2, :]）(1)输出 c ; (2) 输出 c 中第一行的最后一个元素（提示，使用 -1 表示最后一个元素）1234a = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])c = a[1:]print(c)print(c[0][-1])8.建立数组a,初始化a为[[1, 2], [3, 4], [5, 6]]，输出 （0,0）（1,1）（2,0）这三个元素（提示： 使用 print(a[[0, 1, 2], [0, 1, 0]]) ）1234a = np.array([[1, 2], [3, 4], [5, 6]])print(a)#花式索引 第一种print(a[[0,1,2],[0,1,0]])9.建立矩阵a ,初始化为[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]，输出(0,0),(1,2),(2,0),(3,1) (提示使用 b = np.array([0, 2, 0, 1]) print(a[np.arange(4), b]))12345#花式索引 第二种a = np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9], [10, 11, 12]])print(a)b = np.array([0,2,0,1])print(a[np.arange(4),b])10.对9 中输出的那四个元素，每个都加上10，然后重新输出矩阵a.(提示： a[np.arange(4), b] += 10 ）12# 数组广播print(a[np.arange(4),b]+10)numpy 的 array 数学操作 执行 x = np.array([1, 2])，然后输出 x 的数据类型12x = np.array([1, 2])print(x.dtype) 12.执行 x = np.array([1.0, 2.0]) ，然后输出 x 的数据类类型12x = np.array([1.0, 2.0])print(x.dtype) 13.执行 x = np.array([[1, 2], [3, 4]], dtype=np.float64) ，y = np.array([[5, 6], [7, 8]], dtype=np.float64)，然后输出 x+y ,和 np.add(x,y)12345x = np.array([[1, 2], [3, 4]], dtype=np.float64)y = np.array([[5, 6], [7, 8]], dtype=np.float64)print(x+y)print(np.add(x,y))#总结：在numpy中，add和“+”是一样的 14 利用 13题目中的x,y 输出 x-y 和 np.subtract(x,y)12345x = np.array([[1, 2], [3, 4]], dtype=np.float64)y = np.array([[5, 6], [7, 8]], dtype=np.float64)print(x-y)print(np.subtract(x,y))#总结：在numpy中，subtract和“-”是一样的 15 利用13题目中的x，y 输出 x*y ,和 np.multiply(x, y) 还有 np.dot(x,y),比较差异。然后自己换一个不是方阵的试试。123456789x = np.array([[1, 2], [3, 4]], dtype=np.float64)y = np.array([[5, 6], [7, 8]], dtype=np.float64)print(np.multiply(x,y))print(np.dot(x,y))print(x*y)##总结：np.multiply()：数组和矩阵对应位置相乘，输出与相乘数组/矩阵大小一致。# np.dot():执行矩阵乘法运算，若秩为1，则执行对应位置相乘再相加。# *：对array执行对应位置相乘 16 利用13题目中的x,y,输出 x / y .(提示 ： 使用函数 np.divide())12345x = np.array([[1, 2], [3, 4]], dtype=np.float64)y = np.array([[5, 6], [7, 8]], dtype=np.float64)print(np.divide(x,y))print(x/y)## np.divide()与 / 效果相同 17 利用13题目中的x,输出 x的 开方。(提示： 使用函数 np.sqrt() )12x = np.array([[1, 2], [3, 4]], dtype=np.float64)print(np.sqrt(x)) 18.利用13题目中的x,y ,执行 print(x.dot(y)) 和 print(np.dot(x,y))12345x = np.array([[1, 2], [3, 4]], dtype=np.float64)y = np.array([[5, 6], [7, 8]], dtype=np.float64)print(x.dot(y))print(np.dot(x,y))##总结：二维数组矩阵之间dot函数运算得到的乘积是矩阵乘积，一维数组是两个向量的内积 19.利用13题目中的 x,进行求和。提示：输出三种求和(1)print(np.sum(x)): (2)print(np.sum(x，axis =0 )); (3)print(np.sum(x,axis = 1))123456x = np.array([[1, 2], [3, 4]], dtype=np.float64)print(np.sum(x))print(np.sum(x,axis=0))print(np.sum(x,axis=1))##总结：axis为0是压缩行,即将每一列的元素相加,将矩阵压缩为一行## axis为1是压缩列,即将每一行的元素相加,将矩阵压缩为一列，再转置 20.利用13题目中的 x,进行求平均数（提示：输出三种平均数(1)print(np.mean(x)) (2)print(np.mean(x,axis = 0))(3) print(np.mean(x,axis =1))）123456x = np.array([[1, 2], [3, 4]], dtype=np.float64)print(np.mean(x))print(np.mean(x,axis = 0))print(np.mean(x,axis =1))##总结：axis为0是压缩行,即将每一列的元素相加,将矩阵压缩为一行,再取平均值## axis为1是压缩列,即将每一行的元素相加,将矩阵压缩为一列，再转置，再取平均值 21.利用13题目中的x，对x 进行矩阵转置，然后输出转置后的结果，（提示： x.T 表示对 x 的转置）12x = np.array([[1, 2], [3, 4]], dtype=np.float64)print(x.T) 22.利用13题目中的x,求e的指数（提示： 函数 np.exp()）12x = np.array([[1, 2], [3, 4]], dtype=np.float64)print(np.exp(x)) 23.利用13题目中的 x,求值最大的下标（提示(1)print(np.argmax(x)) ,(2) print(np.argmax(x, axis =0))(3)print(np.argmax(x),axis =1))12345678x = np.array([[1, 2,3], [3, 4,5]], dtype=np.float64)print(x)print(np.argmax(x))print(np.argmax(x, axis =0))print(np.argmax(x,axis =1))##总结： numpy.argmax(array, axis) 用于返回一个numpy数组中最大值的索引值。# axis=0则竖着看，当axis=0，是在列中比较，选出最大的 行 索引# axis=1则横着看, 当axis=1，是在行中比较，选出最大的 列 索引 24,画图，y=x*x 其中 x = np.arange(0, 100, 0.1) （提示这里用到 matplotlib.pyplot 库）12345import matplotlib.pyplot as pltx=np.arange(0,100,0.1)y=x*xplt.plot(x,y)plt.show() 25.画图。画正弦函数和余弦函数， x = np.arange(0, 3 * np.pi, 0.1)(提示：这里用到 np.sin() np.cos() 函数和 matplotlib.pyplot 库)1234567x=np.arange(0, 3*np.pi, 0.1)y1=np.sin(x)y2=np.cos(x)plt.plot(x,y1)plt.plot(x,y2)plt.show() Pandas 常用代码12345678910111213141516171819202122232425262728293031323334# !/usr/bin/python# -*- coding: UTF-8 -*-import pandasfrom matplotlib import pyplot# 读取文件df = pandas.read_csv(&quot;BeijingPM20100101_20151231.csv&quot;)# 展示# print(df.head())# print(df.info())# 拼接时间period = pandas.PeriodIndex(year=df[&quot;year&quot;], month=df[&quot;month&quot;], day=df[&quot;day&quot;], hour=df[&quot;hour&quot;], freq=&quot;H&quot;)# 将时间数据赋值df[&quot;dataTime&quot;] = period# 设置索引df.set_index(&quot;dataTime&quot;, inplace=True)# # print(period)# print(df.head())# 通过月份统计df = df.resample(&quot;M&quot;).mean()# (统计)缺失data = df[&quot;PM_US Post&quot;].dropna()# pylot展示x = data.indexy = data.valuespyplot.figure(figsize=(20, 8), dpi=80)pyplot.plot(range(len(x)), y)pyplot.xticks(range(0, len(x), 3), x[::3])pyplot.show() Matplotlib 常用代码12345678910111213141516171819202122232425262728293031323334353637383940414243# !/usr/bin/python# -*- coding: UTF-8 -*-import matplotlibfrom matplotlib import pyplotx = [1, 2, 3, 4, 7, 5, 6, 7, 4, 6, 9, 6, 2, 5, 3, 9, 1, 7]y_1 = [10, 15, 7, 6, 13, 17, 19, 1, 5, 2, 15, 11, 12, 16, 8, 3, 5, 17]y_2 = [17, 5, 3, 8, 16, 12, 11, 15, 2, 5, 1, 19, 17, 13, 6, 7, 15, 10]pyplot.figure(figsize=(20, 12), dpi=50)# 调整字体matplotlib.rc(&quot;font&quot;, family=&quot;MicroSoft YaHei&quot;,weight=&quot;bold&quot;, size=20)# 改变刻度# pyplot.xticks([ i + 1 for i in range(max(x))], [ &quot;time&quot; + str(i + 1) for i in range(max(x))], rotation=45)# 第一个参数x轴 第二个展示的内容 rotation 旋转# 描述pyplot.xlabel(&quot;时间&quot;)pyplot.ylabel(&quot;温度&quot;)pyplot.title(&quot;折线图&quot;)# 折线图pyplot.plot(x, y_1)# pyplot.plot(x, y_2)# 散点图# pyplot.scatter(x, y_1)# pyplot.scatter(x, y_2)# 柱状图# pyplot.bar(x, y_1)# pyplot.bar(x, y_2)# 横版柱状图# pyplot.barh(range(len(x)), y_1, height=0.3)# pyplot.barh(range(len(x)), y_2, height=0.3)# 直方图# pyplot.hist(x, (max(x)-min(x))//1)pyplot.xticks(range(min(x), max(x) + 1, 1))# pyplot.grid()# 保存图片# pyplot.savefig(&quot;link.png&quot;)pyplot.show()","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Numpy","slug":"Numpy","permalink":"http://example.com/tags/Numpy/"},{"name":"Pandas","slug":"Pandas","permalink":"http://example.com/tags/Pandas/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"http://example.com/tags/Matplotlib/"}]},{"title":"无监督学习（Unsupervised Learning）之 聚类与降维","slug":"无监督学习（Unsupervised Learning）之 聚类与降维","date":"2021-08-19T14:36:01.000Z","updated":"2021-10-29T15:00:16.070Z","comments":true,"path":"2021/08/19/无监督学习（Unsupervised Learning）之 聚类与降维/","link":"","permalink":"http://example.com/2021/08/19/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%88Unsupervised%20Learning%EF%BC%89%E4%B9%8B%20%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/","excerpt":"","text":"@TOC 总结 无监督学习 的要点：1、无监督学习的概念 - 什么叫无监督学习（输入都是无label的数据，没有训练集之说，也就是**只能从一些无label的数据中自己寻找规律**） - 无监督学习的两大任务：“化繁为简”（聚类、降维）、“无中生有” 2、聚类Clustering（K-means、HAC）3、降维Dimension Reduction（PCA） 无监督学习的具体分类？ 化繁为简：找一个函数，将本来复杂的输入，变成比较简单的输出。比如找一个函数，可以把所有的树都变成抽象的树。因此我们拥有一大堆各种不同的图像的数据，但不知它的 output 长什么样子。 无中生有：找一个函数，随机给它一个input（比如一个数字1），然后output一棵树，输入数字2，output另外一棵树，输入3，又是另外一棵树。输入一个随机数，就自动画一张图出来，不同的数画出来的图不一样。这个任务里面，要找的可以画图的函数，只有output没有input。只有一大堆的图像，但是不知道输入什么数字才可以得到这些图像。 化繁为简包括 聚类 Q：什么是 聚类？ 假设做图像的聚类，现在有一大堆的图像，然后把它们分成各类。如上图左边的图像都属于 簇1，右边的图像都属于 簇2，上方的图像都属于 簇3。这就像给图像贴标签，把类似的图像，都用同一个簇表示，就做到化繁为简这件事情。 Q：聚类的注意点是什么？ 是 这些数据到底有多少个簇！ 这和神经网络需要设计几层一样，是需要算法工程师的个人经验的。 这个簇不能太多也不能太少。 比如多到说9张图像9个簇，那聚类就没有意义，直接每个图像一个簇就好了，或者说全部图像都是一个簇，也跟没有做一样。 聚类方法最常用的就是K-means，有一大堆未标注数据 $x^{1}$ 到 $x^{n}$ ，每一个 $x$ 代表一张图像，做成 K 个簇。 K-means聚类算法怎么做？先找簇的中心，假如每一个对象都用一个向量表示，有 K 个簇就需要 $c^{1}$ 到 $c^{K}$ 个中心。可以从训练数据里随机找 K个对象出来作为初始化中心。而后对所有数据，决定属于哪一个簇。假设 $x^{n}$ 和 $c^{i}$ 最接近，那么 $x^{n}$ 就属于 $c^{i}$ ，用 $b_{n}^{i}$ 表示。然后更新簇，所有属于 $c^{i}$ 的数据做平均，就是第 $i$ 个簇新的中心，更新要反复进行。 Q：为什么 是从数据集中挑选 K 个样本做初始化 簇中心？答：之所以从数据集挑选K个样本做初始化簇中心，有一个很重要的原因是，如果是纯粹随机的（不从数据集里挑），那很可能在第一次分配这个簇中心的时候，没有任何一个样本跟这个中心很像，也可以说这个簇没有任何样本，再次更新就会出错。 K-means 用更简单的话来说：其算法思想大致为：先从样本集中随机选取 K 个样本作为簇中心，并计算所有样本与这 K 个“簇中心”的距离，对于每一个样本，将其划分到与其距离最近的“簇中心”所在的簇中，对于新的簇计算各个簇的新的“簇中心”。循环反复。 Q：总结一下 K-means 算法的 主要流程 簇个数 K 的选择 初始化簇中心（可以从你的train data里面随机找K个x出来，就是你的k个center） while（收敛——聚类结果不再变化） { 各个样本点到“簇中心”的距离 ； 根据新划分的簇，更新“簇中心”（求均值）; } 层次凝聚聚类算法（HAC）怎么做？首先 我们要做一个树结构 （其过程 非常像 哈夫曼树的构造） 假设有5个样本做层次聚类，先要做一个树结构。计算两两样本的相似度，挑出最相似的数据对。 比如第一个和第二个样本最相似，那就合并（比如用平均值代表），5个样本变为4个样本；再计算相似度，配对的是4，5样本，然后把他们合并（平均值），变成3个样本；接着计算相似度，配对的是黄色数据点和剩下的蓝色数据点，再次合并（平均），最后只剩红色和绿色，那么最后平均起来得到root。根据5笔数和之间的相似度，就建立出了一个树结构。 但树结构只是告诉我们说哪些样本比较像，还没有做聚类。 Q：那怎么做聚类呢？或者说我怎么看我分的那几个聚类？答： 看你怎么切，如图上面不同颜色的切线。 比如在上图蓝线初切一刀，意味着把数据分成3簇，1、2为一簇，3单独为一簇，4、5为一簇。 在红色线切一刀，则1、2、3为一簇，4、5为一簇。 在绿色点切一刀，则1、2为一簇，3、 4、 5单独为一簇。 Q：层次聚类 和 K-means的差别？ 在K-means里要自己决定K的值，也就是你要分多少个簇。 在层次聚类里要决定的是在哪里切一刀，如果切比较容易考虑的话，那层次聚类可能更好。 化繁为简包括 降维 Q：什么是降维？答：降维意思是说，原本高维的东西，其实是可以用低维去表示它。就是找出数据里最主要的方面，用数据里最主要的方面来代替原始数据。换句话说，可以减少数据的维度。就是 z = Wx Q：为什么降维有用？答：假设数据分布如上图左边，在3D空间里分布是螺旋的样子，但是用3D描述数据分布比较浪费的，直觉上也可以感觉可以摊开变成右边2D的样子，只需要2D的空间就可以描述3D的信息。在3D空间里面解比较麻烦，那就在2D里做这个任务。考虑一个实际的简单栗子：每一个input的数字都是28 × 28的矩阵来描述。但是实际上，多数28 × 28矩阵转成一个图像看起来都不像数字，在28 × 28空间里是数字的矩阵是很少的。所以要描述一个数字，或许不需要用到28 × 28维，远比28 × 28维少。所以举一个极端的例子，有一堆3，从像素点看要用28 × 28维来描述每张图像。实际上，只要用一个维度就可以表示，中间的是3，其他的3都是中间的3左转右转10、 20度。所以唯一需要记录的就是中间的3，左转和右转了多少度，即只需要角度的变化，就可以知道28维空间中的变化。 Q：怎么做降维？答：找一个函数，input是一个向量x，output是另外一个向量z（z的维度比x小）。 在降维里最简单的方法是特征选择，把数据的分布拿出来看一下， 如在二维平面上发现数据集中在 $x$ 维度，所以 $y$ 这个维度没什么用，那么就把他拿掉，等于是降维这件事。特征选择不一定有用，有可能case里面任何一个维度都不能拿掉。 另一个常见的方法是PCA，函数是一个很简单的线性函数，input x和output z之间的关系就是一个线性的transform，即 $x$ 乘上一个矩阵 $W$ 得到 $z$ 。现在不知道 $z$ 长什么样子，要根据一大堆的 $x$ 把 $W$ 找出来。 分布式表示（Distributed Representation） Q：光做聚类的话是非常以偏概全的。为什么呢？答：因为在聚类思想中，每个样本都必须属于某一个簇。就好像念力分成6大类，每个人都会被分配到6个大类其中一类。但这样分配太过粗糙，比如某个人的能力既有强化系的特性又有放出系的特性，只分为一类就会丢失很多信息。 **只分为一类就是以偏概全了，应该要用一个向量来表示每个对象，向量的每个维度代表了某一种特质（属性）。这件事情叫做Distributed Representation**。 比如上图所示，这个人每个系都可以有固定的能力占比。 如果对象是一个高维的东西，例如图像，现在用它的特性来表示，就会把它从高维空间变成低维空间，这件事情叫做降维。 Distributed Representation和**降维**是一样的东西，不同的称呼。 ### 主成分分析（PCA） 函数是一个很简单的线性函数，input x和output z之间的关系就是一个线性的transform，即 $x$ 乘上一个矩阵 $W$ 得到 $z$ 。现在不知道 $z$ 长什么样子，要根据一大堆的 $x$ 把 $W$ 找出来。 PCA的实现一般有两种： - 一种是用特征值分解去实现的 - 一种是用奇异值分解去实现的 #### PCA-用特征值分解实现 ![在这里插入图片描述](https://img-blog.csdnimg.cn/3acdbf6ffca44f85b12bb6a0719ae8c9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 刚才讲过PCA要做的事是找 $W$ ，假设一个比较简单的case，考虑一个维度的case。假设要把我们的数据投射到一维空间上，即 $z$ 只是一维的向量。 $w^{1}$ 是W的第一行，和 $x$ （列向量）做内积得到一个标量 $z_{1}$ 。 > **Q：$w^{1}$应该长什么样子？** > 首先假设 $w^{1}$ 的长度是1，即 $||w^{1}||_{2}=1$ 。如果$||w^{1}||_{2}=1$，$w^{1}$ 是高维空间中的一个向量，那么 $z_{1}$ 就是就是 $x$ 在 $w^{1}$ 上的投影长度。现在要求出每一个 $x$ 在 $w^{1}$ 上的投影，那 $w^{1}$ 应该长什么样子？ 举个例子，假设上图右上方是 $x$ 的分布，$x$ 都是二维的，每个点代表一只宝可梦，横坐标是攻击力，纵坐标是防御力。现在要把二维投影到一维，应该要选什么样的 $w^{1}$ ? 可以选 $w^{1}$ 为上图右上方右斜方向，也可以选左斜方向，**选不同的方向，最后得到的投影的结果会不一样**。 那总要给我们一个目标，我们才知道要选什么样的 $w^{1}$ ，现在目标是经过投影后得到的 $z_{1}$ 的分布越大越好。我们不希望投影后所有的点都挤在一起，把本来数据点之间的奇异度消去。我们希望投影后，数据点之间的区别仍然看得出来，那么我们可以找投影后方差越大的那个 $w^{1}$ 。 看上面的例子，如果是右斜方向，那么方差较大，左斜方向方差则较小，所以更可能选择右斜方向作为 $w^{1}$ 。 从上面的例子里看， $w^{1}$ 代表了宝可梦的强度，宝可梦可能有一个隐藏的向量代表它的强度，这个隐藏的向量同时影响了防御力和攻击力，所以防御力和攻击力会同时上升。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/dd45a73b7b0640d1bbb675b9132e5044.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 开始计算： 1、把方差式子展开，转化成协方差（具体转化过程不描述了） 2、结论：我们要找的 $w^{1}$ 就是协方差矩阵 $S$ 的最大特征值所对应的特征向量， $w^{2}$ 就是协方差矩阵 $S$ 的第二大特征值所对应的特征向量，以此类推 . PCA - 用奇异值分解（SVD）特征值分解是一个提取矩阵特征很不错的方法，但是特征值分解只是对方阵而言的，在现实的世界中，我们看到的大部分矩阵都不是方阵。奇异值分解是一个能适用于任意的矩阵的一种分解的方法。 假设现在考虑手写数字识别，我们知道手写数字其实是由一些基本成分组成的，这些基本成分可能是笔画。例如斜的直线，横的直线，比较长的直线，小圈、大圈等等，这些基本成分加起来以后得到一个数字。 基本成分我们写作 $u^{1},u^{2},u^{3}…$，这些基本的成分其实就是一个一个的向量。考虑 MNIST数据集 ，一张图像是28 × 28像素，就是28 × 28维的向量。基本成分其实也是28 × 28维的向量，把这些基本成分向量加起来，得到的向量就代表了一个数字。 如果写成公式的话，就如上图最下方所示的公式。$x$ 代表某一张图像的像素，用向量表示。$x$ 会等于 $u^{1}$ 这个成分乘上 $c{1}$ ，加上 $u^{2}$ 这个成分乘上 $c{2}$，一直加到 $u^{K}$ 这个成分乘上$c_{K}$，再加上 $\\bar{x}$（$\\bar{x}$ 是所有图像的平均）。所以每一张图像，就是一堆成分的线性组合加上所有图像的平均所组成的。 例如数字7是 $u^{1},u^{3},u^{5}$ 加起来的结果，那么对数字7来说，公式里的 $c{1}=1 ,c{2}=0, c{3}=1…$，所以可以用 $c{1},c{2},c{3}…,c{K}$ 来表示一张图像，如果成分远比像素维度小的话，那么用$\\begin{bmatrix}c{1}\\c{2}\\…\\c{K}\\\\end{bmatrix}$表示一张图片是会比较有效的比如7可以由向量 $\\begin{bmatrix}1\\0\\1\\0\\1\\…\\\\end{bmatrix}$ 描述。 我们把公式里的 $\\bar{x}$ 移到左边，$x$ 减 $\\bar{x}$ 等于一堆成分的线性组合，写作 $\\hat{x}$ 。 Q：如果我们不知道K个u（成分）是什么，那怎么找出这K个向量？ 找K个u，让$x−\\bar{x}$ 和 $\\hat{x}$ 越接近越好，$||(x-\\bar{x})-\\hat{x}||{2}$ 称为重构误差，代表没办法用成分描述的部分。接下来，最小化 $||(x-\\bar{x})-\\hat{x}||{2}$，损失函数如上图 $L$。 回忆下PCA，$w{1},w{2},w{3}…w{K}$ 是 $x$ 协方差矩阵的特征向量，事实上 $L$ 的解就是PCA的 $w{1},w{2},w{3}…w{K}$。 PCA实例手写数字识别以把每一张数字图像拆成成分的线性组合，每一个成分也是一张图像（28 × 28 维的向量），所以可以把成分画在图上变成一张图像。 通过PCA画出前30个成分如上图所示，白色的地方代表有笔画。用这些成分做线性组合，就可以得到0-9的数字，所以这些成分叫做Eigen-digit。 Eigen（本征）是说，这些成分都是协方差矩阵的特征向量。 ## 人脸识别 ![在这里插入图片描述](https://img-blog.csdnimg.cn/9e97b877a5114592ac90e2b7f5f3c0f6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 上图右上方有一大堆人脸，找它们前30个主成分。找出来就如上图最下方所示，每张图像都是哀怨的脸，叫做Eigen-face。把这些脸做线性组合，就可以得到所有的脸。 > **Q：但这边有没有觉得有问题，因为主成分找出来的是成分，但是现在找出来的几乎都是完整的脸，也不像是成分啊？像前面的数字识别，成分看起来也像是玛雅文字，而不是笔画，看起来也不是成分啊？** ![在这里插入图片描述](https://img-blog.csdnimg.cn/1215e23adb994fd6b8380a73b1e64527.png#pic_center)> **答**：仔细想想PCA的特性，$α_{1},α_{2}$ 这种权重可以是任何值，可以是正的，也可以是负的。所以当我们用这些主成分组成一张图像的时候，可以把这些成分相加，也可以把这些成分相减，这就会导致你找出的东西不见得是一个图的基本的结构。> > 比如我画一个9，那可以先画一个8，然后把下面的圆圈减掉，再把一杠加上去。我们不一定是把成分加起来，也可以相减，所以说就可以先画一个很复杂的图，然后再把多余的东西减掉。这些成分不见得就是类似笔画的这种东西。 > > 如果要得到类似笔画的东西，就要用另一个技术*NMF（非负矩阵分解）*。PCA可以看成是对矩阵X做SVD，SVD就是一种矩阵分解的技术。**如果使用NMF，就会强迫所有成分的权重都是正的，正的好处就是一张图像必须由成分叠加得到，不能说先画一个复杂的东西再去掉一部分，再来就是所有成分的每个维度都必须是正的。** 所以在同样的任务上，例如手写数字的测试上，使用NMF时，找出来的主成分会如下图所示。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/ac0fc298e03847819527bc49a3198b45.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 你会发现，白色图案类似于笔画，找出来的主成分就成了笔画了。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/36c61755d6ce40318f4df22c47721ab5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 看脸的话，会发现如上图所示。比较像脸的一部分，比如人中、眉毛、嘴唇、下巴。 ## 宝可梦 ![在这里插入图片描述](https://img-blog.csdnimg.cn/c19d6fca60984ad6a435fd0750f485fa.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 有800种宝可梦，每种宝可梦可以用6个特征来表示。所以每个宝可梦就是6维的数据点，6维向量。 现在用PCA来分析，PCA里常有的问题是到底需要几个成分，即到底要把数据降到几维。这个一般取决于你的目的是什么，比如你想做可视化，分析宝可梦特性之间的关系，6维没办法可视化的，那就投影到二维。要用几个主成分就好像是神经网络需要几层，每层几个神经元一样。 一个常见决定使用几个主成分的方法是，去计算每个主成分（特征向量）对应的特征值，这个特征值代表在该主成分上投影数据的方差。 现在的例子里宝可梦是6维的，那就有6 × 6维的协方差矩阵，所以有6个特征值，如上图计算每个特征值比例，结果是0.45，0.18，0.13，0.12，0.07，0.04。那第5、6个主成分的作用比较小，意味着投影数据的方差很小，宝可梦的特性在这两个主成分上信息很少。那么分析宝可梦特性只需要前4个主成分。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/8fcb23f86b76476e9b66585379b04cbb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) PCA后选择4个主成分，每个主成分是一个6维向量（因为原来每个特征都要投影，那就有6种投影数据）。 每个宝可梦可以想成是4主成分向量做线性组合的结果，且每只宝可梦组合的权重不同。 看第一个主成分PC1，数值都是正的，如果给它的权重大，意味着宝可梦6维都是强的，给它的权重小，意味着宝可梦6维都是弱的，所以第一个主成分，代表了这只宝可梦的强度。 看第二个主成分PC2，Def防御力是正值，速度是负值，那么增加权重的时候，会增加防御力并减小速度。 把第一个和第二个主成分画出来如上图最下方，图上有800个点，每个点代表一只宝可梦。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/995d8f5d622b4b3691e432d0e2554a0e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 第三个主成分PC3，特殊防御力是正的，攻击力和HP都是负的，也就是说这是用攻击力和HP来换取特殊防御力的宝可梦。 第四个主成分PC4，HP是正的，攻击力和防御力是负的，这是用攻击力和防御力换取生命值的宝可梦。 把第三、第四主成分画出来如上图最下方，维度是去相关的。 ## 矩阵分解-推荐系统 有时候，你会有两种东西，两种对象，它们之间受到某种共通的潜在因素操控。 假设现在做一个调查，调查每个人手上买的公仔的数目，有5个宅男同学A,B,C,D,E，横轴的公仔人物是凉宫春日、御坂美琴、小野寺、小唯，调查结果如下图。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/7557d3f48de34c97be70ec2ca4212e74.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 看这个矩阵可以发现，买凉宫春日的人，比较有可能有御坂美琴；买小野寺的人，也比较有可能买小唯。这说明人和公仔有一些共同的特性，有共同的因素在操控这些事情发生。 动漫宅获取可以分成两种，一种是萌傲娇的，一种萌天然呆的。每个人都是萌傲娇和萌天然呆平面上的一个点，可以用一个向量表示，那么看上图，A是偏萌傲娇。每一个公仔角色，可能有傲娇属性或者天然呆属性，所以每一个角色，也是平面上一个点，可以用一个向量描述。 如果某个人的属性和角色的属性匹配的话，他们背后的向量就很像（比如做内积的时候值很大），那么A就会买很多的凉宫春日。他们匹配的程度取决于潜在因素是不是匹配的。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/d5f8553af83f4034bbcff5b07c95251a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 所以ABC的属性如上图最左边所示，A、B是萌傲娇的，B稍微没有那么傲娇，C是萌天然呆。每个动漫角色后面也有傲娇、天然呆这两种属性，如果人物属性和角色属性匹配的话，人买角色的可能性就很大。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/006698ec686f439ea7e5161e55e7213f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 上图中右下方矩阵公式中，右边两个矩阵的N应该是M，代表M个人。 我们知道的只有人买的角色的数目，然后凭着这种关系去推论每个人和每个动漫人物背后的潜在因素。每个人背后都有一个向量，代表萌傲娇或者萌天然呆的程度。每个角色后面也有一个序列，代表是傲娇或天然呆的属性。 我们可以把购买的公仔数量合起来看做是一个矩阵X ，行数是人的数量，列数是公仔角色的数量。 现在有一个假设，矩阵X里的每个元素都来自于两个向量的内积。为什么A会有5个凉宫春日的公仔，是因为 $r^{A}·r^{1}$ 的内积很大，约等于5。这件事情用数学公式表达的话，可以把 $r^{A}$ 到 $r^{M}$ 按列排起来，把 $r^{1}$ 到 $r^{4}$ 按行排起来，K是潜在因素的个数，一般没办法知道，需要自己测试出来。 Q：矩阵X的每个维度是什么？我们要做的事情就是找一组rA到rE，找一组r1到r4 ，让两个矩阵相乘后和矩阵X越接近越好，就是最小化重构误差。这个就可以用SVD来解，把Σ并到左边或右边变成两个矩阵就可以了。有时候有些信息是缺失的，比如上图所示的，你不知道A、B、C手上有没有小野寺，可能在那个地区没有发行，所以不知道发行的话到底会不会买。那用SVD就很怪，也可以把缺失值用0代替，但也很奇怪。 Q：那有缺失值怎么办呢？可以用梯度下降的方法来做，写一个损失函数，让$r^{i}$（每个人背后的潜在因素）和$r^{j}$（角色背后的潜在因素）的内积和角色购买数量越接近越好。现在重点是，在summation over元素的时候，可以避开缺失的数据，如果值是缺失的，就不计算。有了损失函数后，就可以使用梯度下降了。根据刚才的方法实际计算一下，假设潜在因素的数量是2。那么A到E都是二维的向量，每个角色也是二维的向量。数值代表了属性的程度，把大的用红色框框圈出来，会发现A、B萌同一组属性，C、D、E萌同一种属性，1,2有同样的属性，3,4有同样的属性。没有办法知道每个属性代表什么，要先找出这些潜在因素，再去分析它的结果。有了这些潜在因素数据，就可以用来预测缺失值。已经知道了$r^{A}$和$r^{3}$，那只要$r^{A}$和$r^{3}$做内积就可以了。 之前的model可以做得更精致一点，刚才说A背后的潜在因素乘上 春日 背后的潜在因素，得到的结果就是矩阵里的数值。但是事实上，可能还会有其他因素操控这些数值。那么更精确的写法就可以写成。 r^{A}⋅r^{1}+b_{A}+b_{1}≈5$b{A}$是跟 $A$ 有关的标量，代表了 $A$ 有多喜欢买公仔，有的人就是喜欢买公仔，也不是喜欢某个角色。$b{1}$是跟 春日 有关的标量，代表了角色有多想让人购买，这个事情是跟属性无关的，本来人就会买这个角色。 然后修改损失函数如上图所示，使用梯度下降求解即可。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"无监督学习","slug":"无监督学习","permalink":"http://example.com/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}]},{"title":"半监督学习 Semi-Supervised","slug":"半监督学习 Semi-Supervised","date":"2021-08-17T14:36:01.000Z","updated":"2021-10-29T15:00:06.612Z","comments":true,"path":"2021/08/17/半监督学习 Semi-Supervised/","link":"","permalink":"http://example.com/2021/08/17/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%20Semi-Supervised/","excerpt":"","text":"@TOC 总结 半监督学习 的要点：Q1：什么是Semi-Supervised？Q2：Semi-Surpervised在生成模型中如何实现的（EM算法）？Q3：Semi-Surpervised基于Low-density Separation（低密度分离）假设是如何实现的？Q4：Semi-Surpervised基于Smoothness Assumption（平滑）假设是如何实现的？ 什么是Semi-Supervised？大家知道在监督学习里，有一大堆的训练数据（由input和output对组成）。例如上图所示 $x^{j}$是一张图片，$y^{r}$ 是类别的 label。半监督学习是说，在label数据上面，有另外一组unlabeled的数据，写成$x^{u}$ (只有 input 没有 output )，有U笔 unlabeled 的数据。通常做半监督学习的时候，我们常见的情景是 unlabeled 的数量远大于labeled 的数量（U&gt;&gt;R)。 举个栗子：现在我们要做一个猫狗分类 如果只考虑 labeled data，我们分类的分界线会画在中间； 如果把 unlabeled data 也考虑进去，我们可能会根据 unlabeled data 的分布，分界线画成图中的斜线； semi-supervised earning使用 unlabel 的方式往往伴随着一些假设，学习有没有用，取决于你这个假设合不合理。（比如灰色的点也可能是个狗不过背景跟猫照片比较像） 半监督学习可以分成两种： 一种叫做转换学习，unlabeled 数据就是 testing set ，使用的是testing set的特征。 另一种是归纳学习，不考虑testing set，学习model的时候不使用testing set。 Q：用 testing set 作为 unlabeled 数据，不是相当于用到了未来数据吗？答：用了 label 数据才算是用了未来数据，用 testing set 的特征不算是使用未来数据。Q：什么时候使用转换学习或者归纳学习？答：看 testing set是不是给你了。在一些比赛里，testing set 它是给你的，那么就可以使用转换学习。但在真正的应用中，一般是没有 testing set 的，这时候就只能做归纳学习。Q：为什么使用半监督学习？答：缺少 lable 的数据，比如图片，收集图片很容易，但是标注label很困难。半监督学习利用未标注数据做一些事。Q：用沙雕的简单日常语言，讲一讲什么是 半监督学习答：对人类来说，可能也是一直在做半监督学习，比如小孩子会从父母那边做一些监督学习，看到一条狗，问父亲是什么，父亲说是狗。之后小孩子会看到其他东西，有狗有猫，没有人会告诉他这些动物是什么，需要自己学出来。 Semi-Surpervised在生成模型中如何实现的（EM算法） Q：在生成模型中为什么使用半监督学习？答：在监督学习中，有一堆用来训练的样本（就是label），你知道它们分别属于类别1，还是类别2。会去估算类别1和类别2的先验概率P(C1),P(C2) ，然后计算类条件概率 P(x|C1),P(x|C2) 。假设 P(x|Ci) 服从一个高斯分布。 假设类别1的数据是从均值为 μ1，协方差为 Σ 的分布中取出来的，而类别2的数据是从均值为 μ2 ，协方差也为 Σ 的分布中取出来的（之前讲过共享协方差，效果会好一点）。然后可以计算后验概率 P(C1|x) ，决定一个决策边界在哪里。如果今天有一些未标注数据，如上图绿点，那仍然假设均值和方差是μ1,μ2,Σ显然不合理。如上图左下所示，Σ应该比较接近圆圈（蓝色圆圈），也许在类1采样的时候有问题，所以采样到奇怪的分布（蓝色椭圆）。如上图右下，类2的μ2不应该在橙色椭圆内，而应该在更下面。这样会使先验概率受到影响，本来两个分布，正例数据是一样多，但是加入未标注数据之后，你可能会觉得类2的正例数据更多（先验概率就更大）。总之加入未标注数据后，会影响对均值和协方差的估测，继而影响类条件概率，最后影响了你的决策边界。 通俗的讲，回顾有监督学习中的生成模型，由于data都是有label的，P(Ci) 是已知的，P(x|Ci) 是通过我们基于高斯分布的假设用最大似然估计出来的；现在半监督学习中的生成模型，data的一部分是unlabel的，P(Ci) 是不确定的（隐变量），P(x|Ci)的假设模型也不能套用原来的 u 等参数，这时候需要用EM算法(Expectation-Maximization algorithm，又译为期望最大化算法) EM算法 具体怎么做EM算法适用于带有无法观测的隐变量的概率模型估计初始化一组参数，如果是二分类任务，就是初始化类1和类2的先验概率、均值和协方差，可以随机初始化，用已经有标注的数据估测，统称为 θ 第一步（E步），用labeled data算出来的高斯模型参数 θ 代入公式去求出每一笔未标注数据（unlabeled data）的后验概率（属于类1 的概率）的 P(C1|Xu)； 第二步（M步），用极大似然估计更新 P(Ci) 以及高斯模型参数 θ ，求出 P(x|Ci)，进一步求出新的后验概率 P(Ci|Xu) ，重复这两步直到收敛（似然概率最大） 至于为什么更新参数是要加入P(Ci|Xu) 这一项，是因为EM算法的思想是把不确定的data用一个概率来表示label，而每一笔不确定的data都有可能来自 类C1 和 类C2，看右下图： Q：EM 算法背后的理论是什么？答：原来只有标注数据的时候，目标是最大化一个似然函数，那么给定θ，每一笔训练数据的似然函数值是可以计算的，然后把所有的似然函数值相加，就是总的似然函数值，然后找 θ 最大化。θ 有显式解，求最大值点（导数为0）。现在加入未标注数据后，我们不知道未标注数据来自哪一个类别，那么未标注数据出现的概率就是和 C1的联合概率+和C2的联合概率（相当于是$\\sum{C}P(x^{u},C^{i})$ 。接下来目标就是最大化 $P{\\theta }(x^{u})$ ，但是 $P_{\\theta }(x^{u})$ 的式子是非凸的，所以使用EM算法求解。 Semi-Surpervised基于Low-density Separation（低密度分离）低密度分离的假设是，不确定的data的label要不是1，要不是0（“非黑即白”）。低密度的意思是，两个Class的分界处是低密度的（分得比较开的） Q：这个世界是非黑即白的，什么是非黑即白？答：假设现在有一大堆的data，有标注数据，有非标注数据，在两个类别之间会有一个明显的鸿沟。给一些标注数据，可以把边界分在上图右边的线，也可以把边界分在上图左边的线。但是考虑非标注数据，那么左边的边界会好一点，在边界处，两个类别的密度是低的（不会出现data） Self-training + Entropy-based Regularization(基于熵的正则化)self-training低密度分离最代表性、最简单的方法是self-training，非常直觉。 我们有一些标注数据，和一些未标注数据。接下来： 从标注数据训练一个model f* (用DNN，deep、shallow还是其他机器学习的方法都可以) 根据f* 标注未标注数据，丢入$x^{u}$ ，得到$y^{u}$ ，${(x^{u} ,y^{u} )}^{R+U}_{u=l}$ 叫做伪标签数据（称为Pseudo-label伪标签） 接下来，从伪标签数据集移除一些数据加到标注数据集（移除哪些数据需要自己决定，设计一些启发式的规则，或者给权重，有些数据的标签比较确定，那就给大的权重） 有了更多的标注数据之后，回头再去训练model f* Q：self-training在回归上有用吗？回归问题用self-training不影响f∗，所以回归问题不能用self-training方法。self-training 很像是刚才生成模型里面用的EM算法，唯一的差别是在做 self-training 的时候，用的是硬标签，生成模型里用的是软标签（概率）。在做 self-training 的时候，会强制分配一个数据属于某一个类别，在生成模型里，使用的是后验概率，部分属于类1，部分属于类2。 Entropy-based Regularization(基于熵的正则化) — self-training的进阶版熵：一个事件的不确定程度 Entropy-based Regularization（基于熵的正则化）是self-training的进阶版，self-training里用概率划分类别，可能觉得比较武断，那就可以用Entropy-based的这个方法。 Entropy-based是说，如果使用神经网络，output是一个分布，我们不去限制output具体属于哪一个类别，而是假设分布很集中（非黑即白的世界）。如上图，假设做5个类别分类的 model： 第一个 类别1的概率为1，其他类别概率为0，是good 第二个 类别5的概率为1，其他类别概率为0，是good 第三个 所有类别的概率很平均，是bad，不符合低密度分离的假设（非黑即白） Q：怎么用数值的方法评估分布是集中还是不集中？ 使用熵，分布的熵告诉你集中还是不集中。可以用 每个类别的概率 乘以 log（每个类别的概率），再对类别个数求和取负数。 这个式子来评估。 这个其实就是理解成损失函数，因为这边讲究的是非黑即白，所以其实是一致的。损失函数 也可以用分布的距离来描述。我们希望model的output在标注集上正确，在未标注集上的熵越小越好。 第一个分布，熵为0，分布集中 第二个分布，熵也为0，分布集中 第三个分布，熵为 ln(5) ，分布比较散 根据这个目标，重新设计损失函数。原来只是希望model在标注集上的output和label距离越近越好，用交叉熵来评估它们之间的距离。 现在在原来的基础上，加上未标注集的output分布的熵。 然后在未标注集部分乘上一个权重，来表明偏向标注部分还是未标注部分。 上图右下的损失函数可以算微分，那就使用梯度下降最小化这个损失函数，迭代求解参数。加入未标注部分，作用就类似于正则化（在原来损失函数后加一个L1正则或者L2正则），这里则加入一个未标注集熵来防止过拟合，所以称之为基于熵的正则化。 Semi-supervised SVM（半监督SVM) Q：SVM 支持向量机（Support Vector Machine）是什么？SVM是找边界，给你两个类别的数据，SVM找一个边界，这个边界一方面要有最大的间隔（让两个class分的越开越好），一方面要有最小的分类错误。如上图，假设现在有一些未标注数据，半监督SVM会穷举所有可能的label。上图中，有四笔未标注数据，每笔数据既可以属于 class1，也可以属于 class2，可能的情况如上图右边所示（还有很多种其他的可能）。然后对每个可能的结果，都去做一个SVM，边界如上图红色线。然后再去找让间隔最大，错误最小的那一种结果。在例子里可能是黑色框这种结果。 Semi-Surpervised基于Smoothness Assumption（平滑性）假设是如何实现的平滑性假设与高密度区域假设：x的分布是不平均的，在某些地方很集中，在某些地方又很分散。如果 x1 和 x2 在一个高密度的区域很相似的话，两者的标签也会很像。 Q：什么叫在高密度区域下呢？ 意思是说可以用高密度的路径做连接举个例子，假设数据的分布如上图右边所示，像一个血轮眼。现在有3笔数据：x1,x2,x3，x1和x2中间是一个高密度区域（x1和x2由一个高密度区域连接），有很多数据(中间想成平原地带，地势平坦，人烟很多)，而x2和x3之间数据稀少(中间想成一座山，人烟稀少)，那么走平原会比走山容易，x2走到x1更容易（更相似）。 Q：举一个现实中，相似图形的栗子？为什么会有高密度区域假设？因为在真实情况下，这个假设成立的可能性很高。我们考虑手写数字识别的例子，有两个2一个3，如果计算像素点相似度的话，可能上图右边的2和3更像。但是从所有数据中看，左边的2到右边的2中间会有很多连续的形态。所以根据平滑度假设，左边的2和右边的2更像，因为右边的2和3之间没有过渡的形态。看人脸识别也是一样的，比如左脸像和右脸像差很多，两个人的左脸像计算像素点相似度的话，可能比同一个人的两张侧脸像更高。但是如果收集到足够多的未标注数据，会找到两个侧脸像的很多过渡形态，根据高密度区域假设，这两张侧脸像就是同一个人。 高密度区域假设，在文件上非常有用，假如现在要区分天文学和旅游的文章。 天文学的文章会出现asteroid、bright，而旅游的文章会出现yellowstone、zion。如果未标注文章和标注文章的词语有重叠，那可以很容易分类。但真实情况情况是，未标注文章和标注文章可能没有任何词语重叠，因为世界上的词语太多了，一篇文章词汇不会很多，每篇文章的词语是非常稀疏的。但是收集到够多的数据的话，就可以说上图d1、d5像，d5、d6像，传播下去就可以说d1、d3是一类，d2、d4是一类。 方法一：聚类，而后标注（图像上不太行） Q：如何实践平滑度假设？最简单的方法是聚类、然后标记。假如数据分布如上图，橙色是class 1，绿色是class 2，蓝色是未标注数据。接下来做聚类，可能把所有数据分成3个簇。在簇1里，class 1的label最多，那簇1里所有数据标记为class 1，同样的簇2和簇3都标记为class 2。把标记后的数据拿去learn就结束了。 这个方式不一定有用，因为要求簇正确，这个方法有效的假设是同一个class的东西聚集在一起。但是在图像里要把同一个class的东西聚集在一起没有那么容易。之前深度学习讲过，不同class的图像可能会很像，同一个class可能会不像，只用像素点做聚类，结果八成是不好的。没办法把同一个class的数据聚集在一起，那未标注数据就没有用。 所以要有用，就要有一个好的方法来描述一张图像，比如用 Deep Autoencoder 抽特征，然后再做聚类。 方法二：基于图的方法另一个方法是引入图结构，来表达通过高密度路径进行连接这件事情。 把现在所有的数据点都建成一个图，每个数据点就是图上的一个点，想办法计算它们之间的奇点，想办法把它们之间的边建出来。 所谓的高密度路径的意思是说，如果有两个点，在图上是相连的，那它们就是同一个class，如果没有相连，就算距离很近，也走不到。 Q：生活中，如何构建图？有些时候，图的表示可以很自然的得到。 举例说网页的分类，你有记录网页和网页之间的超链接，那超链接就很自然的告诉你网页是怎么连接的。 又举例论文的分类，论文和论文之间有引用的关系，这种引用的关系也是另外一种图的边，可以很自然地把这种图画出来。 怎么自己想办法构建图？*其实的图的好坏对结果的影响是非常严重的，但是自己用什么方法做还是很启发的，用自己觉得合适的方式做就可以了。 通常的做法是： 先定义两个对象之间的相似度，比如图像可以是基于像素点的相似度（可能效果不好），也可以是基于自动编码器抽取出来的特征计算相似度（效果可能好一点） 定义完相似度后，就可以构建图了（添加边），图有很多种： K近邻的图，现在有一大堆数据，可以计算数据与数据之间的相似度，然后设置k例如3，就是3个最相似的点相连 e-Neighborhood的图，只有相似度超过某个阈值的点才会相连 所谓的边也不是只有相连和不相连这两种选择，可以给边一些权重，让边跟两个数据点的相似度成正比。相似度可以用Gaussian Radial Basis Function来定义 怎么计算这个相似度可以先算xi,xj的欧式距离，乘以一个参数取负号，再取e为底的指数函数。取exp很有必要，在经验上最后效果比较好。因为取exp，下降速度很快，只有当xi,xj非常靠近时，奇点才会大，距离远一点奇点就会下降很快变得很小。这样才能制造如上图右下方所示的，两个距离近的橙色点有连接，绿色点和橙色点虽然距离也近，但是使用了exp导致只有很近很近的点才有连接，即使远一点点就不会有连接了，有这样的机制才能避免跨海沟的连接(橙色点和绿色点连接)。 基于图的方法是，如果现在在图上面有一些标注数据，比如上图左上方，已经知道了蓝色圈的数据属于class 1，那么跟他们有相连的数据点属于class 1的概率也会上升。每一笔数据会去影响它的邻居。 光会影响邻居还不够，因为有连接说明本来就很像，那很像的input ，output本来也就很像。这种方法真正的精髓是，class是会传递的，虽然一个点没有与标注数据直接相连，但是有连接路径，那么class 1就会随着边传递。 例如上图右上方，所有数据点构建成一个图（理想的例子），然后有一个蓝色点属于class 1，一个红色点属于class 2。经过基于图的方法，蓝色点会传递，红色点也会传递，如上图右下方所示。 要让基于图的这种半监督学习方法有用的话，一个重要的原则是你的数据要多，如果数据不够多，例如下图所示，中间有断开，那信息就传递不过去。 考试一般的考题，定量的计算图定量的使用方式是在这个图的结构上面定一个东西，叫做label的平滑度，来表明这个label有多符合平滑度假设。 怎么定平滑度？ 看上图两个例子，这两个例子都有4个数据点，数据点之间连接的数字代表了边的权重。现在给两个例子的数据不同的label，左边例子的label是1,1,1,0，右边例子的label是0,1,1,0，那谁更平滑呢？ 直观感觉就是左边例子更平滑，但我们需要定量描述。常见的方法是，考虑两两相连的点（不管有label还是没有label），在所有的配对上，计算label差值的平方，然后乘上权重 ，最后求和。 所以左边这个例子的S就是0.5，右边例子的S是3，S越小越平滑。 用矩阵来表达 S可以稍微整理下，写成向量形式如上图。 把y串成一个向量，y包括标注数据和未标注数据，所以有 R+U 维。 L是(R+U)×(R+U)的矩阵，叫做图拉普拉斯，L的定义是 D−W ，W是两两数据点之间的权重，D是W每行值之和（放在对角线）。 再加一个正则化项现在可以用 y转置Ly 来评估现在得到的label有多平滑，式子里面的y是label的值，取决于神经网络的参数。那么如果要把平滑度考虑到神经网络里时，就是在原来的损失函数里加上λS（λ是某一个想要调的参数）。λS像一个正则化项，在调整参数时，不只是让标注数据的output跟真正的label越近越好，同时还要让output的label在标注数据和未标注数据上符合平滑度假设。平滑度假设由S衡量。 不一定要在output上计算平滑度，在深度神经网络里，可以把平滑度计算放在网络的任何地方。你可以假设你的output是平滑度，也可以把某个隐藏层乘上一些别的transform，它也要平滑，也可以要求每个隐藏层的output都是平滑的。 转换的想法 Better Representation我们观察到的世界其实是比较复杂的，在背后有一些比较简单的向量，比较简单的东西在操控这个复杂的世界。那只要看透假象，直指核心，就可以让学习变得比较容易。 例如上图右方剪胡子，胡子的变化是很复杂的，但是胡子受头操控，头的变化是有限的。所以胡子是观测，而头就是Better Representation。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"半监督学习","slug":"半监督学习","permalink":"http://example.com/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}]},{"title":"卷积神经网络CNN（Convolutional Neural Network）","slug":"卷积神经网络CNN（Convolutional Neural Network）","date":"2021-08-12T14:36:01.000Z","updated":"2021-10-29T14:59:59.305Z","comments":true,"path":"2021/08/12/卷积神经网络CNN（Convolutional Neural Network）/","link":"","permalink":"http://example.com/2021/08/12/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%EF%BC%88Convolutional%20Neural%20Network%EF%BC%89/","excerpt":"","text":"@TOC 总结CNN的要点：Q1：什么是CNN？为什么要用CNN？为什么图像处理一般都采用CNN？Q2：实现CNN的步骤？ input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten——&gt;fully connected network——&gt;output Q3：如何用 keras 搭建一个CNN?Q4：CNN的应用?什么时候适用CNN效果最好？满足三个图像三个特性的时候。但要考虑第三点取子样是否合理。 CNN的概述什么是CNN？CNN也叫convnet，中文名称为卷积神经网络，是计算机视觉领域常用的一种深度学习模型。 为什么要用CNN？其可以简化DNN模型，可以减少不必要的神经元节点。特别是用在图像处理上。 为什么图像处理一般都采用CNN？**CNN的参数比全连接神经网络少得多**，为什么CNN只用较少的参数就可以用于处理图像呢？ 这是因为图像具有以下三点特征：1、一些模式比整张图片小得多，例如“鸟喙”就比整张图片小得多；2、同样的模式可能出现在图像的不同区域，例如“鸟喙”可能出现在图片的左上方也可能出现在图像的中间；3、对图像的降采样不会改变图像中的物体。CNN的卷积层的设计对应着前两点，池化层的设计对应着第三点。 如下图所示： 实现CNN的步骤input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten（压平）——&gt;fully connected network——&gt;output 卷积层（减少训练参数） 对应Property1：每一个Filter（待训练的参数，即卷积核）代表一个局部特征探测器（他是一个可以特点图形的表示器），假设现在两个特征探测器（Filter1 和 Filter2） 卷积核1的结果 值最大的那个点所在的图片部分，就是我们要找的内容 卷积核2的结果。与卷积核1的结构共同组成了 feature map 对应Property2：用 Filter1 就能探测出在不同位置的同一个flatten，而不需要用不同的Filter 如果图片是彩色的，也就是说它是三通道的，还没卷积之前，可以说有3个通道（RGB），意味着每一个像素由3个数值表示。如下图所示：卷积核是立方体3×3×3，图片为9×9×3。图片中同样选择卷积核大小，与卷积核累和，但要注意我们并不是把RGB三层，分开算，应该算合为一体的。 与全连接方式的对比全连接层，图像处理的神经网络图如下所示，每个输入与各神经元都有链接（有固定的权值）下面是CNN神经网络图，其主要的目的是减少参数（减少权值数量）。并且可以存在一定的共享权值，下面颜色相同的权值边值应该相同，这样调参可以更快。 池化层（Maxpooling）目的是减少每一个特征的维度，也就是减少后面flatten的输入特征数量。Maxpooling这边我们取每个框内的最大点。在整理一下，变成一个新的feature map 合计上两步得到：做一次卷积+池化后，把原来的 6 × 6 图像变成了 2 × 2 图像，2 × 2图像的深度（每个像素点用多少个值表示）取决于有多少个过滤器，如果有 50 个过滤器，2 × 2 图像就有 50 维，上图是只用两个过滤器，那就是 2 维。所以上图右边，就是一个新的比较小的图像，每个过滤器代表了一个channel(通道)。 重复上两步操作可多次重复上述两个步骤，将输出的结果变得最小化。 Q: 假设我们第一次卷积的时候，我们有25个卷积核，那输出的结果 feature map中应该有25个矩阵。那请问，第二次卷积的时候，输出的feature map 应该是 25×25=625 个矩阵么？答：不对，做完第一次卷积得到25个矩阵，做完第二次后还是25个矩阵。例如输入是三个通道 (RGB) 的 6 × 6 矩阵数据（即一个立方体，6 × 6 × 3），有两个过滤器（也是立方体，三个通道，3 × 3 × 3），则输出为4 × 4 × 2。（4 = 6-2 ； 2是过滤器个数 过滤器决定通道数） Flatten（压平）flatten(压平)的意思是，把特征图拉直，然后丢到一个全连接神经网络里。 CNN in Keras 卷积前，一个pixel用多少个数值表示，取决于通道数 卷积后，一个pixel用多少个数值表示，取决于Filter个数，而通道数决定Filter的高 上一个卷积层有多少个Filter，下一层卷积input就有多少个通道 123456789model = Sequential()model.add(Conv2D(25,3,3),input_shape=(1,28,28))model.add(MaxPooling2D((2,2)))model.add(Conv2D(50,3,3))model.add(MaxPooling2D((2,2)))model.add(Dense(output_dim=100))model.add(Activation(&#x27;relu&#x27;))model.add(Dense(output_dim=10))model.add(Activation(&#x27;softmax&#x27;)) Q：为什么上图第二次 每个卷积核的 参数是 225？答：因为是 3×3×25 那为什么是25而不是50呢？ CNN在学什么？CNN卷积和池化部分在做什么？ 分析第一个层的卷积核是比较容易的，里面每个卷积核就是一个3 3 的矩阵，对应3 3 范围内的9个像素点，只要看到矩阵的值，就知道在检测什么（有明显的特征）。 第二层的卷积核没法知道在做什么，虽然也是 3 × 3 的矩阵，总共 50 个。但是这些卷积核的输入不是像素点，而是在上一层做完卷积和池化后的输出。就算知道第二层卷积核的矩阵值，也不知道在检测什么。另外第二层卷积核考虑的不是原图 3 × 3 的像素点，而是比原图 3 × 3 像素点更大的范围，因为在第一层的池化后，压缩了原图 3 × 3 的区域，第二层卷积核是在压缩后的图像里再选取 3 × 3 像素点，相当于扩大了原图检测的范围。 Q：那怎么分析第二层卷积核在做什么？ 第二层的50个卷积核，每个卷积核的输出是一个 11 × 11 的矩阵。把第k个卷积核输出拿出来如上图左下，矩阵元素表示为 $a_{ij}^{k}$ (第k个卷积核，第i个行，第j个列)。接下来 定义一个“Degree of the activation of the k-th filter”（第k个卷积核的激活程度），值代表第k个卷积核的被激活程度（input和第k个卷积核侦测的东西有多匹配）。 第k个卷积核被激活程度表示为：$a^{k}=\\sum{i=1}^{11}\\sum{j=1}^{11}a_{ij}^{k}$ ，11 × 11 矩阵所有元素值之和。 Q：找一张图像，可以让第k个卷积核被激活程度最大，如果做到这件事情？称 input 的图像为 x，目标是找一个让 $a^{k}$ 最大的 x，如何找到这个 x？ 使用梯度上升，因为我们的目标是最大化 $a^{k}$ 。现在是把 x 当做我们要找的参数，对 x 用梯度上升。原来CNN的 input 是固定的，model 的参数使用梯度下降求解。现在反过来，model 的参数是固定的，使用个梯度上升更新 x，让被激活程度最大。 上图左下，是随便取12个卷积核后对 x 做梯度上升后的结果，每个卷积核都找到一张图像，这张图像让这个卷积核的被激活程度最高。如果有50个卷积核，理论上可以找50张图像。 Q：这12张图像有一个共同的特征：是某种纹路在图上不断反复。为什么会这样？看第三张图像，都是小小的斜条纹，这意味着第三个卷积核是在检测是否有斜的条纹。因为卷积核考虑的范围是很小的，所以原图像上任何地方出现一个小小的斜纹的话，这个卷积核（过滤器）就会被激活，输出值就会很大。如果原图像所有范围都是这种小小的条纹，那这个卷积核的被激活程度就最大。 你会发现每个过滤器都是在检测某一种图案（某一种线条），例如上图左下第3个过滤器是检测斜条纹，第4个是检测短、直的线条，第6个是检测斜成一定程度的线条等等。 每个卷积核（过滤器）都在检测不同角度的线条。 全连接的隐藏层都在干什么？做完卷积和池化后，会做flatten(压平)，把压平后的结果丢到神经网络里去。 Q：在这个神经网络的隐藏层里，每个神经元都在干什么？答：如法炮制之前的做法，定义第 j 个神经元的输出是 $a{j}$ ，然后找一张图像 x，使 $a{j}$ 最大。找到的图像如上图左下所示，9张图像，是对应神经元的输出最大。你会发现跟刚才卷积核（过滤器）观察的图案很不一样，卷积核观察的是类似纹路的东西，因为卷积核只考虑了原图像的一部分区域。输出通过压平后，现在每个神经元是去看整张图像，能使神经元激活程度最高的图像不再是纹路这种小图案，而是一个完整的图形，虽然看起来完全不像是数字，但神经元被激活后也的确在侦测一个完整的数字。 考虑最后的输出？ 如果最后的输出是10维的，每一维对应一个数字。把某一维拿出来，找一张图像使那个维度的输出最大。例如现在要找一张图像，使输出层上对应数字1的神经元的输出最大，理论上这张图像看起来就是数字1但是实际的图像如上图左边所示，每张图像分别代表0,1,2,3,4,5,6,7,8 Q：那为什么是这种是乱七八糟的雪花状呢，而不是我们能看清的数字呢？答：因为神经网络的视角，他就是和人不一样的。他就认为这些雪花图像是不一样的，对于0-8数字。与我们人的思维不同。Q：能不能让这些图像看起来更像数字？我们知道，一张图像是不是一个数字，有一些基本的假设。比如上图左边，人类看起来显示不是数字。那么我们对x做一些正则项约束，告诉机器，虽然有些 x（图像） 可以让 y 很大，但是这些 x 的确不是数字。Q：那加些什么约束呢？比如最简单的想法，图像上的白点是有墨水（笔画）的地方，对一个数字来说，有白点的部分是有限的，数字的笔画只占图的一小部分，所以我们要对 x 做一些限制。假设 $x{ij}$ 是图像像素点的值，每张图像有 28 × 28 个像素点。把所有像素点的值取绝对值并求和（相当于L1正则），我们希望找一个 x ，让 $y{i}$ 越大的同时，也让像素点绝对值之和越小。那我们找出来的图像大部分的地方就不是白色的。最后得到的结果如上图右边所示，和左边的图看起来，已经可以隐约看出来是个数字了。 CNN的应用Deep Dream你给机器一张图像，机器会在这张图像里面，加上它学习到的东西。 比如把上图丢到CNN里面去，然后把某个卷积核或者某个全连接隐藏层拿出来（一个向量），假设是 $\\begin{bmatrix}3.9\\-1.5\\2.3\\:\\\\end{bmatrix}$ 然后把3.9、2.3调大（本来是正的值调大），-1.5调小（负的值调小），正的更正，负的更负。找一个图像使卷积核或者隐藏层（拿出来的）的输出是调整后的向量。这么做的意思是让CNN夸大化它看到的东西。找到的图像会变成上图所示，出现很多奇怪的东西。右边看起来是一头熊，原来是一颗石头。对机器来说，本来就觉得石头像一头熊，强化它的认知后，就学习出来更像一头熊的图案。这个就是Deep Dream。 Deep Styleinput 一张图像，然后让机器去修改这张图像，让它有另一张图的风格，比如让上图看起来是呐喊。 Q：卷积核和过滤器的区别 卷积核就是由长和宽来指定的，是一个二维的概念。 过滤器是是由长、宽和深度指定的，是一个三维的概念。 过滤器可以看做是卷积核的集合。 过滤器比卷积核高一个维度——深度。 —————————————————————————————————— Q：怎么做到图像风格转变呢？把原来的图像丢给CNN，得到CNN过滤器的输出，代表一张图像里有什么样的内容。 然后把呐喊这张图也丢到CNN里，也得到过滤器的输出，但这时候考虑的不是过滤器输出的绝对值，而是考虑过滤器和过滤器输出之间的关系，这个关系代表了一张图像的风格。接下来用同一个CNN找一张图像，这张图像的内容像原图像的内容（过滤器的输出类似），同时这张图像的风格像呐喊的风格（过滤器输出之间的关系类似）。找一张图片同时最大化内容和风格（使用梯度上升更新参数），得到的结果就像两张图片结合一样。 CNN应用在围棋上要让机器下围棋，不一定要用CNN，一般的神经网络也可以做这件事情。只要学习一个网络，也就是找一个函数，输入是棋盘，输出是棋盘上的位置，根据棋盘的盘势，判断下一步落子的位置。输入是19 ×19 向量，向量每一维是棋盘上的一个位置（是黑子则值为1，是白子则值为-1，反之则为0），丢到一个全连接的神经网络，输出也是19 ×19 的向量（每一维对应棋盘一个位置），那这样机器就可以学会下围棋了。 为什么CNN可以用在下围棋上？但实际采用CNN会得到更好的效果！为什么呢？之前举的例子都是把CNN用在图像上面，input 是一个矩阵。用到下棋上，只要把 19 ×19 的向量表示为 19 ×19 的矩阵。对CNN来说，就是把棋盘和棋子当成一个图像，然后输出下一步落子的位置。 收集很多棋谱，告诉CNN，看到落子在5之五，输出天元的位置为1，其他位置为0看到5之五和天元都有棋子，输出就是5之五的位置为1，其他位置为0这个是监督的部分，AlphaGo还有强化学习的部分 总结一下什么时候用CNN?为什么围棋适用？图像要有该有的特性，开头讲过的根据三个特性设计出了CNN的网络结构，在处理图像的时候特别有效。 Q：为什么围棋很适用CNN？答：因为围棋有一些特性和图像处理是很相似的。 围棋是有图像的第一个和第二个特性 在一张图像上面，有一些图案是比整张图像小的，比如鸟嘴。在围棋也有同样的现象，比如看到一些棋子摆放的图案，就要做一些相应的事情（比如上图黑子叫吃的时候，白子要落在下方保证不被吃）。不需要看整个棋盘，只需要看一个小小的范围，就可以侦测白子是不是属于被叫吃的状态。AlphaGo里第一层的过滤器就是用的 5 × 5 过滤器，显然设计这个过滤器的人觉得围棋上最基本的图案在 5 × 5 范围内就可以被侦测出来。 图像还有个特性是相同的图案会出现在不同的区域，在围棋上也有同样的特征。例如叫吃的图案，可以出现在棋盘左上角，也可以出现在棋盘右下角，图案代表了同样的意义（叫吃），所以可以用同一个检测器来处理这些在不同位置的图案。 Q：困惑的是图像的第三个特性，对原图像做子采样不会影响人看到的这张图像的样子，基于第三个特性有了池化层，但Alpha并没有采用池化层（就是做子采样）？因为不能做子采样。比如丢弃棋盘的奇数行和偶数列，想想也应该是不可以的。 也许AlphaGo里的CNN架构有特殊的地方。AlphaGo论文附录里描述了它的网络结构，input是一个19 ×19 ×48 的图像，19×19 是棋盘可以理解，但48是怎么来的？对AlphaGo来说，把每一个位置都用48个值来描述（卷积后有48个通道）。本来我们只要描述一个位置是不是白子、黑子就可以了，而AlphaGo加上了领域知识（看这个位置是不是出于叫吃的状态等等）。 AlphaGo有做zero padding(零填充)，在原来19 ×19 的图像外围补上 0 值变成 23 × 23 的图像，第一层用的是 5 × 5 过滤器，总共 k 个过滤器（paper里用的是192个过滤器），步长stride=1，有用到 ReLu 作为激活函数，有2到12层的过滤器层，最后变成 21 × 21 的图像，接下来再使用 3 × 3 的过滤器，步长 stride=1。最后发现AlphaGo没有使用池化，针对围棋特性设计CNN结构的时候，是不需要池化这个结构的。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"CNN","slug":"CNN","permalink":"http://example.com/tags/CNN/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]},{"title":"为什么要Deep？深而不是宽","slug":"为什么要Deep？深而不是宽","date":"2021-08-10T14:36:01.000Z","updated":"2021-10-29T14:59:48.494Z","comments":true,"path":"2021/08/10/为什么要Deep？深而不是宽/","link":"","permalink":"http://example.com/2021/08/10/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81Deep%EF%BC%9F%E6%B7%B1%E8%80%8C%E4%B8%8D%E6%98%AF%E5%AE%BD/","excerpt":"","text":"@TOC Q：为什么要用要用深度？而不是广度？答：1.因为深度可以用少量的数据，就完成对数据的分类。2.深度，每个层次都是基于上个层次得到的（其实就是学习的过程），我们可以将神经元的数量减少。如果层次很少的话，会导致神经元可能非常多。可以类比逻辑电路。 模组化在比较浅层网络与深层网络时，要让“矮胖”的网络和“高瘦”的网络的参数数目相等，这样比较才公平。但即便是在深层网络参数较少的情况下，深层网络也会比浅层网络表现好。这是因为 深层”其实相当于“模组化”，第一个隐层是最基本的分类器，第二个隐层是用第一个隐层建造的分类器，以此类推。 举个栗子，为什么说深度好！左边第一幅图可以看到，我们需要分四个类，包括长发女，长发男，短发女，短发男。一共四类，其中长发男的数据样本很少，那区分这个类的能力就非常的弱。这个时候，我们就可以先分为两个神经元，一个区分男女，一个区分长发短发，这样中间加一层，可以使得数据样本少的类 鉴定的效果更好。对于分类一个图像来说，深度使得模块化。 类比逻辑电路浅层网络确实可以表示任意函数，但是使用深层结构更有效率。好比逻辑门电路，用两层逻辑门就可以实现任何布尔函数，但是用多层结构更简单、需要的逻辑门更少。 神经网络也是如此，单隐层网络可以表示任何连续函数，但是多层结构表示起来更简单、需要的神经元更少，所以比较不容易overfitting，或只需较少的data。而且，深层结构可以比较有效率地使用data。 类比图形1层hidden layer与3层hidden layer（相同数目的参数），3层的效果更好。但理论上，3层可达到的效果，1层也能达到：要在1层learn的时候，target从真实label改为3层的output，这样1层的结果会接近3层的结果。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]},{"title":"深度学习 Deep Learning 模型优化","slug":"深度学习 Deep Learning 模型优化","date":"2021-08-09T14:36:01.000Z","updated":"2021-10-29T14:59:43.143Z","comments":true,"path":"2021/08/09/深度学习 Deep Learning 模型优化/","link":"","permalink":"http://example.com/2021/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/","excerpt":"","text":"@TOC 深度学习 怎么评价效果与改进？ 先检查 训练阶段 是否有比较好的结果training优化方法： 换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax） 优化器——优化梯度下降和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam） training没问题了，再检查testing是否有比较好的结果 testing（过拟合）优化： 参数在过拟合之前就停止更新 正则化Regularization dropout 如何优化模型谈什么才是overfitting？首先我们在明确一下，深度学习的流程，其与机器学习基本一致。如下图所示：判断 过拟合 需要看两个数据集上的结果（training set → good， testing set → bad）。在试图解决overfitting之后仍要再看一下training set上的结果！ 误区：不能看见所有不好的 performance 都归因到 overfitting。如只看下右图，不能断言56-layer有 overfitting，要看模型在training set上的表现。根据下左图，可以发现原因是训练的时候没有训练好，即这个层次设计可能本身就是有问题的，不然为啥20层的挺好，56层没道理差啊（这不能叫 underfitting，underfitting：参数不够多，模型能力不足）。 对症下药：训练error，测试error分别用什么方法在读到深度学习的方法时，要思考该方法是解决什么问题。是解决training set上的performance不好，还是解决testing set上的performance不好。比如，Dropout是为了解决testing set上结果不好的问题，如果是training set上结果不好而用Dropout，不会有好的结果。下图是 分别解决各问题，可以采用的方法： 模型Train阶段Error 具体解决如下图是，MNIST手写数字识别，激活函数用sigmoid，training data上的accuracy与层数的关系曲线：层数&gt;7时，performance下降，原因不是 overfitting! 因为train的时候就没train好。那模型压根没有训练好，可以采用的方法上面也给出了包括：换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax）。激活函数可能会带来什么样的问题？以sigmoid为例说：会出现梯度消失。 方法一：换激活函数的问题 —— 梯度消失什么是梯度消失 有梯度时，参数才会往梯度最小的地方改变；没有梯度了，参数就停止更新了。前面层的学习速率明显低于后面层（后向传播），这就是梯度消失。 为什么会有梯度消失？ 角度一： 用sigmoid会出现梯度消失的问题（参数的变化经过sigmoid会逐层衰减，对最后的loss影响很小）如上图所示，我刚开始增加的△w，由于 sigmoid函数 ，自变量越大，改变量越小的缘故。数的变化经过sigmoid会逐层衰减，对最后的loss影响很小。也就是对C的偏导会越来越小，导致梯度接近于0，而消失。 角度二：假设现在存在一个网络结构：其整个数学模型可以表示为：若要对于 w1求梯度，根据链式求导法则，得到的解为：这明显数学模型的值，随着隐层的增加，越来越小。不过这个前提是 原先的w（权重）并不是很大，原本相乘就是小于1的。如果w太大的话，第一项相乘就大于1，这就会导致最后的梯度爆炸。 如何解决梯度消失问题 —— 换ReLU激活函数ReLU 与 MaxOut梯度消失是因为 sigmoid 引起的，要解决当然要换一个激活函数。采用的方法是换 ReLU激活函数（原型 input0,输出为原值；可变型）ReLU输出0或x，输出0的ReLU神经元相当于不存在，网络变得瘦长，但是整个网络仍然是非线性的，只有当input改变十分微小的时候才是线性的，因为input不同，输出为0的ReLU神经元也不同。 Q : 为什么ReLU是非线性？明明两端都是线性直线啊？因为ReLU在0点没有导数定义，线性讲究的是在整个定义域内。而在0点处，不可微，所以整体是非线性的。 ReLU是Maxout的特例，Maxout可以学出激活函数。 MaxOut 的训练是怎样的？好在哪？下面是一个神经网络的栗子，我们将激活函数换成 MaxOut激活函数。上面的图 可以删除不需要的边和点，变为如下的神经网络： Q ：如果和上图所示，那我去掉的那些边不是啥用没有？也就是这个权值压根和神经网络没关系呢，不是吗？答 ：当然有关系，因为我们的任务是调参，每个权值和偏值得变化，都会导致 MaxOut激活函数 选择的不同。比如说改变一下 w，他可能会选择 z2呢。 方法二：优化器 —— 优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）寻找最佳参数的方法，调节学习率的方法有（SGD、Adagrad、RMSProp、Momentum、Adam）SGD、Adagrad 可以看之前关于 梯度算法进阶的部分 Post not found: 梯度下降算法 进阶这边主要讲解一下 RMSProp 和 Momentum 关于 RMSProp为什么要使用RMSProp 在 Adagrad 中，学习率是跟损失函数对 w 的二次微分有关。那么对于图中蓝绿相交的一点来说，因为 w1 所在的曲率相对于 w2 要小，所以 w1 的学习率会比 w2 大。现在单考虑 w1（只看横向），那么二次微分是固定的（碗状），也就是说 w1是根据固定的规则去自动调整 η 的。但是现实中同一方向的二次微分是不固定的，因此对于同一方向去 w1，需要不同的规则去调 η。 对于一个参数来说，*Adagrad* 是用固定的规则去调 *η*，*RMSProp* 是用变化的规则去调 *η*![在这里插入图片描述](https://img-blog.csdnimg.cn/cc6becd55c104daaa6f8eddadc55eb9d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) ##### 如何实现RMSProp 在原来分母这一项中，在过去梯度平方和前面加上权值 *a*，现有的梯度平方加上 *1-a*。 其在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小），并且能够使得**陡峭的方向变得平缓**，从而加快训练速度） ![在这里插入图片描述](https://img-blog.csdnimg.cn/1377f4da7b564c9a89ede8f17577f241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### 关于 Momentum ##### Momentum（动量）是用来解决什么问题的？ **这个是用来解决局部最优解的问题的** 说白了就是要延续他的惯性 如何实现Momentum考虑他此时的方向，并保留他的惯性。来调整下一步，最大可能的避免局部最优解。 关于 Adam他其实是一种 Momentum + RMSProp 结合的方法。其具体算法可以看如下图所示： 模型Train阶段OK Test阶段Error，即过拟合方法一 ：参数在过拟合之前就停止更新（Early Stopping）这里的testing set指的是有label的testing set（即validation set ）。 如果learning rate设得对的话，training set的loss会逐渐降低，而testing set与training set可能分布不同，所以testing set的loss可能先降后升，这时就不要一直train下去，而是要在testing loss最小的地方停止train。这里的testing set 实际指的是**validation set**。 ### 方法二 ：正则化Regularization > **Q ： 首先理解什么是范数，L1（范数为1）和L2（范数为2）是什么？** > 范数：向量在不同空间中“长度”的计算公式 > L1：绝对值之和 > L2：平方和 #### L2正则化（权值衰减） ![在这里插入图片描述](https://img-blog.csdnimg.cn/8a8facf4f6bf42ebb56f4f657102b5ed.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) > **Q ： 为什么通常 不考虑 bias？** > L2正则化让function更平滑，而bias与函数平滑程度没有关系。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/35cbdf14ab7049bd9967fcabc1223ae2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 参数更新： 因为η、λ、n都是正的，**所以 *1−ηλ*小于1，它的效果是减小w，这也就是权重衰减（weight decay）的由来**。**当然考虑到后面的导数项，w最终的值可能增大也可能减小**。 正则化在NN中虽有用但不明显。 NN参数初始值一般接近0，update参数即是要参数原理0。L2正则化（让参数接近0）的作用可能与early stopping类似。 > **Q : 为什么参数w衰减能防止过拟合?** > 答 ：模型过于复杂会导致过拟合。那么越小的w（可以想象成0理解），表示网络复杂度低，越简单的网络结构，就越不会过拟合。比如模型 *y=w1×w1 + w2×w2* 的平方 中把 *w2=0* 代入，模型就会简化，就不会引起过拟合。![在这里插入图片描述](https://img-blog.csdnimg.cn/c8fc90454614466ebee4a2d5a549a25e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) > **Q : 对正则化解决过拟合问题的一些本质理解？** > 正则化防止过拟合的本质：减少“没用参数”的权值（防止过拟合），同时也减少“有用参数”的权值（会增加bias误差） > **Q : 什么是有用参数，什么是没用参数？如上图中，怎么就把 *x2* 删去，不把 *x1* 删去呢？** > 我们姑且假设 *w1* 是有用参数， *w2* 是无用参数，由公式知参数更新值跟权值、梯度值两个因素有关，实际上，无论是 *x1* 还是 *x2* ，权值都会衰减，每update一次参数，权值 *w* 就会衰减一次，但如果是下图的情况，*损失函数Loss* 的减少跟 *w2* 没关系的，所以对其偏导为0，那么 *w2* 的参数更新只跟权值有关了，随着更新次数叠加，权值就会逐渐衰减接近0；对于***有用参数 w1*** ，虽然它权值衰减，但是它其作用的是后面的偏导值，所以它还是不会变成0的。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/50e060cb7bc24fbe896ef111e287092b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### L1正则化 L1是在Loss函数加上绝对值之和，求偏导后比原始的更新规则多出了η ×λ ×sgn(w)这一项。**当w为正时，更新后的w变小。当w为负时，更新后的w变大（一加一减）——因此它的效果就是让w往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合** ![在这里插入图片描述](https://img-blog.csdnimg.cn/113c9ac61f5946c783a434a07f8d52e9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### L1和L2相比 L1 update的速度是*|ηλ||ηλ|* （划横线那项每次改变量是一定的）。而 L2 update 的速度与w的t有关（如果wt 很大，那么改变量也很大）。 用L1做training，结果比较sparse(稀疏的)，参数中有很多接近0的值，也有很多很大的值。 L2 learn的结果：参数值平均来讲比较小。 ### Dropout **Dropout也是为了简化神经网络结构的目的**，但L1、L2正则化是通过修改代价函数来实现的，而Dropout则是通过修改神经网络本身来实现的。 #### dropout是如何实现的 在training的时候，每次update参数之前，对每一个Neuron（包括input_layer）做sampling，决定这个Neuron按一定几率p丢掉，跟它相连的weight也被丢掉，结果得到一个细长的Network。（每一次update一个mini-batch之前，拿来traing的Network structure是不一样的）。 换句话说input layer中每个element也算是一个neuron. 每次更新参数之前都要resample. **用dropout，在training上的结果会变差，但在testing上的结果会变好。** ![在这里插入图片描述](https://img-blog.csdnimg.cn/196bfc65730b4cb6b5877bcbc0a40729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 在**testing的时候不做dropout，所有neuron都要用**。 如果training时的删除神经元的概率为p%，则在testing时，所有的weight都要乘以（1-p）% ![在这里插入图片描述](https://img-blog.csdnimg.cn/2c2491b39cef4452b88c9c465a8a1cbe.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) #### Dropout的原理 ![在这里插入图片描述](https://img-blog.csdnimg.cn/27c81c02d95847c2a5776da769696c54.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) > **Q : 为什么当在做 *testing* 的时候，weights需要都乘以 *(1-p)%* (p是Dropout的概率)？** > > 答：如下图所示，左侧是在 *Traing* 阶段，*w2* 与 *w4* 由于丢失几率和丢掉(几率是这里是0.5)，假设神经元此时都是1，这时输出的应该是 *w1+w3*；右侧是在 *Testing* 阶段，在这个阶段要保证所有的神经元都不做 *Dropout* 。所以变成了w1+w2+w3+w4，约等于变成了左侧的两倍；所有取所有weight都要乘以（1-0.5）。 实际上，dropout是利用ensemble思想，把一个复杂神经网络的训练转化为，训练很多个简单的神经网络，然后再把多个简单神经网络训练出来的参数做平均。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/96b24fb760ee4d65b18862bc7bcf4ee0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) 一个复杂model, bias准，但variance大，把多个复杂model ensemble起来，variance变小。 每个dropout后的结构由一个batch来train，但是权重是共享的，每个权重是由多个batch 来train的。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/32d269be253c4f1790664d3b5c88caca.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center) **在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的。** **Dropout用在ReLU、Maxout上效果较好。** Q : 为什么 Dropout 在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的？ 而不是相同答：因为神经元之间的层次，使用的激活函数不一定都是线性的，只有线性的情况下才会是相同的。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]},{"title":"深度学习 Deep Learning 基础","slug":"深度学习 Deep Learning 基础","date":"2021-08-07T09:03:01.000Z","updated":"2021-10-29T14:59:33.904Z","comments":true,"path":"2021/08/07/深度学习 Deep Learning 基础/","link":"","permalink":"http://example.com/2021/08/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E5%9F%BA%E7%A1%80/","excerpt":"","text":"@TOC 深度学习需要明白的几个问题？思路： 什么是深度学习？为什么需要深度学习？深度学习和机器学习的关系？ 深度学习的步骤 确定神经网络模型的损失函数，如何优化模型，即调参问题 如何使用Back Propagation（反向传播） 方法 update DNN（深度神经网络）参数 深度学习的概念什么是深度学习？深度学习（Deep Learning，DL）是指多层的人工神经网络和训练它的方法。一层神经网络会把大量矩阵数字作为输入，通过非线性激活方法取权重，再产生另一个数据集合作为输出。这就像生物神经大脑的工作机理一样，通过合适的矩阵数量，多层组织链接一起，形成神经网络“大脑”进行精准复杂的处理，就像人们识别物体标注图片一样。 深度学习的model是一个深度神经网络结构（neural structure） 深度学习的“深度”是指神经网络的隐层（hidden layer）数量足够多 深度学习是自动提取特征（Feature extractor），不需要像逻辑回归那样特征转换（Feature engineering） 为什么需要深度学习？ 深度学习和机器学习的关系？ 传统机器学习的模型结构较简单，很依赖算法工程师做特征工程甚至子模型来提升模型效果。就像我们之前上节那个栗子一样，做多分类的问题，四个角对角是一个类的情况，没办法进行分类，所以只能使用特征工程来进行特征的变换。 深度学习由于其层次化的结构，理论上可以拟合任意函数，整个复杂结构即可以用来对特征进行自动组合（如图像），也可以用来构建复杂的模型（如nlp领域里的LSTM，能够考虑上下文）。 深度学习的步骤其实和机器学习一样分为三步。 Step 1：定义一个神经网络结构（neural structure）神经网络的创建包括3部分： 神经网络有多少隐层（layer） 每一层有多少神经元（neuron） 每个神经元之间如何连接 常见的出名神经网络 神经元怎么定义？每个神经元都有一个 bias 和一个 function ，每条输入的边都有一个 weight 一个神经网络的栗子下面是一个 3个隐层（layer）、六个神经元（neuron）（每个球都是一个神经元）、全连接前馈网络（Fully Connection Feedforward Network） “前馈”是指整个网络中无反馈，信号从输入层向输出层单向传播，可用一个有向无环图表示其实我们常用的网络，都是前馈神经网络，从输入到输出是一个有向图，中间不会有环或者反向传播。当然，我们在训练前馈神经网络的时候，会用到反向传播进行参数调整。但仍不影响整个网络的有向和前馈性质。 神经网络如何工作？其实 这就是矩阵运算（可以使用GPU加速计算）总体可以归纳为： 栗子：识别手写数字图像从图像中识别是数字几？ 制作神经网络模型 的FAQ（最容易被问得问题） Q1： 神经网络需要几个隐层（layers）？每个层需要多少个神经元呢？ 反复试验+ 直觉 （说白了就是要慢慢试= = 看经验呗） Q2：神经网络可以自动确定结构吗？ 理论上其实是可以的，不过这些方法我们还没学到。Evoluntionary Artifical Neural Networks Q3：我们可以设计层次之间的结构么？ 意思就是说例如Layer1 链接 Layer3 这样跳着的 等等。当然可以 CNN就是不按顺序来的，具体看下一节。 Step 2：确定神经网络模型的损失函数还是和逻辑回归一样，用交叉熵损失函数，调参使得交叉熵损失函数最小，如下图所示：当然上面只是一个点的，把每个样本结合起来看。 不过这个地方有几个疑问？ Q1：神经网络里面有很多层，所以有很多 w 和 b 调整。那是全体都一次性调整么？ 答： 现在不知道啊！ Q2：上面我是把所有的 交叉熵 都加在一起 然后对 整个大的损失函数进行调参是这样嘛？ 那我的训练样本应该是 各个数字都有是吗？ 答： 现在不知道啊！ Step 3：如何找到一个最好的函数（最佳参数），即调参用的还是 梯度下降法 随机选取一组参数 输入所有的训练样本 然后样本数据不变，参数不断变，用梯度下降法更新参数 Backpropagation（反向传播） 来优化调参速度神经网络可能有很多个隐层，因此可能有百万数量级的参数，为了在梯度下降时有效地快速计算梯度，使用反向传播。下图是 使用的损失函数为：交叉熵损失函数 ， 梯度下降法就是对每个参数求偏导，然后根据偏导大小进行左右移动，找到偏导为0的点，就是最佳参数值。 计算对参数偏导的表达式 交叉熵损失函数，为 正确值乘以 ln的带入x样本的线性模型 +（1-正确值）乘以ln（1-带入x样本线性模型） 只考虑刚输入阶段的神经元，可以得到用 sigmoid激活函数之前的量 z，而 z 是由线性模型（按权重分配向量 + 偏值 b 得到）。如下图所示，可以看到对参数 w 的偏导可以按照链式法则为 ∂C/∂w=∂z/∂w × ∂C/∂z 前项为前项传递，后项为后向传递 前项传递非常好看出来，就是对应的输入值，比如 ∂C/∂w1=∂z/∂w1 × ∂C/∂z 。其中∂z/∂w1 看图上所示，不就是对 w1 进行偏导么，那就是 x1。 后项过程比较复杂，根据链式法则，∂C/∂z=∂a/∂z × ∂C/∂a，其中∂a/∂z = σ&#39;(z) 如下图所示 归纳一下得到如下：这个时候我们从另一观点看待上面的式子：有另外一个神经元（下图中的三角形，表示乘法/放大器），input是∂C/∂z‘与∂C/∂z′&#39; ，权重分别是 w3,w4，求和经过神经元（乘以σ′(z)），得到 ∂C/∂z。（相当于反向传播，先线性加权再乘以一个σ′(z) 和正向非常类似） 后项传递 的两种情况如上图所示是我们最后得到的后项传递的式子，其中我们还有两个项不知道。那我们现在需要计算这两个部分，但分为两种情况 case 1：下一层是最终输出层第一种情况，z′,z′′ 所接的neuron是output layer的neuron。这个就比较简单，直接根据最后一层的输出反向写出即可。 case 2：下一层不是最终输出层第二种情况，z′,z′′ 所接的neuron不是output layer的neuron。就上面那个图，我们可以推得类似后项传递的式子就这样反复迭代(递归)，直到遇到case1的情况，就可以算出整个后项传递。然后结合之前的前项传递，就是我们要得到的对这个参数的偏微分值。 总结梯度下降时需要计算损失函数对每个参数偏微分∂C/∂w，w 代表相邻隐层之间的一条连线（即权值），每个 w 只有一个所指的神经元。 链式法则将计算 ∂C/∂w 拆成前向过程与后向过程。 前向过程计算的是∂z/∂w ，这里 z 是 w 所指neuron的input，计算结果是与 w 相连的值。后向过程计算的是∂C/∂z，这里 z 仍是 w 所指neuron的input，计算结果通过从后至前递归得到。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]},{"title":"逻辑回归 Logistic Regression","slug":"逻辑回归 Logistic Regression","date":"2021-08-05T15:08:06.000Z","updated":"2021-10-29T14:59:16.334Z","comments":true,"path":"2021/08/05/逻辑回归 Logistic Regression/","link":"","permalink":"http://example.com/2021/08/05/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%20Logistic%20Regression/","excerpt":"","text":"@TOC 逻辑回归需要明白的几个问题？ 1、逻辑回归(Logistics Regression) 与 线性回归(Linear Regression)的区别在哪2、生成模型(Generative Model) 与 判别模型(Discriminative Model）的区别在哪 生成模型就是要学习 x 和 y 的联合概率分布 P(x,y)，然后根据贝叶斯公式来求得条件概率 P(y|x)，预测条件概率最大的 y。 判别模型就是直接学习条件概率分布 P(y|x)。 3、逻辑回归(Logistics Regression) 与 深度学习（ VS Deep Learning）逻辑回归具有缺陷，需要做特征工程来转变特征，但是这个人为步骤非常麻烦，所以引入了深度学习。 逻辑回归与线性回归什么是逻辑回归？ 逻辑回归是解决分类问题的一种算法 它与 线性模型 形式上有点像（本质上是在线性模型外面“裹”一个sigmoid激活函数，来表示概率的函数） 它是一种判别模型，与前面说的生成模型不同 它是深度学习的基础 对比逻辑回归与线性回归区别一：模型不同本质上是在线性模型外面“裹”一个sigmoid激活函数，来表示概率的函数 总结的来看 区别二：损失函数Loss不同逻辑回归的为什么似然函数最大，参数就越有可能，越合理？最大似然估计：现在已经拿到了很多个样本（你的数据集中所有因变量），这些样本值已经实现，最大似然估计就是去找到那个（组）参数估计值，使得前面已经实现的样本值发生概率最大。因为你手头上的样本已经实现了，其发生概率最大才符合逻辑。这时是求样本所有观测的联合概率最大化，是个连乘积，只要取对数，就变成了线性加总。此时通过对参数求导数，并令一阶导数为零，就可以通过解方程（组），得到最大似然估计值。 总结一下： 问题：为什么逻辑回归不采用线性回归的差平方来做？例如，其实目前离目标点还很远，但梯度已经为0了，这显然不合理。 区别三：如何调参的方式是一致的 化简逻辑回归损失函数左侧部分 化简逻辑回归右侧部分 化简，调参如下总结 生成模型与判别模型什么是生成模型和判别模型？从本质上讲，生成模型和判别模型是解决分类问题的两类基本思路 。分类问题，就是给定一个数据 x，要判断它对应的所属标签 y 生成模型就是要学习 x 和 y 的联合概率分布 P(x,y)，然后根据贝叶斯公式来求得条件概率 P(y|x)，预测条件概率最大的 y。 判别模型就是直接学习条件概率分布 P(y|x)。 两种模型案例 举个栗子？ 栗子1：假设你从来没有见过大象和猫，连听都没有听过，这时，给你看了一张大象的照片和一张猫的照片。Q : 你看过之后，有人牵了一头真的大象过来，问你只是大象还是猫？ 用判别模型的思路回答：你回想刚才看过的照片，大象比猫很明显有个长鼻子，所以眼前这个有着长鼻子的动物就是大象。 用生成模型的思路回答：你回想刚才看过的照片，然后用笔把它们画在了纸上，拿着纸和我家的大象做比较，你发现，眼前的动物更像是大象。 第一个解决问题的思路就是判别模型，因为你只记住了大象和猫之间的不同之处。第二个解决问题的思路就是生成模型，因为你实际上学习了什么是大象，什么是猫。 栗子2：有四个形式为(x,y)的样本。(1,0), (1,0), (2,0), (2,1）。假设，我们想从这四个样本中，学习到如何通过x判断y的模型。 用生成模型，我们要学习 P(x,y)。如下所示：我们学习到了四个概率值，它们的总和是1，这就是联合分布律P(x,y)。（因为这是离散的，连续的话叫联合概率密度） 用判别模型，我们要学习 P(y|x)，如下所示：因为这是条件分布律，每一行概率值相加都为1。 Q : 当 x=1 时，请问 y 是 0 还是 1 呢？ 用生成模型，我们会比较P(x=1,y=0) = 1/2P(x=1,y=1) = 0我们发现 P(x=1,y=0)的概率要比 P(x=1,y=1)的概率大，所以，我们判断：x=1时，y=0。 用判别模型，我们会比较：P(y=0|x=1) = 1P(y=1|x=1) = 0同样，P(y=0|x=1) 要比 P(y=1|x=1)大，所以，我们判断：x=1时，y=0。 我们看到，虽然最后预测的结果一样，但是得出结果的逻辑却是完全不同的。 生成模型为啥叫生成模型？生成模型之所以叫生成模型，是因为：它背后的思想是，x是特征，y是标签，什么样的标签就会生成什么样的特征。好比说，标签是大象，那么可能生成的特征就有大耳朵，长鼻子等等。当我们来根据x来判断y时，我们实际上是在比较，什么样的y标签更可能生成特征x，我们预测的结果就是更可能生成x特征的y标签。 为什么一般来说，判别模型表现得会比生成模型好？我们举一个栗子，现在有Class1 和 Class2 两类数据。现在训练集数据如图所示：Q : 问请问如下的测试集，他是应该属于Class1 还是 Class2 呢？我们这边用判别模型来计算，算出如下图所示的数据：然后用贝叶斯公式算出 P(C1 | x) ，就是当x1和x2全为1 的情况下的概率是多少。算出的结果是 ＜ 0.5 的，但从我们人的角度看，其实应该是属于Class1的，因为Class2里面压根就没有x1，x2同时为1的存在。这是为什么呢？因为我们的样本太少了，用判别模型是可以帮助我们在有限的数据样本中假象数据。 那用生成模型怎么做呢？ 所以判别模型的优势在于 样本量少的时候表现比判别模型好，因为它能自己脑补出一个假想模型 噪声对它影响较小，因为它没有过分依赖数据，它是按照自己假想模型走的 常见的生成模型和判别模型有哪些呢？生成模型 HMM（隐马尔可夫模型） 朴素贝叶斯 判别模型 逻辑回归 SVM（支持向量机） CRF（条件随机场） 最近邻 一般的神经网络 逻辑回归与深度学习逻辑回归解决多分类问题逻辑回归是解决分类问题的，实际中的问题大多是多分类的问题，多分类问题会用到softmax。 逻辑回归其实就是线性回归在外面加了个sigmoid激活函数（二分类）或者softmax激活函数（多分类）。 sigmoid激活函数 和 softmax函数的区别：通常在二分类中使用sigmoid作为最后的激活层。在多分类单标签中使用softmax作为激活层，取概率最高即可。多标签问题中使用sigmoid作为激活层，相当于把每一个类别都当成了二分类来处理。多分类问题解决 逻辑回归的局限性 用深度学习去解决这个问题这个怎么变换过来的啊？是需要用特征工程的方法的，而特征工程是需要我们人为地去建立一个特征函数去把这些点转化，实际上是比较难的，或者说比较费工夫的这个时候我们需要引入 深度学习","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"逻辑回归","slug":"逻辑回归","permalink":"http://example.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"分类问题","slug":"分类问题","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"}]},{"title":"分类问题 Classification 案例一：神奇宝贝是水系还是普通系？","slug":"分类问题 Classification 案例一：神奇宝贝是水系还是普通系？","date":"2021-08-04T06:21:06.000Z","updated":"2021-10-29T14:59:22.982Z","comments":true,"path":"2021/08/04/分类问题 Classification 案例一：神奇宝贝是水系还是普通系？/","link":"","permalink":"http://example.com/2021/08/04/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%20Classification%20%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9A%E7%A5%9E%E5%A5%87%E5%AE%9D%E8%B4%9D%E6%98%AF%E6%B0%B4%E7%B3%BB%E8%BF%98%E6%98%AF%E6%99%AE%E9%80%9A%E7%B3%BB%EF%BC%9F/","excerpt":"","text":"@TOC 概念：（从概率生成模型到判别模型）概率生成模型：由数据学习联合概率密度分布 P(X,Y) ，然后求出条件概率分布P(Y|X) 作为预测的模型。例如：朴素贝叶斯、隐马尔可夫（em算法）判别模型：由数据直接学习决策函数 Y=f(X) 或者条件概率分布 P(Y|X) 作为预测的模型。例如：k近邻法、感知机、决策树、逻辑回归、线性回归、最大熵模型、支持向量机(SVM)、提升方法、条件随机场（CRF） 分类问题的思路 分类问题及其解决方法的讨论 1. 首先，什么是分类问题？ 2. 接着，分类问题该如何解决呢？ 建立概率生成模型的步骤（以朴素贝叶斯分类器为例）step1：求先验概率step2：确定数据属于哪一个分布，用最大似然估计出分布函数的参数step3：求出后验概率 生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出 分类问题及其解决方法的讨论什么是分类问题？说白了 就是输入一个事务的一些参数特征，通过数学模型，可以得到这个东西是什么。 这也包括二分问题（结果是由两面）与多分问题。 案例：举个栗子，输入一个神奇宝贝，输出：他是属于什么属性的？ 这是一个典型的多分问题，因为属性有好几种啊。举个栗子，输入一个神奇宝贝图片，输出：他是可达鸭么？ 这是一个典型的二分问题，因为结果只有两种 是还是不是。举个栗子，假设有两个类别（水系和普通系），每个类别有不同的精灵，现在我抓到一个精灵，那么它是属于水系和普通系的概率分别是多少。这也是个典型的二分问题。 如何解决分类问题？如何解决二分问题？问题分析对于二分类问题，定义一个function也就是数学model，当输出函数值大于0就划分为类别1，否则就为类别2. 而损失函数定义为在测试数据上误分类的次数。 那这个function我到底怎么定义呢？实际上，可以将其定义为一个概率模型。它可以是一个条件概率模型 P(C1 | X),当 P(C1 | X) &gt; 0.5 ,比如在神奇宝贝二分问题中，我们定义X是这张图片的参数，而C1表示是可达鸭，整个的意思就变为了在这些图片参数的条件下这张图片是可达鸭的概率是多少，概率大于一半，说明确实很有可能就是可达鸭。或者对于第二个栗子，同样的可以规定条件概率模型 P(C2 | X)，表示在捕捉了一个精灵后，他的参数条件下，是水系的概率是多少？（这边C2表示，捕捉的是水系） 这边我们以栗子2为例，假如我们捕捉了一只神奇宝贝(其实他就是可达鸭)，问他是水系的概率是多少？（理论上其实，他就是水系的，但机器需要通过概率论去推，需要包括以下的概率推导） 如上图所示： x就表示是可达鸭先验概率：这里是P(C1)——训练样本中的精灵是水系的概率;同理P(C2)——训练样本中的精灵是普通系的概率——————————————————————————————————————————————————————————————————P(x | C1)：这里是指在水系中是可达鸭的概率P(x | C2)：这里是指在普通系中是可达鸭的概率两者可以用最大似然估计法求出——————————————————————————————————————————————————————————————————后验概率：这里指抓到的神奇宝贝可达鸭是水系的概率。其用贝叶斯公式算出，公式如上图所示 求先验概率 P(C1)：训练样本中的精灵是水系的概率根据训练样本，分别算出水系和普通系的概率 选择概率分布函数，用最大似然估计出分布函数的参数（就是调参） 注： 当样本数据x取实数值时，采用正太分布(高斯分布) 当每种特征的数值都在0-1内时，采用伯努利分布 当每种特征取值在{1, 2 , 3 , …，K}，采用多项式分布（Multinomial Distribution） 首先，我们目标是求水系样本中的79个精灵中，抓到其中一种神奇宝贝的概率 P(x | C1) ，那么这个概率应该是跟精灵的属性有关的。这里我们选择两种属性（物防和法防）讨论，此时数据中（x,水系）中的x应该是一个神奇宝贝向量（[x1物防，x2法防] , 水系）。 2、然后，这里选择正太分布（二维）：也就是说在水系样本中的79个精灵中，抓到其中一种精灵的概率 P( x | C1) 呈正太分布。 接着，用最大似然估计法算出分布函数的参数似然函数L：x1,x2…x79同时出现的概率函数。最大似然估计：使似然函数最大时的参数估计。调整的参数最后求出后验概率 即P(C1 | x): 抓到的可达鸭是水系的概率利用的就是贝叶斯公式。整体每个部分的逻辑可以看下图所示：效果不好的解决方法实验结果分类后，准确率并不高。理论上考虑其他因素，即增加维度可以增大准确率。但效果还是不佳，这该怎么办。实验结果生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出回到如何用机器学习的三大步骤解决分类问题： 逻辑回归方法（判别模型）的引出 化简推到一下（纯数学）所以其实不用考虑，N1，N2，μ1，μ2，∑的值。 直接就是w和b两个参数，这也是为什么之前，我们将∑按权值分配后，图像由线性分类的原因。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"分类问题","slug":"分类问题","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"}]},{"title":"梯度下降算法 进阶","slug":"梯度下降算法 进阶","date":"2021-08-04T05:16:06.000Z","updated":"2021-10-29T14:59:09.676Z","comments":true,"path":"2021/08/04/梯度下降算法 进阶/","link":"","permalink":"http://example.com/2021/08/04/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%20%E8%BF%9B%E9%98%B6/","excerpt":"","text":"@TOC 回顾梯度算法是一种迭代的算法，每看一个参数都会更新。 学习率η（Learning Rate）自定义的学习率对参数选择的影响学习率需要选取合适的值，过小会导致模型调参的速度太慢，但过大会导致错失掉了最佳参数点 如何调整学习率η？ 在最开始的时候，随机点离目标点很远，我们一般会选取一个比较大的学习率；当做了几期后，我们离目标点很近了，所以我们会减小学习率 缩减为 如下图所示的公式 不同的参数应该设置不同的学习率 下面是常用的 调整学习率的方法： AdagradAdagrad是解决不同参数应该使用不同的更新速率的问题。Adagrad自适应地为各个参数分配不同学习率的算法。 其原理为：里面比较核心的部分在 每次σ的取值。每次σ规定为之前所有g平方对应的之和的均方根。例如下图所示：其中 g 是每次的偏导值结合之前说的 η 值的变化 可以得到如下的公式推导： 提问: 发现一个现象，本来应该是随着gradient的增大，我们的学习率是希望增大的，也就是图中的g上标t；但是与此同时随着gradient的增大，我们的分母是在逐渐增大，也就对整体学习率是减少的，这是为什么呢？这是因为随着我们更新次数的增大，我们是希望我们的学习率越来越慢。因为我们认为在学习率的最初阶段，我们是距离损失函数最优解很远的，随着更新的次数的增多，我们认为越来越接近最优解，于是学习速率也随之变慢。 为什么化简之后是如上这个式子呢，其在图像上的意义是 一阶导数比上二阶数的值。如下图所示： Stochastic Gradient Descent（SGD随机梯度下降法） ？？？其和 普通的梯度下降算法区别在。普通遍历在求和的时候需要浪费大量时间，进而去掉求和产生了随机梯度下降算法。和下图看到的一样： 只是要注意一下标准的梯度下降和随机梯度下降的区别： 标准下降时在权值更新前汇总所有样例得到的标准梯度，随机下降则是通过考察每次训练实例来更新（就是随机选择一些按顺序的后续样本点来，而不是全体数据）。 对于步长 η 的取值，标准梯度下降的 η 比随机梯度下降的大。因为标准梯度下降的是使用准确的梯度，理直气壮地走，随机梯度下降使用的是近似的梯度，就得小心翼翼地走，怕一不小心误入歧途南辕北辙了。 当损失函数有多个局部极小值时，随机梯度反而更可能避免进入局部极小值中。 小批量随机梯度下降（batch gradient descent）如果在每次迭代中，梯度下降是用整个训练数据集来计算梯度的话，则会带来大量的计算量。因此提出批量梯度下降来进行优化。每次优化不再是对整体数据集来计算损失，取而代之使用随机采样小批量的样本来计算梯度。 Feature Scaling （特征缩放）其意思就是说要将所有特征有相同的规模。例如下图所示，X2 的范围明显大宇 X1，所以要将 X2 进行缩放。 为什么要做Feature Scaling？ 为什么要做Feature Scaling？如左图，X1 和 X2 数值规模大小相差很大，那 W2 这参数的变动会极大的影响损失函数，而 W1 影响度就很小。所以我们需要对 X2 进行特征缩放，使其与 X1 保持一个规模。并且其实从图像可以看出，如果按左图来做的话，我们很难找到一组合适的参数集合，因为他梯度下降的方法不是直线的而是曲线；而右图是近乎直线。（最里面圈的损失函数最小） 如何实现Feature Scaling？ 如上图所示，假如有R个数据样本，每个样本有X1 - Xi 个特征。我们用上面的公式计算出其应该的scale（其实说实在的这不就是化成标准正太分布么） 梯度下降算法数学总结提出问题：如下图所示（我怎么样才能在红圈里找到最小损失的那个点呢） 首先要回顾泰勒公式二元泰勒： 用泰勒展开损失函数理解为点乘，反向180度的时候，损失函数才是最小的：最终可以表达成： 梯度下降算法缺点在哪其不仅仅包括可能有找到是局部最优解问题，有可能在中间的时候就有偏微分为0的时候，而这时这个点可能离全局最优解点 很远。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"模型误差的来源分析","slug":"模型误差的来源分析","date":"2021-08-02T05:16:06.000Z","updated":"2021-10-29T14:59:02.125Z","comments":true,"path":"2021/08/02/模型误差的来源分析/","link":"","permalink":"http://example.com/2021/08/02/%E6%A8%A1%E5%9E%8B%E8%AF%AF%E5%B7%AE%E7%9A%84%E6%9D%A5%E6%BA%90%E5%88%86%E6%9E%90/","excerpt":"","text":"@TOC 思路：1、首先，误差的两大来源 bias（偏差） 和 variance（方差） 是指什么2、然后，bias（偏差）和 variance（方差）是怎么产生的3、进一步，如何判断你的模型是 bias大（欠拟合）还是variance大（过拟合），如何解决 ？ 模型的两大来源bias（偏差）和variance（方差） 什么是bias和variance呢？思路： 首先要知道什么是误差 在了解什么是bias和variance 什么是误差？机器学习就是寻找一个函数，然后给它一个输入，就能得到一个理想的输出。f head是理论上找到的最佳函数，f star 是我们用模型预测出来的函数，两者的差值就是误差。 什么是bias和variance（偏差和方差）什么是bias（偏差）？举个栗子说明，下图是用一定样本数的均值m来估计假设的随机变量的平均值u，这是一种无偏估计（unbiased）。 也就是说，估计值的期望等于假设值（如上文的E(m)=u），即为无偏差，反之有偏差（bias）。当样本数越来越大时，m就越靠近u。 什么是variance（方差）方差表达的是数据的离散程度这里对于方差的估计是有差估计： 总结直观理解最后，bias和variance的直观理解： bias表示的是预测的f bar（f star预测值的期望）与f head（实际正确值）的距离 variance表示的是每次预测的f star（预测值）与f bar（预测值的期望）的距离（看图） bias和variance是怎么产生的 下面结合实际的实验说明，bias和variance是如何产生的。————————————————————————————————————————————————————bias如何知晓？，就要做多次实验，确定多个f star（一次实验一个预测值），然后求出f star 样本集的期望（E(f star)）那么首先，我们虚拟出100个神奇宝贝平行宇宙（相当于设置了100组实验），每个预祝一个神奇宝贝训练家捕捉10只神奇宝贝（相当于每组实验10个数据），如下图：然后思考，对于这样的数据，我们选用什么model比较好 ?哪一个model最后的bias比较小？如上图，不同宇宙的神奇宝贝数据非常随机，项次越高，模型越复杂 方差 variance对于方差而言，其表示结果的离散程度，项次越高，模型越复杂，则其离散程度肯定是越大的。因为模型越简单，收到数据的影响也就越低，比如：我极端一点，f(x)=c，数据根本不会影响model最后的预测值 偏差 bias图中看出，简单model可能并不包含目标，因此会造成较大的bias，而复杂的model是涵盖目标的，所以bias小。 偏差和方差的总结 简单的模型（次数小），bias会比较大，但variance会比较小，预测值更加集中。复杂的模型（次数大），bias会比较小，但variance会比较大，预测值更加的离散。因此，我们理想中的目标是找到一个平衡点，使bias和variance尽可能小。 判断你的模型是bias大（欠拟合）还是variance大（过拟合）并解决如何判断 bias过大（欠拟合）需要重新设计模型 模型考虑的特征没有全，也就是很多其实没有作用。关键特征可能还没考虑到，需要加入进去 模型应该需要更加的复杂，增加更高的次项。 variance过大（过拟合） 需要更多的数据，有些数据不够有特点 可以增加一个 正则项，加强模型的平滑度，使其预测值分布不要太离散 解决实际测试比共有数据集误差更大的问题将训练集，分为两部分。这叫做2-折交叉验证。一部分还是当做训练样本，帮助我们进行调参；另一部分用作验证，验证我的模型损失如何，是否合理（充当原来共有训练集的作用）。而现在原有训练集的部分用来充当实际样本数据，算出误差值，以便于真正在实际中误差太大。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"线性回归Regression 案例一：宝可梦进化CP值","slug":"线性回归Regression 案例一：宝可梦进化CP值","date":"2021-07-31T03:16:06.000Z","updated":"2021-10-29T15:00:58.738Z","comments":true,"path":"2021/07/31/线性回归Regression 案例一：宝可梦进化CP值/","link":"","permalink":"http://example.com/2021/07/31/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92Regression%20%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9A%E5%AE%9D%E5%8F%AF%E6%A2%A6%E8%BF%9B%E5%8C%96CP%E5%80%BC/","excerpt":"","text":"@TOC 本栗子：预测Pokemon精灵攻击力。输入：进化前的CP值、物种（Bulbasaur）、血量（HP）、重量（Weight）、高度（Height）输出：进化后的CP值 实现回归的步骤（机器学习的步骤）Step1 确定一个model - 线性模型 输入的特征包括：进化前的CP值（Xcp）、物种（Bulbasaur）（Xs）、血量（HP）（Xhp）、重量（Weight）（Xw）、高度（Height）（Xh） 先从简单的单个特征 进化前的CP值（Xcp）开始（后面改进再考虑多个特征）。 Step2 goodness of function（函数优化）——损失函数 确定model后（案例为线性模型），开始训练数据（使用的为训练样本集） 训练10个训练样本后得到10个的预测进化CP值（y）如下图所示。左侧为训练样本本身真实的进化CP值，右侧为横轴为进化前CP值（Xcp） 确定损失函数。损失函数用于评价一个模型的好坏。损失函数的值越小，那么模型越好。对于本案例，损失函数采用最简单的距离表示。即求实际进化后的CP值与模型预测的CP值差，来判定模型的好坏。 List item Step3 best function（找出最好的一个函数 即调参）——使用梯度下降法 案例采用梯度下降法来帮助选择 w 和 b 两个参数取何值时损失函数最小，也就意味着构建的模型越准确。 什么是梯度下降法？梯度指的是？………………………………………………………………………………………………………梯度？在单变量的函数中，梯度其实就是对应点函数的微分，代表着这个函数在某个给定点的切线的斜率在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向 即例如二维就是 偏导 i + 偏导 j………………………………………………………………………………………………………梯度下降法(SGD Stochastic gradient descent）？答： “下山最快路径”的一种算法我们是尝试使用偏导来衡量函数随自变量的值变化关系，选择变化更为平缓的那一处 对应的 w 和 b 作为调整后的参数 一维视角：只考虑一个参数 w 如上图 learning rate（学习率）：移动的步长 一般用η来表示………………………………………………………………………………………………………如何寻找一个最合适的 w ？步骤1：随机在横轴上选取一个 w0 。步骤2：计算微分，也就是当前的斜率，根据斜率来判定移动的方向。微分大于0应向右移动（增加 w ）；微分小于0向左移动（减少 w ）步骤3：根据学习率，按步骤2得到的方向移动重复步骤2和步骤3，直到找到最低点。横轴即对于的最佳 w 参数………………………………………………………………………………………………………如下图，是经过迭代多次后找到的最佳点（得是全局最优解） 。注：大部分损失函数都为正 二维视角：考虑两个参数 w 和 b如何寻找一个最合适的 w ？步骤1：随机在横轴上选取一个 w0 ，b0 。步骤2：计算各偏导，也就是当前偏导的斜率，根据斜率来判定移动的方向。微分大于0应向右移动（增加 w 或 b）；微分小于0向左移动（减少 w 或 b）步骤3：根据学习率，按步骤2得到的方向移动重复步骤2和步骤3，直到找到最低点。横轴即对于的最佳 w 和 b 参数 二维情况：梯度下降法的效果颜色约深的区域代表的损失函数越小？ 为什么呢？ 梯度算法的优缺点 总结一下梯度下降法： 我们要解决使损失函数L(w,b) 最小时参数的最佳值，梯度下降法是每次update参数值，直到损失函数最小时找到对应最佳的参数w，b 缺点1：求解的未必是全局最优解，有可能是局部最优解。 用下山的例子讲： 比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处。……………………………………………………………………………………………………… 从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。 优点1：无论随机从哪个点出发，得到的最佳参数一定是同一组 用下山的例子讲： 因为山只有一处是最低点，在确保能找到全局最优解的情况下，无论人从山上哪一点出发，一定能找到这特定一处的最低洼处。 Step4 回归结果分析 经过上述三个步骤后，得到了训练后的“最佳参数w，b”，那么现在这个模型在测试集上是什么表现呢？得到的结果是：测试集的误差比在训练集上得到的损失值大 这个事非常正常。因为你训练集里面可能有些数据是不典型的，同样测试集中很多也包含了训练集中没有的因素。所以一个函数模型在实际应用中，效果基本上时打折扣的。一般会采用两种方式来加强这个函数模型： select another model（选择另一个模型）即增加维度，增加高此项多项式 consider the hidden factors（考虑其他隐藏因素） 优化模型方法一：增加高次项（一般用于拟合度不够的情况）回到Step1 尝试二次项、三次项、四次项、五次项…… 右上图为训练集损失，下图是测试集的损失。第五次过拟合导致了，测试集损失度很高。 选择合适的模型，即我到底要加到几次项呢？ 越复杂的模型所包含的函数也就越多，那么它包含理想模型的可能性也就越大，但是如果过分地去拟合理想模型，就会出现过拟合的情况。 横向比较各个多项次，训练集和测试集的失误。理论上，失误会随着高次项而变小，如果变大，则表示模型过拟合了。所以，如上图所示，在为3次的时候，训练集和测试集的误差差值最小。并且4次开始，以及存在过拟合现象了。因此本案例可选择3次项线性模型。 优化模型方法二：考虑其他隐藏因素回到Step1 输入的特征包括：进化前的CP值（Xcp）、物种（Bulbasaur）（Xs）、血量（HP）（Xhp）、重量（Weight）（Xw）、高度（Height）（Xh）除了之前考虑的进化前的CP值（Xcp），其他均为隐藏因素………………………………………………………………………………这里另外考虑的是神奇宝贝的种类？因为，有时候一个模型恰恰只能符合一种神奇宝贝，也就是不同神奇宝贝应该有不同的预测模型。 不同的神奇宝贝有不同的预测模型 拟合这个模型的曲线，可以看出不同神奇宝贝拟合成了不同的类线性直线 如果还考虑了其他隐藏元素。如图是横轴是对应的隐藏元素，纵轴是对应进化后的CP值。 如果都采用最高二次项，考虑所有其他的隐藏因素。该案例的数学模型就变成 如图所示的式子。 考虑更多的因素反而出现了过拟合的问题，说明有些因素跟本次实验的CP值预测没有关系！………………………………………………………………………………过拟合这么讨厌，到底如何减少过拟合问题呢？往下看！ 优化模型：防止过拟合（为损失函数加一个正则项）正则项是什么? 方法：正则化?比如先考虑一个参数w，正则化就是在损失函数上加上一个与w（斜率）相关的值（正则项），那么要是loss function越小的话，w也会越小，w越小就使function更加平滑（function没那么大跳跃） 正则化的缺点正则化虽然能够减少过拟合的现象，但是因为加在损失函数后面的值是平白无故加上去的，所以正则化过度的话会导致bias偏差增大 ？？？？ 总结1）实现参数的稀疏有什么好处吗？一个好处是可以简化模型，避免过拟合。因为一个模型中真正重要的参数可能并不多，如果考虑所有的参数起作用，那么可以对训练数据可以预测的很好，但是对测试数据表现性能极差。另一个好处是参数变少可以使整个模型获得更好的可解释性。2）参数值越小代表模型越简单吗？是的。为什么参数越小，说明模型越简单呢，这是因为越复杂的模型，越是会尝试对所有的样本进行拟合，甚至包括一些异常样本点，这就容易造成在较小的区间里预测值产生较大的波动，这种较大的波动也反映了在这个区间里的导数很大，而只有较大的参数值才能产生较大的导数。因此复杂的模型，其参数值会比较大。","categories":[{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"线性回归","slug":"线性回归","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}]}],"categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"},{"name":"医学图像","slug":"医学图像","permalink":"http://example.com/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/"},{"name":"研究课题-事件脉络","slug":"研究课题-事件脉络","permalink":"http://example.com/categories/%E7%A0%94%E7%A9%B6%E8%AF%BE%E9%A2%98-%E4%BA%8B%E4%BB%B6%E8%84%89%E7%BB%9C/"},{"name":"深度学习基础","slug":"深度学习基础","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"数据集","slug":"数据集","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E9%9B%86/"},{"name":"python工具包类","slug":"python工具包类","permalink":"http://example.com/categories/python%E5%B7%A5%E5%85%B7%E5%8C%85%E7%B1%BB/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习基础","slug":"机器学习基础","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://example.com/tags/JavaScript/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"前端性能","slug":"前端性能","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD/"},{"name":"Vue","slug":"Vue","permalink":"http://example.com/tags/Vue/"},{"name":"网络安全","slug":"网络安全","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"MockJS","slug":"MockJS","permalink":"http://example.com/tags/MockJS/"},{"name":"医学图像处理","slug":"医学图像处理","permalink":"http://example.com/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"事件脉络","slug":"事件脉络","permalink":"http://example.com/tags/%E4%BA%8B%E4%BB%B6%E8%84%89%E7%BB%9C/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"ResNet","slug":"ResNet","permalink":"http://example.com/tags/ResNet/"},{"name":"迁移学习","slug":"迁移学习","permalink":"http://example.com/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"},{"name":"数据集","slug":"数据集","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"http://example.com/tags/Matplotlib/"},{"name":"目标检测","slug":"目标检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"目标检测，OpenCv","slug":"目标检测，OpenCv","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%8COpenCv/"},{"name":"yolo","slug":"yolo","permalink":"http://example.com/tags/yolo/"},{"name":"argparse","slug":"argparse","permalink":"http://example.com/tags/argparse/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"},{"name":"GoogleNet","slug":"GoogleNet","permalink":"http://example.com/tags/GoogleNet/"},{"name":"Keras","slug":"Keras","permalink":"http://example.com/tags/Keras/"},{"name":"刘二","slug":"刘二","permalink":"http://example.com/tags/%E5%88%98%E4%BA%8C/"},{"name":"Kaggle","slug":"Kaggle","permalink":"http://example.com/tags/Kaggle/"},{"name":"CNN","slug":"CNN","permalink":"http://example.com/tags/CNN/"},{"name":"DataLoader","slug":"DataLoader","permalink":"http://example.com/tags/DataLoader/"},{"name":"多维度特征","slug":"多维度特征","permalink":"http://example.com/tags/%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%89%B9%E5%BE%81/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"http://example.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"邱锡鹏","slug":"邱锡鹏","permalink":"http://example.com/tags/%E9%82%B1%E9%94%A1%E9%B9%8F/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://example.com/tags/Tensorflow/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"},{"name":"优化器","slug":"优化器","permalink":"http://example.com/tags/%E4%BC%98%E5%8C%96%E5%99%A8/"},{"name":"线性模型","slug":"线性模型","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"},{"name":"非线性模型","slug":"非线性模型","permalink":"http://example.com/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"},{"name":"激活函数","slug":"激活函数","permalink":"http://example.com/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"name":"Numpy","slug":"Numpy","permalink":"http://example.com/tags/Numpy/"},{"name":"Pandas","slug":"Pandas","permalink":"http://example.com/tags/Pandas/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"无监督学习","slug":"无监督学习","permalink":"http://example.com/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"半监督学习","slug":"半监督学习","permalink":"http://example.com/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"分类问题","slug":"分类问题","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"},{"name":"线性回归","slug":"线性回归","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}]}