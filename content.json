{"meta":{"title":"一只柴犬","subtitle":"","description":"","author":"凯凯超人","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2021-08-02T14:36:04.948Z","updated":"2021-08-02T14:36:04.948Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"卷积神经网络CNN（Convolutional Neural Network）","slug":"卷积神经网络CNN（Convolutional Neural Network）","date":"2021-08-12T14:36:01.000Z","updated":"2021-08-12T16:23:22.584Z","comments":true,"path":"2021/08/12/卷积神经网络CNN（Convolutional Neural Network）/","link":"","permalink":"http://example.com/2021/08/12/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%EF%BC%88Convolutional%20Neural%20Network%EF%BC%89/","excerpt":"","text":"@[TOC](卷积神经网络CNN（Convolutional Neural Network）) 总结CNN的要点：Q1：什么是CNN？为什么要用CNN？为什么图像处理一般都采用CNN？Q2：实现CNN的步骤？input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten——&gt;fully connected network——&gt;output Q3：如何用 keras 搭建一个CNN?Q4：CNN的应用?什么时候适用CNN效果最好？满足三个图像三个特性的时候。但要考虑第三点取子样是否合理。 CNN的概述什么是CNN？CNN也叫convnet，中文名称为卷积神经网络，是计算机视觉领域常用的一种深度学习模型。 为什么要用CNN？其可以简化DNN模型，可以减少不必要的神经元节点。特别是用在图像处理上。 为什么图像处理一般都采用CNN？CNN的参数比全连接神经网络少得多，为什么CNN只用较少的参数就可以用于处理图像呢？这是因为图像具有以下三点特征：1、一些模式比整张图片小得多，例如“鸟喙”就比整张图片小得多；2、同样的模式可能出现在图像的不同区域，例如“鸟喙”可能出现在图片的左上方也可能出现在图像的中间；3、对图像的降采样不会改变图像中的物体。CNN的卷积层的设计对应着前两点，池化层的设计对应着第三点。 如下图所示： 实现CNN的步骤input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten（压平）——&gt;fully connected network——&gt;output 卷积层（减少训练参数） 对应Property1：每一个Filter（待训练的参数，即卷积核）代表一个局部特征探测器（他是一个可以特点图形的表示器），假设现在两个特征探测器（Filter1 和 Filter2） 卷积核1的结果 值最大的那个点所在的图片部分，就是我们要找的内容 卷积核2的结果。与卷积核1的结构共同组成了 feature map 对应Property2：用 Filter1 就能探测出在不同位置的同一个flatten，而不需要用不同的Filter 如果图片是彩色的，也就是说它是三通道的，还没卷积之前，可以说有3个通道（RGB），意味着每一个像素由3个数值表示。如下图所示：卷积核是立方体3×3×3，图片为9×9×3。图片中同样选择卷积核大小，与卷积核累和，但要注意我们并不是把RGB三层，分开算，应该算合为一体的。 与全连接方式的对比全连接层，图像处理的神经网络图如下所示，每个输入与各神经元都有链接（有固定的权值）下面是CNN神经网络图，其主要的目的是减少参数（减少权值数量）。并且可以存在一定的共享权值，下面颜色相同的权值边值应该相同，这样调参可以更快。 池化层（Maxpooling）目的是减少每一个特征的维度，也就是减少后面flatten的输入特征数量。Maxpooling这边我们取每个框内的最大点。在整理一下，变成一个新的feature map 合计上两步得到：做一次卷积+池化后，把原来的 6 × 6 图像变成了 2 × 2 图像，2 × 2图像的深度（每个像素点用多少个值表示）取决于有多少个过滤器，如果有 50 个过滤器，2 × 2 图像就有 50 维，上图是只用两个过滤器，那就是 2 维。所以上图右边，就是一个新的比较小的图像，每个过滤器代表了一个channel(通道)。 重复上两步操作可多次重复上述两个步骤，将输出的结果变得最小化。 Q: 假设我们第一次卷积的时候，我们有25个卷积核，那输出的结果 feature map中应该有25个矩阵。那请问，第二次卷积的时候，输出的feature map 应该是 25×25=625 个矩阵么？答：不对，做完第一次卷积得到25个矩阵，做完第二次后还是25个矩阵。例如输入是三个通道 (RGB) 的 6 × 6 矩阵数据（即一个立方体，6 × 6 × 3），有两个过滤器（也是立方体，三个通道，3 × 3 × 3），则输出为4 × 4 × 2。（4 = 6-2 ； 2是过滤器个数 过滤器决定通道数） Flatten（压平）flatten(压平)的意思是，把特征图拉直，然后丢到一个全连接神经网络里。 CNN in Keras 卷积前，一个pixel用多少个数值表示，取决于通道数 卷积后，一个pixel用多少个数值表示，取决于Filter个数，而通道数决定Filter的高 上一个卷积层有多少个Filter，下一层卷积input就有多少个通道 123456789model = Sequential()model.add(Conv2D(25,3,3),input_shape=(1,28,28))model.add(MaxPooling2D((2,2)))model.add(Conv2D(50,3,3))model.add(MaxPooling2D((2,2)))model.add(Dense(output_dim=100))model.add(Activation(&#x27;relu&#x27;))model.add(Dense(output_dim=10))model.add(Activation(&#x27;softmax&#x27;)) Q：为什么上图第二次 每个卷积核的 参数是 225？答：因为是 3×3×25 那为什么是25而不是50呢？ CNN在学什么？CNN卷积和池化部分在做什么？ 分析第一个层的卷积核是比较容易的，里面每个卷积核就是一个3 * 3 的矩阵，对应3 * 3 范围内的9个像素点，只要看到矩阵的值，就知道在检测什么（有明显的特征）。 第二层的卷积核没法知道在做什么，虽然也是 3 × 3 的矩阵，总共 50 个。但是这些卷积核的输入不是像素点，而是在上一层做完卷积和池化后的输出。就算知道第二层卷积核的矩阵值，也不知道在检测什么。另外第二层卷积核考虑的不是原图 3 × 3 的像素点，而是比原图 3 × 3 像素点更大的范围，因为在第一层的池化后，压缩了原图 3 × 3 的区域，第二层卷积核是在压缩后的图像里再选取 3 × 3 像素点，相当于扩大了原图检测的范围。 Q：那怎么分析第二层卷积核在做什么？ 第二层的50个卷积核，每个卷积核的输出是一个 11 × 11 的矩阵。把第k个卷积核输出拿出来如上图左下，矩阵元素表示为 $a_{ij}^{k}$ (第k个卷积核，第i个行，第j个列)。接下来 定义一个“Degree of the activation of the k-th filter”（第k个卷积核的激活程度），值代表第k个卷积核的被激活程度（input和第k个卷积核侦测的东西有多匹配）。 第k个卷积核被激活程度表示为：$a^{k}=\\sum_{i=1}^{11}\\sum_{j=1}^{11}a_{ij}^{k}$ ，11 × 11 矩阵所有元素值之和。 Q：找一张图像，可以让第k个卷积核被激活程度最大，如果做到这件事情？*称 input 的图像为 x，目标是找一个让 $a^{k}$ 最大的 x，如何找到这个 x？*使用梯度上升，因为我们的目标是最大化 $a^{k}$ 。现在是把 x 当做我们要找的参数，对 x 用梯度上升。原来CNN的 input 是固定的，model 的参数使用梯度下降求解。现在反过来，model 的参数是固定的，使用个梯度上升更新 x，让被激活程度最大。 上图左下，是随便取12个卷积核后对 x 做梯度上升后的结果，每个卷积核都找到一张图像，这张图像让这个卷积核的被激活程度最高。如果有50个卷积核，理论上可以找50张图像。 Q：这12张图像有一个共同的特征：是某种纹路在图上不断反复。为什么会这样？看第三张图像，都是小小的斜条纹，这意味着第三个卷积核是在检测是否有斜的条纹。因为卷积核考虑的范围是很小的，所以原图像上任何地方出现一个小小的斜纹的话，这个卷积核（过滤器）就会被激活，输出值就会很大。如果原图像所有范围都是这种小小的条纹，那这个卷积核的被激活程度就最大。 你会发现每个过滤器都是在检测某一种图案（某一种线条），例如上图左下第3个过滤器是检测斜条纹，第4个是检测短、直的线条，第6个是检测斜成一定程度的线条等等。每个卷积核（过滤器）都在检测不同角度的线条。 全连接的隐藏层都在干什么？做完卷积和池化后，会做flatten(压平)，把压平后的结果丢到神经网络里去。 Q：在这个神经网络的隐藏层里，每个神经元都在干什么？答：如法炮制之前的做法，定义第 j 个神经元的输出是 $a_{j}$ ，然后找一张图像 x，使 $a_{j}$ 最大。找到的图像如上图左下所示，9张图像，是对应神经元的输出最大。你会发现跟刚才卷积核（过滤器）观察的图案很不一样，卷积核观察的是类似纹路的东西，因为卷积核只考虑了原图像的一部分区域。输出通过压平后，现在每个神经元是去看整张图像，能使神经元激活程度最高的图像不再是纹路这种小图案，而是一个完整的图形，虽然看起来完全不像是数字，但神经元被激活后也的确在侦测一个完整的数字。 考虑最后的输出？ 如果最后的输出是10维的，每一维对应一个数字。把某一维拿出来，找一张图像使那个维度的输出最大。例如现在要找一张图像，使输出层上对应数字1的神经元的输出最大，理论上这张图像看起来就是数字1但是实际的图像如上图左边所示，每张图像分别代表0,1,2,3,4,5,6,7,8 Q：那为什么是这种是乱七八糟的雪花状呢，而不是我们能看清的数字呢？答：因为神经网络的视角，他就是和人不一样的。他就认为这些雪花图像是不一样的，对于0-8数字。与我们人的思维不同。Q：能不能让这些图像看起来更像数字？我们知道，一张图像是不是一个数字，有一些基本的假设。比如上图左边，人类看起来显示不是数字。那么我们对x做一些正则项约束，告诉机器，虽然有些 x（图像） 可以让 y 很大，但是这些 x 的确不是数字。Q：那加些什么约束呢？比如最简单的想法，图像上的白点是有墨水（笔画）的地方，对一个数字来说，有白点的部分是有限的，数字的笔画只占图的一小部分，所以我们要对 x 做一些限制。假设 $x_{ij}$ 是图像像素点的值，每张图像有 28 × 28 个像素点。把所有像素点的值取绝对值并求和（相当于L1正则），我们希望找一个 x ，让 $y_{i}$ 越大的同时，也让像素点绝对值之和越小。那我们找出来的图像大部分的地方就不是白色的。最后得到的结果如上图右边所示，和左边的图看起来，已经可以隐约看出来是个数字了。 CNN的应用Deep Dream你给机器一张图像，机器会在这张图像里面，加上它学习到的东西。 比如把上图丢到CNN里面去，然后把某个卷积核或者某个全连接隐藏层拿出来（一个向量），假设是 $\\begin{bmatrix}3.9\\-1.5\\2.3\\:\\\\end{bmatrix}$ 然后把3.9、2.3调大（本来是正的值调大），-1.5调小（负的值调小），正的更正，负的更负。找一个图像使卷积核或者隐藏层（拿出来的）的输出是调整后的向量。这么做的意思是让CNN夸大化它看到的东西。找到的图像会变成上图所示，出现很多奇怪的东西。右边看起来是一头熊，原来是一颗石头。对机器来说，本来就觉得石头像一头熊，强化它的认知后，就学习出来更像一头熊的图案。这个就是Deep Dream。 Deep Styleinput 一张图像，然后让机器去修改这张图像，让它有另一张图的风格，比如让上图看起来是呐喊。 Q：卷积核和过滤器的区别 卷积核就是由长和宽来指定的，是一个二维的概念。 过滤器是是由长、宽和深度指定的，是一个三维的概念。 过滤器可以看做是卷积核的集合。 过滤器比卷积核高一个维度——深度。 —————————————————————————————————— Q：怎么做到图像风格转变呢？把原来的图像丢给CNN，得到CNN过滤器的输出，代表一张图像里有什么样的内容。 然后把呐喊这张图也丢到CNN里，也得到过滤器的输出，但这时候考虑的不是过滤器输出的绝对值，而是考虑过滤器和过滤器输出之间的关系，这个关系代表了一张图像的风格。接下来用同一个CNN找一张图像，这张图像的内容像原图像的内容（过滤器的输出类似），同时这张图像的风格像呐喊的风格（过滤器输出之间的关系类似）。找一张图片同时最大化内容和风格（使用梯度上升更新参数），得到的结果就像两张图片结合一样。 CNN应用在围棋上要让机器下围棋，不一定要用CNN，一般的神经网络也可以做这件事情。只要学习一个网络，也就是找一个函数，输入是棋盘，输出是棋盘上的位置，根据棋盘的盘势，判断下一步落子的位置。输入是19 ×19 向量，向量每一维是棋盘上的一个位置（是黑子则值为1，是白子则值为-1，反之则为0），丢到一个全连接的神经网络，输出也是19 ×19 的向量（每一维对应棋盘一个位置），那这样机器就可以学会下围棋了。 为什么CNN可以用在下围棋上？但实际采用CNN会得到更好的效果！为什么呢？之前举的例子都是把CNN用在图像上面，input 是一个矩阵。用到下棋上，只要把 19 ×19 的向量表示为 19 ×19 的矩阵。对CNN来说，就是把棋盘和棋子当成一个图像，然后输出下一步落子的位置。 收集很多棋谱，告诉CNN，看到落子在5之五，输出天元的位置为1，其他位置为0看到5之五和天元都有棋子，输出就是5之五的位置为1，其他位置为0这个是监督的部分，AlphaGo还有强化学习的部分 总结一下什么时候用CNN?为什么围棋适用？图像要有该有的特性，开头讲过的根据三个特性设计出了CNN的网络结构，在处理图像的时候特别有效。 Q：为什么围棋很适用CNN？答：因为围棋有一些特性和图像处理是很相似的。围棋是有图像的第一个和第二个特性 在一张图像上面，有一些图案是比整张图像小的，比如鸟嘴。在围棋也有同样的现象，比如看到一些棋子摆放的图案，就要做一些相应的事情（比如上图黑子叫吃的时候，白子要落在下方保证不被吃）。不需要看整个棋盘，只需要看一个小小的范围，就可以侦测白子是不是属于被叫吃的状态。AlphaGo里第一层的过滤器就是用的 5 × 5 过滤器，显然设计这个过滤器的人觉得围棋上最基本的图案在 5 × 5 范围内就可以被侦测出来。 图像还有个特性是相同的图案会出现在不同的区域，在围棋上也有同样的特征。例如叫吃的图案，可以出现在棋盘左上角，也可以出现在棋盘右下角，图案代表了同样的意义（叫吃），所以可以用同一个检测器来处理这些在不同位置的图案。 Q：困惑的是图像的第三个特性，对原图像做子采样不会影响人看到的这张图像的样子，基于第三个特性有了池化层，但Alpha并没有采用池化层（就是做子采样）？因为不能做子采样。比如丢弃棋盘的奇数行和偶数列，想想也应该是不可以的。 也许AlphaGo里的CNN架构有特殊的地方。AlphaGo论文附录里描述了它的网络结构，input是一个19 ×19 ×48 的图像，19×19 是棋盘可以理解，但48是怎么来的？对AlphaGo来说，把每一个位置都用48个值来描述（卷积后有48个通道）。本来我们只要描述一个位置是不是白子、黑子就可以了，而AlphaGo加上了领域知识（看这个位置是不是出于叫吃的状态等等）。 AlphaGo有做zero padding(零填充)，在原来19 ×19 的图像外围补上 0 值变成 23 × 23 的图像，第一层用的是 5 × 5 过滤器，总共 k 个过滤器（paper里用的是192个过滤器），步长stride=1，有用到 ReLu 作为激活函数，有2到12层的过滤器层，最后变成 21 × 21 的图像，接下来再使用 3 × 3 的过滤器，步长 stride=1。最后发现AlphaGo没有使用池化，针对围棋特性设计CNN结构的时候，是不需要池化这个结构的。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"CNN","slug":"CNN","permalink":"http://example.com/tags/CNN/"},{"name":"卷积核","slug":"卷积核","permalink":"http://example.com/tags/%E5%8D%B7%E7%A7%AF%E6%A0%B8/"},{"name":"过滤器","slug":"过滤器","permalink":"http://example.com/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"name":"Maxpooling","slug":"Maxpooling","permalink":"http://example.com/tags/Maxpooling/"}]},{"title":"为什么要Deep？深而不是宽","slug":"为什么要Deep？深而不是宽","date":"2021-08-10T14:36:01.000Z","updated":"2021-08-10T17:02:00.593Z","comments":true,"path":"2021/08/10/为什么要Deep？深而不是宽/","link":"","permalink":"http://example.com/2021/08/10/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81Deep%EF%BC%9F%E6%B7%B1%E8%80%8C%E4%B8%8D%E6%98%AF%E5%AE%BD/","excerpt":"","text":"@TOC Q：为什么要用要用深度？而不是广度？答：1.因为深度可以用少量的数据，就完成对数据的分类。2.深度，每个层次都是基于上个层次得到的（其实就是学习的过程），我们可以将神经元的数量减少。如果层次很少的话，会导致神经元可能非常多。可以类比逻辑电路。 模组化在比较浅层网络与深层网络时，要让“矮胖”的网络和“高瘦”的网络的参数数目相等，这样比较才公平。但即便是在深层网络参数较少的情况下，深层网络也会比浅层网络表现好。这是因为 深层”其实相当于“模组化”，第一个隐层是最基本的分类器，第二个隐层是用第一个隐层建造的分类器，以此类推。 举个栗子，为什么说深度好！左边第一幅图可以看到，我们需要分四个类，包括长发女，长发男，短发女，短发男。一共四类，其中长发男的数据样本很少，那区分这个类的能力就非常的弱。这个时候，我们就可以先分为两个神经元，一个区分男女，一个区分长发短发，这样中间加一层，可以使得数据样本少的类 鉴定的效果更好。对于分类一个图像来说，深度使得模块化。 类比逻辑电路浅层网络确实可以表示任意函数，但是使用深层结构更有效率。好比逻辑门电路，用两层逻辑门就可以实现任何布尔函数，但是用多层结构更简单、需要的逻辑门更少。 神经网络也是如此，单隐层网络可以表示任何连续函数，但是多层结构表示起来更简单、需要的神经元更少，所以比较不容易overfitting，或只需较少的data。而且，深层结构可以比较有效率地使用data。 类比图形1层hidden layer与3层hidden layer（相同数目的参数），3层的效果更好。但理论上，3层可达到的效果，1层也能达到：要在1层learn的时候，target从真实label改为3层的output，这样1层的结果会接近3层的结果。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"}]},{"title":"深度学习 Deep Learning 模型优化","slug":"深度学习 Deep Learning 模型优化","date":"2021-08-09T14:36:01.000Z","updated":"2021-08-09T14:37:14.552Z","comments":true,"path":"2021/08/09/深度学习 Deep Learning 模型优化/","link":"","permalink":"http://example.com/2021/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/","excerpt":"","text":"@[TOC](深度学习 Deep Learning 后续优化) 深度学习 怎么评价效果与改进？ 先检查 训练阶段 是否有比较好的结果training优化方法： 换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax） 优化器——优化梯度下降和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam） training没问题了，再检查testing是否有比较好的结果 testing（过拟合）优化： 参数在过拟合之前就停止更新 正则化Regularization dropout 如何优化模型谈什么才是overfitting？首先我们在明确一下，深度学习的流程，其与机器学习基本一致。如下图所示：判断 过拟合 需要看两个数据集上的结果（training set → good， testing set → bad）。在试图解决overfitting之后仍要再看一下training set上的结果！ 误区：不能看见所有不好的 performance 都归因到 overfitting。如只看下右图，不能断言56-layer有 overfitting，要看模型在training set上的表现。根据下左图，可以发现原因是训练的时候没有训练好，即这个层次设计可能本身就是有问题的，不然为啥20层的挺好，56层没道理差啊（这不能叫 underfitting，underfitting：参数不够多，模型能力不足）。 对症下药：训练error，测试error分别用什么方法在读到深度学习的方法时，要思考该方法是解决什么问题。是解决training set上的performance不好，还是解决testing set上的performance不好。比如，Dropout是为了解决testing set上结果不好的问题，如果是training set上结果不好而用Dropout，不会有好的结果。下图是 分别解决各问题，可以采用的方法： 模型Train阶段Error 具体解决如下图是，MNIST手写数字识别，激活函数用sigmoid，training data上的accuracy与层数的关系曲线：层数&gt;7时，performance下降，原因不是 overfitting! 因为train的时候就没train好。那模型压根没有训练好，可以采用的方法上面也给出了包括：换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax）。激活函数可能会带来什么样的问题？以sigmoid为例说：会出现梯度消失。 方法一：换激活函数的问题 —— 梯度消失什么是梯度消失有梯度时，参数才会往梯度最小的地方改变；没有梯度了，参数就停止更新了。前面层的学习速率明显低于后面层（后向传播），这就是梯度消失。 为什么会有梯度消失？ 角度一： 用sigmoid会出现梯度消失的问题（参数的变化经过sigmoid会逐层衰减，对最后的loss影响很小）如上图所示，我刚开始增加的△w，由于 sigmoid函数 ，自变量越大，改变量越小的缘故。数的变化经过sigmoid会逐层衰减，对最后的loss影响很小。也就是对C的偏导会越来越小，导致梯度接近于0，而消失。 角度二：假设现在存在一个网络结构：其整个数学模型可以表示为：若要对于 w1求梯度，根据链式求导法则，得到的解为：这明显数学模型的值，随着隐层的增加，越来越小。不过这个前提是 原先的w（权重）并不是很大，原本相乘就是小于1的。如果w太大的话，第一项相乘就大于1，这就会导致最后的梯度爆炸。 如何解决梯度消失问题 —— 换ReLU激活函数ReLU 与 MaxOut梯度消失是因为 sigmoid 引起的，要解决当然要换一个激活函数。采用的方法是换 ReLU激活函数（原型 input&lt;0时，输出为0，input&gt;0,输出为原值；可变型）ReLU输出0或x，输出0的ReLU神经元相当于不存在，网络变得瘦长，但是整个网络仍然是非线性的，只有当input改变十分微小的时候才是线性的，因为input不同，输出为0的ReLU神经元也不同。 Q : 为什么ReLU是非线性？明明两端都是线性直线啊？因为ReLU在0点没有导数定义，线性讲究的是在整个定义域内。而在0点处，不可微，所以整体是非线性的。 ReLU是Maxout的特例，Maxout可以学出激活函数。 MaxOut 的训练是怎样的？好在哪？下面是一个神经网络的栗子，我们将激活函数换成 MaxOut激活函数。上面的图 可以删除不需要的边和点，变为如下的神经网络： Q ：如果和上图所示，那我去掉的那些边不是啥用没有？也就是这个权值压根和神经网络没关系呢，不是吗？答 ：当然有关系，因为我们的任务是调参，每个权值和偏值得变化，都会导致 MaxOut激活函数 选择的不同。比如说改变一下 w，他可能会选择 z2呢。 方法二：优化器 —— 优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）寻找最佳参数的方法，调节学习率的方法有（SGD、Adagrad、RMSProp、Momentum、Adam）SGD、Adagrad 可以看之前关于 梯度算法进阶的部分 Post not found: 梯度下降算法 进阶这边主要讲解一下 RMSProp 和 Momentum 关于 RMSProp为什么要使用RMSProp 在 Adagrad 中，学习率是跟损失函数对 w 的二次微分有关。那么对于图中蓝绿相交的一点来说，因为 w1 所在的曲率相对于 w2 要小，所以 w1 的学习率会比 w2 大。现在单考虑 w1（只看横向），那么二次微分是固定的（碗状），也就是说 w1是根据固定的规则去自动调整 η 的。但是现实中同一方向的二次微分是不固定的，因此对于同一方向去 w1，需要不同的规则去调 η。对于一个参数来说，Adagrad 是用固定的规则去调 η，RMSProp 是用变化的规则去调 η 如何实现RMSProp在原来分母这一项中，在过去梯度平方和前面加上权值 a，现有的梯度平方加上 1-a。其在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小），并且能够使得陡峭的方向变得平缓，从而加快训练速度） 关于 MomentumMomentum（动量）是用来解决什么问题的？这个是用来解决局部最优解的问题的 说白了就是要延续他的惯性 如何实现Momentum考虑他此时的方向，并保留他的惯性。来调整下一步，最大可能的避免局部最优解。 关于 Adam他其实是一种 Momentum + RMSProp 结合的方法。其具体算法可以看如下图所示： 模型Train阶段OK Test阶段Error，即过拟合方法一 ：参数在过拟合之前就停止更新（Early Stopping）这里的testing set指的是有label的testing set（即validation set ）。如果learning rate设得对的话，training set的loss会逐渐降低，而testing set与training set可能分布不同，所以testing set的loss可能先降后升，这时就不要一直train下去，而是要在testing loss最小的地方停止train。这里的testing set 实际指的是validation set。 方法二 ：正则化Regularization Q ： 首先理解什么是范数，L1（范数为1）和L2（范数为2）是什么？范数：向量在不同空间中“长度”的计算公式L1：绝对值之和L2：平方和 L2正则化（权值衰减） Q ： 为什么通常 不考虑 bias？L2正则化让function更平滑，而bias与函数平滑程度没有关系。 参数更新：因为η、λ、n都是正的，所以 1−ηλ小于1，它的效果是减小w，这也就是权重衰减（weight decay）的由来**。当然考虑到后面的导数项，w最终的值可能增大也可能减小**。 正则化在NN中虽有用但不明显。NN参数初始值一般接近0，update参数即是要参数原理0。L2正则化（让参数接近0）的作用可能与early stopping类似。 Q : 为什么参数w衰减能防止过拟合?答 ：模型过于复杂会导致过拟合。那么越小的w（可以想象成0理解），表示网络复杂度低，越简单的网络结构，就越不会过拟合。比如模型 y=w1×w1 + w2×w2 的平方 中把 w2=0 代入，模型就会简化，就不会引起过拟合。Q : 对正则化解决过拟合问题的一些本质理解？正则化防止过拟合的本质：减少“没用参数”的权值（防止过拟合），同时也减少“有用参数”的权值（会增加bias误差）Q : 什么是有用参数，什么是没用参数？如上图中，怎么就把 x2 删去，不把 x1 删去呢？我们姑且假设 w1 是有用参数， w2 是无用参数，由公式知参数更新值跟权值、梯度值两个因素有关，实际上，无论是 x1 还是 x2 ，权值都会衰减，每update一次参数，权值 w 就会衰减一次，但如果是下图的情况，损失函数Loss 的减少跟 w2 没关系的，所以对其偏导为0，那么 w2 的参数更新只跟权值有关了，随着更新次数叠加，权值就会逐渐衰减接近0；对于有用参数 w1 ，虽然它权值衰减，但是它其作用的是后面的偏导值，所以它还是不会变成0的。 L1正则化L1是在Loss函数加上绝对值之和，求偏导后比原始的更新规则多出了η ×λ ×sgn(w)这一项。当w为正时，更新后的w变小。当w为负时，更新后的w变大（一加一减）——因此它的效果就是让w往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合 L1和L2相比L1 update的速度是*|ηλ||ηλ|* （划横线那项每次改变量是一定的）。而 L2 update 的速度与w的t有关（如果wt 很大，那么改变量也很大）。用L1做training，结果比较sparse(稀疏的)，参数中有很多接近0的值，也有很多很大的值。L2 learn的结果：参数值平均来讲比较小。 DropoutDropout也是为了简化神经网络结构的目的，但L1、L2正则化是通过修改代价函数来实现的，而Dropout则是通过修改神经网络本身来实现的。 dropout是如何实现的在training的时候，每次update参数之前，对每一个Neuron（包括input_layer）做sampling，决定这个Neuron按一定几率p丢掉，跟它相连的weight也被丢掉，结果得到一个细长的Network。（每一次update一个mini-batch之前，拿来traing的Network structure是不一样的）。 换句话说input layer中每个element也算是一个neuron.每次更新参数之前都要resample.用dropout，在training上的结果会变差，但在testing上的结果会变好。在testing的时候不做dropout，所有neuron都要用。如果training时的删除神经元的概率为p%，则在testing时，所有的weight都要乘以（1-p）% Dropout的原理 Q : 为什么当在做 testing 的时候，weights需要都乘以 (1-p)% (p是Dropout的概率)？ 答：如下图所示，左侧是在 Traing 阶段，w2 与 w4 由于丢失几率和丢掉(几率是这里是0.5)，假设神经元此时都是1，这时输出的应该是 w1+w3；右侧是在 Testing 阶段，在这个阶段要保证所有的神经元都不做 Dropout 。所以变成了w1+w2+w3+w4，约等于变成了左侧的两倍；所有取所有weight都要乘以（1-0.5）。 实际上，dropout是利用ensemble思想，把一个复杂神经网络的训练转化为，训练很多个简单的神经网络，然后再把多个简单神经网络训练出来的参数做平均。一个复杂model, bias准，但variance大，把多个复杂model ensemble起来，variance变小。每个dropout后的结构由一个batch来train，但是权重是共享的，每个权重是由多个batch 来train的。在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的。Dropout用在ReLU、Maxout上效果较好。 Q : 为什么 Dropout 在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的？ 而不是相同答：因为神经元之间的层次，使用的激活函数不一定都是线性的，只有线性的情况下才会是相同的。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"模型优化","slug":"模型优化","permalink":"http://example.com/tags/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/"}]},{"title":"深度学习 Deep Learning 基础","slug":"深度学习 Deep Learning 基础","date":"2021-08-07T09:03:01.000Z","updated":"2021-08-07T09:03:41.534Z","comments":true,"path":"2021/08/07/深度学习 Deep Learning 基础/","link":"","permalink":"http://example.com/2021/08/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E5%9F%BA%E7%A1%80/","excerpt":"","text":"@[TOC](深度学习 Deep Learning 基础) 深度学习需要明白的几个问题？思路： 什么是深度学习？为什么需要深度学习？深度学习和机器学习的关系？ 深度学习的步骤 确定神经网络模型的损失函数，如何优化模型，即调参问题 如何使用Back Propagation（反向传播） 方法 update DNN（深度神经网络）参数 深度学习的概念什么是深度学习？深度学习（Deep Learning，DL）是指多层的人工神经网络和训练它的方法。一层神经网络会把大量矩阵数字作为输入，通过非线性激活方法取权重，再产生另一个数据集合作为输出。这就像生物神经大脑的工作机理一样，通过合适的矩阵数量，多层组织链接一起，形成神经网络“大脑”进行精准复杂的处理，就像人们识别物体标注图片一样。 深度学习的model是一个深度神经网络结构（neural structure） 深度学习的“深度”是指神经网络的隐层（hidden layer）数量足够多 深度学习是自动提取特征（Feature extractor），不需要像逻辑回归那样特征转换（Feature engineering） 为什么需要深度学习？ 深度学习和机器学习的关系？ 传统机器学习的模型结构较简单，很依赖算法工程师做特征工程甚至子模型来提升模型效果。就像我们之前上节那个栗子一样，做多分类的问题，四个角对角是一个类的情况，没办法进行分类，所以只能使用特征工程来进行特征的变换。 深度学习由于其层次化的结构，理论上可以拟合任意函数，整个复杂结构即可以用来对特征进行自动组合（如图像），也可以用来构建复杂的模型（如nlp领域里的LSTM，能够考虑上下文）。 深度学习的步骤其实和机器学习一样分为三步。 Step 1：定义一个神经网络结构（neural structure）神经网络的创建包括3部分： 神经网络有多少隐层（layer） 每一层有多少神经元（neuron） 每个神经元之间如何连接 常见的出名神经网络 神经元怎么定义？每个神经元都有一个 bias 和一个 function ，每条输入的边都有一个 weight 一个神经网络的栗子下面是一个 3个隐层（layer）、六个神经元（neuron）（每个球都是一个神经元）、全连接前馈网络（Fully Connection Feedforward Network） “前馈”是指整个网络中无反馈，信号从输入层向输出层单向传播，可用一个有向无环图表示其实我们常用的网络，都是前馈神经网络，从输入到输出是一个有向图，中间不会有环或者反向传播。当然，我们在训练前馈神经网络的时候，会用到反向传播进行参数调整。但仍不影响整个网络的有向和前馈性质。 神经网络如何工作？其实 这就是矩阵运算（可以使用GPU加速计算）总体可以归纳为： 栗子：识别手写数字图像从图像中识别是数字几？ 制作神经网络模型 的FAQ（最容易被问得问题） Q1： 神经网络需要几个隐层（layers）？每个层需要多少个神经元呢？ 反复试验+ 直觉 （说白了就是要慢慢试= = 看经验呗） Q2：神经网络可以自动确定结构吗？ 理论上其实是可以的，不过这些方法我们还没学到。Evoluntionary Artifical Neural Networks Q3：我们可以设计层次之间的结构么？ 意思就是说例如Layer1 链接 Layer3 这样跳着的 等等。当然可以 CNN就是不按顺序来的，具体看下一节。 Step 2：确定神经网络模型的损失函数还是和逻辑回归一样，用交叉熵损失函数，调参使得交叉熵损失函数最小，如下图所示：当然上面只是一个点的，把每个样本结合起来看。 不过这个地方有几个疑问？ Q1：神经网络里面有很多层，所以有很多 w 和 b 调整。那是全体都一次性调整么？ 答： 现在不知道啊！ Q2：上面我是把所有的 交叉熵 都加在一起 然后对 整个大的损失函数进行调参是这样嘛？ 那我的训练样本应该是 各个数字都有是吗？ 答： 现在不知道啊！ Step 3：如何找到一个最好的函数（最佳参数），即调参用的还是 梯度下降法 随机选取一组参数 输入所有的训练样本 然后样本数据不变，参数不断变，用梯度下降法更新参数 Backpropagation（反向传播） 来优化调参速度神经网络可能有很多个隐层，因此可能有百万数量级的参数，为了在梯度下降时有效地快速计算梯度，使用反向传播。下图是 使用的损失函数为：交叉熵损失函数 ， 梯度下降法就是对每个参数求偏导，然后根据偏导大小进行左右移动，找到偏导为0的点，就是最佳参数值。 计算对参数偏导的表达式 交叉熵损失函数，为 正确值乘以 ln的带入x样本的线性模型 +（1-正确值）乘以ln（1-带入x样本线性模型） 只考虑刚输入阶段的神经元，可以得到用 sigmoid激活函数之前的量 z，而 z 是由线性模型（按权重分配向量 + 偏值 b 得到）。如下图所示，可以看到对参数 w 的偏导可以按照链式法则为 $$∂C/∂w=∂z/∂w × ∂C/∂z $$ 前项为前项传递，后项为后向传递 前项传递非常好看出来，就是对应的输入值，比如 ∂C/∂w1=∂z/∂w1 × ∂C/∂z 。其中∂z/∂w1 看图上所示，不就是对 w1 进行偏导么，那就是 x1。 后项过程比较复杂，根据链式法则，∂C/∂z=∂a/∂z × ∂C/∂a，其中∂a/∂z = σ&#39;(z) 如下图所示 归纳一下得到如下：这个时候我们从另一观点看待上面的式子：有另外一个神经元（下图中的三角形，表示乘法/放大器），input是∂C/∂z‘与∂C/∂z′&#39; ，权重分别是 w3,w4，求和经过神经元（乘以σ′(z)），得到 ∂C/∂z。（相当于反向传播，先线性加权再乘以一个σ′(z) 和正向非常类似） 后项传递 的两种情况如上图所示是我们最后得到的后项传递的式子，其中我们还有两个项不知道。那我们现在需要计算这两个部分，但分为两种情况 case 1：下一层是最终输出层第一种情况，z′,z′′ 所接的neuron是output layer的neuron。这个就比较简单，直接根据最后一层的输出反向写出即可。 case 2：下一层不是最终输出层第二种情况，z′,z′′ 所接的neuron不是output layer的neuron。就上面那个图，我们可以推得类似后项传递的式子就这样反复迭代(递归)，直到遇到case1的情况，就可以算出整个后项传递。然后结合之前的前项传递，就是我们要得到的对这个参数的偏微分值。 总结梯度下降时需要计算损失函数对每个参数偏微分∂C/∂w，w 代表相邻隐层之间的一条连线（即权值），每个 w 只有一个所指的神经元。 链式法则将计算 ∂C/∂w 拆成前向过程与后向过程。 前向过程计算的是∂z/∂w ，这里 z 是 w 所指neuron的input，计算结果是与 w 相连的值。后向过程计算的是∂C/∂z，这里 z 仍是 w 所指neuron的input，计算结果通过从后至前递归得到。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"反向传播","slug":"反向传播","permalink":"http://example.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"}]},{"title":"逻辑回归 Logistic Regression","slug":"逻辑回归 Logistic Regression","date":"2021-08-05T15:08:06.000Z","updated":"2021-08-05T15:08:47.033Z","comments":true,"path":"2021/08/05/逻辑回归 Logistic Regression/","link":"","permalink":"http://example.com/2021/08/05/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%20Logistic%20Regression/","excerpt":"","text":"@[TOC](逻辑回归问题 Logistic Regression) 逻辑回归需要明白的几个问题？ 1、逻辑回归(Logistics Regression) 与 线性回归(Linear Regression)的区别在哪2、生成模型(Generative Model) 与 判别模型(Discriminative Model）的区别在哪 生成模型就是要学习 x 和 y 的联合概率分布 *P(x,y)*，然后根据贝叶斯公式来求得条件概率 *P(y|x)*，预测条件概率最大的 y。 判别模型就是直接学习条件概率分布 *P(y|x)*。 3、逻辑回归(Logistics Regression) 与 深度学习（ VS Deep Learning）逻辑回归具有缺陷，需要做特征工程来转变特征，但是这个人为步骤非常麻烦，所以引入了深度学习。 逻辑回归与线性回归什么是逻辑回归？ 逻辑回归是解决分类问题的一种算法 它与 线性模型 形式上有点像（本质上是在线性模型外面“裹”一个sigmoid激活函数，来表示概率的函数） 它是一种判别模型，与前面说的生成模型不同 它是深度学习的基础 对比逻辑回归与线性回归区别一：模型不同本质上是在线性模型外面“裹”一个sigmoid激活函数，来表示概率的函数 总结的来看 区别二：损失函数Loss不同逻辑回归的 为什么似然函数最大，参数就越有可能，越合理？最大似然估计：现在已经拿到了很多个样本（你的数据集中所有因变量），这些样本值已经实现，最大似然估计就是去找到那个（组）参数估计值，使得前面已经实现的样本值发生概率最大。因为你手头上的样本已经实现了，其发生概率最大才符合逻辑。这时是求样本所有观测的联合概率最大化，是个连乘积，只要取对数，就变成了线性加总。此时通过对参数求导数，并令一阶导数为零，就可以通过解方程（组），得到最大似然估计值。 总结一下： 问题：为什么逻辑回归不采用线性回归的差平方来做？例如，其实目前离目标点还很远，但梯度已经为0了，这显然不合理。 区别三：如何调参的方式是一致的 化简逻辑回归损失函数左侧部分 化简逻辑回归右侧部分 化简，调参如下总结 生成模型与判别模型什么是生成模型和判别模型？从本质上讲，生成模型和判别模型是解决分类问题的两类基本思路 。分类问题，就是给定一个数据 x，要判断它对应的所属标签 y 生成模型就是要学习 x 和 y 的联合概率分布 *P(x,y)*，然后根据贝叶斯公式来求得条件概率 *P(y|x)*，预测条件概率最大的 y。 判别模型就是直接学习条件概率分布 *P(y|x)*。 两种模型案例 举个栗子？ 栗子1：假设你从来没有见过大象和猫，连听都没有听过，这时，给你看了一张大象的照片和一张猫的照片。Q : 你看过之后，有人牵了一头真的大象过来，问你只是大象还是猫？ 用判别模型的思路回答：你回想刚才看过的照片，大象比猫很明显有个长鼻子，所以眼前这个有着长鼻子的动物就是大象。 用生成模型的思路回答：你回想刚才看过的照片，然后用笔把它们画在了纸上，拿着纸和我家的大象做比较，你发现，眼前的动物更像是大象。 第一个解决问题的思路就是判别模型，因为你只记住了大象和猫之间的不同之处。第二个解决问题的思路就是生成模型，因为你实际上学习了什么是大象，什么是猫。 栗子2：有四个形式为(x,y)的样本。(1,0), (1,0), (2,0), (2,1）。假设，我们想从这四个样本中，学习到如何通过x判断y的模型。 用生成模型，我们要学习 *P(x,y)*。如下所示：我们学习到了四个概率值，它们的总和是1，这就是联合分布律P(x,y)。（因为这是离散的，连续的话叫联合概率密度） 用判别模型，我们要学习 *P(y|x)*，如下所示：因为这是条件分布律，每一行概率值相加都为1。 Q : 当 x=1 时，请问 y 是 0 还是 1 呢？ 用生成模型，我们会比较P(x=1,y=0) = 1/2P(x=1,y=1) = 0我们发现 *P(x=1,y=0)*的概率要比 P(x=1,y=1)的概率大，所以，我们判断：x=1时，y=0。 用判别模型，我们会比较：P(y=0|x=1) = 1P(y=1|x=1) = 0同样，P(y=0|x=1) 要比 P(y=1|x=1)大，所以，我们判断：x=1时，y=0。 我们看到，虽然最后预测的结果一样，但是得出结果的逻辑却是完全不同的。 生成模型为啥叫生成模型？生成模型之所以叫生成模型，是因为：它背后的思想是，x是特征，y是标签，什么样的标签就会生成什么样的特征。好比说，标签是大象，那么可能生成的特征就有大耳朵，长鼻子等等。当我们来根据x来判断y时，我们实际上是在比较，什么样的y标签更可能生成特征x，我们预测的结果就是更可能生成x特征的y标签。 为什么一般来说，判别模型表现得会比生成模型好？我们举一个栗子，现在有Class1 和 Class2 两类数据。现在训练集数据如图所示：Q : 问请问如下的测试集，他是应该属于Class1 还是 Class2 呢？我们这边用判别模型来计算，算出如下图所示的数据：然后用贝叶斯公式算出 P(C1 | x) ，就是当x1和x2全为1 的情况下的概率是多少。算出的结果是 ＜ 0.5 的，但从我们人的角度看，其实应该是属于Class1的，因为Class2里面压根就没有x1，x2同时为1的存在。这是为什么呢？因为我们的样本太少了，用判别模型是可以帮助我们在有限的数据样本中假象数据。 那用生成模型怎么做呢？ 所以判别模型的优势在于 样本量少的时候表现比判别模型好，因为它能自己脑补出一个假想模型 噪声对它影响较小，因为它没有过分依赖数据，它是按照自己假想模型走的 常见的生成模型和判别模型有哪些呢？生成模型 HMM（隐马尔可夫模型） 朴素贝叶斯 判别模型 逻辑回归 SVM（支持向量机） CRF（条件随机场） 最近邻 一般的神经网络 逻辑回归与深度学习逻辑回归解决多分类问题逻辑回归是解决分类问题的，实际中的问题大多是多分类的问题，多分类问题会用到softmax。 逻辑回归其实就是线性回归在外面加了个sigmoid激活函数（二分类）或者softmax激活函数（多分类）。 sigmoid激活函数 和 softmax函数的区别：通常在二分类中使用sigmoid作为最后的激活层。在多分类单标签中使用softmax作为激活层，取概率最高即可。多标签问题中使用sigmoid作为激活层，相当于把每一个类别都当成了二分类来处理。多分类问题解决 逻辑回归的局限性 用深度学习去解决这个问题这个怎么变换过来的啊？是需要用特征工程的方法的，而特征工程是需要我们人为地去建立一个特征函数去把这些点转化，实际上是比较难的，或者说比较费工夫的这个时候我们需要引入 深度学习","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"分类问题","slug":"分类问题","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"http://example.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"}]},{"title":"分类问题 Classification 案例一：神奇宝贝是水系还是普通系？","slug":"分类问题 Classification 案例一：神奇宝贝是水系还是普通系？","date":"2021-08-04T06:21:06.000Z","updated":"2021-08-06T14:47:11.946Z","comments":true,"path":"2021/08/04/分类问题 Classification 案例一：神奇宝贝是水系还是普通系？/","link":"","permalink":"http://example.com/2021/08/04/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%20Classification%20%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9A%E7%A5%9E%E5%A5%87%E5%AE%9D%E8%B4%9D%E6%98%AF%E6%B0%B4%E7%B3%BB%E8%BF%98%E6%98%AF%E6%99%AE%E9%80%9A%E7%B3%BB%EF%BC%9F/","excerpt":"","text":"@[TOC](分类问题 Classification) 概念：（从概率生成模型到判别模型）概率生成模型：由数据学习联合概率密度分布 P(X,Y) ，然后求出条件概率分布P(Y|X) 作为预测的模型。例如：朴素贝叶斯、隐马尔可夫（em算法）判别模型：由数据直接学习决策函数 Y=f(X) 或者条件概率分布 P(Y|X) 作为预测的模型。例如：k近邻法、感知机、决策树、逻辑回归、线性回归、最大熵模型、支持向量机(SVM)、提升方法、条件随机场（CRF） 分类问题的思路 分类问题及其解决方法的讨论 1. 首先，什么是分类问题？ 2. 接着，分类问题该如何解决呢？ 建立概率生成模型的步骤（以朴素贝叶斯分类器为例）step1：求先验概率step2：确定数据属于哪一个分布，用最大似然估计出分布函数的参数step3：求出后验概率 生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出 分类问题及其解决方法的讨论什么是分类问题？说白了 就是输入一个事务的一些参数特征，通过数学模型，可以得到这个东西是什么。 这也包括二分问题（结果是由两面）与多分问题。 案例：举个栗子，输入一个神奇宝贝，输出：他是属于什么属性的？ 这是一个典型的多分问题，因为属性有好几种啊。举个栗子，输入一个神奇宝贝图片，输出：他是可达鸭么？ 这是一个典型的二分问题，因为结果只有两种 是还是不是。举个栗子，假设有两个类别（水系和普通系），每个类别有不同的精灵，现在我抓到一个精灵，那么它是属于水系和普通系的概率分别是多少。这也是个典型的二分问题。 如何解决分类问题？如何解决二分问题？问题分析对于二分类问题，定义一个function也就是数学model，当输出函数值大于0就划分为类别1，否则就为类别2. 而损失函数定义为在测试数据上误分类的次数。 那这个function我到底怎么定义呢？实际上，可以将其定义为一个概率模型。它可以是一个条件概率模型 P(C1 | X),当 P(C1 | X) &gt; 0.5 ,比如在神奇宝贝二分问题中，我们定义X是这张图片的参数，而C1表示是可达鸭，整个的意思就变为了在这些图片参数的条件下这张图片是可达鸭的概率是多少，概率大于一半，说明确实很有可能就是可达鸭。或者对于第二个栗子，同样的可以规定**条件概率模型 *P(C2 | X)***，表示在捕捉了一个精灵后，他的参数条件下，是水系的概率是多少？（这边C2表示，捕捉的是水系） 这边我们以栗子2为例，假如我们捕捉了一只神奇宝贝(其实他就是可达鸭)，问他是水系的概率是多少？（理论上其实，他就是水系的，但机器需要通过概率论去推，需要包括以下的概率推导） 如上图所示： x就表示是可达鸭先验概率：这里是P(C1)——训练样本中的精灵是水系的概率;同理P(C2)——训练样本中的精灵是普通系的概率——————————————————————————————————————————————————————————————————*P(x | C1)*：这里是指在水系中是可达鸭的概率*P(x | C2)*：这里是指在普通系中是可达鸭的概率两者可以用最大似然估计法求出——————————————————————————————————————————————————————————————————后验概率：这里指抓到的神奇宝贝可达鸭是水系的概率。其用贝叶斯公式算出，公式如上图所示 求先验概率 P(C1)：训练样本中的精灵是水系的概率根据训练样本，分别算出水系和普通系的概率 选择概率分布函数，用最大似然估计出分布函数的参数（就是调参） 注： 当样本数据x取实数值时，采用正太分布(高斯分布) 当每种特征的数值都在0-1内时，采用伯努利分布 当每种特征取值在{1, 2 , 3 , …，K}，采用多项式分布（Multinomial Distribution） 首先，我们目标是求水系样本中的79个精灵中，抓到其中一种神奇宝贝的概率 P(x | C1) ，那么这个概率应该是跟精灵的属性有关的。这里我们选择两种属性（物防和法防）讨论，此时数据中（x,水系）中的x应该是一个神奇宝贝向量（[x1物防，x2法防] , 水系）。 2、然后，这里选择正太分布（二维）：也就是说在水系样本中的79个精灵中，抓到其中一种精灵的概率 P( x | C1) 呈正太分布。 接着，用最大似然估计法算出分布函数的参数似然函数L：x1,x2…x79同时出现的概率函数。最大似然估计：使似然函数最大时的参数估计。调整的参数最后求出后验概率 即P(C1 | x): 抓到的可达鸭是水系的概率利用的就是贝叶斯公式。整体每个部分的逻辑可以看下图所示：效果不好的解决方法 实验结果分类后，准确率并不高。理论上考虑其他因素，即增加维度可以增大准确率。但效果还是不佳，这该怎么办。实验结果 生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出回到如何用机器学习的三大步骤解决分类问题： 逻辑回归方法（判别模型）的引出 化简推到一下（纯数学）所以其实不用考虑，N1，N2，μ1，μ2，∑的值。 直接就是w和b两个参数，这也是为什么之前，我们将∑按权值分配后，图像由线性分类的原因。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"分类问题","slug":"分类问题","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"}]},{"title":"梯度下降算法 进阶","slug":"梯度下降算法 进阶","date":"2021-08-04T05:16:06.000Z","updated":"2021-08-04T12:49:04.332Z","comments":true,"path":"2021/08/04/梯度下降算法 进阶/","link":"","permalink":"http://example.com/2021/08/04/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%20%E8%BF%9B%E9%98%B6/","excerpt":"","text":"@[TOC](梯度算法 进阶) 回顾梯度算法是一种迭代的算法，每看一个参数都会更新。 学习率η（Learning Rate）自定义的学习率对参数选择的影响学习率需要选取合适的值，过小会导致模型调参的速度太慢，但过大会导致错失掉了最佳参数点 如何调整学习率η？ 在最开始的时候，随机点离目标点很远，我们一般会选取一个比较大的学习率；当做了几期后，我们离目标点很近了，所以我们会减小学习率 缩减为 如下图所示的公式 不同的参数应该设置不同的学习率 下面是常用的 调整学习率的方法： AdagradAdagrad是解决不同参数应该使用不同的更新速率的问题。Adagrad自适应地为各个参数分配不同学习率的算法。 其原理为：里面比较核心的部分在 每次σ的取值。每次σ规定为之前所有g平方对应的之和的均方根。例如下图所示：其中 g 是每次的偏导值结合之前说的 η 值的变化 可以得到如下的公式推导： 提问: 发现一个现象，本来应该是随着gradient的增大，我们的学习率是希望增大的，也就是图中的g上标t；但是与此同时随着gradient的增大，我们的分母是在逐渐增大，也就对整体学习率是减少的，这是为什么呢？这是因为随着我们更新次数的增大，我们是希望我们的学习率越来越慢。因为我们认为在学习率的最初阶段，我们是距离损失函数最优解很远的，随着更新的次数的增多，我们认为越来越接近最优解，于是学习速率也随之变慢。 为什么化简之后是如上这个式子呢，其在图像上的意义是 一阶导数比上二阶数的值。如下图所示： Stochastic Gradient Descent（SGD随机梯度下降法） ？？？其和 普通的梯度下降算法区别在。普通遍历在求和的时候需要浪费大量时间，进而去掉求和产生了随机梯度下降算法。和下图看到的一样： 只是要注意一下标准的梯度下降和随机梯度下降的区别： 标准下降时在权值更新前汇总所有样例得到的标准梯度，随机下降则是通过考察每次训练实例来更新（就是随机选择一些按顺序的后续样本点来，而不是全体数据）。 对于步长 η 的取值，标准梯度下降的 η 比随机梯度下降的大。因为标准梯度下降的是使用准确的梯度，理直气壮地走，随机梯度下降使用的是近似的梯度，就得小心翼翼地走，怕一不小心误入歧途南辕北辙了。 当损失函数有多个局部极小值时，随机梯度反而更可能避免进入局部极小值中。 小批量随机梯度下降（batch gradient descent）如果在每次迭代中，梯度下降是用整个训练数据集来计算梯度的话，则会带来大量的计算量。因此提出批量梯度下降来进行优化。每次优化不再是对整体数据集来计算损失，取而代之使用随机采样小批量的样本来计算梯度。 Feature Scaling （特征缩放）其意思就是说要将所有特征有相同的规模。例如下图所示，X2 的范围明显大宇 X1，所以要将 X2 进行缩放。 为什么要做Feature Scaling？ 为什么要做Feature Scaling？如左图，X1 和 X2 数值规模大小相差很大，那 W2 这参数的变动会极大的影响损失函数，而 W1 影响度就很小。所以我们需要对 X2 进行特征缩放，使其与 X1 保持一个规模。并且其实从图像可以看出，如果按左图来做的话，我们很难找到一组合适的参数集合，因为他梯度下降的方法不是直线的而是曲线；而右图是近乎直线。（最里面圈的损失函数最小） 如何实现Feature Scaling？ 如上图所示，假如有R个数据样本，每个样本有X1 - Xi 个特征。我们用上面的公式计算出其应该的scale（其实说实在的这不就是化成标准正太分布么） 梯度下降算法数学总结提出问题：如下图所示（我怎么样才能在红圈里找到最小损失的那个点呢） 首先要回顾泰勒公式二元泰勒： 用泰勒展开损失函数理解为点乘，反向180度的时候，损失函数才是最小的：最终可以表达成： 梯度下降算法缺点在哪其不仅仅包括可能有找到是局部最优解问题，有可能在中间的时候就有偏微分为0的时候，而这时这个点可能离全局最优解点 很远。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"模型误差的来源分析","slug":"模型误差的来源分析","date":"2021-08-02T05:16:06.000Z","updated":"2021-08-04T12:48:42.267Z","comments":true,"path":"2021/08/02/模型误差的来源分析/","link":"","permalink":"http://example.com/2021/08/02/%E6%A8%A1%E5%9E%8B%E8%AF%AF%E5%B7%AE%E7%9A%84%E6%9D%A5%E6%BA%90%E5%88%86%E6%9E%90/","excerpt":"","text":"@TOC 思路：1、首先，误差的两大来源 bias（偏差） 和 variance（方差） 是指什么2、然后，bias（偏差）和 variance（方差）是怎么产生的3、进一步，如何判断你的模型是 bias大（欠拟合）还是variance大（过拟合），如何解决 ？ 模型的两大来源bias（偏差）和variance（方差） 什么是bias和variance呢？思路： 首先要知道什么是误差 在了解什么是bias和variance 什么是误差？机器学习就是寻找一个函数，然后给它一个输入，就能得到一个理想的输出。f head是理论上找到的最佳函数，f star 是我们用模型预测出来的函数，两者的差值就是误差。 什么是bias和variance（偏差和方差）什么是bias（偏差）？举个栗子说明，下图是用一定样本数的均值m来估计假设的随机变量的平均值u，这是一种无偏估计（unbiased）。 也就是说，估计值的期望等于假设值（如上文的E(m)=u），即为无偏差，反之有偏差（bias）。当样本数越来越大时，m就越靠近u。 什么是variance（方差）方差表达的是数据的离散程度这里对于方差的估计是有差估计： 总结直观理解最后，bias和variance的直观理解： bias表示的是预测的f bar（f star预测值的期望）与f head（实际正确值）的距离 variance表示的是每次预测的f star（预测值）与f bar（预测值的期望）的距离（看图） bias和variance是怎么产生的 下面结合实际的实验说明，bias和variance是如何产生的。————————————————————————————————————————————————————bias如何知晓？，就要做多次实验，确定多个f star（一次实验一个预测值），然后求出f star 样本集的期望（E(f star)）那么首先，我们虚拟出100个神奇宝贝平行宇宙（相当于设置了100组实验），每个预祝一个神奇宝贝训练家捕捉10只神奇宝贝（相当于每组实验10个数据），如下图：然后思考，对于这样的数据，我们选用什么model比较好 ?哪一个model最后的bias比较小？如上图，不同宇宙的神奇宝贝数据非常随机，项次越高，模型越复杂 方差 variance对于方差而言，其表示结果的离散程度，项次越高，模型越复杂，则其离散程度肯定是越大的。因为模型越简单，收到数据的影响也就越低，比如：我极端一点，f(x)=c，数据根本不会影响model最后的预测值 偏差 bias图中看出，简单model可能并不包含目标，因此会造成较大的bias，而复杂的model是涵盖目标的，所以bias小。 偏差和方差的总结 简单的模型（次数小），bias会比较大，但variance会比较小，预测值更加集中。复杂的模型（次数大），bias会比较小，但variance会比较大，预测值更加的离散。因此，我们理想中的目标是找到一个平衡点，使bias和variance尽可能小。 判断你的模型是bias大（欠拟合）还是variance大（过拟合）并解决如何判断 bias过大（欠拟合）需要重新设计模型 模型考虑的特征没有全，也就是很多其实没有作用。关键特征可能还没考虑到，需要加入进去 模型应该需要更加的复杂，增加更高的次项。 variance过大（过拟合） 需要更多的数据，有些数据不够有特点 可以增加一个 正则项，加强模型的平滑度，使其预测值分布不要太离散 解决实际测试比共有数据集误差更大的问题将训练集，分为两部分。这叫做2-折交叉验证。一部分还是当做训练样本，帮助我们进行调参；另一部分用作验证，验证我的模型损失如何，是否合理（充当原来共有训练集的作用）。而现在原有训练集的部分用来充当实际样本数据，算出误差值，以便于真正在实际中误差太大。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"线性回归Regression 案例一：宝可梦进化CP值","slug":"线性回归Regression 案例一：宝可梦进化CP值","date":"2021-07-31T03:16:06.000Z","updated":"2021-08-04T12:49:26.964Z","comments":true,"path":"2021/07/31/线性回归Regression 案例一：宝可梦进化CP值/","link":"","permalink":"http://example.com/2021/07/31/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92Regression%20%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9A%E5%AE%9D%E5%8F%AF%E6%A2%A6%E8%BF%9B%E5%8C%96CP%E5%80%BC/","excerpt":"","text":"@[TOC](线性回归Regression 案例一：宝可梦进化CP值) 本栗子：预测Pokemon精灵攻击力。输入：进化前的CP值、物种（Bulbasaur）、血量（HP）、重量（Weight）、高度（Height）输出：进化后的CP值 实现回归的步骤（机器学习的步骤）Step1 确定一个model - 线性模型 输入的特征包括：进化前的CP值（Xcp）、物种（Bulbasaur）（Xs）、血量（HP）（Xhp）、重量（Weight）（Xw）、高度（Height）（Xh） 先从简单的单个特征 进化前的CP值（Xcp）开始（后面改进再考虑多个特征）。 Step2 goodness of function（函数优化）——损失函数 确定model后（案例为线性模型），开始训练数据（使用的为训练样本集） 训练10个训练样本后得到10个的预测进化CP值（y）如下图所示。左侧为训练样本本身真实的进化CP值，右侧为横轴为进化前CP值（Xcp） 确定损失函数。损失函数用于评价一个模型的好坏。损失函数的值越小，那么模型越好。对于本案例，损失函数采用最简单的距离表示。即求实际进化后的CP值与模型预测的CP值差，来判定模型的好坏。 List item Step3 best function（找出最好的一个函数 即调参）——使用梯度下降法 案例采用梯度下降法来帮助选择 w 和 b 两个参数取何值时损失函数最小，也就意味着构建的模型越准确。 什么是梯度下降法？梯度指的是？………………………………………………………………………………………………………梯度？在单变量的函数中，梯度其实就是对应点函数的微分，代表着这个函数在某个给定点的切线的斜率在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向 即例如二维就是 偏导 i + 偏导 j………………………………………………………………………………………………………梯度下降法(SGD Stochastic gradient descent）？答： “下山最快路径”的一种算法我们是尝试使用偏导来衡量函数随自变量的值变化关系，选择变化更为平缓的那一处 对应的 w 和 b 作为调整后的参数 一维视角：只考虑一个参数 w 如上图 learning rate（学习率）：移动的步长 一般用η来表示………………………………………………………………………………………………………如何寻找一个最合适的 w ？步骤1：随机在横轴上选取一个 w0 。步骤2：计算微分，也就是当前的斜率，根据斜率来判定移动的方向。微分大于0应向右移动（增加 w ）；微分小于0向左移动（减少 w ）步骤3：根据学习率，按步骤2得到的方向移动重复步骤2和步骤3，直到找到最低点。横轴即对于的最佳 w 参数………………………………………………………………………………………………………如下图，是经过迭代多次后找到的最佳点（得是全局最优解） 。注：大部分损失函数都为正 二维视角：考虑两个参数 w 和 b 如何寻找一个最合适的 w ？步骤1：随机在横轴上选取一个 w0 ，b0 。步骤2：计算各偏导，也就是当前偏导的斜率，根据斜率来判定移动的方向。微分大于0应向右移动（增加 w 或 b）；微分小于0向左移动（减少 w 或 b）步骤3：根据学习率，按步骤2得到的方向移动重复步骤2和步骤3，直到找到最低点。横轴即对于的最佳 w 和 b 参数 二维情况：梯度下降法的效果颜色约深的区域代表的损失函数越小？ 为什么呢？ 梯度算法的优缺点 总结一下梯度下降法： 我们要解决使损失函数L(w,b) 最小时参数的最佳值，梯度下降法是每次update参数值，直到损失函数最小时找到对应最佳的参数w，b 缺点1：求解的未必是全局最优解，有可能是局部最优解。 用下山的例子讲： 比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处。……………………………………………………………………………………………………… 从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。 优点1：无论随机从哪个点出发，得到的最佳参数一定是同一组 用下山的例子讲： 因为山只有一处是最低点，在确保能找到全局最优解的情况下，无论人从山上哪一点出发，一定能找到这特定一处的最低洼处。 Step4 回归结果分析 经过上述三个步骤后，得到了训练后的“最佳参数w，b”，那么现在这个模型在测试集上是什么表现呢？得到的结果是：测试集的误差比在训练集上得到的损失值大 这个事非常正常。因为你训练集里面可能有些数据是不典型的，同样测试集中很多也包含了训练集中没有的因素。所以一个函数模型在实际应用中，效果基本上时打折扣的。一般会采用两种方式来加强这个函数模型： select another model（选择另一个模型）即增加维度，增加高此项多项式 consider the hidden factors（考虑其他隐藏因素） 优化模型方法一：增加高次项（一般用于拟合度不够的情况）回到Step1 尝试二次项、三次项、四次项、五次项…… 右上图为训练集损失，下图是测试集的损失。第五次过拟合导致了，测试集损失度很高。 选择合适的模型，即我到底要加到几次项呢？ 越复杂的模型所包含的函数也就越多，那么它包含理想模型的可能性也就越大，但是如果过分地去拟合理想模型，就会出现过拟合的情况。 横向比较各个多项次，训练集和测试集的失误。理论上，失误会随着高次项而变小，如果变大，则表示模型过拟合了。所以，如上图所示，在为3次的时候，训练集和测试集的误差差值最小。并且4次开始，以及存在过拟合现象了。因此本案例可选择3次项线性模型。 优化模型方法二：考虑其他隐藏因素回到Step1 输入的特征包括：进化前的CP值（Xcp）、物种（Bulbasaur）（Xs）、血量（HP）（Xhp）、重量（Weight）（Xw）、高度（Height）（Xh）除了之前考虑的进化前的CP值（Xcp），其他均为隐藏因素………………………………………………………………………………这里另外考虑的是神奇宝贝的种类？因为，有时候一个模型恰恰只能符合一种神奇宝贝，也就是不同神奇宝贝应该有不同的预测模型。 不同的神奇宝贝有不同的预测模型 拟合这个模型的曲线，可以看出不同神奇宝贝拟合成了不同的类线性直线 如果还考虑了其他隐藏元素。如图是横轴是对应的隐藏元素，纵轴是对应进化后的CP值。 如果都采用最高二次项，考虑所有其他的隐藏因素。该案例的数学模型就变成 如图所示的式子。 考虑更多的因素反而出现了过拟合的问题，说明有些因素跟本次实验的CP值预测没有关系！………………………………………………………………………………过拟合这么讨厌，到底如何减少过拟合问题呢？往下看！ 优化模型：防止过拟合（为损失函数加一个正则项）正则项是什么? 方法：正则化?比如先考虑一个参数w，正则化就是在损失函数上加上一个与w（斜率）相关的值（正则项），那么要是loss function越小的话，w也会越小，w越小就使function更加平滑（function没那么大跳跃） 正则化的缺点正则化虽然能够减少过拟合的现象，但是因为加在损失函数后面的值是平白无故加上去的，所以正则化过度的话会导致bias偏差增大 ？？？？ 总结 1）实现参数的稀疏有什么好处吗？一个好处是可以简化模型，避免过拟合。因为一个模型中真正重要的参数可能并不多，如果考虑所有的参数起作用，那么可以对训练数据可以预测的很好，但是对测试数据表现性能极差。另一个好处是参数变少可以使整个模型获得更好的可解释性。2）参数值越小代表模型越简单吗？是的。为什么参数越小，说明模型越简单呢，这是因为越复杂的模型，越是会尝试对所有的样本进行拟合，甚至包括一些异常样本点，这就容易造成在较小的区间里预测值产生较大的波动，这种较大的波动也反映了在这个区间里的导数很大，而只有较大的参数值才能产生较大的导数。因此复杂的模型，其参数值会比较大。","categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"线性回归","slug":"线性回归","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}]}],"categories":[{"name":"机器学习基础-李宏毅","slug":"机器学习基础-李宏毅","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E6%9D%8E%E5%AE%8F%E6%AF%85/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"李宏毅","slug":"李宏毅","permalink":"http://example.com/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/"},{"name":"CNN","slug":"CNN","permalink":"http://example.com/tags/CNN/"},{"name":"卷积核","slug":"卷积核","permalink":"http://example.com/tags/%E5%8D%B7%E7%A7%AF%E6%A0%B8/"},{"name":"过滤器","slug":"过滤器","permalink":"http://example.com/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"name":"Maxpooling","slug":"Maxpooling","permalink":"http://example.com/tags/Maxpooling/"},{"name":"模型优化","slug":"模型优化","permalink":"http://example.com/tags/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/"},{"name":"反向传播","slug":"反向传播","permalink":"http://example.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"分类问题","slug":"分类问题","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"http://example.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"线性回归","slug":"线性回归","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}]}