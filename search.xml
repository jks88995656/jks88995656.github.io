<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>/2023/03/20/HTML%20%E7%9A%84%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="HTML-的前端面试题"><a href="#HTML-的前端面试题" class="headerlink" title="HTML 的前端面试题"></a>HTML 的前端面试题</h1><h2 id="考点1：对-html5-的理解"><a href="#考点1：对-html5-的理解" class="headerlink" title="考点1：对 html5 的理解"></a>考点1：对 html5 的理解</h2><h3 id="面试题：谈一谈你对-html5-中标签语义化的理解"><a href="#面试题：谈一谈你对-html5-中标签语义化的理解" class="headerlink" title="面试题：谈一谈你对 html5 中标签语义化的理解"></a>面试题：谈一谈你对 html5 中标签语义化的理解</h3><p>html 语义化是用正确的标签做正确的事情。有三大好处：</p>
<ul>
<li><p>结构清晰：html 语义化让页面的内容结构化，即使在没有样式 CSS 情况下也以一种文档格式显示，并且是容易阅读的。</p>
</li>
<li><p>SEO：有利于 SEO ，可以让搜索引擎更好地获取到更多有效信息，搜索引擎的爬虫依赖于标签来确定上下文和各个关键字的权重，有效提升网页的搜索量。</p>
</li>
<li><p>可维护性：使阅读源代码的人对网站更容易将网站分块，便于阅读维护理解。</p>
</li>
</ul>
<p><img src="https://uploadfiles.nowcoder.com/images/20220301/4107856_1646121492395/44B73F2E744FF268279D16601DB2CBC8" alt=""></p>
<h3 id="面试题：说一说-html-语义化的标签有哪些"><a href="#面试题：说一说-html-语义化的标签有哪些" class="headerlink" title="面试题：说一说 html 语义化的标签有哪些"></a>面试题：说一说 html 语义化的标签有哪些</h3><p>记住几个好记的就可以了</p>
<p>header，nav，section，aside，footer等及其作用</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">header</span>&gt;</span>     <span class="comment">&lt;!--：页眉通常包括网站标志、主导航、全站链接以及搜索框。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">nav</span>&gt;</span>         <span class="comment">&lt;!--：标记导航，仅对文档中重要的链接群使用。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span>    <span class="comment">&lt;!--：定义文档中的节（section、区段）。比如章节、页眉、页脚或文档中的其他部分。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">aside</span>&gt;</span>         <span class="comment">&lt;!--：定义其所处内容之外的内容。如侧栏、文章的一组链接、广告、友情链接、相关产品列表等。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">footer</span>&gt;</span>     <span class="comment">&lt;!--：页脚，只有当父级是body时，才是整个页面的页脚。--&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="面试题：说一说-html5-的几个特性"><a href="#面试题：说一说-html5-的几个特性" class="headerlink" title="面试题：说一说 html5 的几个特性"></a>面试题：说一说 html5 的几个特性</h3><ul>
<li><p>绘画 canvas： HTML5 的一个新元素，它使用 JavaScript 在网页上绘制图形。</p>
</li>
<li><p>video 和 audio：用于视频和音频的播放。</p>
</li>
<li><p>本地离线存储：localStorage 长期存储数据，浏览器关闭后数据不丢失。sessionStorage 的数据在浏览器关闭后自动删除。</p>
</li>
<li><p>新的结构标签：语义化更好的内容元素，比如 article，footer，header，nav，section。</p>
</li>
<li><p>增强表单：input 的type 属性值新增 calendar,date,time,email,url 等。</p>
</li>
<li><p>新的技术 webworker，websocket，Geolocation</p>
</li>
</ul>
<h2 id="考点2：标签类型"><a href="#考点2：标签类型" class="headerlink" title="考点2：标签类型"></a>考点2：标签类型</h2><h3 id="面试题：块级元素、行内元素和空元素的理解，分别举例子？"><a href="#面试题：块级元素、行内元素和空元素的理解，分别举例子？" class="headerlink" title="面试题：块级元素、行内元素和空元素的理解，分别举例子？"></a>面试题：块级元素、行内元素和空元素的理解，分别举例子？</h3><ul>
<li><p><strong>块级元素：总是在新行上开始</strong>；高度，行高以及外边距和内边距都可控制；宽度缺省是它的容器的 100%， 除非设定一个宽度。它可以容纳内联元素和其他块元素。</p>
<p>块级元素标签有：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>至<span class="tag">&lt;<span class="name">h6</span>&gt;</span>，<span class="tag">&lt;<span class="name">div</span>&gt;</span>，<span class="tag">&lt;<span class="name">p</span>&gt;</span>，<span class="tag">&lt;<span class="name">ul</span>&gt;</span>，<span class="tag">&lt;<span class="name">ol</span>&gt;</span>，<span class="tag">&lt;<span class="name">li</span>&gt;</span>，<span class="tag">&lt;<span class="name">dl</span>&gt;</span>，<span class="tag">&lt;<span class="name">dt</span>&gt;</span>，<span class="tag">&lt;<span class="name">dd</span>&gt;</span>，</span><br><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span>，<span class="tag">&lt;<span class="name">article</span>&gt;</span>，<span class="tag">&lt;<span class="name">aside</span>&gt;</span>，<span class="tag">&lt;<span class="name">audio</span>&gt;</span>，<span class="tag">&lt;<span class="name">video</span>&gt;</span>，<span class="tag">&lt;<span class="name">footer</span>&gt;</span>，<span class="tag">&lt;<span class="name">header</span>&gt;</span>，<span class="tag">&lt;<span class="name">nav</span>&gt;</span>， <span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>行内元素：和其他元素都在一行上；</strong> 高，行高及外边距和内边距不可改变； 宽度就是它的文字或图片的宽度，不可改变； 内联元素只能容纳文本或者其他内联元素； 设置宽度 width 无效。 设置高度 height 无效，可以通过 line-height 来设置。 设置 margin 只有左右margin 有效，上下无效。 设置 padding 只有左右 padding 有效，上下则无效。</p>
<p>常见的行内元素标签有：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span>&gt;</span>，<span class="tag">&lt;<span class="name">span</span>&gt;</span>，<span class="tag">&lt;<span class="name">strong</span>&gt;</span> ，<span class="tag">&lt;<span class="name">i</span>&gt;</span>，<span class="tag">&lt;<span class="name">b</span>&gt;</span>，<span class="tag">&lt;<span class="name">button</span>&gt;</span>，<span class="tag">&lt;<span class="name">textarea</span>&gt;</span>，<span class="tag">&lt;<span class="name">em</span>&gt;</span>，</span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>，<span class="tag">&lt;<span class="name">select</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>空元素：没有闭合标签的标签被称作为空标签。</strong></p>
<p>常见的空元素标签有：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">input</span> /&gt;</span> <span class="tag">&lt;<span class="name">img</span> /&gt;</span><span class="tag">&lt;<span class="name">hr</span>/&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="考点3：标签-Iframe"><a href="#考点3：标签-Iframe" class="headerlink" title="考点3：标签 Iframe"></a>考点3：标签 Iframe</h2><h3 id="面试题：为什么要少用-Iframe-标签，它的缺点是什么？"><a href="#面试题：为什么要少用-Iframe-标签，它的缺点是什么？" class="headerlink" title="面试题：为什么要少用 Iframe 标签，它的缺点是什么？"></a>面试题：为什么要少用 Iframe 标签，它的缺点是什么？</h3><ol>
<li><p>iframe 会阻塞主页面的 onload 事件；</p>
</li>
<li><p>iframe 和主页面共享连接池，而浏览器对相同域的连接有限制，所以会影响页面的并行加载，会产生很多页面，不容易管理。</p>
</li>
<li><p>如果框架个数多的话，可能会出现上下、左右滚动条，会分散访问者的注意力，用户体验度差。</p>
</li>
<li><p><strong>代码复杂，无法被一些搜索引擎索引到，这一点很关键，现在的搜索引擎爬虫还不能很好的处理 iframe 中的内容，所以使用 iframe 会不利于搜索引擎优化（SEO）。</strong></p>
</li>
<li><p>很多的移动设备无法完全显示框架，设备兼容性差。</p>
</li>
<li><p><strong>iframe 框架页面会增加服务器的 http 请求，对于大型网站是不可取的</strong>。</p>
</li>
</ol>
<h2 id="考点4：本地存储"><a href="#考点4：本地存储" class="headerlink" title="考点4：本地存储"></a>考点4：本地存储</h2><h3 id="面试题：-cookie、localstroage、sessionStorage-的区别？以及对应的优缺点？"><a href="#面试题：-cookie、localstroage、sessionStorage-的区别？以及对应的优缺点？" class="headerlink" title="面试题： cookie、localstroage、sessionStorage 的区别？以及对应的优缺点？"></a>面试题： cookie、localstroage、sessionStorage 的区别？以及对应的优缺点？</h3><ul>
<li><p>cookie：是服务器发给客户端的特殊信息，以文本形式存储在客户端，<strong>每次请求都会带上 cookie</strong>。cookie 的保存时间：设置过期时间，浏览器关闭后不会清除，保存在硬盘中, 过期时间到期后失效。如果不设置过期时间，保存在内存中, 浏览器关闭后消失。</p>
<p>其缺点在于：</p>
<ol>
<li><p>大小受限，单个 cookie 大小不能超过 4kb</p>
</li>
<li><p>用户可以禁用 cookie, 使功能受限。</p>
</li>
<li><p>安全性较低，有些状态不能保存在客户端。</p>
</li>
<li>每次访问都要传送 cookie 给服务器，浪费带宽</li>
<li>cookie 数据有路径（path）的概念，可以限制 cookie 只属于某个路径下。</li>
</ol>
</li>
<li><p><code>localStorage</code> 和 <code>sessionStorage</code> 存储大小都是 5MB，都保存在客户端不与服务器端进行交互，只能储存字符串类型，对于复杂的 <code>json</code> 格式可以进行 <code>stringify</code> 和 <code>parse</code> 来处理。</p>
<p>区别是 <code>localStorage</code> 是永久储存, 除非主动删除, 否则不会消失；</p>
<p>而 <code>sessionStroage</code> 的有效期只是网页在浏览器打开到关闭的时间段。</p>
</li>
</ul>
<h2 id="考点5：前端基础概念问题"><a href="#考点5：前端基础概念问题" class="headerlink" title="考点5：前端基础概念问题"></a>考点5：前端基础概念问题</h2><h3 id="面试题：什么是防抖和节流？有什么区别？"><a href="#面试题：什么是防抖和节流？有什么区别？" class="headerlink" title="面试题：什么是防抖和节流？有什么区别？"></a>面试题：什么是防抖和节流？有什么区别？</h3><p>函数防抖和函数节流：<strong>优化高频率执行js代码的一种手段</strong>，js中的一些事件如浏览器的resize、scroll，鼠标的mousemove、mouseover，input输入框的keypress等事件在触发时，会不断地调用绑定在事件上的回调函数，极大地浪费资源，降低前端性能。<strong>为了优化体验，需要对这类事件进行调用次数的限制</strong></p>
<p>举个生活种的例子就是，比如你在做联想输入，需要根据输入，进行联想。你每次输入一个数字，他都会去响应调用服务器请求联想数据给你在下面显示，你要是打字打的太快，他跟不上啊！</p>
<ul>
<li><p><strong>防抖：</strong>把中间的处理函数全部过滤掉了，<strong>只执行在规定时间内的最后一个事件</strong></p>
<p>比如我设置一个时间例如 200ms</p>
<ul>
<li>如果在200ms内没有再次触发事件，那么就执行对应的处理函数</li>
<li>如果在200ms内再次触发事件，那么当前的计时取消，重新开始计时</li>
</ul>
<p>一般是定义一个 debounce 函数，其是由闭包进行实现的：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里的 fn 也就是 我们的 事件对应的处理函数</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">debounce</span>(<span class="params">fn,delay</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> timer = <span class="literal">null</span> <span class="comment">//借助闭包</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(timer)&#123;</span><br><span class="line"><span class="comment">//进入该分支语句，说明当前正在一个计时过程中，并且又触发了相同事件。所以要取消当前的计时，重新开始计时</span></span><br><span class="line">            <span class="built_in">clearTimeout</span>(timer) </span><br><span class="line">        &#125;</span><br><span class="line">        timer = <span class="built_in">setTimeout</span>(fn,delay)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>节流：中间的处理函数被时间限制，<strong>只能在一段时间中执行一次</strong>。但是<strong>只是减少了频率</strong></p>
<p>一般是定义一个 throttle函数，其也是由闭包进行实现的：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">throttle</span>(<span class="params">fn,delay</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> valid = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">       <span class="keyword">if</span>(!valid)&#123;</span><br><span class="line">           <span class="comment">//休息时间 暂不工作</span></span><br><span class="line">           <span class="keyword">return</span> <span class="literal">false</span> </span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">// 工作时间，执行函数并且在间隔期内把状态位设为无效</span></span><br><span class="line">        valid = <span class="literal">false</span></span><br><span class="line">        <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">            fn()</span><br><span class="line">            valid = <span class="literal">true</span>;</span><br><span class="line">        &#125;, delay)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>连续的事件，只需触发一次回调的场景有：</p>
<ul>
<li>搜索框搜索输入。只需用户最后一次输入完，再发送请求</li>
<li>手机号、邮箱验证输入检测</li>
<li>窗口大小Resize。只需窗口调整完成后，计算窗口大小。防止重复渲染。</li>
</ul>
<p>函数节流的应用场景:</p>
<p>间隔一段时间执行一次回调的场景有：</p>
<ul>
<li>滚动加载，加载更多或滚到底部监听</li>
<li>谷歌搜索框，搜索联想功能</li>
<li>高频点击提交，表单重复提交</li>
</ul>
</blockquote>
<h3 id="面试题：html标签中的-src-和-href-有什么区别？"><a href="#面试题：html标签中的-src-和-href-有什么区别？" class="headerlink" title="面试题：html标签中的 src 和 href 有什么区别？"></a>面试题：html标签中的 src 和 href 有什么区别？</h3><ul>
<li><p>href是超文本引用，它是指向资源的位置，建立与目标文件的联系</p>
<p>浏览器解析<font color="blue"><strong>href不会阻塞对文档的处理</strong></font>（这就是官方建议使用link引入而不是@import的原因）</p>
</li>
<li><p>src目的是把资源下载到页面中</p>
<font color="red">**src会阻塞对文档的处理**。</font>



</li>
</ul>
<h3 id="面试题：script标签中-defer-和-async-的区别"><a href="#面试题：script标签中-defer-和-async-的区别" class="headerlink" title="面试题：script标签中 defer 和 async 的区别"></a>面试题：script标签中 defer 和 async 的区别</h3><ul>
<li><p>defer <strong>浏览器指示脚本在文档被解析后执行</strong>，<strong>script被异步加载后并不会立即执行，而是等待文档被解析完毕后执行</strong></p>
<p>defer只适用于外联脚本，例如如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;x.min.js&quot;</span> <span class="attr">defer</span>=<span class="string">&quot;defer&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><font color="blue"><strong>如果有多个声明了defer的脚本，则会按顺序下载和执行</strong>。</font>defer脚本会在<strong>DOMContentLoaded</strong> 和 <strong>load</strong>事件 之前执行</p>
</li>
<li><p>async 为是<strong>脚本加载完毕后立即执行</strong></p>
<p>async 也只适用于外联脚本，例如如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;x.min.js&quot;</span> <span class="attr">async</span>=<span class="string">&quot;async&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>其下载和执行也是异步的，<strong>不能确保 多个声明async的脚本 彼此的先后顺序</strong>。所以 async 脚本与<strong>DOMContentLoaded</strong> 的先后执行顺序，是不可预知的。</p>
</li>
</ul>
<h3 id="面试题：html页面渲染过程？"><a href="#面试题：html页面渲染过程？" class="headerlink" title="面试题：html页面渲染过程？"></a>面试题：html页面渲染过程？</h3><p>以下四个步骤是浏览器进行页面渲染的基本流程</p>
<ol>
<li>解析 HTML 和 CSS：浏览器首先将 HTML 和 CSS 解析成 DOM（文档对象模型）和 CSSOM（CSS 对象模型）两个树形结构，这两个结构合并后便构成了渲染树（Render Tree）。</li>
<li>布局：浏览器根据渲染树中每个元素的位置和大小计算出它们在屏幕上的实际位置，这个过程叫做布局（Layout），也称为回流（Reflow）。</li>
<li>绘制：浏览器根据渲染树和布局计算出来的元素位置和大小，将它们绘制到屏幕上，这个过程叫做绘制（Paint）。</li>
<li>合成：浏览器将绘制好的层按照它们的层级关系合成成最终的图像，并显示在屏幕上。</li>
</ol>
<p><strong>另外需要理解 重绘和重排</strong></p>
<p>重绘：重绘是改变不影响元素的网页中的位置的元素样式（重绘不会带来重新布局，所以并不一定伴随重排）</p>
<p>重排：渲染绘制，即根据计算好的信息绘制整个页面，渲染出最终的页面。</p>
<p><strong>重绘不一定需要重排，重排必然导致重绘</strong></p>
]]></content>
  </entry>
  <entry>
    <title>AlexNet 元老 开创的创新点</title>
    <url>/2021/10/29/AlexNet%20%E5%85%83%E8%80%81%20%E5%BC%80%E5%88%9B%E7%9A%84%E5%88%9B%E6%96%B0%E7%82%B9/</url>
    <content><![CDATA[<p>@<a href="AlexNet 元老 开创的创新点">TOC</a></p>
<h1 id="创新点1：CNN-卷积神经网络"><a href="#创新点1：CNN-卷积神经网络" class="headerlink" title="创新点1：CNN 卷积神经网络"></a>创新点1：CNN 卷积神经网络</h1><p>这个就不用说了 CNN 都懂的啊</p>
<h1 id="创新点2：relu激活函数"><a href="#创新点2：relu激活函数" class="headerlink" title="创新点2：relu激活函数"></a>创新点2：relu激活函数</h1><p>relu 是一个 非饱和的激活函数。用公式来说就是：</p>
<script type="math/tex; mode=display">f(x) = max (0 , x )</script><p>饱和函数最大的问题在，他左右两边随自变量的变化，应变量变化缓慢。换句话就是说，他的梯度变化基本没有，甚至有可能是0。这就有可能导致梯度消失（如果是0的话），或者训练时间很长，且收敛效果不佳。</p>
<h1 id="创新点3：双GPU模型并行"><a href="#创新点3：双GPU模型并行" class="headerlink" title="创新点3：双GPU模型并行"></a>创新点3：双GPU模型并行</h1><p>作者使用这个完全是因为当年的GPU的内存实在太小了。那对于现在来说这并不是什么问题，但是这个思想可以参考。<br><img src="https://img-blog.csdnimg.cn/img_convert/2addade07ed13528e4c86bdc62d8b5dc.png#pic_center" alt="AlexNet的网络结构"></p>
<h1 id="创新点4：LRN局部响应归一化"><a href="#创新点4：LRN局部响应归一化" class="headerlink" title="创新点4：LRN局部响应归一化"></a>创新点4：LRN局部响应归一化</h1><p>其提出的目的，是作者认为，每个通道的像素点不应该过高的激活，过高的激活可能就会导致 <strong>其他通道的对应像素点激活被抑制</strong>。这就好像，生物学上，你过分的激活了对顶芽的生长，就会抑制其侧芽的生长一样。</p>
<p>其作用在AlexNet的前两个卷积层，顺序为 Relu之后为LRN再 MaxPooling</p>
<p>他整体的思路如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/fa9ffa5a4bcf383a94fcb9f0f7f5d496.png#pic_center" alt="LRN描述"><br>上面相当于其查看了其附近两个通道的，公式就是上面红色的部分。其具体的计算公式如右图所示（其参数意思看下图）<br><img src="https://img-blog.csdnimg.cn/img_convert/c0ed720c1d6fb8a5a998d12f1aee458c.png#pic_center" alt="LRN 公式参考"></p>
<p><font color="red">但这个方法 被后来的VGG证实没有啥用，就是其根本就不起作用。用了还占内存</font><br>其实想想看确实没啥用，Relu函数作为一个非饱和激活函数，其压根不需要normalization啊。normalization的意思是将数据统一在中间区域内，本质的含义其实就是为了让他避免饱和区啦。</p>
<h1 id="创新点5：重叠池化-overlapping-pooling"><a href="#创新点5：重叠池化-overlapping-pooling" class="headerlink" title="创新点5：重叠池化 overlapping pooling"></a>创新点5：重叠池化 overlapping pooling</h1><p>作者认为可以 防止过拟合。 现在没人用了。<br><img src="https://img-blog.csdnimg.cn/img_convert/fa0b6df532ca6ec291650ea1cc13ca44.png#pic_center" alt="重叠池化"></p>
<h1 id="创新点6：防止过拟合之数据增强"><a href="#创新点6：防止过拟合之数据增强" class="headerlink" title="创新点6：防止过拟合之数据增强"></a>创新点6：防止过拟合之数据增强</h1><p>其提供了两种数据增强的方式。 注意：这个完全可以由CPU来做，所以作者在训练上一个batch的时候，已经准备好了下一次batch所需要的图像数据。</p>
<ol>
<li>第一种就是图像翻转，裁剪等（平移和水平翻转）<br><img src="https://img-blog.csdnimg.cn/img_convert/8a93f605bc3e15d5edda9ad9893c5fc0.png#pic_center" alt="图像翻转，裁剪"></li>
<li>颜色变换。<br> 其使用了PCA的方式先提取了一下他的主成分。他的意思是我在其主成分的基础上进行一定的调整颜色和光照强度和亮度，这样的话可以使我生成的图片更加的自然。具体可以看下面的公式：<br><img src="https://img-blog.csdnimg.cn/img_convert/a6c26321e94e016760b8adc7858da580.png#pic_center" alt="颜色变换的公式"></li>
</ol>
<h1 id="创新点7：防止过拟合之Dropout"><a href="#创新点7：防止过拟合之Dropout" class="headerlink" title="创新点7：防止过拟合之Dropout"></a>创新点7：防止过拟合之Dropout</h1><p>这个非常有用。现在还在用。<br>其大致的意思就是，训练阶段每一个batch随机掐死一半的神经元（也就是将神经元的输出设置为0 即其在前向和反向传播中均不起作用）。<br>在预测阶段，保留所有神经元。<br>这里还是要具体了解一下，暂时我还不知道具体原理啥的。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Keras  MNIST（数字识别）数据集分类（普通全神经网络）</title>
    <url>/2021/08/30/Keras%20%20MNIST%EF%BC%88%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%89%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E7%B1%BB%EF%BC%88%E6%99%AE%E9%80%9A%E5%85%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%89/</url>
    <content><![CDATA[<p>@<a href="Keras  MNIST（数字识别）数据集分类">TOC</a></p>
<h1 id="导入需要的包"><a href="#导入需要的包" class="headerlink" title="导入需要的包"></a>导入需要的包</h1><p>首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span>  Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(matplotlib.get_backend())</span><br></pre></td></tr></table></figure>
<h1 id="载入MNIST-数据"><a href="#载入MNIST-数据" class="headerlink" title="载入MNIST 数据"></a>载入MNIST 数据</h1><p>该数据集一共有训练集 6w 张，测试集 1w 张<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(train_images,train_labels),(test_images,test_labels)= mnist.load_data()</span><br></pre></td></tr></table></figure></p>
<p>可以查看一下图像和标签  是什么</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数字5</span></span><br><span class="line"><span class="built_in">print</span>(train_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签5</span></span><br><span class="line"><span class="built_in">print</span>(train_labels[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 数字7</span></span><br><span class="line"><span class="built_in">print</span>(test_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签7</span></span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>可以 打印 一下图片 看看是什么样子<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow(test_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/a745fc12bef94f93b93f80b2e89bb0d0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="图片数据处理"><a href="#图片数据处理" class="headerlink" title="图片数据处理"></a>图片数据处理</h1><h2 id="查看图片原有-shape"><a href="#查看图片原有-shape" class="headerlink" title="查看图片原有 shape"></a>查看图片原有 shape</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train_images (60000, 28, 28)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images&#x27;</span>, train_images.shape)</span><br><span class="line"><span class="comment"># train_labels (60000,)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>, train_labels.shape)</span><br></pre></td></tr></table></figure>
<h2 id="图片数据处理：将图片压平"><a href="#图片数据处理：将图片压平" class="headerlink" title="图片数据处理：将图片压平"></a>图片数据处理：将图片压平</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line"><span class="comment"># 将 (60000, 28, 28) -&gt; (60000, 784)  压平图片</span></span><br><span class="line">train_images_scale = train_images.reshape(train_images.shape[<span class="number">0</span>], train_images.shape[<span class="number">1</span>] * train_images.shape[<span class="number">2</span>])/<span class="number">255.0</span></span><br><span class="line">test_images_scale = test_images.reshape(test_images.shape[<span class="number">0</span>], test_images.shape[<span class="number">1</span>] * test_images.shape[<span class="number">2</span>])/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_images变换后 (60000, 784)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images变换后&#x27;</span>, train_images_scale.shape)</span><br><span class="line"><span class="comment"># test_images变换后 (10000, 784)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_images变换后&#x27;</span>, test_images_scale.shape)</span><br></pre></td></tr></table></figure>
<h2 id="标签数据处理：转换成-one-hot-格式"><a href="#标签数据处理：转换成-one-hot-格式" class="headerlink" title="标签数据处理：转换成 one hot 格式"></a>标签数据处理：转换成 one hot 格式</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 换 one hot 格式  共十个分类</span></span><br><span class="line"><span class="comment"># np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。</span></span><br><span class="line">train_labels_hot = np_utils.to_categorical(train_labels,num_classes=<span class="number">10</span>)</span><br><span class="line">test_labels_hot = np_utils.to_categorical(test_labels,num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_labels (60000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>,train_labels_hot.shape)</span><br><span class="line"><span class="comment"># test_labels (10000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_labels&#x27;</span>,test_labels_hot.shape)</span><br></pre></td></tr></table></figure>
<h1 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h1><p>只有输入和输出层， 输入压平图像 维度为784   输出为 10分类<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 输入压平图像 维度为784   输出为 10分类</span></span><br><span class="line">model.add(Dense(units=<span class="number">10</span>,input_dim=<span class="number">784</span>,bias_initializer=<span class="string">&quot;one&quot;</span>,activation=<span class="string">&quot;softmax&quot;</span>))</span><br></pre></td></tr></table></figure><br>优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重新定义 sgd 优化器  加速一下学习率</span></span><br><span class="line">sgd = SGD(learning_rate=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= sgd,loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,metrics=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p> 一共 60000张训练图片 按批次训练 一批次32张   一共6w/32 = 1875 个批次<br>训练完一轮6w张，表示一个epoch<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一共 60000张训练图片 按批次训练 一批次32张   一共6w/32 = 1875 个批次</span></span><br><span class="line"><span class="comment"># 训练完一轮6w张，表示一个epoch</span></span><br><span class="line">model.fit(train_images_scale,train_labels_hot,batch_size=<span class="number">32</span>,epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/576f033299d04330a371c33eb6a2abac.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="训练过程"></p>
<h1 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h1><p>就是在 测试集上的表现<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/eb52f38d3e944137a3ade6e5b9d1e1a9.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="预测数据"><a href="#预测数据" class="headerlink" title="预测数据"></a>预测数据</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 看下输入的形状</span></span><br><span class="line"><span class="built_in">print</span>(test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">784</span>).shape)</span><br><span class="line"><span class="comment"># 模型预测  输出每个分类的 概率</span></span><br><span class="line"><span class="built_in">print</span>(model.predict((test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">784</span>))))</span><br><span class="line"><span class="comment"># 选取最大的那个 就是预测的标签</span></span><br><span class="line"><span class="built_in">print</span>(np.argmax(model.predict((test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">784</span>)))))</span><br><span class="line"><span class="comment"># 实际该图片的 标签</span></span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输入的图像 变换后形状<br><img src="https://img-blog.csdnimg.cn/4302df2ba0e44c04897aaf00f6955dad.png#pic_center" alt="在这里插入图片描述"><br>模型预测 数据 输出的概率分类结果<br><img src="https://img-blog.csdnimg.cn/3ffa135e578d486c8404588781678e0c.png#pic_center" alt="在这里插入图片描述"><br>选出其中最大的 以及 实际图片标签 均为 数字7<br><img src="https://img-blog.csdnimg.cn/5a585701d439431aa1853283c8592b46.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title>Keras  RNN 实现 MNIST 手写数字识别</title>
    <url>/2021/09/04/Keras%20%20RNN%20%E5%AE%9E%E7%8E%B0%20MNIST%20%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<p>@<a href="Keras  RNN 实现 MNIST 手写数字识别">TOC</a></p>
<p>我们就以 MNIST数据集的手写识别 为例子</p>
<h1 id="导入需要的包"><a href="#导入需要的包" class="headerlink" title="导入需要的包"></a>导入需要的包</h1><p>首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span>  Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers.recurrent <span class="keyword">import</span> SimpleRNN</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(matplotlib.get_backend())</span><br></pre></td></tr></table></figure>
<h1 id="载入MNIST-数据"><a href="#载入MNIST-数据" class="headerlink" title="载入MNIST 数据"></a>载入MNIST 数据</h1><p>该数据集一共有训练集 6w 张，测试集 1w 张<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(train_images,train_labels),(test_images,test_labels)= mnist.load_data()</span><br></pre></td></tr></table></figure></p>
<p>可以查看一下图像和标签  是什么</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数字5</span></span><br><span class="line"><span class="built_in">print</span>(train_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签5</span></span><br><span class="line"><span class="built_in">print</span>(train_labels[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 数字7</span></span><br><span class="line"><span class="built_in">print</span>(test_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签7</span></span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>可以 打印 一下图片 看看是什么样子<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow(test_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/a745fc12bef94f93b93f80b2e89bb0d0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="图片数据处理"><a href="#图片数据处理" class="headerlink" title="图片数据处理"></a>图片数据处理</h1><h2 id="查看图片原有-shape"><a href="#查看图片原有-shape" class="headerlink" title="查看图片原有 shape"></a>查看图片原有 shape</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train_images (60000, 28, 28)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images&#x27;</span>, train_images.shape)</span><br><span class="line"><span class="comment"># train_labels (60000,)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>, train_labels.shape)</span><br></pre></td></tr></table></figure>
<h2 id="图片数据处理：归一化"><a href="#图片数据处理：归一化" class="headerlink" title="图片数据处理：归一化"></a>图片数据处理：归一化</h2><p>除以255.0 是为了归一化，使得元素点 全部变为在 0-1 之间<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line"><span class="comment">#  (60000, 28, 28) </span></span><br><span class="line">train_images_scale = train_images/<span class="number">255.0</span></span><br><span class="line">test_images_scale = test_images/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_images变换后 (60000, 28, 28)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images变换后&#x27;</span>, train_images_scale.shape)</span><br><span class="line"><span class="comment"># test_images变换后 (10000, 28, 28)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_images变换后&#x27;</span>, test_images_scale.shape)</span><br></pre></td></tr></table></figure></p>
<h2 id="标签数据处理：转换成-one-hot-格式"><a href="#标签数据处理：转换成-one-hot-格式" class="headerlink" title="标签数据处理：转换成 one hot 格式"></a>标签数据处理：转换成 one hot 格式</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 换 one hot 格式  共十个分类</span></span><br><span class="line"><span class="comment"># np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。</span></span><br><span class="line">train_labels_hot = np_utils.to_categorical(train_labels,num_classes=<span class="number">10</span>)</span><br><span class="line">test_labels_hot = np_utils.to_categorical(test_labels,num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_labels (60000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>,train_labels_hot.shape)</span><br><span class="line"><span class="comment"># test_labels (10000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_labels&#x27;</span>,test_labels_hot.shape)</span><br></pre></td></tr></table></figure>
<h1 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h1><p>先定义 RNN 所需的参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义rnn 的参数</span></span><br><span class="line"><span class="comment"># 数据长度 一行一共有28个元素</span></span><br><span class="line">input_size = <span class="number">28</span></span><br><span class="line"><span class="comment"># 序列长度 一共有28个序列 也就是28行</span></span><br><span class="line">time_steps = <span class="number">28</span></span><br><span class="line"><span class="comment"># 隐藏层cell个数</span></span><br><span class="line">cell_size = <span class="number">50</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>再定义 RNN 模型<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment">#循环神经网络</span></span><br><span class="line">model.add(SimpleRNN(</span><br><span class="line">    units=cell_size, <span class="comment">#输出</span></span><br><span class="line">    input_shape=(time_steps,input_size) <span class="comment">#输入</span></span><br><span class="line">))</span><br><span class="line"><span class="comment"># 输出层</span></span><br><span class="line">model.add(Dense(input_dim=cell_size,units=<span class="number">10</span>,activation=<span class="string">&quot;softmax&quot;</span>))</span><br></pre></td></tr></table></figure><br>优化器使用 Adam， 损失函数 选择 交叉熵   并编译</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义优化器  10的 -4次方</span></span><br><span class="line">adam = Adam(learning_rate=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= adam,loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,metrics=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p> 一共 60000张训练图片 按批次训练 一批次64张   一共6w/64 个批次<br>训练完一轮6w张，表示一个epoch<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一共 60000张训练图片 按批次训练 一批次64张   </span></span><br><span class="line"><span class="comment"># 训练完一轮6w张，表示一个epoch</span></span><br><span class="line">model.fit(train_images_scale,train_labels_hot,batch_size=<span class="number">64</span>,epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/35cafae3dc0e431086f33cdf4a23dc52.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h1><p>就是在 测试集上的表现<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)</span><br></pre></td></tr></table></figure><br>也可以看一下 在训练集上的表现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(train_images_scale,train_labels_hot)</span><br></pre></td></tr></table></figure>
<p>下面是 结果（上训练集 下测试集）<br><img src="https://img-blog.csdnimg.cn/d93ee2873e72460e96c0c4a9a663985b.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="预测数据"><a href="#预测数据" class="headerlink" title="预测数据"></a>预测数据</h1><font color="red">**有问题 输入的 数据维度不对 不知道错哪了？？？**</font>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 看下输入的形状</span></span><br><span class="line"><span class="comment"># # 预测数据</span></span><br><span class="line"><span class="built_in">print</span>(test_images_scale[<span class="number">0</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(model.predict((test_images_scale[<span class="number">0</span>]/<span class="number">255.0</span>)))</span><br><span class="line"><span class="built_in">print</span>(np.argmax(model.predict((test_images_scale[<span class="number">0</span>]/<span class="number">255.0</span>))))</span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输入的图像 变换后形状<br><img src="https://img-blog.csdnimg.cn/c6e4d5008f9c416ba48bea577a86c238.png#pic_center" alt="在这里插入图片描述"><br>模型预测 数据 输出的概率分类结果<br><img src="https://img-blog.csdnimg.cn/ba872c35347041b592db07d82b429d35.png#pic_center" alt="在这里插入图片描述"><br>选出其中最大的 以及 实际图片标签 均为 数字7<br><img src="https://img-blog.csdnimg.cn/5a585701d439431aa1853283c8592b46.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Keras  CNN 实现 MNIST 手写数字识别</title>
    <url>/2021/09/03/Keras%20%20CNN%20%E5%AE%9E%E7%8E%B0%20MNIST%20%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<p>@<a href="Keras  CNN 实现 MNIST 手写数字识别">TOC</a></p>
<p>我们就以 MNIST数据集的手写识别 为例子</p>
<h1 id="导入需要的包"><a href="#导入需要的包" class="headerlink" title="导入需要的包"></a>导入需要的包</h1><p>首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span>  Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense,Dropout,Convolution2D,MaxPooling2D,Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(matplotlib.get_backend())</span><br></pre></td></tr></table></figure>
<h1 id="载入MNIST-数据"><a href="#载入MNIST-数据" class="headerlink" title="载入MNIST 数据"></a>载入MNIST 数据</h1><p>该数据集一共有训练集 6w 张，测试集 1w 张<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(train_images,train_labels),(test_images,test_labels)= mnist.load_data()</span><br></pre></td></tr></table></figure></p>
<p>可以查看一下图像和标签  是什么</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数字5</span></span><br><span class="line"><span class="built_in">print</span>(train_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签5</span></span><br><span class="line"><span class="built_in">print</span>(train_labels[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 数字7</span></span><br><span class="line"><span class="built_in">print</span>(test_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签7</span></span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>可以 打印 一下图片 看看是什么样子<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow(test_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/a745fc12bef94f93b93f80b2e89bb0d0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="图片数据处理"><a href="#图片数据处理" class="headerlink" title="图片数据处理"></a>图片数据处理</h1><h2 id="查看图片原有-shape"><a href="#查看图片原有-shape" class="headerlink" title="查看图片原有 shape"></a>查看图片原有 shape</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train_images (60000, 28, 28)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images&#x27;</span>, train_images.shape)</span><br><span class="line"><span class="comment"># train_labels (60000,)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>, train_labels.shape)</span><br></pre></td></tr></table></figure>
<h2 id="图片数据处理：变成四维-，并归一化"><a href="#图片数据处理：变成四维-，并归一化" class="headerlink" title="图片数据处理：变成四维 ，并归一化"></a>图片数据处理：变成四维 ，并归一化</h2><p>变维度的 -1 是个通配符，系统会自动完成应该变成多少<br>除以255.0 是为了归一化，使得元素点 全部变为在 0-1 之间<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line"><span class="comment"># CNN 输入的是一张图片</span></span><br><span class="line"><span class="comment"># 将 (60000, 28, 28) -&gt; (60000, 28, 28, 1)  变成四维</span></span><br><span class="line"><span class="comment"># 第四个 1  表示的为深度   黑白图像为 1   彩色图像为 3</span></span><br><span class="line">train_images_scale = train_images.reshape(-<span class="number">1</span>, train_images.shape[<span class="number">1</span>] ,train_images.shape[<span class="number">2</span>],<span class="number">1</span>)/<span class="number">255.0</span></span><br><span class="line">test_images_scale = test_images.reshape(-<span class="number">1</span>,test_images.shape[<span class="number">1</span>], test_images.shape[<span class="number">2</span>],<span class="number">1</span>)/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_images变换后 (60000, 28, 28, 1)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images变换后&#x27;</span>, train_images_scale.shape)</span><br><span class="line"><span class="comment"># test_images变换后 (10000, 28, 28, 1)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_images变换后&#x27;</span>, test_images_scale.shape)</span><br></pre></td></tr></table></figure></p>
<h2 id="标签数据处理：转换成-one-hot-格式"><a href="#标签数据处理：转换成-one-hot-格式" class="headerlink" title="标签数据处理：转换成 one hot 格式"></a>标签数据处理：转换成 one hot 格式</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 换 one hot 格式  共十个分类</span></span><br><span class="line"><span class="comment"># np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。</span></span><br><span class="line">train_labels_hot = np_utils.to_categorical(train_labels,num_classes=<span class="number">10</span>)</span><br><span class="line">test_labels_hot = np_utils.to_categorical(test_labels,num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_labels (60000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>,train_labels_hot.shape)</span><br><span class="line"><span class="comment"># test_labels (10000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_labels&#x27;</span>,test_labels_hot.shape)</span><br></pre></td></tr></table></figure>
<h1 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h1><p>思路是 卷积 再池化 重复步骤  再压平给 全身神经网络<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment">#第一个卷积层</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    input shape 激入平面</span></span><br><span class="line"><span class="string">    filters 卷积核/过滤器 个数</span></span><br><span class="line"><span class="string">    kernel_size 卷积窗口大小</span></span><br><span class="line"><span class="string">    strides 步长</span></span><br><span class="line"><span class="string">    padding（边界填充）padding方式 same/valid</span></span><br><span class="line"><span class="string">    activation 激活函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 用same 保持整个还是 28 × 28</span></span><br><span class="line">model.add(Convolution2D(</span><br><span class="line">    input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>),filters=<span class="number">32</span>,kernel_size=<span class="number">5</span>,strides=<span class="number">1</span>,padding=<span class="string">&#x27;same&#x27;</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#第一个池化层</span></span><br><span class="line">model.add(MaxPooling2D(</span><br><span class="line">    pool_size=<span class="number">2</span>,strides=<span class="number">2</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"><span class="comment">#第二卷积层</span></span><br><span class="line">model.add(Convolution2D(<span class="number">64</span>,<span class="number">5</span>,strides=<span class="number">1</span>,padding=<span class="string">&#x27;same&#x27;</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#第二个池化层</span></span><br><span class="line">model.add(MaxPooling2D(</span><br><span class="line">    pool_size=<span class="number">2</span>,strides=<span class="number">2</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#把第二个池化层的前出扁平化为1维</span></span><br><span class="line">model.add(Flatten())</span><br><span class="line"><span class="comment">#第一个全连接层</span></span><br><span class="line">model.add(Dense(units=<span class="number">1024</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#Dropout</span></span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"><span class="comment">#第二个全连接层</span></span><br><span class="line">model.add(Dense(units=<span class="number">10</span>,input_dim=<span class="number">1024</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure></p>
<p>优化器使用 Adam， 损失函数 选择 交叉熵   并编译</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义优化器  10的 -4次方</span></span><br><span class="line">adam = Adam(learning_rate=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= adam,loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,metrics=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p> 一共 60000张训练图片 按批次训练 一批次64张   一共6w/64 个批次<br>训练完一轮6w张，表示一个epoch<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一共 60000张训练图片 按批次训练 一批次64张   </span></span><br><span class="line"><span class="comment"># 训练完一轮6w张，表示一个epoch</span></span><br><span class="line">model.fit(train_images_scale,train_labels_hot,batch_size=<span class="number">64</span>,epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/35cafae3dc0e431086f33cdf4a23dc52.png#pic_center" alt="在这里插入图片描述"><br>上图只跑了一次 epoch，因为笔记本太慢了<br><strong>注意： 最好用 GPU 来跑 ，不然笔记本非常的慢</strong></p>
<h1 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h1><p>就是在 测试集上的表现<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)</span><br></pre></td></tr></table></figure><br>也可以看一下 在训练集上的表现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(train_images_scale,train_labels_hot)</span><br></pre></td></tr></table></figure>
<p>下面是 结果（上训练集 下测试集）<br><img src="https://img-blog.csdnimg.cn/d93ee2873e72460e96c0c4a9a663985b.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="预测数据"><a href="#预测数据" class="headerlink" title="预测数据"></a>预测数据</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 看下输入的形状</span></span><br><span class="line"><span class="built_in">print</span>(test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>).shape)</span><br><span class="line"><span class="built_in">print</span>(model.predict((test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))))</span><br><span class="line"><span class="built_in">print</span>(np.argmax(model.predict((test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))))</span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输入的图像 变换后形状<br><img src="https://img-blog.csdnimg.cn/c6e4d5008f9c416ba48bea577a86c238.png#pic_center" alt="在这里插入图片描述"><br>模型预测 数据 输出的概率分类结果<br><img src="https://img-blog.csdnimg.cn/ba872c35347041b592db07d82b429d35.png#pic_center" alt="在这里插入图片描述"><br>选出其中最大的 以及 实际图片标签 均为 数字7<br><img src="https://img-blog.csdnimg.cn/5a585701d439431aa1853283c8592b46.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/Mock.js%20%E5%AD%A6%E4%B9%A0_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="Mock-js-结合Vue-学习"><a href="#Mock-js-结合Vue-学习" class="headerlink" title="Mock.js 结合Vue 学习"></a>Mock.js 结合Vue 学习</h1><h2 id="步骤1：搭建Vue2-0测试项目"><a href="#步骤1：搭建Vue2-0测试项目" class="headerlink" title="步骤1：搭建Vue2.0测试项目"></a>步骤1：搭建Vue2.0测试项目</h2><p>Mock.js 的用途就是在，后端接口没有完成的时候，我们需要根据后端的API字段 模拟出临时的数据访问接口。</p>
<p>其官网为 ：<strong>mockjs.com</strong></p>
<p>如何在 Vue（脚手架） 中使用的官网为：<a href="https://github.com/nuysoft/Mock/wiki/Getting-Started">Getting Started · nuysoft/Mock Wiki · GitHub</a></p>
<p>其原理是</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/Mockjs原理.png" alt=""></p>
<h3 id="步骤1-1：先配置一个环境"><a href="#步骤1-1：先配置一个环境" class="headerlink" title="步骤1.1：先配置一个环境"></a>步骤1.1：先配置一个环境</h3><p>我们创建一个用于学习 mockJS的 vue 文件项目 mock_demo<font color="red">（不能有大写字母）</font></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vue create mock_demo</span><br></pre></td></tr></table></figure>
<p>选择 vue2.0 即可。</p>
<h3 id="步骤1-2：安装依赖"><a href="#步骤1-2：安装依赖" class="headerlink" title="步骤1.2：安装依赖"></a>步骤1.2：安装依赖</h3><p><strong>vue环境搭建好后，开始安装 mock依赖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//使用axios发送  ajax</span><br><span class="line">npm install axios --save</span><br><span class="line">//使用mockjs产生随机数据</span><br><span class="line">npm install mockjs --save-dev</span><br><span class="line">//使用json5解决json文件,无法添加注释问题</span><br><span class="line">npm install json5 --save-dev</span><br></pre></td></tr></table></figure>
<h2 id="步骤2-：学习MOCKJS"><a href="#步骤2-：学习MOCKJS" class="headerlink" title="步骤2 ：学习MOCKJS"></a>步骤2 ：学习MOCKJS</h2><p>新建mock文件夹,新建testMockjs.js</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> Mock = <span class="built_in">require</span>(<span class="string">&#x27;mockjs&#x27;</span>);<span class="comment">//mockjs 导入依赖模块</span></span><br><span class="line"><span class="keyword">var</span> id = Mock.mock(<span class="string">&#x27;@id&#x27;</span>)<span class="comment">//得到随机的id,字符串</span></span><br><span class="line"><span class="built_in">console</span>.log(Mock.mock(<span class="string">&#x27;@id&#x27;</span>), <span class="keyword">typeof</span> id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> obj = Mock.mock(&#123;</span><br><span class="line">    <span class="attr">id</span>: <span class="string">&quot;@id()&quot;</span>,<span class="comment">//得到随机的id,对象</span></span><br><span class="line">    <span class="attr">username</span>: <span class="string">&quot;@cname()&quot;</span>,<span class="comment">//随机生成中文名字</span></span><br><span class="line">    <span class="attr">date</span>: <span class="string">&quot;@date()&quot;</span>,<span class="comment">//随机生成日期</span></span><br><span class="line">    <span class="attr">avatar</span>: <span class="string">&quot;@image(&#x27;200x200&#x27;,&#x27;red&#x27;,&#x27;#fff&#x27;,&#x27;avatar&#x27;)&quot;</span>,<span class="comment">//生成图片,参数:size, background, foreground, text</span></span><br><span class="line">    <span class="attr">description</span>: <span class="string">&quot;@paragraph()&quot;</span>,<span class="comment">//描述</span></span><br><span class="line">    <span class="attr">ip</span>: <span class="string">&quot;@ip()&quot;</span>,<span class="comment">//IP地址</span></span><br><span class="line">    <span class="attr">email</span>: <span class="string">&quot;@email()&quot;</span><span class="comment">//email</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="built_in">console</span>.log(obj)</span><br></pre></td></tr></table></figure>
<p>其会随机生成对应的内容，这个随机生成的特定写法，可以查阅：<a href="http://mockjs.com/examples.html">http://mockjs.com/examples.html</a></p>
<h2 id="步骤3：学习JSON5"><a href="#步骤3：学习JSON5" class="headerlink" title="步骤3：学习JSON5"></a>步骤3：学习JSON5</h2><p>Json文件,中如果说存在注释文件和编辑器都会报错,<strong>我们采用json5格式来让json格式可以存在注释</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/Json5.jfif" alt=""></p>
<h3 id="步骤3-1：编辑器安装JSON5扩展"><a href="#步骤3-1：编辑器安装JSON5扩展" class="headerlink" title="步骤3.1：编辑器安装JSON5扩展"></a>步骤3.1：编辑器安装JSON5扩展</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/按钻过json5.jfif" style="zoom: 67%;" /></p>
<h3 id="步骤3-2：引入JSON5库来解析JSON5格式"><a href="#步骤3-2：引入JSON5库来解析JSON5格式" class="headerlink" title="步骤3.2：引入JSON5库来解析JSON5格式"></a>步骤3.2：引入JSON5库来解析JSON5格式</h3><p>在mock文件夹下,新建testJSON5.js</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&#x27;path&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> JSON5 = <span class="built_in">require</span>(<span class="string">&#x27;json5&#x27;</span>);</span><br><span class="line"><span class="comment">//读取json文件</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getJsonFile</span>(<span class="params">filePath</span>) </span>&#123;</span><br><span class="line">    <span class="comment">//读取指定json文件</span></span><br><span class="line">    <span class="keyword">var</span> json = fs.readFileSync(path.resolve(__dirname,filePath), <span class="string">&#x27;utf-8&#x27;</span>);</span><br><span class="line">    <span class="comment">//解析并返回</span></span><br><span class="line">    <span class="keyword">return</span> JSON5.parse(json);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> json = getJsonFile(<span class="string">&#x27;./userInfo.json5&#x27;</span>);</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;json&#x27;</span>, json) </span><br></pre></td></tr></table></figure>
<h2 id="步骤4：MOCK和VUE-CLI结合"><a href="#步骤4：MOCK和VUE-CLI结合" class="headerlink" title="步骤4：MOCK和VUE-CLI结合"></a>步骤4：MOCK和VUE-CLI结合</h2><h3 id="步骤4-1-修改VUE-CONFIG-JS"><a href="#步骤4-1-修改VUE-CONFIG-JS" class="headerlink" title="步骤4.1 修改VUE.CONFIG.JS"></a>步骤4.1 修改VUE.CONFIG.JS</h3><p>在项目根目录下,修改其 vue.config.js</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; defineConfig &#125; = <span class="built_in">require</span>(<span class="string">&#x27;@vue/cli-service&#x27;</span>)</span><br><span class="line"><span class="built_in">module</span>.exports = defineConfig(&#123;</span><br><span class="line">  <span class="attr">transpileDependencies</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="comment">// 添加一个 devServer</span></span><br><span class="line">  <span class="attr">devServer</span>: &#123;</span><br><span class="line">    <span class="attr">before</span>: <span class="built_in">require</span>(<span class="string">&#x27;./mock/index.js&#x27;</span>)<span class="comment">//引入mock/index.js</span></span><br><span class="line">&#125;&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="步骤4-2-了解在vue-cli中如何利用webpack的devServer启动一个后端服务器"><a href="#步骤4-2-了解在vue-cli中如何利用webpack的devServer启动一个后端服务器" class="headerlink" title="步骤4.2 了解在vue-cli中如何利用webpack的devServer启动一个后端服务器"></a>步骤4.2 了解在vue-cli中如何利用webpack的devServer启动一个后端服务器</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/Mockjs原理.png" alt=""></p>
<h5 id="我们下面借助vue-cli-里面的-webpack的devServer来启动一个后端服务器"><a href="#我们下面借助vue-cli-里面的-webpack的devServer来启动一个后端服务器" class="headerlink" title="我们下面借助vue-cli 里面的 webpack的devServer来启动一个后端服务器"></a>我们下面借助vue-cli 里面的 webpack的devServer来启动一个后端服务器</h5><p><a href="https://cli.vuejs.org/zh/config/#devserver">参考vue-cli文档</a>:<a href="https://cli.vuejs.org/zh/config/#devserver">https://cli.vuejs.org/zh/config/#devserver</a></p>
<p><a href="https://webpack.js.org/configuration/dev-server/#devserverbefore">webpack官方文档</a>：<a href="https://webpack.js.org/configuration/dev-server/#devserverbefore">https://webpack.js.org/configuration/dev-server/#devserverbefore</a></p>
<h3 id="步骤4-2-新建INDEX-JS"><a href="#步骤4-2-新建INDEX-JS" class="headerlink" title="步骤4.2 新建INDEX.JS"></a>步骤4.2 新建INDEX.JS</h3><p>在mock文件夹下,新建index.js</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&#x27;path&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> Mock = <span class="built_in">require</span>(<span class="string">&#x27;mockjs&#x27;</span>);<span class="comment">//mockjs 导入依赖模块</span></span><br><span class="line"><span class="keyword">const</span> JSON5 = <span class="built_in">require</span>(<span class="string">&#x27;json5&#x27;</span>);</span><br><span class="line"><span class="comment">//读取json文件</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getJsonFile</span>(<span class="params">filePath</span>) </span>&#123;</span><br><span class="line">    <span class="comment">//读取指定json文件</span></span><br><span class="line">    <span class="keyword">var</span> json = fs.readFileSync(path.resolve(__dirname,filePath), <span class="string">&#x27;utf-8&#x27;</span>);</span><br><span class="line">    <span class="comment">//解析并返回</span></span><br><span class="line">    <span class="keyword">return</span> JSON5.parse(json);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回一个函数</span></span><br><span class="line"><span class="built_in">module</span>.exports = <span class="function"><span class="keyword">function</span>(<span class="params">app</span>)</span>&#123;</span><br><span class="line">    <span class="comment">//监听http请求</span></span><br><span class="line">    app.get(<span class="string">&#x27;/user/userinfo&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">rep, res</span>) </span>&#123;</span><br><span class="line">        <span class="comment">//每次响应请求时读取mock data的json文件</span></span><br><span class="line">        <span class="comment">//getJsonFile方法定义了如何读取json文件并解析成数据对象</span></span><br><span class="line">        <span class="keyword">var</span> json = getJsonFile(<span class="string">&#x27;./userInfo.json5&#x27;</span>);</span><br><span class="line">        <span class="comment">//将json传入 Mock.mock 方法中，生成的数据返回给浏览器</span></span><br><span class="line">        res.json(Mock.mock(json));</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>Keras MNIST 过拟合问题解决：Dropout 与 正则化</title>
    <url>/2021/09/02/Keras%20MNIST%20%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%EF%BC%9ADropout%20%E4%B8%8E%20%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    <content><![CDATA[<p>@<a href="Keras MNIST 过拟合问题解决：Dropout 与 正则化">TOC</a></p>
<p>我们就以 MNIST数据集的手写识别 为例子<br>做 过拟合问题的应用  包括 Dropout 和 正则化</p>
<h1 id="导入需要的包"><a href="#导入需要的包" class="headerlink" title="导入需要的包"></a>导入需要的包</h1><p>首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便）</p>
<h2 id="使用Dropout-需要导入的包"><a href="#使用Dropout-需要导入的包" class="headerlink" title="使用Dropout 需要导入的包"></a>使用Dropout 需要导入的包</h2><p>需要 导入 另一个包 keras.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span>  Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(matplotlib.get_backend())</span><br></pre></td></tr></table></figure></p>
<h2 id="使用-正则化-需要导入的包"><a href="#使用-正则化-需要导入的包" class="headerlink" title="使用 正则化  需要导入的包"></a>使用 正则化  需要导入的包</h2><p>layers 层中 引入 keras.regularizers   中  l2 范式<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span>  Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(matplotlib.get_backend())</span><br></pre></td></tr></table></figure></p>
<h1 id="载入MNIST-数据"><a href="#载入MNIST-数据" class="headerlink" title="载入MNIST 数据"></a>载入MNIST 数据</h1><p>该数据集一共有训练集 6w 张，测试集 1w 张<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(train_images,train_labels),(test_images,test_labels)= mnist.load_data()</span><br></pre></td></tr></table></figure></p>
<p>可以查看一下图像和标签  是什么</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数字5</span></span><br><span class="line"><span class="built_in">print</span>(train_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签5</span></span><br><span class="line"><span class="built_in">print</span>(train_labels[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 数字7</span></span><br><span class="line"><span class="built_in">print</span>(test_images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 标签7</span></span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>可以 打印 一下图片 看看是什么样子<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow(test_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/a745fc12bef94f93b93f80b2e89bb0d0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="图片数据处理"><a href="#图片数据处理" class="headerlink" title="图片数据处理"></a>图片数据处理</h1><h2 id="查看图片原有-shape"><a href="#查看图片原有-shape" class="headerlink" title="查看图片原有 shape"></a>查看图片原有 shape</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train_images (60000, 28, 28)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images&#x27;</span>, train_images.shape)</span><br><span class="line"><span class="comment"># train_labels (60000,)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>, train_labels.shape)</span><br></pre></td></tr></table></figure>
<h2 id="图片数据处理：将图片压平"><a href="#图片数据处理：将图片压平" class="headerlink" title="图片数据处理：将图片压平"></a>图片数据处理：将图片压平</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line"><span class="comment"># 将 (60000, 28, 28) -&gt; (60000, 784)  压平图片</span></span><br><span class="line">train_images_scale = train_images.reshape(train_images.shape[<span class="number">0</span>], train_images.shape[<span class="number">1</span>] * train_images.shape[<span class="number">2</span>])/<span class="number">255.0</span></span><br><span class="line">test_images_scale = test_images.reshape(test_images.shape[<span class="number">0</span>], test_images.shape[<span class="number">1</span>] * test_images.shape[<span class="number">2</span>])/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_images变换后 (60000, 784)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_images变换后&#x27;</span>, train_images_scale.shape)</span><br><span class="line"><span class="comment"># test_images变换后 (10000, 784)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_images变换后&#x27;</span>, test_images_scale.shape)</span><br></pre></td></tr></table></figure>
<h2 id="标签数据处理：转换成-one-hot-格式"><a href="#标签数据处理：转换成-one-hot-格式" class="headerlink" title="标签数据处理：转换成 one hot 格式"></a>标签数据处理：转换成 one hot 格式</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 换 one hot 格式  共十个分类</span></span><br><span class="line"><span class="comment"># np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。</span></span><br><span class="line">train_labels_hot = np_utils.to_categorical(train_labels,num_classes=<span class="number">10</span>)</span><br><span class="line">test_labels_hot = np_utils.to_categorical(test_labels,num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_labels (60000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train_labels&#x27;</span>,train_labels_hot.shape)</span><br><span class="line"><span class="comment"># test_labels (10000, 10)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_labels&#x27;</span>,test_labels_hot.shape)</span><br></pre></td></tr></table></figure>
<h1 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h1><h2 id="添加-Dropout"><a href="#添加-Dropout" class="headerlink" title="添加 Dropout"></a>添加 Dropout</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 输入压平图像 维度为784   输出为 10分类</span></span><br><span class="line"><span class="comment"># 加个隐层</span></span><br><span class="line">model.add(Dense(units=<span class="number">200</span>,input_dim=<span class="number">784</span>,bias_initializer=<span class="string">&quot;one&quot;</span>,activation=<span class="string">&quot;tanh&quot;</span>))</span><br><span class="line"><span class="comment"># 上层40%的神经元不工作</span></span><br><span class="line">model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(Dense(units=<span class="number">100</span>,input_dim=<span class="number">200</span>,bias_initializer=<span class="string">&quot;one&quot;</span>,activation=<span class="string">&quot;tanh&quot;</span>))</span><br><span class="line"><span class="comment"># 上层40%的神经元不工作</span></span><br><span class="line">model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(Dense(units=<span class="number">10</span>,input_dim=<span class="number">100</span>,bias_initializer=<span class="string">&quot;one&quot;</span>,activation=<span class="string">&quot;softmax&quot;</span>))</span><br></pre></td></tr></table></figure>
<p>优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重新定义 sgd 优化器  加速一下学习率</span></span><br><span class="line">sgd = SGD(learning_rate=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= sgd,loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,metrics=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="添加-正则化项"><a href="#添加-正则化项" class="headerlink" title="添加 正则化项"></a>添加 正则化项</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 输入压平图像 维度为784   输出为 10分类</span></span><br><span class="line"><span class="comment"># 加个隐层</span></span><br><span class="line">model.add(Dense(units=<span class="number">200</span>,input_dim=<span class="number">784</span>,bias_initializer=<span class="string">&quot;one&quot;</span>,activation=<span class="string">&quot;tanh&quot;</span>,kernel_initializer=l2(<span class="number">0.003</span>)))</span><br><span class="line">model.add(Dense(units=<span class="number">100</span>,input_dim=<span class="number">200</span>,bias_initializer=<span class="string">&quot;one&quot;</span>,activation=<span class="string">&quot;tanh&quot;</span>,kernel_initializer=l2(<span class="number">0.003</span>)))</span><br><span class="line">model.add(Dense(units=<span class="number">10</span>,input_dim=<span class="number">100</span>,bias_initializer=<span class="string">&quot;one&quot;</span>,activation=<span class="string">&quot;softmax&quot;</span>,kernel_initializer=l2(<span class="number">0.003</span>)))</span><br></pre></td></tr></table></figure>
<p>优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重新定义 sgd 优化器  加速一下学习率</span></span><br><span class="line">sgd = SGD(learning_rate=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 优化器使用加速学习率的 sgd ， 损失函数 选择 交叉熵</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= sgd,loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,metrics=<span class="string">&quot;accuracy&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p> 一共 60000张训练图片 按批次训练 一批次32张   一共6w/32 = 1875 个批次<br>训练完一轮6w张，表示一个epoch<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一共 60000张训练图片 按批次训练 一批次32张   一共6w/32 = 1875 个批次</span></span><br><span class="line"><span class="comment"># 训练完一轮6w张，表示一个epoch</span></span><br><span class="line">model.fit(train_images_scale,train_labels_hot,batch_size=<span class="number">32</span>,epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><br><img src="https://img-blog.csdnimg.cn/576f033299d04330a371c33eb6a2abac.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="训练过程"></p>
<h1 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h1><h2 id="Dropout的结果"><a href="#Dropout的结果" class="headerlink" title="Dropout的结果"></a>Dropout的结果</h2><p>就是在 测试集上的表现<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)</span><br></pre></td></tr></table></figure><br>也可以看一下 在训练集上的表现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(train_images_scale,train_labels_hot)</span><br></pre></td></tr></table></figure>
<p>下面是 结果（上训练集 下测试集）<br><img src="https://img-blog.csdnimg.cn/7c46786df7d74ef383b14a1627e0cf9d.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="正则化的结果"><a href="#正则化的结果" class="headerlink" title="正则化的结果"></a>正则化的结果</h2><p>就是在 测试集上的表现<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(test_images_scale,test_labels_hot)</span><br></pre></td></tr></table></figure><br>也可以看一下 在训练集上的表现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss,accuracy = model.evaluate(train_images_scale,train_labels_hot)</span><br></pre></td></tr></table></figure>
<p>下面是 结果（上训练集 下测试集）</p>
<p><font color="red"><strong>出现了错误 不知道是哪里的问题哎？</strong></font><br><img src="https://img-blog.csdnimg.cn/44c6138733e4436ba6d847fec0f88cfd.png#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TypeError: __call__() got an unexpected keyword argument <span class="string">&#x27;dtype&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/e71199da4cfb4c2aaf69d39fc4dacfd3.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="预测数据"><a href="#预测数据" class="headerlink" title="预测数据"></a>预测数据</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 看下输入的形状</span></span><br><span class="line"><span class="built_in">print</span>(test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">784</span>).shape)</span><br><span class="line"><span class="comment"># 模型预测  输出每个分类的 概率</span></span><br><span class="line"><span class="built_in">print</span>(model.predict((test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">784</span>))))</span><br><span class="line"><span class="comment"># 选取最大的那个 就是预测的标签</span></span><br><span class="line"><span class="built_in">print</span>(np.argmax(model.predict((test_images_scale[<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">784</span>)))))</span><br><span class="line"><span class="comment"># 实际该图片的 标签</span></span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输入的图像 变换后形状<br><img src="https://img-blog.csdnimg.cn/4302df2ba0e44c04897aaf00f6955dad.png#pic_center" alt="在这里插入图片描述"><br>模型预测 数据 输出的概率分类结果<br><img src="https://img-blog.csdnimg.cn/3ffa135e578d486c8404588781678e0c.png#pic_center" alt="在这里插入图片描述"><br>选出其中最大的 以及 实际图片标签 均为 数字7<br><img src="https://img-blog.csdnimg.cn/5a585701d439431aa1853283c8592b46.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title>Keras 构建 线性模型和非线性模型</title>
    <url>/2021/08/24/Keras%20%E6%9E%84%E5%BB%BA%20%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>@<a href="Keras 构建 线性模型和非线性模型">TOC</a></p>
<h1 id="预测线性模型"><a href="#预测线性模型" class="headerlink" title="预测线性模型"></a>预测线性模型</h1><p>使用的数据 是我们随机生成的<br>、<br>首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># matplotlib.use(&#x27;TkAgg&#x27;)</span></span><br><span class="line"><span class="comment"># print(matplotlib.get_backend())</span></span><br><span class="line"><span class="comment"># Sequential按顺序构成的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="comment"># Dense全连接层</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br></pre></td></tr></table></figure>
<p>先准备我们需要的数据。随机生成100个随机值x，并随机产生100个噪声值。我们按 $y=0.1x+0.2$ 的公式，得到对应的y标签值。 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用numpy 生成100个 随机点</span></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 测试集，但其实都是随机的 用x_data 也可以</span></span><br><span class="line">x_pre = np.random.rand(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 噪声 使得每个点不是 均匀在一条直线上</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.01</span>,x_data.shape)</span><br><span class="line">y_data = x_data * <span class="number">0.1</span> + <span class="number">0.2</span> + noise</span><br></pre></td></tr></table></figure>
<p>可以将 100个点的分布图画出。 注意图的显示可能有问题，自行解决一下哦。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.scatter(x_data,y_data)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Q：为什么我们要引入 噪声呢？<br>答：引入噪声可以让我们的数据更加的离散分布 在 我们设计的线性模型上。 使得假设的数据更加的合理。 如下图所示 。 <font color="orange">橙色</font>的是我们设定的线性模型，<font color="blue">蓝色</font>的是 加入噪声以后的数据分布<br><img src="https://img-blog.csdnimg.cn/92fd1e153f2845aba178b80a7845b8cb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<p>使用 keras 中的 Sequential （顺序构成的模型） 构建模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构建一个顺序模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 在模型中添加一个全连接层</span></span><br><span class="line"><span class="comment"># units 输出的维度</span></span><br><span class="line"><span class="comment"># input_dim 输入的维度</span></span><br><span class="line">model.add(Dense(units=<span class="number">1</span>,input_dim=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># sgd 随机梯度下降法</span></span><br><span class="line"><span class="comment"># mse Mean Squared Error 均方误差</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>,loss=<span class="string">&#x27;mse&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>之后我们就按照批次训练。 共训练3001个批次。有两种写法。<br>方法一：<br>用一个循环体，循环3001次； 每500次 打印一次 损失值。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练3001个批次</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3001</span>):</span><br><span class="line">    <span class="comment">#每次训练一个批次</span></span><br><span class="line">    cost = model.train_on_batch(x_data,y_data)</span><br><span class="line">    <span class="comment"># 每500个 batch 打印一次 cost值</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;cost:&quot;</span>,cost)</span><br></pre></td></tr></table></figure><br>方法二： 直接使用 model.fit () 函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.fit(x_data,y_data,epochs=<span class="number">3001</span>)</span><br></pre></td></tr></table></figure>
<p> 可以查看 参数值 W （权重）和 b（偏置值）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W,b = model.layers[<span class="number">0</span>].get_weights()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W：&#x27;</span>,W,<span class="string">&#x27;b:&#x27;</span>,b)</span><br></pre></td></tr></table></figure>
<p>预测 测试集的 结果 使用 model.predict () 函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 测试集 输入网络中，得到预测值 y_pred</span></span><br><span class="line">y_pred = model.predict(x_pre)</span><br></pre></td></tr></table></figure>
<p>可以再 把预测的 图打出来</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.scatter(x_pre,y_pred)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>我们的训练 使用方法二 <strong>结果如图所示：</strong><br><img src="https://img-blog.csdnimg.cn/45c3db30524a45a48e919881f6c36710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="预测非线性模型"><a href="#预测非线性模型" class="headerlink" title="预测非线性模型"></a>预测非线性模型</h1><p>使用的数据 也是我们随机生成的</p>
<p>首先导入我们需要的包（直接把Sequential 和 Dense 直接导入 这样之后方便） 注意SGD 需要 tensorflow.keras.optimizers 导入</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)</span><br><span class="line"><span class="comment"># Sequential按顺序构成的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="comment"># Dense全连接层</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense,Activation</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> SGD</span><br></pre></td></tr></table></figure>
<p>先准备我们需要的数据。用等差数列生成200个值x，并随机产生200个噪声值。我们按 $y=x^{2}$ 的公式，得到对应的y标签值。 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用numpy 生成 200 个随机点</span></span><br><span class="line">x_data = np.linspace(-<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">200</span>)</span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">x_pre = np.linspace(-<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">200</span>)</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.02</span>,x_data.shape)</span><br><span class="line">y_data = np.square(x_data) + noise</span><br></pre></td></tr></table></figure>
<p>可以将 200个点的分布图画出。 注意图的显示可能有问题，自行解决一下哦。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.scatter(x_data,y_data)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p>使用 keras 中的 Sequential （顺序构成的模型） 构建模型。 <font color="red">与线性模型的区别在，我们需要 增加激活函数，并且增加一个 中间层（含有10个神经元）。</font>  <font color="blue">并且增加一点 sgd 的学习率，不然学习度太慢，需要的训练次数就会非常大。</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构建一个顺序模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 在模型中添加一个全连接层</span></span><br><span class="line"><span class="comment"># units 输出的维度  维度就是神经元个数</span></span><br><span class="line"><span class="comment"># input_dim 输入的维度</span></span><br><span class="line"><span class="comment"># 需要的神经模型为 1-10-1</span></span><br><span class="line">model.add(Dense(units=<span class="number">10</span>,input_dim=<span class="number">1</span>,activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">model.add(Dense(units=<span class="number">1</span>,input_dim=<span class="number">10</span>,activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line"><span class="comment"># sgd 随机梯度下降法</span></span><br><span class="line"><span class="comment"># mse Mean Squared Error 均方误差</span></span><br><span class="line"><span class="comment"># sgd 的学习率太小 训练次数可能非常多</span></span><br><span class="line"><span class="comment"># 需要修改一下 sgd的学习率</span></span><br><span class="line">sgd = SGD(lr=<span class="number">0.3</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= sgd,loss=<span class="string">&#x27;mse&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>之后我们就按照批次训练。 共训练3001个批次。有两种写法。<br>方法一：<br>用一个循环体，循环3001次； 每500次 打印一次 损失值。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练3001个批次</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3001</span>):</span><br><span class="line">    <span class="comment">#每次训练一个批次</span></span><br><span class="line">    cost = model.train_on_batch(x_data,y_data)</span><br><span class="line">    <span class="comment"># 每500个 batch 打印一次 cost值</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;cost:&quot;</span>,cost)</span><br></pre></td></tr></table></figure><br>方法二： 直接使用 model.fit () 函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.fit(x_data,y_data,epochs=<span class="number">3001</span>)</span><br></pre></td></tr></table></figure>
<p> 可以查看 参数值 W （权重）和 b（偏置值）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W,b = model.layers[<span class="number">0</span>].get_weights()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W：&#x27;</span>,W,<span class="string">&#x27;b:&#x27;</span>,b)</span><br></pre></td></tr></table></figure>
<p>预测 测试集的 结果 使用 model.predict () 函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 测试集 输入网络中，得到预测值 y_pred</span></span><br><span class="line">y_pred = model.predict(x_pre)</span><br></pre></td></tr></table></figure>
<p>可以再 把预测的 图打出来</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.scatter(x_pre,y_pred)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>我们的训练 使用方法二 <strong>结果如图所示：</strong><br><img src="https://img-blog.csdnimg.cn/79b89f1dec6e4327a2679c2c9882d6c7.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
        <tag>线性模型</tag>
        <tag>非线性模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Keras 实现 Kaggle 数据集 Titanic 预测</title>
    <url>/2021/09/17/Keras%20%E5%AE%9E%E7%8E%B0%20Kaggle%20%E6%95%B0%E6%8D%AE%E9%9B%86%20Titanic%20%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<p>@<a href="Keras 实现 Kaggle 数据集 Titanic 预测">TOC</a></p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><blockquote>
<p>使用乘客数据(如姓名、年龄、性别、社会经济阶层等)，建立一个模型预测泰坦尼克号沉船上哪些乘客能够幸存。<br>数据被分成训练集和测试集两组，它们分别在train.csv和test.csv文档中。我们的模型将基于训练集的乘客的性别和阶级等特征建立。在测试集中每个乘客是否幸存的信息是缺省的，其将由我们模型预测出来作为答案提交。</p>
</blockquote>
<h1 id="加载本地下载的-Titanic-数据集"><a href="#加载本地下载的-Titanic-数据集" class="headerlink" title="加载本地下载的 Titanic 数据集"></a>加载本地下载的 Titanic 数据集</h1><p>这里使用的 是 pandas 的 read_csv() 方法。 读取的格式为 DataFrame。<br><img src="https://img-blog.csdnimg.cn/0c79c9053cc34cd39d609475f2ac37f3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># xlsx训练数据导入</span></span><br><span class="line">train_filepath = <span class="string">r&quot;../dataset/Titanic/train.csv&quot;</span></span><br><span class="line">train_data = pd.read_csv(train_filepath)</span><br><span class="line">test_filepath = <span class="string">r&quot;../dataset/Titanic/test.csv&quot;</span></span><br><span class="line">test_data = pd.read_csv(test_filepath)</span><br></pre></td></tr></table></figure><br>同样可以用 shape函数查看 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#(891,12)</span></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br></pre></td></tr></table></figure>
<h1 id="数据分析与预处理"><a href="#数据分析与预处理" class="headerlink" title="数据分析与预处理"></a>数据分析与预处理</h1><p>在预处理数据前，首先整体分析各项数据对预测模型的重要性</p>
<p>（1）PassengerID：乘客的ID<br>（2）Survived：乘客是否幸存，取值为0或1，是我们预测/分类的目标。<br>（3）Pclass：客舱等级，可能蕴含着乘客的阶层、乘客客舱的位置等信息，比较重要。<br>（4）Name： 姓名，是无关信息。<br>（5）Sex：性别。灾难来临时常让妇女儿童先走，而同等条件女性体力普遍弱于男性，这些因素都会影响到一名乘客幸存的可能性，因此比较重要。<br>（6）Age：年龄，较为重要，理由同上。<br>（7）Parch：直系亲友数目，比较重要。<br>（8）SibSp：旁系亲友数目，比较重要。<br>（9）Ticket：票编号，是无关信息。<br>（10）Fare：票价，可能会反映乘客的社会阶层等。<br>（11）Cabin：客舱编号，可能会反映客舱位置等，但由于缺省太多，数据量很小不具有代表性，可以视为噪音剔除。<br>（12）Embarked：上船的港口编号。</p>
<p>在剔除了一些数据后，是否会因信息损失而降低模型的准确度？例如乘客的姓名可能暗含船上乘客之间家庭的关系。实际上我们的模型本来就是建立在不完全观测上（比如我们不知道船上的一对男女乘客有没有发生像Jack和Rose那样的故事），不确定性是必然存在的。把握主要矛盾，舍弃噪音信息是建立模型的一个好思路。</p>
<h2 id="训练数据预处理方法"><a href="#训练数据预处理方法" class="headerlink" title="训练数据预处理方法"></a>训练数据预处理方法</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="comment"># 训练数据预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PreprocessTrainData</span>(<span class="params">train_data</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理1：筛除无关特征</span></span><br><span class="line">    <span class="comment"># 无关的有 乘客的ID 姓名 票编号客舱编号（数据量太少，当噪声剔除）</span></span><br><span class="line">    <span class="comment"># 是否幸存 客舱等级 性别 年龄 旁系亲友数目  直系亲友数目 票价  上船港口编号</span></span><br><span class="line">    cols=[<span class="string">&#x27;Survived&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;SibSp&#x27;</span>, <span class="string">&#x27;Parch&#x27;</span>, <span class="string">&#x27;Fare&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>]</span><br><span class="line">    <span class="comment"># colums表示列名  index 表示行名</span></span><br><span class="line">    train_data = pd.DataFrame(train_data, columns=cols)</span><br><span class="line">    <span class="comment">#(891,8)</span></span><br><span class="line">    <span class="built_in">print</span>(train_data.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理2：填充缺失特征并标准化特征</span></span><br><span class="line">    age_mean = train_data[<span class="string">&#x27;Age&#x27;</span>].mean()</span><br><span class="line">    <span class="comment"># fillna 为 无值的数据填充</span></span><br><span class="line">    train_data[<span class="string">&#x27;Age&#x27;</span>] = train_data[<span class="string">&#x27;Age&#x27;</span>].fillna(age_mean)</span><br><span class="line"></span><br><span class="line">    fare_mean = train_data[<span class="string">&#x27;Fare&#x27;</span>].mean()</span><br><span class="line">    train_data[<span class="string">&#x27;Fare&#x27;</span>] = train_data[<span class="string">&#x27;Fare&#x27;</span>].fillna(fare_mean)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理3：性别编码0-1  将&#123;&#x27;female&#x27;: 0, &#x27;male&#x27;: 1&#125;</span></span><br><span class="line">    train_data[<span class="string">&#x27;Sex&#x27;</span>]= train_data[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;female&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>&#125;).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理4：登港地点转换为one-hot编码</span></span><br><span class="line">    <span class="comment"># 这是将 Embarked这一列 分成 one-hot形式 共有三个港口 所以分成了3列</span></span><br><span class="line">    x_OneHot_df = pd.get_dummies(data=train_data,columns=[<span class="string">&quot;Embarked&quot;</span>])</span><br><span class="line">    ndarray = x_OneHot_df.values</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;ndarray&#x27;</span>,ndarray)</span><br><span class="line">    <span class="comment">#(891,10)</span></span><br><span class="line">    <span class="built_in">print</span>(ndarray.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理5：全体特征标准化，标签向量化</span></span><br><span class="line">    <span class="comment"># &#x27;Survived&#x27;</span></span><br><span class="line">    label = ndarray[:,:<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># label的shape： (891,1)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label的shape：&quot;</span>,label.shape)</span><br><span class="line">    <span class="comment"># 除了&#x27;Survived&#x27; 其他全部特征</span></span><br><span class="line">    features = ndarray[:,<span class="number">1</span>:]</span><br><span class="line">    <span class="comment"># features的shape： (891, 9)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;features的shape：&quot;</span>, features.shape)</span><br><span class="line">    <span class="comment"># 求一个所有列的平均值</span></span><br><span class="line">    mean = features.mean(axis=<span class="number">0</span>)</span><br><span class="line">    features -= mean</span><br><span class="line">    <span class="comment"># 求一个所有列的方差</span></span><br><span class="line">    std = features.std(axis=<span class="number">0</span>)</span><br><span class="line">    features /= std</span><br><span class="line">    <span class="keyword">return</span> features,label</span><br></pre></td></tr></table></figure>
<h2 id="测试数据预处理方法"><a href="#测试数据预处理方法" class="headerlink" title="测试数据预处理方法"></a>测试数据预处理方法</h2><p>本质上与训练数据相同，只是少了一列 标签</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 测试数据预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PreprocessTestData</span>(<span class="params">test_data</span>):</span></span><br><span class="line">    <span class="comment"># 预处理1：筛除无关特征</span></span><br><span class="line">    <span class="comment"># 客舱等级 性别 年龄 旁系亲友数目 直系亲友数目 票价  上船港口编号</span></span><br><span class="line">    cols=[ <span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;SibSp&#x27;</span>, <span class="string">&#x27;Parch&#x27;</span>, <span class="string">&#x27;Fare&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>]</span><br><span class="line">    test_data = test_data[cols]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理2：填充缺失特征并标准化特征</span></span><br><span class="line">    age_mean = test_data[<span class="string">&#x27;Age&#x27;</span>].mean()</span><br><span class="line">    test_data[<span class="string">&#x27;Age&#x27;</span>] = test_data[<span class="string">&#x27;Age&#x27;</span>].fillna(age_mean)</span><br><span class="line"></span><br><span class="line">    fare_mean = test_data[<span class="string">&#x27;Fare&#x27;</span>].mean()</span><br><span class="line">    test_data[<span class="string">&#x27;Fare&#x27;</span>] = test_data[<span class="string">&#x27;Fare&#x27;</span>].fillna(fare_mean)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理3：性别编码0-1</span></span><br><span class="line">    test_data[<span class="string">&#x27;Sex&#x27;</span>]= test_data[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;female&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>&#125;).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理4：登港地点转换为one-hot编码</span></span><br><span class="line">    x_OneHot_df = pd.get_dummies(data=test_data,columns=[<span class="string">&quot;Embarked&quot;</span>])</span><br><span class="line">    ndarray = x_OneHot_df.values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理5：全体特征标准化，标签向量化</span></span><br><span class="line">    features = ndarray</span><br><span class="line">    mean = features.mean(axis=<span class="number">0</span>)</span><br><span class="line">    features -= mean</span><br><span class="line">    std = features.std(axis=<span class="number">0</span>)</span><br><span class="line">    features /= std</span><br><span class="line">    <span class="keyword">return</span> features</span><br></pre></td></tr></table></figure>
<h2 id="拿到处理后的数据"><a href="#拿到处理后的数据" class="headerlink" title="拿到处理后的数据"></a>拿到处理后的数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_train, y_train = PreprocessTrainData(train_data)</span><br><span class="line">x_test = PreprocessTestData(test_data)</span><br></pre></td></tr></table></figure>
<h1 id="构建网络模型"><a href="#构建网络模型" class="headerlink" title="构建网络模型"></a>构建网络模型</h1><p>构建网络时需要注意控制网络的大小。模型中容量（模型可学习的参数）不足可能导致欠拟合；但模型也不是越大越好，因为模型过大可能导致过拟合，泛化能力下降。其他降低过拟合的方法包括添加dropout正则化、权重正则化等。此外还需要在评估模型（将在下文阐述）的过程中尝试不同的超参数（学习率等）以找到最佳配置。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第三步 构建网络</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TitanicModel</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建网络-模型定义</span></span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(layers.Dense(input_dim=<span class="number">9</span>,units=<span class="number">64</span>, kernel_regularizer=regularizers.l1_l2(l1=<span class="number">0.001</span>,l2=<span class="number">0.001</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(layers.Dense(units=<span class="number">64</span>, kernel_regularizer=regularizers.l1_l2(l1=<span class="number">0.001</span>,l2=<span class="number">0.001</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(layers.Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建网络-编译模型</span></span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h1 id="训练模型（带验证集）"><a href="#训练模型（带验证集）" class="headerlink" title="训练模型（带验证集）"></a>训练模型（带验证集）</h1><h2 id="划分测试集和验证集"><a href="#划分测试集和验证集" class="headerlink" title="划分测试集和验证集"></a>划分测试集和验证集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 留出验证集</span></span><br><span class="line">num_val = <span class="number">300</span></span><br><span class="line"><span class="comment"># 将训练集样本顺序 随机打乱</span></span><br><span class="line">np.random.shuffle([x_train,y_train])</span><br><span class="line"><span class="comment"># 取出 前300个 训练样本作为 验证集</span></span><br><span class="line">x_val = x_train[:num_val]</span><br><span class="line"><span class="comment"># 其他的部分作为 真实的训练集</span></span><br><span class="line">partial_x_train = x_train[num_val:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取出前三百个的标签 作为 验证集</span></span><br><span class="line">y_val = y_train[:num_val]</span><br><span class="line"><span class="comment"># 其他的 作为真实的训练集</span></span><br><span class="line">partial_y_train = y_train[num_val:]</span><br></pre></td></tr></table></figure>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model = TitanicModel()</span><br><span class="line">model.fit(partial_x_train, partial_y_train, epochs = <span class="number">150</span>, batch_size=<span class="number">16</span>, validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>
<h1 id="预测测试样本并评估"><a href="#预测测试样本并评估" class="headerlink" title="预测测试样本并评估"></a>预测测试样本并评估</h1><h2 id="预测测试样本"><a href="#预测测试样本" class="headerlink" title="预测测试样本"></a>预测测试样本</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_test2 = model.predict_classes(x_test)</span><br><span class="line"><span class="built_in">print</span>(y_test2)</span><br></pre></td></tr></table></figure>
<h2 id="读取正确答案"><a href="#读取正确答案" class="headerlink" title="读取正确答案"></a>读取正确答案</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">real_label_filepath = <span class="string">r&quot;../dataset/Titanic/gender_submission.csv&quot;</span></span><br><span class="line">real_label = pd.read_csv(real_label_filepath)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取正确数值一列</span></span><br><span class="line">onehot = pd.get_dummies(data=real_label)</span><br><span class="line">xarray = onehot.values</span><br><span class="line">real = xarray[:,<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(real.shape,y_test2.shape)</span><br></pre></td></tr></table></figure>
<h2 id="输出正确率与保存预测答案"><a href="#输出正确率与保存预测答案" class="headerlink" title="输出正确率与保存预测答案"></a>输出正确率与保存预测答案</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> (y_pre,y_rel) <span class="keyword">in</span> <span class="built_in">zip</span>(y_test2,real):</span><br><span class="line">    <span class="keyword">if</span> y_pre == y_rel:</span><br><span class="line">        count = count+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;count:&quot;</span>,count)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;这个模型的正确率是：&quot;</span> ,count/y_test2.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">r&quot;../dataset/Titanic/gender_submission_predict.csv&quot;</span>,<span class="string">&#x27;w+&#x27;</span>,newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    csv_file = csv.writer(f)</span><br><span class="line">    csv_file.writerows(y_test2)</span><br></pre></td></tr></table></figure>
<h1 id="这个模型的优点"><a href="#这个模型的优点" class="headerlink" title="这个模型的优点"></a>这个模型的优点</h1><p>这个模型 来自 [<a href="https://zhuanlan.zhihu.com/p/278057962?utm_source=wechat_session&amp;ivk_sa=1024320u">https://zhuanlan.zhihu.com/p/278057962?utm_source=wechat_session&amp;ivk_sa=1024320u</a>]<br>此模型在kaggle上排名前12%。总结其优点如下：</p>
<p>（1）几乎完全没有人工干预。我们并不需要深入理解和分析每种因素对乘客幸存可能性的影响，而只需将数据几乎交由机器自己来学习便能得到准确度极高的预测结果。</p>
<p>（2）几乎没有引入数据集以外的新信息。引入新信息的行为包括将已知的乘客生存信息填入预测结果（kaggle上实现100%准确率的来源）等。此模型仅在数据处理阶段，引入部分常识判断的信息。</p>
<p>（3）<strong>模型泛化能力强</strong>。这里的“泛化”是指在模型建立过程中没有对该问题“过拟合”。实质上一味追求此问题的预测准确率是没有意义的。过度分析并设计复杂的特征工程也许可以提高测试集的准确率，但实质上很可能是对该问题的过拟合，不能在其他类似问题上泛化。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Keras</tag>
        <tag>刘二</tag>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据处理篇之Matplotlib系列</title>
    <url>/2021/10/30/Python%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AF%87%E4%B9%8BMatplotlib%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<p>@<a href="Python数据处理篇之Matplotlib系列">TOC</a></p>
<h1 id="创建画布与显示"><a href="#创建画布与显示" class="headerlink" title="创建画布与显示"></a>创建画布与显示</h1><p><a href="https://www.cnblogs.com/zyg123/p/10504622.html">Python数据处理篇之Matplotlib系列(一)—-初识Matplotlib</a></p>
<h1 id="plt-scatter-散点图"><a href="#plt-scatter-散点图" class="headerlink" title="plt.scatter()散点图"></a>plt.scatter()散点图</h1><p><a href="https://www.cnblogs.com/zyg123/p/10504628.html">Python数据处理篇之Matplotlib系列(二)—-plt.scatter()散点图</a></p>
<h1 id="plt-plot-折线图"><a href="#plt-plot-折线图" class="headerlink" title="plt.plot()折线图"></a>plt.plot()折线图</h1><p><a href="https://www.cnblogs.com/zyg123/p/10504633.html">Python数据处理篇之Matplotlib系列(三)—-plt.plot()折线图</a></p>
<h1 id="plt-bar-与plt-barh条形图"><a href="#plt-bar-与plt-barh条形图" class="headerlink" title="plt.bar()与plt.barh条形图"></a>plt.bar()与plt.barh条形图</h1><p><a href="https://www.cnblogs.com/zyg123/p/10504637.html">Python数据处理篇之Matplotlib系列(四)—-plt.bar()与plt.barh条形图</a></p>
<h1 id="plt-pie-饼状图"><a href="#plt-pie-饼状图" class="headerlink" title="plt.pie()饼状图"></a>plt.pie()饼状图</h1><p><a href="https://www.cnblogs.com/zyg123/p/10504640.html">Python数据处理篇之Matplotlib系列(五)—-plt.pie()饼状图</a></p>
<h1 id="plt-hist-与plt-hist2d-直方图"><a href="#plt-hist-与plt-hist2d-直方图" class="headerlink" title="plt.hist()与plt.hist2d()直方图"></a>plt.hist()与plt.hist2d()直方图</h1><p><a href="https://www.cnblogs.com/zyg123/p/10504645.html">Python数据处理篇之Matplotlib系列(六)—-plt.hist()与plt.hist2d()直方图</a></p>
<h1 id="matplotlib原理分析"><a href="#matplotlib原理分析" class="headerlink" title="matplotlib原理分析"></a>matplotlib原理分析</h1><p><a href="https://www.cnblogs.com/zyg123/p/10512513.html">Python数据处理篇之Matplotlib系列(七)—-matplotlib原理分析</a></p>
]]></content>
      <categories>
        <category>python工具包类</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>python</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 多分类问题的解决</title>
    <url>/2021/09/15/Pytorch%20%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<p>@<a href="Pytorch 多分类问题的解决">TOC</a></p>
<h1 id="多分类问题-激活函数的选择-Softmax"><a href="#多分类问题-激活函数的选择-Softmax" class="headerlink" title="多分类问题 激活函数的选择 Softmax"></a>多分类问题 激活函数的选择 Softmax</h1><p><img src="https://img-blog.csdnimg.cn/87f8f15a7fc0480d95ba08f55f1c6a4c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="应该解决的条件"><br>选择 Softmax 函数的关键点是：</p>
<ul>
<li>确保输出的每一个概率都是 ≥ 0 的</li>
<li>所有的概率之和应该为 1</li>
</ul>
<p>Softmax 激活函数完美解决了这个问题：</p>
<p><img src="https://img-blog.csdnimg.cn/a3a45fd36d8d4f45a7c7347e26e7d744.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="Softmax公式"><br>举个简单的例子<br><img src="https://img-blog.csdnimg.cn/799dea5f0b8348cea9c294567d552202.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="算数案例"></p>
<h1 id="CrossEntropyLoss-和-NLLLoss区别"><a href="#CrossEntropyLoss-和-NLLLoss区别" class="headerlink" title="CrossEntropyLoss 和 NLLLoss区别"></a>CrossEntropyLoss 和 NLLLoss区别</h1><p>NLLLoss全称是Negative Log Likelyhood Loss，负对数似然损失函数。<br>softmax + NLLLoss = CrossEntropyLoss</p>
<p>在Pytorch中</p>
<ul>
<li>CrossEntropyLoss可以直接接到模型结果之后，直接得出交叉熵损失。</li>
<li>NLLLoss需要在模型结果后先接一个Softmax，将模型结果变成概率，再用NLLLoss求预测损失。</li>
</ul>
<h1 id="实现梯度下降"><a href="#实现梯度下降" class="headerlink" title="实现梯度下降"></a>实现梯度下降</h1><h2 id="Step1：准备数据"><a href="#Step1：准备数据" class="headerlink" title="Step1：准备数据"></a>Step1：准备数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="Step2：初始化参数w"><a href="#Step2：初始化参数w" class="headerlink" title="Step2：初始化参数w"></a>Step2：初始化参数w</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始值w为1</span></span><br><span class="line">w = <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<h2 id="Step3：定义模型"><a href="#Step3：定义模型" class="headerlink" title="Step3：定义模型"></a>Step3：定义模型</h2><p><img src="https://img-blog.csdnimg.cn/45983f52cebc4ab2b4d3cf4e0ee7e16b.png#pic_center" alt="在这里插入图片描述"><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x_data</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x_data * w</span><br></pre></td></tr></table></figure></p>
<h2 id="Step4：定义损失函数"><a href="#Step4：定义损失函数" class="headerlink" title="Step4：定义损失函数"></a>Step4：定义损失函数</h2><p><img src="https://img-blog.csdnimg.cn/fb6f96943d1b46a696049f6c07965484.png#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x_data, y_data</span>):</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):</span><br><span class="line">        y_pred = forward(x)</span><br><span class="line">        loss = loss + (y_pred - y) ** <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> loss / <span class="built_in">len</span>(x_data)</span><br></pre></td></tr></table></figure>
<h2 id="Step5：定义梯度"><a href="#Step5：定义梯度" class="headerlink" title="Step5：定义梯度"></a>Step5：定义梯度</h2><p><img src="https://img-blog.csdnimg.cn/845af8941e0c4ee08fe574a29c869950.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 求梯度 也就是 损失函数对w的偏导</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">x_data, y_data</span>):</span></span><br><span class="line">    grad = <span class="number">0</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    x = [1, 2, 3]</span></span><br><span class="line"><span class="string">    y = [4, 5, 6, 7]</span></span><br><span class="line"><span class="string">    xy = zip(x, y)</span></span><br><span class="line"><span class="string">    print xy</span></span><br><span class="line"><span class="string">    运行的结果是： [(1, 4), (2, 5), (3, 6)]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):</span><br><span class="line">        grad = grad + <span class="number">2</span> * x * (x * w - y)</span><br><span class="line">    <span class="keyword">return</span> grad / <span class="built_in">len</span>(x_data)</span><br></pre></td></tr></table></figure>
<h2 id="Step6：训练并更新参数-w"><a href="#Step6：训练并更新参数-w" class="headerlink" title="Step6：训练并更新参数 w"></a>Step6：训练并更新参数 w</h2><p><img src="https://img-blog.csdnimg.cn/731d4beb873c41938a42b58461044c56.png#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 没训练过的时候 w是初始值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Predict (before training)&#x27;</span>, <span class="number">4</span>, forward(<span class="number">4</span>))</span><br><span class="line"><span class="comment"># 这批数据样本 训练 99次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="comment"># 每次都是计算一整个数据集的 平均loss</span></span><br><span class="line">    loss_val = loss(x_data, y_data)</span><br><span class="line">    grad_val = gradient(x_data, y_data)</span><br><span class="line">    w = w - <span class="number">0.01</span> * grad_val</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#x27;</span>, epoch, <span class="string">&#x27;w=&#x27;</span>, w, <span class="string">&#x27;loss=&#x27;</span>, loss_val)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Predict (after training)&#x27;</span>, <span class="number">4</span>, forward(<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<h1 id="实现多分类"><a href="#实现多分类" class="headerlink" title="实现多分类"></a>实现多分类</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一步 准备数据</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    <span class="comment"># 用均值和方差进行归一化</span></span><br><span class="line">    transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">])</span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">                               train=<span class="literal">True</span>,</span><br><span class="line">                               download=<span class="literal">True</span>,</span><br><span class="line">                               transform=transform)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">                              train=<span class="literal">False</span>,</span><br><span class="line">                              download=<span class="literal">True</span>,</span><br><span class="line">                              transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,</span><br><span class="line">                         shuffle=<span class="literal">False</span>,</span><br><span class="line">                         batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步 设计模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 这个是必须写的</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 构建层次模型</span></span><br><span class="line">        self.l1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">        self.l2 = torch.nn.Linear(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.l3 = torch.nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.l4 = torch.nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.l5 = torch.nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>,<span class="number">784</span>)</span><br><span class="line">        x = F.relu(self.l1(x))</span><br><span class="line">        x = F.relu(self.l2(x))</span><br><span class="line">        x = F.relu(self.l3(x))</span><br><span class="line">        x = F.relu(self.l4(x))</span><br><span class="line">        <span class="keyword">return</span> self.l5(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化这个网络模型</span></span><br><span class="line">model = Net()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步 定义损失函数和优化器</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四步 训练模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 这个0 的意思表示 索引从0开始计</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第五步 测试并检验</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            <span class="comment">#输出每行最大的那个</span></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Numpy、Pandas、Matplotlib  常用代码</title>
    <url>/2021/08/21/Numpy%E3%80%81Pandas%E3%80%81Matplotlib%20%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>@<a href="Numpy、Pandas、Matplotlib  常用代码">TOC</a></p>
<h1 id="Numpy-常用代码"><a href="#Numpy-常用代码" class="headerlink" title="Numpy 常用代码"></a>Numpy 常用代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数组</span></span><br><span class="line">n = numpy.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(n)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数组，并做2行3列的分隔</span></span><br><span class="line">m = numpy.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(m)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据，分隔成3位数组</span></span><br><span class="line">t = numpy.arange(<span class="number">27</span>).reshape(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(t)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载文本，为int方式</span></span><br><span class="line">tx1 = numpy.loadtxt(<span class="string">&quot;numpy.txt&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=<span class="string">&quot;int&quot;</span>)</span><br><span class="line"><span class="comment"># 横列替换</span></span><br><span class="line">tx2 = numpy.loadtxt(<span class="string">&quot;numpy.txt&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=<span class="string">&quot;int&quot;</span>, unpack=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(tx1)</span><br><span class="line"><span class="built_in">print</span>(tx2)</span><br><span class="line"><span class="comment"># 1:2横截取，[1,2]为选取</span></span><br><span class="line">tx3 = tx1[<span class="number">1</span>:<span class="number">2</span>,[<span class="number">1</span>,<span class="number">2</span>]]</span><br><span class="line"><span class="built_in">print</span>(tx3)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 竖拼接</span></span><br><span class="line">tx4 = numpy.vstack((tx1, tx2))</span><br><span class="line"><span class="built_in">print</span>(tx4)</span><br><span class="line"><span class="comment"># 横拼接</span></span><br><span class="line">tx5 = numpy.hstack((tx1, tx2))</span><br><span class="line"><span class="built_in">print</span>(tx5)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<h2 id="函数简介"><a href="#函数简介" class="headerlink" title="函数简介"></a>函数简介</h2><h3 id="arrange-函数：用于创建数值范围并返回数组对象"><a href="#arrange-函数：用于创建数值范围并返回数组对象" class="headerlink" title="arrange 函数：用于创建数值范围并返回数组对象"></a>arrange 函数：用于创建数值范围并返回数组对象</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.arrange([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>],dtype=numpy.int6或dtype=<span class="string">&#x27;i8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="linspace-函数：-用于创建等差数组"><a href="#linspace-函数：-用于创建等差数组" class="headerlink" title="linspace 函数： 用于创建等差数组"></a>linspace 函数： 用于创建等差数组</h3><p>numpy.linspace(start,stop,num,endpoint,retstep,dtype)</p>
<p>dtype：默认为 float64<br>num：设置生成的元素个数<br>endpoint：设置是否包含结束值（stop），False为不包含，<strong>默认为True</strong><br>retstep：设置是否返回步长（即公差），False表示返回，<strong>默认为False</strong>。当值为 True时，返回值为 二元组，包括数组与步长。</p>
<h3 id="logspace-函数：-用于创建等比数组"><a href="#logspace-函数：-用于创建等比数组" class="headerlink" title="logspace 函数： 用于创建等比数组"></a>logspace 函数： 用于创建等比数组</h3><p>numpy.logspace(start,stop,num,endpoint,base,dtype)</p>
<p>start：开始值，值为$base^{start}$    =》 base为底的 start次幂<br>stop：结束值，值为$base^{stop}$    =》base为底的 stop次幂<br>base：底数<br>dtype：默认数据类型 float64<br>endpoint：True为包含结束值，默认为True</p>
<h2 id="numpy-练习题一"><a href="#numpy-练习题一" class="headerlink" title="numpy 练习题一"></a>numpy 练习题一</h2><p><strong>numpy 的基本用法</strong><br>1.导入numpy库<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><br>2.建立一个一维数组 a 初始化为[4,5,6],<br>(1)输出a 的类型（type）<br>(2)输出a的各维度的大小（shape）<br>(3)输出 a的第一个元素（值为4）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line"><span class="built_in">print</span>(a.dtype)</span><br><span class="line"><span class="built_in">print</span>(a.shape)</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><br>3.建立一个二维数组 b,初始化为 [ [4, 5, 6],[1, 2, 3]]<br> (1)输出各维度的大小（shape）<br> (2)输出 b(0,0)，b(0,1),b(1,1) 这三个元素（对应值分别为4,5,2）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b = np.array([[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(b[<span class="number">0</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(b[<span class="number">1</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br><span class="line"><span class="built_in">print</span>(b[<span class="number">0</span>][<span class="number">0</span>],b[<span class="number">0</span>][<span class="number">1</span>],b[<span class="number">1</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>4  (1)建立一个全0矩阵 a, 大小为 3x3; 类型为整型（提示: dtype = int）(2)建立一个全1矩阵b,大小为4x5; (3)建立一个单位矩阵c ,大小为4x4; (4)生成一个随机数矩阵d,大小为 3x2.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">c = np.zeros([<span class="number">3</span>,<span class="number">3</span>],dtype=<span class="built_in">int</span>)</span><br><span class="line">d = np.ones([<span class="number">4</span>,<span class="number">5</span>],dtype=<span class="built_in">int</span>)</span><br><span class="line">e = np.identity(<span class="number">4</span>,dtype=<span class="built_in">int</span>)</span><br><span class="line">f = np.random.rand(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"><span class="built_in">print</span>(e)</span><br><span class="line"><span class="built_in">print</span>(f)</span><br></pre></td></tr></table></figure><br>5  建立一个数组 a,(值为[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]] ) ,(1)打印a; (2)输出 下标为(2,3),(0,0) 这两个数组元素的值<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],[<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">2</span>][<span class="number">3</span>],a[<span class="number">0</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure><br>6.把上一题的 a数组的 0到1行 2到3列，放到b里面去，（此处不需要从新建立a,直接调用即可）(1),输出b;(2) 输出b 的（0,0）这个元素的值<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b = a[<span class="number">0</span>:<span class="number">2</span>,<span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="built_in">print</span>(b[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"> <span class="comment">#？？？ 用ndarray不会</span></span><br></pre></td></tr></table></figure><br>7 把第5题中数组a的最后两行所有元素放到 c中，（提示： a[1:2, :]）(1)输出 c ; (2) 输出 c 中第一行的最后一个元素（提示，使用 -1 表示最后一个元素）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],[<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line">c = a[<span class="number">1</span>:]</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(c[<span class="number">0</span>][-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><br>8.建立数组a,初始化a为[[1, 2], [3, 4], [5, 6]]，输出 （0,0）（1,1）（2,0）这三个元素（提示： 使用 print(a[[0, 1, 2], [0, 1, 0]]) ）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment">#花式索引 第一种</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]])</span><br></pre></td></tr></table></figure><br>9.建立矩阵a ,初始化为[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]，输出(0,0),(1,2),(2,0),(3,1) (提示使用 b = np.array([0, 2, 0, 1]) print(a[np.arange(4), b]))<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#花式索引 第二种</span></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">b = np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(a[np.arange(<span class="number">4</span>),b])</span><br></pre></td></tr></table></figure><br>10.对9 中输出的那四个元素，每个都加上10，然后重新输出矩阵a.(提示： a[np.arange(4), b] += 10 ）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数组广播</span></span><br><span class="line"><span class="built_in">print</span>(a[np.arange(<span class="number">4</span>),b]+<span class="number">10</span>)</span><br></pre></td></tr></table></figure><br><strong>numpy 的 array 数学操作</strong></p>
<ol>
<li>执行 x = np.array([1, 2])，然后输出 x 的数据类型<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(x.dtype)</span><br></pre></td></tr></table></figure>
12.执行 x = np.array([1.0, 2.0]) ，然后输出 x 的数据类类型<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1.0</span>, <span class="number">2.0</span>])</span><br><span class="line"><span class="built_in">print</span>(x.dtype)</span><br></pre></td></tr></table></figure>
13.执行 x = np.array([[1, 2], [3, 4]], dtype=np.float64) ，y = np.array([[5, 6], [7, 8]], dtype=np.float64)，然后输出 x+y ,和 np.add(x,y)<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(x+y)</span><br><span class="line"><span class="built_in">print</span>(np.add(x,y))</span><br><span class="line"><span class="comment">#总结：在numpy中，add和“+”是一样的</span></span><br></pre></td></tr></table></figure>
14  利用 13题目中的x,y 输出 x-y 和 np.subtract(x,y)<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(x-y)</span><br><span class="line"><span class="built_in">print</span>(np.subtract(x,y))</span><br><span class="line"><span class="comment">#总结：在numpy中，subtract和“-”是一样的</span></span><br></pre></td></tr></table></figure>
15  利用13题目中的x，y 输出 x*y ,和 np.multiply(x, y) 还有 np.dot(x,y),比较差异。然后自己换一个不是方阵的试试。<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(np.multiply(x,y))</span><br><span class="line"><span class="built_in">print</span>(np.dot(x,y))</span><br><span class="line"><span class="built_in">print</span>(x*y)</span><br><span class="line"></span><br><span class="line"><span class="comment">##总结：np.multiply()：数组和矩阵对应位置相乘，输出与相乘数组/矩阵大小一致。</span></span><br><span class="line"><span class="comment"># np.dot():执行矩阵乘法运算，若秩为1，则执行对应位置相乘再相加。</span></span><br><span class="line"><span class="comment"># *：对array执行对应位置相乘</span></span><br></pre></td></tr></table></figure>
16 利用13题目中的x,y,输出 x / y .(提示 ： 使用函数 np.divide())<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(np.divide(x,y))</span><br><span class="line"><span class="built_in">print</span>(x/y)</span><br><span class="line"><span class="comment">## np.divide()与 / 效果相同</span></span><br></pre></td></tr></table></figure>
17 利用13题目中的x,输出 x的 开方。(提示： 使用函数 np.sqrt() )<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(np.sqrt(x))</span><br></pre></td></tr></table></figure>
18.利用13题目中的x,y ,执行 print(x.dot(y)) 和 print(np.dot(x,y))<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(x.dot(y))</span><br><span class="line"><span class="built_in">print</span>(np.dot(x,y))</span><br><span class="line"><span class="comment">##总结：二维数组矩阵之间dot函数运算得到的乘积是矩阵乘积，一维数组是两个向量的内积</span></span><br></pre></td></tr></table></figure>
19.利用13题目中的 x,进行求和。提示：输出三种求和<br>(1)print(np.sum(x)): (2)print(np.sum(x，axis =0 )); (3)print(np.sum(x,axis = 1))<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x))</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x,axis=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x,axis=<span class="number">1</span>))</span><br><span class="line"><span class="comment">##总结：axis为0是压缩行,即将每一列的元素相加,将矩阵压缩为一行</span></span><br><span class="line"><span class="comment">## axis为1是压缩列,即将每一行的元素相加,将矩阵压缩为一列，再转置</span></span><br></pre></td></tr></table></figure>
20.利用13题目中的 x,进行求平均数（提示：输出三种平均数(1)print(np.mean(x)) (2)print(np.mean(x,axis = 0))(3) print(np.mean(x,axis =1))）<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(np.mean(x))</span><br><span class="line"><span class="built_in">print</span>(np.mean(x,axis = <span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(np.mean(x,axis =<span class="number">1</span>))</span><br><span class="line"><span class="comment">##总结：axis为0是压缩行,即将每一列的元素相加,将矩阵压缩为一行,再取平均值</span></span><br><span class="line"><span class="comment">## axis为1是压缩列,即将每一行的元素相加,将矩阵压缩为一列，再转置，再取平均值</span></span><br></pre></td></tr></table></figure>
21.利用13题目中的x，对x 进行矩阵转置，然后输出转置后的结果，（提示： x.T 表示对 x 的转置）<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(x.T)</span><br></pre></td></tr></table></figure>
22.利用13题目中的x,求e的指数（提示： 函数 np.exp()）<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(np.exp(x))</span><br></pre></td></tr></table></figure>
23.利用13题目中的 x,求值最大的下标（提示(1)print(np.argmax(x)) ,(2) print(np.argmax(x, axis =0))(3)print(np.argmax(x),axis =1))<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>,<span class="number">3</span>], [<span class="number">3</span>, <span class="number">4</span>,<span class="number">5</span>]], dtype=np.float64)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(np.argmax(x))</span><br><span class="line"><span class="built_in">print</span>(np.argmax(x, axis =<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(np.argmax(x,axis =<span class="number">1</span>))</span><br><span class="line"><span class="comment">##总结： numpy.argmax(array, axis) 用于返回一个numpy数组中最大值的索引值。</span></span><br><span class="line"><span class="comment"># axis=0则竖着看，当axis=0，是在列中比较，选出最大的 行 索引</span></span><br><span class="line"><span class="comment"># axis=1则横着看, 当axis=1，是在行中比较，选出最大的 列 索引</span></span><br></pre></td></tr></table></figure>
24,画图，y=x*x 其中 x = np.arange(0, 100, 0.1) （提示这里用到 matplotlib.pyplot 库）<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x=np.arange(<span class="number">0</span>,<span class="number">100</span>,<span class="number">0.1</span>)</span><br><span class="line">y=x*x</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
25.画图。画正弦函数和余弦函数， x = np.arange(0, 3 * np.pi, 0.1)(提示：这里用到 np.sin() np.cos() 函数和 matplotlib.pyplot 库)<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=np.arange(<span class="number">0</span>, <span class="number">3</span>*np.pi, <span class="number">0.1</span>)</span><br><span class="line">y1=np.sin(x)</span><br><span class="line">y2=np.cos(x)</span><br><span class="line">plt.plot(x,y1)</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Pandas-常用代码"><a href="#Pandas-常用代码" class="headerlink" title="Pandas 常用代码"></a>Pandas 常用代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取文件</span></span><br><span class="line">df = pandas.read_csv(<span class="string">&quot;BeijingPM20100101_20151231.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 展示</span></span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"><span class="comment"># print(df.info())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接时间</span></span><br><span class="line">period = pandas.PeriodIndex(year=df[<span class="string">&quot;year&quot;</span>], month=df[<span class="string">&quot;month&quot;</span>], day=df[<span class="string">&quot;day&quot;</span>], hour=df[<span class="string">&quot;hour&quot;</span>], freq=<span class="string">&quot;H&quot;</span>)</span><br><span class="line"><span class="comment"># 将时间数据赋值</span></span><br><span class="line">df[<span class="string">&quot;dataTime&quot;</span>] = period</span><br><span class="line"><span class="comment"># 设置索引</span></span><br><span class="line">df.set_index(<span class="string">&quot;dataTime&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># # print(period)</span></span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过月份统计</span></span><br><span class="line">df = df.resample(<span class="string">&quot;M&quot;</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># (统计)缺失</span></span><br><span class="line">data = df[<span class="string">&quot;PM_US Post&quot;</span>].dropna()</span><br><span class="line"></span><br><span class="line"><span class="comment"># pylot展示</span></span><br><span class="line">x = data.index</span><br><span class="line">y = data.values</span><br><span class="line"></span><br><span class="line">pyplot.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">80</span>)</span><br><span class="line">pyplot.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(x)), y)</span><br><span class="line">pyplot.xticks(<span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(x), <span class="number">3</span>), x[::<span class="number">3</span>])</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<h1 id="Matplotlib-常用代码"><a href="#Matplotlib-常用代码" class="headerlink" title="Matplotlib 常用代码"></a>Matplotlib 常用代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">7</span>]</span><br><span class="line">y_1 = [<span class="number">10</span>, <span class="number">15</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">13</span>, <span class="number">17</span>, <span class="number">19</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">15</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">16</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">17</span>]</span><br><span class="line">y_2 = [<span class="number">17</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">12</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">19</span>, <span class="number">17</span>, <span class="number">13</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">15</span>, <span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">pyplot.figure(figsize=(<span class="number">20</span>, <span class="number">12</span>), dpi=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整字体</span></span><br><span class="line">matplotlib.rc(<span class="string">&quot;font&quot;</span>, family=<span class="string">&quot;MicroSoft YaHei&quot;</span>,weight=<span class="string">&quot;bold&quot;</span>, size=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 改变刻度</span></span><br><span class="line"><span class="comment"># pyplot.xticks([ i + 1 for i in range(max(x))], [ &quot;time&quot; + str(i + 1) for i in range(max(x))], rotation=45)</span></span><br><span class="line"><span class="comment"># 第一个参数x轴 第二个展示的内容 rotation 旋转</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 描述</span></span><br><span class="line">pyplot.xlabel(<span class="string">&quot;时间&quot;</span>)</span><br><span class="line">pyplot.ylabel(<span class="string">&quot;温度&quot;</span>)</span><br><span class="line">pyplot.title(<span class="string">&quot;折线图&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 折线图</span></span><br><span class="line">pyplot.plot(x, y_1)</span><br><span class="line"><span class="comment"># pyplot.plot(x, y_2)</span></span><br><span class="line"><span class="comment"># 散点图</span></span><br><span class="line"><span class="comment"># pyplot.scatter(x, y_1)</span></span><br><span class="line"><span class="comment"># pyplot.scatter(x, y_2)</span></span><br><span class="line"><span class="comment"># 柱状图</span></span><br><span class="line"><span class="comment"># pyplot.bar(x, y_1)</span></span><br><span class="line"><span class="comment"># pyplot.bar(x, y_2)</span></span><br><span class="line"><span class="comment"># 横版柱状图</span></span><br><span class="line"><span class="comment"># pyplot.barh(range(len(x)), y_1, height=0.3)</span></span><br><span class="line"><span class="comment"># pyplot.barh(range(len(x)), y_2, height=0.3)</span></span><br><span class="line"><span class="comment"># 直方图</span></span><br><span class="line"><span class="comment"># pyplot.hist(x, (max(x)-min(x))//1)</span></span><br><span class="line">pyplot.xticks(<span class="built_in">range</span>(<span class="built_in">min</span>(x), <span class="built_in">max</span>(x) + <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># pyplot.grid()</span></span><br><span class="line"><span class="comment"># 保存图片</span></span><br><span class="line"><span class="comment"># pyplot.savefig(&quot;link.png&quot;)</span></span><br><span class="line"></span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Matplotlib</tag>
        <tag>Numpy</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch CNN概念性解决</title>
    <url>/2021/09/16/Pytorch%20CNN%E6%A6%82%E5%BF%B5%E6%80%A7%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<p>@<a href="Pytorch CNN概念性解决">TOC</a><br>需要知道的几点</p>
<ol>
<li>卷积核里的参数都是超参数，是通过训练进行调整的</li>
</ol>
<h1 id="CNN的流程"><a href="#CNN的流程" class="headerlink" title="CNN的流程"></a>CNN的流程</h1><p>input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten（压平）——&gt;fully connected network——&gt;output</p>
<h1 id="CNN的卷积操作运算"><a href="#CNN的卷积操作运算" class="headerlink" title="CNN的卷积操作运算"></a>CNN的卷积操作运算</h1><h2 id="单通道图像"><a href="#单通道图像" class="headerlink" title="单通道图像"></a>单通道图像</h2><p><img src="https://img-blog.csdnimg.cn/f37680551d064da8b5dfe82c2e998a8d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="卷积计算方式"></p>
<h2 id="多通道图像-如三通道RGB"><a href="#多通道图像-如三通道RGB" class="headerlink" title="多通道图像  如三通道RGB"></a>多通道图像  如三通道RGB</h2><p>用三个卷积核，分别对3个通道各自卷积，然后再相加整合输出。<br><img src="https://img-blog.csdnimg.cn/379e12b328b14abda21ae5a551f94f9a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="RGB卷积"></p>
<h1 id="如何看待卷积核的个数和通道数"><a href="#如何看待卷积核的个数和通道数" class="headerlink" title="如何看待卷积核的个数和通道数"></a>如何看待卷积核的个数和通道数</h1><p><img src="https://img-blog.csdnimg.cn/21b1a72bd38e4c7984d1b65e3e0f1d2f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="卷积核的个数和通道数"><br>记住两条规律就好：</p>
<ul>
<li>卷积核通道数 = 输入通道数</li>
<li>卷积核个数 = 输出通道数</li>
</ul>
<p>注意卷积层一般都是4维的 包括：批次，输入通道数，卷积核大小（宽，高）<br>可以参考下面的卷积程序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入通道数为5  输出通道数为10</span></span><br><span class="line">in_channels,out_channels = <span class="number">5</span>, <span class="number">10</span></span><br><span class="line"><span class="comment"># 初始化图像高度</span></span><br><span class="line">width,height = <span class="number">100</span>,<span class="number">100</span></span><br><span class="line"><span class="comment"># 卷积核的大小</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line"><span class="comment"># 批次</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line"><span class="comment"># 随机生成100×100的 图像</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(batch_size,in_channels,width,height)</span><br><span class="line"><span class="comment"># 设置卷积层 输入维度，输出维度，卷积核大小</span></span><br><span class="line">conv_layer = torch.nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size)</span><br><span class="line"><span class="comment"># 将图片放入卷积层 输出结果</span></span><br><span class="line">output = conv_layer(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([1, 5, 100, 100])</span></span><br><span class="line"><span class="comment"># 分别为 batch_size,图片通道数，图像宽100，图像高100</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 10, 98, 98])</span></span><br><span class="line"><span class="comment"># 分别为 batch_size,输出通道数10（其实就是卷积核的个数），图像卷积后（由于卷积核是3×3 所以减去2）</span></span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"><span class="comment"># torch.Size([10, 5, 3, 3])</span></span><br><span class="line"><span class="comment"># 输出通道（卷积核数量） 输入通道（卷积核通道数） 卷积核大小</span></span><br><span class="line"><span class="built_in">print</span>(conv_layer.weight.shape)</span><br></pre></td></tr></table></figure>
<h1 id="如何看待-padding"><a href="#如何看待-padding" class="headerlink" title="如何看待 padding"></a>如何看待 padding</h1><p><strong>padding的目的是，为了规定输出图像的大小。</strong><br>例如 原来是  5×5 的原图，通过卷积核为 3×3 那 输出的图 是 3×3 的<br>但如果设置 padding 为1，那么相当于把原图扩充为 7×7 了。<br><img src="https://img-blog.csdnimg.cn/d6da81ad35f544e19c1b32e73f70714f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="padding为1时候的卷积"><br>可以参考一下如下的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 假设的灰度图片像素值 图片为5×5</span></span><br><span class="line"><span class="built_in">input</span> = [<span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">7</span>,</span><br><span class="line">         <span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">2</span>,</span><br><span class="line">         <span class="number">1</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">4</span>,</span><br><span class="line">         <span class="number">9</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">2</span>,</span><br><span class="line">         <span class="number">3</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 将输入的图片变成Tensor类型，并且reshape一下</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 参数从左到右分别为</span></span><br><span class="line"><span class="string">    batch_size,in_channels,width,height</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">input</span> = torch.Tensor(<span class="built_in">input</span>).view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积核的大小</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 从左到右分别为 </span></span><br><span class="line"><span class="string">    in_channels,out_channels,kernel_size</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">conv_layer = torch.nn.Conv2d(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    自定义一个tensor向量 再将其 reshape</span></span><br><span class="line"><span class="string">    batch_size,in_channels,width,height</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">kernel = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]).view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 初始化卷积层</span></span><br><span class="line">conv_layer.weight.data = kernel.data</span><br><span class="line"></span><br><span class="line">output = conv_layer(<span class="built_in">input</span>)</span><br><span class="line"><span class="comment"># torch.Size([1, 1, 5, 5])</span></span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/8123cd0423f9446ba513f9e8b03bb0d0.png#pic_center" alt="输出结果"></p>
<h1 id="如何看待步长-stride"><a href="#如何看待步长-stride" class="headerlink" title="如何看待步长 stride"></a>如何看待步长 stride</h1><p>设置一下 stride就可以了<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv_layer = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, bias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><br>改变步长的意义，其实就是为了缩小输出尺寸</p>
<h1 id="如何看待Max-Pooling"><a href="#如何看待Max-Pooling" class="headerlink" title="如何看待Max Pooling"></a>如何看待Max Pooling</h1><p><img src="https://img-blog.csdnimg.cn/84eff2cc1acd44c79a6cf251af071e3d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="MaxPooling示意图"><br>可以参考如下的代码:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = [ <span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,</span><br><span class="line">          <span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,</span><br><span class="line">          <span class="number">1</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,</span><br><span class="line">          <span class="number">9</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入的 batch_size为1 通道数为1 也就是灰度图像 大小是4×4</span></span><br><span class="line"><span class="built_in">input</span> = torch.Tensor(<span class="built_in">input</span>).view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment">#  默认的步长 stride也是2</span></span><br><span class="line">maxpooling_layer = torch.nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">output = maxpooling_layer(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    这里只进行了一个 maxpooling操作</span></span><br><span class="line"><span class="string">    input = [ 3,4,6,5,</span></span><br><span class="line"><span class="string">            2,4,6,8,</span></span><br><span class="line"><span class="string">            1,6,7,8,</span></span><br><span class="line"><span class="string">            9,7,4,6] </span></span><br><span class="line"><span class="string">    变为</span></span><br><span class="line"><span class="string">       [4,8</span></span><br><span class="line"><span class="string">        9,8]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="设计一个网络并实现"><a href="#设计一个网络并实现" class="headerlink" title="设计一个网络并实现"></a>设计一个网络并实现</h1><h2 id="如图所示为-要设计的网络模型"><a href="#如图所示为-要设计的网络模型" class="headerlink" title="如图所示为 要设计的网络模型"></a>如图所示为 要设计的网络模型</h2><p><img src="https://img-blog.csdnimg.cn/b352a2f5626544ae924453466305321f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="要设计的网络模型"></p>
<h2 id="转换成流程图"><a href="#转换成流程图" class="headerlink" title="转换成流程图"></a>转换成流程图</h2><p><img src="https://img-blog.csdnimg.cn/5bbf95bc996345c9a8ae13238acaa8ad.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="Pytorch-代码实现这个网络"><a href="#Pytorch-代码实现这个网络" class="headerlink" title="Pytorch 代码实现这个网络"></a>Pytorch 代码实现这个网络</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设计网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNNNet</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CNNNet, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># Flatten data from (n, 1, 28, 28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = self.pooling(torch.relu(self.conv1(x)))</span><br><span class="line">        x = self.pooling(torch.relu(self.conv2(x)))</span><br><span class="line">        <span class="comment"># flatten (n,320)</span></span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 实例化这个网络</span></span><br><span class="line">CNNmodel = CNNNet()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>CNN</tag>
        <tag>刘二</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 实现 多维特征的输入——糖尿病预测</title>
    <url>/2021/09/13/Pytorch%20%E5%AE%9E%E7%8E%B0%20%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5%E2%80%94%E2%80%94%E7%B3%96%E5%B0%BF%E7%97%85%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<p>@<a href="Pytorch 实现 多维特征的输入——糖尿病预测">TOC</a></p>
<p>整体的设计思路<br>大致的设计步骤 分为5步 如下所示：<br><img src="https://img-blog.csdnimg.cn/66ed2d3a9e914f229e8c67a8248b1dee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="实现的步骤"><br>第五步：是进行 评估模型并预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h1 id="Step1：准备数据"><a href="#Step1：准备数据" class="headerlink" title="Step1：准备数据"></a>Step1：准备数据</h1><p>数据格式包含759个样本，其中有8个特征已经其是否会加剧糖尿病的预测标签（1或0）。<br><img src="https://img-blog.csdnimg.cn/7475f37ead424166967915beceedd5ec.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据维度预览"><br>我们将759个样本，分为758个训练样本以及1个测试样本。</p>
<p>先读入本地 csv 文件内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    numpy读取本地文件</span></span><br><span class="line"><span class="string">    delimiter 分割号</span></span><br><span class="line"><span class="string">    dtype 读取数据类型  一般机器学习类的都是float32 </span></span><br><span class="line"><span class="string">    因为显卡一般他内核里面是按32位工作的</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;./dataset/diabetes.csv&#x27;</span>,delimiter=<span class="string">&quot;,&quot;</span>,dtype=np.float32)</span><br></pre></td></tr></table></figure>
<p>可以查看一下 读入的数据维度情况</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># (759,9) 759行 9列</span></span><br><span class="line"><span class="built_in">print</span>(xy.shape)</span><br></pre></td></tr></table></figure>
<p>其中758个样本作为测试集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numpy 转 张量  最后一组样本我们当测试样本吧  其余的当训练样本</span></span><br><span class="line">x_train = torch.from_numpy(xy[:-<span class="number">1</span>,:-<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(x_train.shape)</span><br><span class="line">y_train = torch.from_numpy(xy[:-<span class="number">1</span>,[-<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<p>最后一个样本作为训练集，用于预测结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 当测试样本 的 一组数据</span></span><br><span class="line">x_test = torch.from_numpy(xy[-<span class="number">1</span>:,:-<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(x_test.shape)</span><br><span class="line">y_test = torch.from_numpy(xy[-<span class="number">1</span>:,[-<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<h1 id="Step2：定义模型"><a href="#Step2：定义模型" class="headerlink" title="Step2：定义模型"></a>Step2：定义模型</h1><p>同样每一层都为 逻辑回归模型。但这边有8个特征，所以导入的应该是个矩阵。<br><img src="https://img-blog.csdnimg.cn/79a71c6a9f0245d9914e4fcef6607793.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="怎么构建线性模型"><br><img src="https://img-blog.csdnimg.cn/ad19f89d0a57481e8f2bdb1e37e8d7ee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="数据维度的变换 输入n行8个特征得到n行1列的预测"></p>
<h2 id="torch-nn-Linear-in-features-out-features-bias-True-方法"><a href="#torch-nn-Linear-in-features-out-features-bias-True-方法" class="headerlink" title="torch.nn.Linear(in_features,out_features,bias=True) 方法"></a>torch.nn.Linear(in_features,out_features,bias=True) 方法</h2><p><img src="https://img-blog.csdnimg.cn/0e75527101244e56a7687acb4eaa9315.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="torch.nn.Linear函数详解"><br>下面这个函数 使得8维度线性变换为6维度<br>注：1.整个模型都是以 列向量为操作单位的（这么做其实是为了利用计算机的并行计算能力加快训练速度），所以维度指的是有多少列，比如左下角这个维度就是8。<br>2.激活函数的引入，其实就是为了引入非线性的因素。这样就可以使得我们可以非线性的变换矩阵维度。<br><img src="https://img-blog.csdnimg.cn/1c73a9cbdba047818bda33c1c9ab517f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="8D到6D的真正含义"><br>下面是我们 构建的整体的 线性网络模型<br><img src="https://img-blog.csdnimg.cn/06e1c8bb27054087bce6ccb4c0eee8c0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="整体网络模型"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第二部 定义模型</span></span><br><span class="line"><span class="comment"># 这个其实有点类似与 神经网络的结构了 每个线性层后面都加了一个sigmoid函数 做了次非线性变换</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FullLeanerModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 定义多层线性模型的结构</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FullLeanerModel,self).__init__()</span><br><span class="line">        <span class="comment"># 第一个线性转换 将8维转换为6维</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>,<span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>,<span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前馈 运行输出结果</span></span><br><span class="line">    <span class="comment"># 会被自动调用 是方法的重写</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        <span class="comment"># 用一个变量比较 简单</span></span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span>  x</span><br></pre></td></tr></table></figure>
<p>实例化这个模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 实例化模型</span></span><br><span class="line">FullLeanerModel = FullLeanerModel()</span><br></pre></td></tr></table></figure>
<h1 id="Step3：定义损失函数和优化器"><a href="#Step3：定义损失函数和优化器" class="headerlink" title="Step3：定义损失函数和优化器"></a>Step3：定义损失函数和优化器</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第三步 定义 损失函数和优化器</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(FullLeanerModel.parameters(),lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Step4：训练模型"><a href="#Step4：训练模型" class="headerlink" title="Step4：训练模型"></a>Step4：训练模型</h1><p>训练模型100次</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第四步 训练</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> 前两步 就是正向传播 forward</span></span><br><span class="line"><span class="string">    1. 预测 标签</span></span><br><span class="line"><span class="string">    2. 预测 与 实际 算出损失值</span></span><br><span class="line"><span class="string">    3. 反向传播 backward 优化参数</span></span><br><span class="line"><span class="string">    4. 更新参数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>):</span><br><span class="line">    y_pred = FullLeanerModel(x_train)</span><br><span class="line">    loss = criterion(y_pred,y_train)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;迭代次数:&#x27;</span>,epoch,<span class="string">&quot;  损失值:&quot;</span>,loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()   <span class="comment">#更新参数</span></span><br></pre></td></tr></table></figure>
<h1 id="评估模型并预测"><a href="#评估模型并预测" class="headerlink" title="评估模型并预测"></a>评估模型并预测</h1><h2 id="输出所有层次的-权重和偏置"><a href="#输出所有层次的-权重和偏置" class="headerlink" title="输出所有层次的 权重和偏置"></a>输出所有层次的 权重和偏置</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    <span class="comment"># 输出各层  权重w 和 偏置b</span></span><br><span class="line"><span class="keyword">for</span> weight, bias <span class="keyword">in</span> FullLeanerModel.state_dict().items():  <span class="comment"># param is weight or bias(Tensor)</span></span><br><span class="line"><span class="built_in">print</span>( weight,bias)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/5c3c93e1544a4005873d7fabd4f88e51.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="各层次的权重和偏置值"></p>
<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_yuce = FullLeanerModel(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试样本的预测值为&quot;</span>,y_yuce.data,<span class="string">&quot;实际样本的标签值为&quot;</span>,y_test.data)</span><br></pre></td></tr></table></figure>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    numpy读取本地文件</span></span><br><span class="line"><span class="string">    delimiter 分割号</span></span><br><span class="line"><span class="string">    dtype 读取数据类型  一般机器学习类的都是float32 因为显卡一般他内核里面是按32位工作的</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;./dataset/diabetes.csv&#x27;</span>,delimiter=<span class="string">&quot;,&quot;</span>,dtype=np.float32)</span><br><span class="line"><span class="comment"># (759,9) 759行 9列</span></span><br><span class="line"><span class="built_in">print</span>(xy.shape)</span><br><span class="line"><span class="comment"># numpy 转 张量  最后一组样本我们当测试样本吧  其余的当训练样本</span></span><br><span class="line">x_train = torch.from_numpy(xy[:-<span class="number">1</span>,:-<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(x_train.shape)</span><br><span class="line">y_train = torch.from_numpy(xy[:-<span class="number">1</span>,[-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当测试样本 的 一组数据</span></span><br><span class="line">x_test = torch.from_numpy(xy[-<span class="number">1</span>:,:-<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(x_test.shape)</span><br><span class="line">y_test = torch.from_numpy(xy[-<span class="number">1</span>:,[-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二部 定义模型</span></span><br><span class="line"><span class="comment"># 这个其实有点类似与 神经网络的结构了 每个线性层后面都加了一个sigmoid函数 做了次非线性变换</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FullLeanerModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 定义多层线性模型的结构</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FullLeanerModel,self).__init__()</span><br><span class="line">        <span class="comment"># 第一个线性转换 将8维转换为6维</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>,<span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>,<span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前馈 运行</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        <span class="comment"># 用一个变量比较 简单</span></span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span>  x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化模型</span></span><br><span class="line">FullLeanerModel = FullLeanerModel()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步 定义 损失函数和优化器</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(FullLeanerModel.parameters(),lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四步 训练</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> 前两步 就是正向传播 forward</span></span><br><span class="line"><span class="string">    1. 预测 标签</span></span><br><span class="line"><span class="string">    2. 预测 与 实际 算出损失值</span></span><br><span class="line"><span class="string">    3. 反向传播 backward 优化参数</span></span><br><span class="line"><span class="string">    4. 更新参数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>):</span><br><span class="line">    y_pred = FullLeanerModel(x_train)</span><br><span class="line">    loss = criterion(y_pred,y_train)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;迭代次数:&#x27;</span>,epoch,<span class="string">&quot;  损失值:&quot;</span>,loss.item())</span><br><span class="line">![在这里插入图片描述](https://img-blog.csdnimg.cn/f600a0b6fbe24b60b35a0f2bc26f9444.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16<span class="comment">#pic_center)</span></span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()   <span class="comment">#更新参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第五步 评估模型</span></span><br><span class="line">    <span class="comment"># 输出各层  权重w 和 偏置b</span></span><br><span class="line"><span class="keyword">for</span> weight, bias <span class="keyword">in</span> FullLeanerModel.state_dict().items():  <span class="comment"># param is weight or bias(Tensor)</span></span><br><span class="line">    <span class="built_in">print</span>( weight,bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_yuce = FullLeanerModel(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试样本的预测值为&quot;</span>,y_yuce.data,<span class="string">&quot;实际样本的标签值为&quot;</span>,y_test.data)</span><br></pre></td></tr></table></figure>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><img src="https://img-blog.csdnimg.cn/d4fac45272664d249443217900408b79.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="实验结果"><br>可以看到 最后一个样本模型预测概率是 0.6529 。&gt;0.5 我们可以推测其标签就是1，而实际标签也是1，所以这个模型预测结果目前看是正确的。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>刘二</tag>
        <tag>Pytorch</tag>
        <tag>多维度特征</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch GoogleNet中的Inception</title>
    <url>/2021/09/21/Pytorch%20GoogleNet%E4%B8%AD%E7%9A%84Inception/</url>
    <content><![CDATA[<p>@<a href="Pytorch GoogleNet中的Inception">TOC</a></p>
<h1 id="GoogleNet-的概念"><a href="#GoogleNet-的概念" class="headerlink" title="GoogleNet 的概念"></a>GoogleNet 的概念</h1><p>是基于AlexNet，VGG 后的模型</p>
<h1 id="特殊点：Inception"><a href="#特殊点：Inception" class="headerlink" title="特殊点：Inception"></a>特殊点：Inception</h1><h2 id="为什么要提出-Inception"><a href="#为什么要提出-Inception" class="headerlink" title="为什么要提出 Inception"></a>为什么要提出 Inception</h2><p>一般来说，提升网络性能最直接的办法是<strong>增加网络深度和宽度</strong>，但一味地增加，会带来诸多问题：</p>
<ol>
<li>参数太多，如果训练数据集有限，很容易产生过拟合； </li>
<li>网络越大、参数越多，计算复杂度越大，难以应用；</li>
<li>网络越深，容易出现梯度消失问题（梯度越往后穿越容易消失），难以优化模型。</li>
</ol>
<blockquote>
<p><strong>梯度消失和梯度爆炸</strong> 是什么？<br>查看文章   <a href="https://www.jianshu.com/p/ece360b7fabb">如何理解梯度消失和梯度爆炸</a><br>以及本博客文章 <a href="https://jks88995656.github.io/2021/09/20/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E7%90%86%E8%A7%A3/">梯度消失和梯度爆炸的理解</a></p>
</blockquote>
<p>我们希望在增加网络深度和宽度的同时减少参数，为了减少参数，自然就想到将<strong>全连接变成稀疏连接</strong>。但是在实现上，全连接变成稀疏连接后实际计算量并不会有质的提升，因为<font color="blue">大部分硬件是针对密集矩阵计算优化的，稀疏矩阵虽然数据量少，但是计算所消耗的时间却很难减少。</font><br>在这种需求和形势下，Google研究人员提出了Inception的方法。</p>
<h2 id="Inception-模块的结构"><a href="#Inception-模块的结构" class="headerlink" title="Inception 模块的结构"></a>Inception 模块的结构</h2><p>Inception 模块 是GoogleNet 重复使用的重要部分。其最大的特点是 引入了 1×1 的卷积核。其目的是用于 缩小通道数，将像素信息融合，也叫做 <strong>通道压缩</strong>。<br><img src="https://img-blog.csdnimg.cn/img_convert/9f3c90923dc228229c3f6c1695777fa3.png#pic_center" alt="在这里插入图片描述"><br>同时其可以减少卷积核的参数数量 例如:如下的操作数对比（28×28表示 卷积的时候图片像素点也要乘的啊）<br><img src="https://img-blog.csdnimg.cn/img_convert/7e7182fa5f7155ca6f80ac1cc6689c08.png#pic_center" alt="参数变化 用1×1后"><br>Inception 模块的内容如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/d98aae54e7979a26c11393e6c0fb7ad3.png#pic_center" alt="Inception 模块结构"></p>
<h2 id="Pytorch-实现-Inception-模块"><a href="#Pytorch-实现-Inception-模块" class="headerlink" title="Pytorch 实现 Inception 模块"></a>Pytorch 实现 Inception 模块</h2><p>下图中为每个部分的代码模块。 每个部分的 上侧是 pytorch中网络初始化部分，下侧是 pytorch中网络前馈实现的部分。<br><img src="https://img-blog.csdnimg.cn/img_convert/065b0f6abeae7092776e18a5b4755ac3.png#pic_center" alt="各部分实现图"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionA</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(InceptionA, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第一个部分</span></span><br><span class="line">        self.branch_pool = torch.nn.Conv2d(in_channels, <span class="number">24</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二个部分</span></span><br><span class="line">        self.branch1x1 = torch.nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第三个部分</span></span><br><span class="line">        self.branch5x5_1 = torch.nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch5x5_2 = torch.nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第四个部分</span></span><br><span class="line">        self.branch3x3_1 = torch.nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_2 = torch.nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_3 = torch.nn.Conv2d(<span class="number">24</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 第一个部分</span></span><br><span class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        branch_pool = self.branch_pool(branch_pool)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二个部分</span></span><br><span class="line">        branch1x1 = self.branch1x1(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第三个部分</span></span><br><span class="line">        branch5x5 = self.branch5x5_1(x)</span><br><span class="line">        branch5x5 = self.branch5x5_2(branch5x5)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第四个部分</span></span><br><span class="line">        branch3x3 = self.branch3x3_1(x)</span><br><span class="line">        branch3x3 = self.branch3x3_2(branch3x3)</span><br><span class="line">        branch3x3 = self.branch3x3_3(branch3x3)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通道整合</span></span><br><span class="line">        outputs = [branch_pool, branch1x1, branch5x5, branch3x3]</span><br><span class="line">        <span class="comment"># 整合通道 通道的位置在1处  （batch,通道,宽度,长度）</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="GoogleNet-网络的整体模型"><a href="#GoogleNet-网络的整体模型" class="headerlink" title="GoogleNet 网络的整体模型"></a>GoogleNet 网络的整体模型</h1><p><img src="https://img-blog.csdnimg.cn/img_convert/42c1625cbe9b8e8c37de67bfbf3d319a.png#pic_center" alt="GoogleNet 全貌"></p>
<h1 id="使用Mnist-使用Inception"><a href="#使用Mnist-使用Inception" class="headerlink" title="使用Mnist 使用Inception"></a>使用Mnist 使用Inception</h1><h2 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">88</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.incep1 = InceptionA(in_channels=<span class="number">10</span>)</span><br><span class="line">        self.incep2 = InceptionA(in_channels=<span class="number">20</span>)</span><br><span class="line">        self.mp = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">1408</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        in_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.mp(self.conv1(x)))</span><br><span class="line">        x = self.incep1(x)</span><br><span class="line">        x = F.relu(self.mp(self.conv2(x)))</span><br><span class="line">        x = self.incep2(x)</span><br><span class="line">        <span class="comment"># 变成列向量</span></span><br><span class="line">        x = x.view(in_size, -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="Mnist-数据集-训练-整体代码"><a href="#Mnist-数据集-训练-整体代码" class="headerlink" title="Mnist 数据集 训练 整体代码"></a>Mnist 数据集 训练 整体代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一步 准备数据</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    <span class="comment"># 用均值和方差进行归一化</span></span><br><span class="line">    transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">])</span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">                               train=<span class="literal">True</span>,</span><br><span class="line">                               download=<span class="literal">True</span>,</span><br><span class="line">                               transform=transform)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">                              train=<span class="literal">False</span>,</span><br><span class="line">                              download=<span class="literal">True</span>,</span><br><span class="line">                              transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,</span><br><span class="line">                         shuffle=<span class="literal">False</span>,</span><br><span class="line">                         batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionA</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(InceptionA, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第一个部分</span></span><br><span class="line">        self.branch_pool = torch.nn.Conv2d(in_channels, <span class="number">24</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二个部分</span></span><br><span class="line">        self.branch1x1 = torch.nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第三个部分</span></span><br><span class="line">        self.branch5x5_1 = torch.nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch5x5_2 = torch.nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第四个部分</span></span><br><span class="line">        self.branch3x3_1 = torch.nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_2 = torch.nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_3 = torch.nn.Conv2d(<span class="number">24</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 第一个部分</span></span><br><span class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        branch_pool = self.branch_pool(branch_pool)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二个部分</span></span><br><span class="line">        branch1x1 = self.branch1x1(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第三个部分</span></span><br><span class="line">        branch5x5 = self.branch5x5_1(x)</span><br><span class="line">        branch5x5 = self.branch5x5_2(branch5x5)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第四个部分</span></span><br><span class="line">        branch3x3 = self.branch3x3_1(x)</span><br><span class="line">        branch3x3 = self.branch3x3_2(branch3x3)</span><br><span class="line">        branch3x3 = self.branch3x3_3(branch3x3)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通道整合</span></span><br><span class="line">        outputs = [branch_pool, branch1x1, branch5x5, branch3x3]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">88</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.incep1 = InceptionA(in_channels=<span class="number">10</span>)</span><br><span class="line">        self.incep2 = InceptionA(in_channels=<span class="number">20</span>)</span><br><span class="line">        self.mp = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">1408</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        in_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.mp(self.conv1(x)))</span><br><span class="line">        x = self.incep1(x)</span><br><span class="line">        x = F.relu(self.mp(self.conv2(x)))</span><br><span class="line">        x = self.incep2(x)</span><br><span class="line">        <span class="comment"># 变成列向量</span></span><br><span class="line">        x = x.view(in_size, -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化这个网络模型</span></span><br><span class="line">model = Net()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步 定义损失函数和优化器</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义测试函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            outputs = model(data)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)</span><br><span class="line">            correct += predicted.eq(target.view_as(predicted)).<span class="built_in">sum</span>().item()</span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%) \n&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    )) \</span><br><span class="line"> \</span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epochs</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">            <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">                <span class="comment"># prepare data</span></span><br><span class="line">                inputs, labels = data</span><br><span class="line">                <span class="comment"># 前馈</span></span><br><span class="line">                y_predict = model(inputs)</span><br><span class="line">                loss = criterion(y_predict, labels)</span><br><span class="line">                <span class="comment"># 反馈</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                loss.backward()</span><br><span class="line">                <span class="comment"># 更新</span></span><br><span class="line">                optimizer.step()</span><br><span class="line">                <span class="keyword">if</span> (batch_idx + <span class="number">1</span>) % <span class="number">30</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                        epoch, batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                               <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">    test()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h1><p><a href="https://zhuanlan.zhihu.com/p/73857137">深度学习|经典网络：GoogLeNet（一）</a><br><a href="https://zhuanlan.zhihu.com/p/89002063">GoogLeNet</a></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Pytorch</tag>
        <tag>GoogleNet</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 封装函数</title>
    <url>/2021/09/17/Pytorch%20%E5%B0%81%E8%A3%85%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>@<a href="Pytorch 封装函数">TOC</a></p>
<h1 id="torch-tensor-view"><a href="#torch-tensor-view" class="headerlink" title="torch.tensor.view"></a>torch.tensor.view</h1><p>Tensor.view(*shape) → Tensor<br> view()的作用相当于numpy中的reshape，重新定义矩阵的形状。<br> <img src="https://img-blog.csdnimg.cn/95e47412ecb142e1b2f5dfcb469d9762.png#pic_center" alt="在这里插入图片描述"><br>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">30</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&gt;&gt;a:tensor([ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>,  <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>, <span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>,</span><br><span class="line">        <span class="number">15.</span>, <span class="number">16.</span>, <span class="number">17.</span>, <span class="number">18.</span>, <span class="number">19.</span>, <span class="number">20.</span>, <span class="number">21.</span>, <span class="number">22.</span>, <span class="number">23.</span>, <span class="number">24.</span>, <span class="number">25.</span>, <span class="number">26.</span>, <span class="number">27.</span>, <span class="number">28.</span>,</span><br><span class="line">        <span class="number">29.</span>, <span class="number">30.</span>])</span><br><span class="line"></span><br><span class="line">b = a.view(<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">&gt;&gt;b:tensor([[[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">5.</span>],</span><br><span class="line">         [ <span class="number">6.</span>,  <span class="number">7.</span>,  <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>],</span><br><span class="line">         [<span class="number">11.</span>, <span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">16.</span>, <span class="number">17.</span>, <span class="number">18.</span>, <span class="number">19.</span>, <span class="number">20.</span>],</span><br><span class="line">         [<span class="number">21.</span>, <span class="number">22.</span>, <span class="number">23.</span>, <span class="number">24.</span>, <span class="number">25.</span>],</span><br><span class="line">         [<span class="number">26.</span>, <span class="number">27.</span>, <span class="number">28.</span>, <span class="number">29.</span>, <span class="number">30.</span>]]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b.view(b.size(<span class="number">0</span>),-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(b.view(b.size(<span class="number">1</span>),-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(b.view(b.size(<span class="number">2</span>),-<span class="number">1</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>b是一个2组3行5列，<br>b.size(0)就是留下2组，后面3行5列拉直成15个数，行成2行15列；<br>b.size(1)就是留下3行，2组5列拉成10个数，行成3行10列；<br>b.size(2)就是留下5列，2组3行拉成6个数，行成5行6列</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 实现 简易逻辑回归模型 —— 刘二</title>
    <url>/2021/09/12/Pytorch%20%E5%AE%9E%E7%8E%B0%20%E7%AE%80%E6%98%93%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%20%E2%80%94%E2%80%94%20%E5%88%98%E4%BA%8C/</url>
    <content><![CDATA[<p>@<a href="Pytorch 实现 简易逻辑回归模型 —— 刘二">TOC</a></p>
<p>用Pytorch 实现 简单的逻辑回归。整个流程图可以如下图所示：<br><img src="https://img-blog.csdnimg.cn/ed9e3efcda894426bc9e66c6c0c5d408.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="逻辑回归预测流程"></p>
<p>大致的设计步骤 分为5步 如下所示：<br><img src="https://img-blog.csdnimg.cn/66ed2d3a9e914f229e8c67a8248b1dee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>第五步：是进行 评估模型并预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<h1 id="Step1：准备数据"><a href="#Step1：准备数据" class="headerlink" title="Step1：准备数据"></a>Step1：准备数据</h1><p><img src="https://img-blog.csdnimg.cn/91dc702ff784417993b5d0e5f63f75ed.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 准备数据</span></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<h1 id="Step2：设计模型"><a href="#Step2：设计模型" class="headerlink" title="Step2：设计模型"></a>Step2：设计模型</h1><p>内涵的线性模型比较简单 为 $y=Wx+b$ 只有两个超参数 W 和 b</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第二步 设计模型</span></span><br><span class="line"><span class="comment"># 构建一个线性模型类 所有的模型类都必须继承torch.nn.Module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegressionModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 调用父类的构造 这步必须得有</span></span><br><span class="line">        <span class="built_in">super</span>(LogisticRegressionModel, self).__init__()</span><br><span class="line">        <span class="comment"># Linear 是一个模型类 这边实例化他给 linear</span></span><br><span class="line">        <span class="comment"># w 权重 = 1  b 偏置 = 1</span></span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 线性模型之后 在外套sigmoid激活函数</span></span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure>
<h2 id="torch-nn-Linear-in-features-out-features-bias-True-方法"><a href="#torch-nn-Linear-in-features-out-features-bias-True-方法" class="headerlink" title="torch.nn.Linear(in_features,out_features,bias=True) 方法"></a>torch.nn.Linear(in_features,out_features,bias=True) 方法</h2><p><img src="https://img-blog.csdnimg.cn/0e75527101244e56a7687acb4eaa9315.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>实例化这个模型为 model</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 实例化这个模型</span></span><br><span class="line">model = LogisticRegressionModel()</span><br></pre></td></tr></table></figure>
<h1 id="Step3：构建损失函数和优化器"><a href="#Step3：构建损失函数和优化器" class="headerlink" title="Step3：构建损失函数和优化器"></a>Step3：构建损失函数和优化器</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第三步 构建损失函数和优化器</span></span><br><span class="line"><span class="comment"># BCELoss  Binary Cross Entropy</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>) <span class="comment"># size_average = True 的话 就 乘以 1/N  默认为true</span></span><br><span class="line"><span class="comment">#model.parameters() 可以找到模型所有需要训练的参数</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>) </span><br></pre></td></tr></table></figure>
<h2 id="torch-nn-BCELoss-size-average-False-方法"><a href="#torch-nn-BCELoss-size-average-False-方法" class="headerlink" title="torch.nn.BCELoss(size_average=False) 方法"></a>torch.nn.BCELoss(size_average=False) 方法</h2><p>用于创建一个 BCE 损失函数<br><img src="https://img-blog.csdnimg.cn/c901445a0aad460d8c7c50e0a9287cd8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="torch-optim-SGD-…-方法"><a href="#torch-optim-SGD-…-方法" class="headerlink" title="torch.optim.SGD(…) 方法"></a>torch.optim.SGD(…) 方法</h2><p>优化器选择 SGD   可调整学习率<br>$w^{*} = w - α\frac{\partial L}{\partial W}$<br><img src="https://img-blog.csdnimg.cn/aab4fe33c3844ea386a7c14cc9350865.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="Step4-训练模型"><a href="#Step4-训练模型" class="headerlink" title="Step4: 训练模型"></a>Step4: 训练模型</h1><p> 前两步 就是正向传播 forward</p>
<ol>
<li>预测 标签</li>
<li>预测 与 实际 算出损失值</li>
<li>反向传播 backward 优化参数</li>
<li>更新参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第四步 训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred,y_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;迭代次数:&#x27;</span>,epoch,<span class="string">&quot;  损失值:&quot;</span>,loss.item() )</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()   <span class="comment">#更新参数</span></span><br></pre></td></tr></table></figure>
<h1 id="Step5-评估模型并预测"><a href="#Step5-评估模型并预测" class="headerlink" title="Step5: 评估模型并预测"></a>Step5: 评估模型并预测</h1><p>这边没有准备 测试集及其标签</p>
<p>输出 超参数  权重w 和 偏置b<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出 超参数  权重w 和 偏置b</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w = &#x27;</span>,model.linear.weight.item() )</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b = &#x27;</span>,model.linear.bias.item())</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 预测 </span></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x为4.0 预测的 y值为：&#x27;</span>,y_test.data)</span><br></pre></td></tr></table></figure>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><font color="red"> 这边少了 怎么输出 准确率？ </font><br><img src="https://img-blog.csdnimg.cn/e9bb2b08573e4016bb049d6289513ec9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_11,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="可以画一下图"><a href="#可以画一下图" class="headerlink" title="可以画一下图"></a>可以画一下图</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">200</span>)</span><br><span class="line">x_t = torch.Tensor(x).view((<span class="number">200</span>, <span class="number">1</span>))</span><br><span class="line">y_t = model(x_t)</span><br><span class="line">y = y_t.data.numpy()</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">10</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>], c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Hours&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Probability of Pass&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="实现源码"><a href="#实现源码" class="headerlink" title="实现源码"></a>实现源码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 第一步 载入数据</span></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步 设计模型</span></span><br><span class="line"><span class="comment"># 构建一个线性模型类 所有的模型类都必须继承torch.nn.Module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegressionModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 调用父类的构造 这步必须得有</span></span><br><span class="line">        <span class="built_in">super</span>(LogisticRegressionModel, self).__init__()</span><br><span class="line">        <span class="comment"># Linear 是一个模型类 这边实例化他给 linear</span></span><br><span class="line">        <span class="comment"># w 权重 = 1  b 偏置 = 1</span></span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 线性模型之后 在外套sigmoid激活函数</span></span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化这个模型</span></span><br><span class="line">model = LogisticRegressionModel()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步 构建损失函数和优化器</span></span><br><span class="line"><span class="comment"># BCELoss  Binary Cross Entropy</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>) <span class="comment"># size_average = True 的话 就 乘以 1/N  默认为true</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>) <span class="comment">#model.parameters() 可以找到</span></span><br><span class="line"><span class="comment"># 模型所有需要训练的参数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四步 训练</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> 前两步 就是正向传播 forward</span></span><br><span class="line"><span class="string">    1. 预测 标签</span></span><br><span class="line"><span class="string">    2. 预测 与 实际 算出损失值</span></span><br><span class="line"><span class="string">    3. 反向传播 backward 优化参数</span></span><br><span class="line"><span class="string">    4. 更新参数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred,y_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;迭代次数:&#x27;</span>,epoch,<span class="string">&quot;  损失值:&quot;</span>,loss.item() )</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()   <span class="comment">#更新参数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第五步 评估模型</span></span><br><span class="line"><span class="comment"># 输出 超参数  权重w 和 偏置b</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w = &#x27;</span>,model.linear.weight.item() )</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b = &#x27;</span>,model.linear.bias.item())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x为4.0 预测的 y值为：&#x27;</span>,y_test.data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">200</span>)</span><br><span class="line">x_t = torch.Tensor(x).view((<span class="number">200</span>, <span class="number">1</span>))</span><br><span class="line">y_t = model(x_t)</span><br><span class="line">y = y_t.data.numpy()</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">10</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>], c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Hours&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Probability of Pass&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>刘二</tag>
        <tag>Pytorch</tag>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 实现 线性回归模型 —— 刘二</title>
    <url>/2021/09/08/Pytorch%20%E5%AE%9E%E7%8E%B0%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%20%E2%80%94%E2%80%94%20%E5%88%98%E4%BA%8C/</url>
    <content><![CDATA[<p>@<a href="Pytorch 实现 线性回归模型 —— 刘二">TOC</a></p>
<p>用Pytorch 实现 线性模型。整个流程图可以如下图所示：<br><img src="https://img-blog.csdnimg.cn/0728aba4a28542838fdb11f7bf4a668c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>大致的设计步骤 分为5步 如下所示：<br><img src="https://img-blog.csdnimg.cn/e1aa1c61b89b4e46adebe9d44c61ff2b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>第五步：是进行 评估模型并预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<h1 id="Step1：准备数据"><a href="#Step1：准备数据" class="headerlink" title="Step1：准备数据"></a>Step1：准备数据</h1><p><img src="https://img-blog.csdnimg.cn/91dc702ff784417993b5d0e5f63f75ed.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 准备数据</span></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>],[<span class="number">2.0</span>],[<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">2.0</span>],[<span class="number">4.0</span>],[<span class="number">6.0</span>]])</span><br></pre></td></tr></table></figure>
<h1 id="Step2：设计模型"><a href="#Step2：设计模型" class="headerlink" title="Step2：设计模型"></a>Step2：设计模型</h1><p>这边的线性模型比较简单 为 $y=Wx+b$ 只有两个超参数 W 和 b<br><img src="https://img-blog.csdnimg.cn/51e148a09e1d452e8a4e9794e3c4035a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>要通过输入的维度和 输出的维度，才能明确 $W$ 和 $b$ 的维度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构建一个线性模型类 所有的模型类都必须继承torch.nn.Module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">	<span class="comment"># 构造方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 调用父类的构造 这步必须得有</span></span><br><span class="line">        <span class="built_in">super</span>(LinearModel,self).__init__()</span><br><span class="line">        <span class="comment"># Linear 是一个模型类 这边实例化他给 对象linear</span></span><br><span class="line">        <span class="comment"># w 权重 = 1  b 偏执 = 1</span></span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">	<span class="comment"># 方法重写</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">    	<span class="comment"># 预测值 </span></span><br><span class="line">        y_pred = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure>
<h2 id="torch-nn-Linear-in-features-out-features-bias-True-方法"><a href="#torch-nn-Linear-in-features-out-features-bias-True-方法" class="headerlink" title="torch.nn.Linear(in_features,out_features,bias=True) 方法"></a>torch.nn.Linear(in_features,out_features,bias=True) 方法</h2><p><img src="https://img-blog.csdnimg.cn/0e75527101244e56a7687acb4eaa9315.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>实例化这个模型为 model</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 实例化这个模型</span></span><br><span class="line">model = LinearModel()</span><br></pre></td></tr></table></figure>
<h1 id="Step3：构建损失函数和优化器"><a href="#Step3：构建损失函数和优化器" class="headerlink" title="Step3：构建损失函数和优化器"></a>Step3：构建损失函数和优化器</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 损失函数：mean squared error</span></span><br><span class="line">criterion = torch.nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>) <span class="comment"># size_average = True 的话 就 乘以 1/N  默认为true</span></span><br><span class="line"><span class="comment"># model.parameters() 可以找到模型所有需要训练的参数   优化器：SGD</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>) </span><br></pre></td></tr></table></figure>
<h2 id="torch-nn-MSELoss-size-average-False-方法"><a href="#torch-nn-MSELoss-size-average-False-方法" class="headerlink" title="torch.nn.MSELoss(size_average=False) 方法"></a>torch.nn.MSELoss(size_average=False) 方法</h2><p>用于创建一个MSE损失函数<br><img src="https://img-blog.csdnimg.cn/4921387ab8ea4db6a6aaca5ed892fef5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="torch-optim-SGD-…-方法"><a href="#torch-optim-SGD-…-方法" class="headerlink" title="torch.optim.SGD(…) 方法"></a>torch.optim.SGD(…) 方法</h2><p>优化器选择 SGD   可调整学习率<br>$w^{*} = w - α\frac{\partial L}{\partial W}$<br><img src="https://img-blog.csdnimg.cn/aab4fe33c3844ea386a7c14cc9350865.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="Step4-训练模型"><a href="#Step4-训练模型" class="headerlink" title="Step4: 训练模型"></a>Step4: 训练模型</h1><p> 前两步 就是正向传播 forward</p>
<ol>
<li>预测 标签</li>
<li>预测 与 实际 算出损失值</li>
<li>反向传播 backward 优化参数</li>
<li>更新参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"> <span class="comment">#数据跑 99次  range是不到那个数字的</span></span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred,y_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;迭代次数:&#x27;</span>,epoch,<span class="string">&quot;  损失值:&quot;</span>,loss)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()   <span class="comment">#更新参数</span></span><br></pre></td></tr></table></figure>
<h1 id="Step5-评估模型并预测"><a href="#Step5-评估模型并预测" class="headerlink" title="Step5: 评估模型并预测"></a>Step5: 评估模型并预测</h1><p>这边没有准备 测试集及其标签</p>
<p>输出 超参数  权重w 和 偏置b<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出 超参数  权重w 和 偏置b</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w = &#x27;</span>,model.linear.weight.item() )</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b = &#x27;</span>,model.linear.bias.item())</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 预测 </span></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x为4.0 预测的 y值为：&#x27;</span>,y_test.data)</span><br></pre></td></tr></table></figure>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><font color="red"> 这边少了 怎么输出 准确率？ </font><br><img src="https://img-blog.csdnimg.cn/c0013d6d060148b8ac02605d0fa0d163.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="实现源码"><a href="#实现源码" class="headerlink" title="实现源码"></a>实现源码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据</span></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>],[<span class="number">2.0</span>],[<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">2.0</span>],[<span class="number">4.0</span>],[<span class="number">6.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步 设计模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 调用父类的构造 这步必须得有</span></span><br><span class="line">        <span class="built_in">super</span>(LinearModel,self).__init__()</span><br><span class="line">        <span class="comment"># Linear 是一个模型类 这边实例化他给 linear</span></span><br><span class="line">        <span class="comment"># w 权重 = 1  b 偏执 = 1</span></span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        y_pred = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化这个模型</span></span><br><span class="line">model = LinearModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步 构建损失函数和优化器</span></span><br><span class="line"><span class="comment"># mean squared error</span></span><br><span class="line">criterion = torch.nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>) <span class="comment"># size_average = True 的话 就 乘以 1/N  默认为true</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>) <span class="comment">#model.parameters() 可以找到</span></span><br><span class="line"><span class="comment"># 模型所有需要训练的参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四步 训练</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> 前两步 就是正向传播 forward</span></span><br><span class="line"><span class="string">    1. 预测 标签</span></span><br><span class="line"><span class="string">    2. 预测 与 实际 算出损失值</span></span><br><span class="line"><span class="string">    3. 反向传播 backward 优化参数</span></span><br><span class="line"><span class="string">    4. 更新参数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred,y_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;迭代次数:&#x27;</span>,epoch,<span class="string">&quot;  损失值:&quot;</span>,loss)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()   <span class="comment">#更新参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第五步 评估模型</span></span><br><span class="line"><span class="comment"># 输出 超参数  权重w 和 偏置b</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w = &#x27;</span>,model.linear.weight.item() )</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b = &#x27;</span>,model.linear.bias.item())</span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x为4.0 预测的 y值为：&#x27;</span>,y_test.data)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>刘二</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 数据读取 DataLoader与Dataset 概念</title>
    <url>/2021/09/13/Pytorch%20%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%20DataLoader%E4%B8%8EDataset%20%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>@<a href="Pytorch 数据读取 DataLoader与Dataset 概念">TOC</a></p>
<p>在机器学习中，我们对数据的处理主要分为4个阶段，如下图所示：<br><img src="https://img-blog.csdnimg.cn/b32a357d69624036babcbab934d6ea0f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<ol>
<li>第一步，收集需要的数据，数据包括原始样本 和 对应标签；</li>
<li>第二步，对数据集进行划分，把数据集划分为 <strong>训练集、验证集和测试集</strong> ；训练集用于训练模型，验证集用于验证模型是否过拟合（也可以理解为用验证集挑选模型的超参数），测试集用于测试模型的性能，测试模型的泛化能力；</li>
<li><p>第三步，从本地读取数据，要按 Mini-batch 分批训练。一起训练，内存不够。使用的方法为 <strong>DataLoader</strong> ，其又分为两个部分：</p>
<ol>
<li><strong>Sample</strong>  用于生成索引，即样本的序号；</li>
<li><strong>Dataset</strong> 是根据索引去读取图片以及对应的标签；</li>
</ol>
</li>
<li><p>第四步，数据预处理，把数据读取进来往往还需要对数据进行一系列的图像预处理，比如说<strong>数据的中心化，标准化，旋转或者翻转</strong>等等。Pytorch 中数据预处理是通过 <strong>transforms</strong> 进行处理的；</p>
</li>
</ol>
<h1 id="DataLoader-和-Dataset"><a href="#DataLoader-和-Dataset" class="headerlink" title="DataLoader 和 Dataset"></a>DataLoader 和 Dataset</h1><h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><p><img src="https://img-blog.csdnimg.cn/d48e19e8e3a44038a1ee9e38c54ae4dd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>torch.utils.data.DataLoader</strong></p>
<p>功能：构建可迭代的数据装载器；<br>dataset: Dataset类，决定数据从哪里读取及如何读取；<br>batchsize：批次样本数量大小；<br>num_works:是否多进程读取数据； 可以设置为几个进程<br>shuffle：每个epoch是否乱序；<br>drop_last：当样本数不能被 batchsize 整除时，是否舍弃最后一批数据；</p>
</blockquote>
<p>Epoch，Iteration，Batchsize的区别</p>
<blockquote>
<p>Epoch：所有训练样本都已输入到模型中，称为一个Epoch<br>Iteration：一批样本输入到模型中，称之为一个Iteration；<br>Batchsize：批次样本数量大小，决定一个Epoch中有多少个Iteration； Iteration = Epoch ➗ Batchsize<br><img src="https://img-blog.csdnimg.cn/9819b23c3821402ca0fe804a641bfd00.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">样本总数：<span class="number">87</span>，Batchsize=<span class="number">8</span> （样本不能被Batchsize整除）</span><br><span class="line"><span class="number">1</span> Epoch = <span class="number">10</span> Iteration，drop_last = <span class="literal">True</span></span><br><span class="line"><span class="number">1</span> Epoch = <span class="number">11</span> Iteration， drop_last = <span class="literal">False</span></span><br></pre></td></tr></table></figure><br>用法例如：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_loader = DataLoader(dataset=diabetesdataset,batch_size=<span class="number">32</span>,num_workers=<span class="number">2</span>,shuffle=<span class="literal">True</span>,drop_last=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p><img src="https://img-blog.csdnimg.cn/4cb1ec48dac047f3b025dd652a96e11b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>torch.utils.data.Dataset</strong><br>Dataset是用来定义数据从哪里读取，以及如何读取的问题；</p>
<p><font color="red">功能：Dataset抽象类，所有自定义的Dataset需要继承它，并且重写<strong>getitem</strong>()； </font><br><strong> getitem </strong>()：接收一个索引，返回一个样本</p>
</blockquote>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># DiabetesDataset 继承 Dataset</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiabetesDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,filepath</span>):</span></span><br><span class="line">        xy = np.loadtxt(filepath,delimiter=<span class="string">&#x27;,&#x27;</span>,dtype=np.float32)</span><br><span class="line">        <span class="comment"># 一共有几个样本</span></span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># numpy 转 张量  最后一组样本我们当测试样本吧  其余的当训练样本</span></span><br><span class="line">        self.x_train = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_train = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 继承Dataset的方法并重写</span></span><br><span class="line">    <span class="comment"># 其实用来帮助找索引位置的  dataset[index]</span></span><br><span class="line">    <span class="comment"># 函数功能是根据index索引去返回数据样本以及标签label</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.x_train[index],self.y_train[index]</span><br><span class="line">    <span class="comment"># 函数功能是用来查看数据的长度，也就是 dataset 样本的数量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br></pre></td></tr></table></figure>
<h2 id="Dataloader的运行机制"><a href="#Dataloader的运行机制" class="headerlink" title="Dataloader的运行机制"></a>Dataloader的运行机制</h2><h3 id="数据读取的三个问题：1、读哪些数据；2、从哪读数据；3、怎么读数据？"><a href="#数据读取的三个问题：1、读哪些数据；2、从哪读数据；3、怎么读数据？" class="headerlink" title="数据读取的三个问题：1、读哪些数据；2、从哪读数据；3、怎么读数据？"></a>数据读取的三个问题：1、读哪些数据；2、从哪读数据；3、怎么读数据？</h3><ol>
<li>从代码中可以发现，index 是从 sampler.py 中输出的，所以读哪些数据是由sampler得到的；</li>
<li>从代码中看，是从Dataset中的 文件地址参数 告诉我们 Pytorch 是从硬盘中的哪一个文件夹获取数据；</li>
<li>从代码中可以发现，Pytorch是从Dataset的getitem()中具体实现的，根据索引去读取数据；</li>
</ol>
<h3 id="DataLoader数据读取流程"><a href="#DataLoader数据读取流程" class="headerlink" title="DataLoader数据读取流程"></a>DataLoader数据读取流程</h3><p><img src="https://img-blog.csdnimg.cn/323718d3de4e415d9ba5af77011315cc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>简单描述一下流程图，首先在for循环中去使用DataLoader，进入DataLoader之后是否采用多进程进入DataLoaderlter，进入DataLoaderIter之后会使用sampler去获取Index，拿到索引之后传输到DatasetFetcher，在DatasetFetcher中会调用Dataset，Dataset根据给定的Index，在getitem中从硬盘里面去读取实际的Img和Label，读取了一个batch_size的数据之后，通过一个collate_fn将数据进行整理，整理成batch_Data的形式，接着就可以输入到模型中训练；</p>
<p><strong>读哪些是由Sampler决定的，从哪读是由Dataset决定的，怎么读是由getitem决定的</strong></p>
<h1 id="详细原文转载"><a href="#详细原文转载" class="headerlink" title="详细原文转载"></a>详细原文转载</h1><p><a href="https://blog.csdn.net/qq_37388085/article/details/102663166">https://blog.csdn.net/qq_37388085/article/details/102663166</a></p>
<h1 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h1><p>糖尿病案例。 数据读取采用 批处理 DataLoader。<br>理论上 测试集和训练集 都应该分别有一个 DataLoader</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># Dataset 是个抽象类，所以其不可以被实例化</span></span><br><span class="line"><span class="comment"># Dataset 可以为其他的子类所继承的</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;../dataset/diabetes.csv&#x27;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32)</span><br><span class="line"><span class="comment"># (759,9) 759行 9列</span></span><br><span class="line"><span class="comment"># 当测试样本 的 一组数据</span></span><br><span class="line">x_test = torch.from_numpy(xy[-<span class="number">1</span>:, :-<span class="number">1</span>])</span><br><span class="line">y_test = torch.from_numpy(xy[-<span class="number">1</span>:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># DiabetesDataset 继承 Dataset</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiabetesDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, filepath</span>):</span></span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">        <span class="comment"># 一共有几个样本</span></span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># numpy 转 张量  最后一组样本我们当测试样本吧  其余的当训练样本</span></span><br><span class="line">        self.x_train = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_train = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 继承Dataset的方法并重写</span></span><br><span class="line">    <span class="comment"># 其实用来帮助找索引位置的  dataset[index]</span></span><br><span class="line">    <span class="comment"># 函数功能是根据index索引去返回数据样本以及标签label</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.x_train[index], self.y_train[index]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 函数功能是用来查看数据的长度，也就是 dataset 样本的数量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化这个类</span></span><br><span class="line">diabetesdataset = DiabetesDataset(<span class="string">&#x27;../dataset/diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个 loader</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    batch_size 就是批次大小</span></span><br><span class="line"><span class="string">    shuffle True的话就表示要打乱数据</span></span><br><span class="line"><span class="string">    num_workers  读取Mni-batch的时候要多线程</span></span><br><span class="line"><span class="string">                2就表示由2个线程进行读取</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 返回 （x,y）</span></span><br><span class="line">train_loader = DataLoader(dataset=diabetesdataset, batch_size=<span class="number">32</span>, num_workers=<span class="number">2</span>, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二部 定义模型</span></span><br><span class="line"><span class="comment"># 这个其实有点类似与 神经网络的结构了 每个线性层后面都加了一个sigmoid函数 做了次非线性变换</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FullLeanerModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 定义多层线性模型的结构</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FullLeanerModel, self).__init__()</span><br><span class="line">        <span class="comment"># 第一个线性转换 将8维转换为6维</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前馈 运行</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 用一个变量比较 简单</span></span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化模型</span></span><br><span class="line">FullLeanerModel = FullLeanerModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步 定义 损失函数和优化器</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(FullLeanerModel.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四步 训练</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> 前两步 就是正向传播 forward</span></span><br><span class="line"><span class="string">    1. 预测 标签</span></span><br><span class="line"><span class="string">    2. 预测 与 实际 算出损失值</span></span><br><span class="line"><span class="string">    3. 反向传播 backward 优化参数</span></span><br><span class="line"><span class="string">    4. 更新参数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># 1. Prepare data</span></span><br><span class="line">            inputs, labels = data</span><br><span class="line">            <span class="comment"># 2. Forward</span></span><br><span class="line">            y_pred = FullLeanerModel(inputs)</span><br><span class="line">            loss = criterion(y_pred, labels)</span><br><span class="line">            <span class="comment"># 3. Backward</span></span><br><span class="line">            optimizer.zero_grad()  <span class="comment"># 梯度清零</span></span><br><span class="line">            loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">            <span class="comment"># 4. Update</span></span><br><span class="line">            optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第五步 评估模型</span></span><br><span class="line">    <span class="comment"># 输出各层  权重w 和 偏置b</span></span><br><span class="line">    <span class="keyword">for</span> weight, bias <span class="keyword">in</span> FullLeanerModel.state_dict().items():  <span class="comment"># param is weight or bias(Tensor)</span></span><br><span class="line">        <span class="built_in">print</span>(weight, bias)</span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    y_yuce = FullLeanerModel(x_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;测试样本的预测值为&quot;</span>, y_yuce.data, <span class="string">&quot;实际样本的标签值为&quot;</span>, y_test.data)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://img-blog.csdnimg.cn/6df0d9baee164ff69400094abdfff61a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>刘二</tag>
        <tag>Pytorch</tag>
        <tag>DataLoader</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow 代码学习</title>
    <url>/2021/08/22/Tensorflow%20%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>@<a href="Tensorflow 代码学习">TOC</a></p>
<p>机器学习的整体思路为：</p>
<p><img src="https://img-blog.csdnimg.cn/d73975270b58452892a3cd9133defd42.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="用TensorFlow-预测线性模型"><a href="#用TensorFlow-预测线性模型" class="headerlink" title="用TensorFlow 预测线性模型"></a>用TensorFlow 预测线性模型</h1><p>我们以这个做最简单的栗子，题目描述如下图所示：<br><img src="https://img-blog.csdnimg.cn/e862ba592668447dadbb087a5a43ef87.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="问题描述"><br>这就是一个 最简单的数据模型。</p>
<p>首先我们要引入需要的包，这边使用的是 keras API包<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><br>先构建模型，构建的为一层的神经网络，输入只有一个变量x<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = keras.Sequential([keras.layers.Dense(units=<span class="number">1</span>,input_shape=[<span class="number">1</span>])])</span><br></pre></td></tr></table></figure><br>再设置 优化器 和 损失函数<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>,loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br></pre></td></tr></table></figure><br>准备训练数据<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xs = np.array([-<span class="number">1.0</span>,<span class="number">0.0</span>,<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>],dtype=<span class="built_in">float</span>)</span><br><span class="line">ys = np.array([-<span class="number">3.0</span>,-<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">5.0</span>,<span class="number">7.0</span>],dtype=<span class="built_in">float</span>)</span><br></pre></td></tr></table></figure><br>训练模型 迭代500次<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.fit(xs,ys,epochs=<span class="number">500</span>)</span><br></pre></td></tr></table></figure><br>使用模型，对一个 测试集 x 进行预测 y 并输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.predict([<span class="number">10.0</span>]))</span><br></pre></td></tr></table></figure></p>
<p>总体代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#构建模型</span></span><br><span class="line"><span class="comment">#构建一层的神经网络，并且输入只有1个值</span></span><br><span class="line">model = keras.Sequential([keras.layers.Dense(units=<span class="number">1</span>,input_shape=[<span class="number">1</span>])])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>,loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备训练数据</span></span><br><span class="line">xs = np.array([-<span class="number">1.0</span>,<span class="number">0.0</span>,<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>],dtype=<span class="built_in">float</span>)</span><br><span class="line">ys = np.array([-<span class="number">3.0</span>,-<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">5.0</span>,<span class="number">7.0</span>],dtype=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">model.fit(xs,ys,epochs=<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用模型，对一个x 进行预测 y</span></span><br><span class="line"><span class="built_in">print</span>(model.predict([<span class="number">10.0</span>]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>结果如下所示：<br><img src="https://img-blog.csdnimg.cn/e82d07bccb7441059c354a3bde71f0e8.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="实验结果"><br>预测的结果是 18.977886   按照 正确的数学模型 $y = 2x - 1$ 结果应该是 19 。但深度学习不可能完美预测这个值，只能是近似。</p>
<h2 id="需要理解的几个点"><a href="#需要理解的几个点" class="headerlink" title="需要理解的几个点"></a>需要理解的几个点</h2><blockquote>
<p>Q1 ：请问 <code>model.fit(xs,ys,epochs=500)</code> 的 epochs 500 是什么意思？<br>就是针对同一批数据，利用各类算法（比如梯度下降算法），优化训练的次数，理论上训练次数越多，损失函数越小，准确度越高。</p>
<p>Q2：如何看待这个模型是不是正确的？ 第一，需要看输出的 loss 是不是越来越小 ，accuracy 越来越高。 如果loss<br>不是越来越小，那就说明有问题 第二，你可以看看在测试集 上表现怎么样。</p>
<p>Q3：请问 这个 epochs 越多越好么？ 当然不是，正常来说 模型在测试集上的表现 是不如训练集的。 要选取一个合适的 epochs 值，不然会出现 过拟合的现象。<img src="https://img-blog.csdnimg.cn/56bdd71ef3784049ad7ddd4003317a7e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>  <strong>注意：过拟合 是在测试集上的概念。是训练集上表现不错，但测试集表现不尽人意，叫做过拟合</strong></p>
</blockquote>
<h1 id="用TensorFlow-做全神经网络的图像识别分类"><a href="#用TensorFlow-做全神经网络的图像识别分类" class="headerlink" title="用TensorFlow 做全神经网络的图像识别分类"></a>用TensorFlow 做全神经网络的图像识别分类</h1><p>对 Fashion MNIST 进行图像分类 类别包括<br>0 T-shirt/top(体恤) 1 Trouser(裤子) 2 Pullover(套头衫) 3 Dress(连衣裙) 4 Coat(外套) 5 Sandal(凉鞋) 6 Shirt(衬衫) 7 Sneaker(运动鞋) 8 Bag(袋子) 9 Ankle boot(短靴）<br><img src="https://img-blog.csdnimg.cn/fd0a80f2af654b2d83c71cef332f3e53.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="总体代码"><a href="#总体代码" class="headerlink" title="总体代码"></a>总体代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line">(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#具体值 每一个数字都是灰度值</span></span><br><span class="line"><span class="built_in">print</span>(train_images[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#可以可视化的 查看其中的图片</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建一个全连接的神经网络</span></span><br><span class="line">model = keras.Sequential()</span><br><span class="line"><span class="comment">#输入层</span></span><br><span class="line">model.add(keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))</span><br><span class="line"><span class="comment">#中间层 128个神经元 激活函数使用relu</span></span><br><span class="line">model.add(keras.layers.Dense(<span class="number">128</span>,activation=tf.nn.relu))</span><br><span class="line"><span class="comment">#输出层 10个神经元 激活函数使用softmax</span></span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>,activation=tf.nn.softmax))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中间层  参数共有 100480个</span></span><br><span class="line"><span class="comment">#为 784 × 128 = 100352  还要再加上 每个神经元都有的 bias 100352+128=100480</span></span><br><span class="line"><span class="comment"># 输出层  参数共有 1290个</span></span><br><span class="line"><span class="comment"># 同理 为 128 × 10 + 10 = 1290</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer 优化器   loss：损失函数</span></span><br><span class="line"><span class="comment"># 当标签是除了0，1以外有其他数字的  用sparse_categorical_crossentropy</span></span><br><span class="line"><span class="comment">#为 one-hot  只有一个1 如： [0,0,0,1]用 categorical_crossentropy</span></span><br><span class="line">train_images_scaled = train_images/<span class="number">255</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.optimizers.Adam(),loss=tf.losses.sparse_categorical_crossentropy,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(train_images_scaled,train_labels,epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">test_images_scaled = test_images/<span class="number">255</span></span><br><span class="line"><span class="comment"># # 输出 loss 和 accuracy</span></span><br><span class="line"><span class="comment"># model.evaluate(test_images_scaled,test_labels)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.shape(test_images[<span class="number">0</span>]/<span class="number">255</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 要满足输入的维度, 并从</span></span><br><span class="line"><span class="built_in">print</span>(model.predict((test_images[<span class="number">0</span>]/<span class="number">255</span>).reshape(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line"><span class="built_in">print</span>(np.argmax(model.predict((test_images[<span class="number">0</span>]/<span class="number">255</span>).reshape(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))))</span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>先引入 需要的包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure>
<h2 id="加载Fashion-MNIST数据集"><a href="#加载Fashion-MNIST数据集" class="headerlink" title="加载Fashion MNIST数据集"></a>加载Fashion MNIST数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line">(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure>
<p>可以查看一下 图片内容是什么  是个 28 × 28 的二维数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#具体值 每一个数字都是灰度值</span></span><br><span class="line"><span class="built_in">print</span>(train_images[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>可以可视化的 查看一下 这张图片</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#可以可视化的 查看其中的图片</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/c40c76a3833444aa9b950977e09d3a95.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="构造神经元网络模型"><a href="#构造神经元网络模型" class="headerlink" title="构造神经元网络模型"></a>构造神经元网络模型</h2><p>有两种表达方式<br>方式一 ：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#构建一个全连接的神经网络</span></span><br><span class="line">model = keras.Sequential()</span><br><span class="line"><span class="comment">#输入层</span></span><br><span class="line">model.add(keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))</span><br><span class="line"><span class="comment">#中间层 128个神经元 激活函数使用relu</span></span><br><span class="line">model.add(keras.layers.Dense(<span class="number">128</span>,activation=tf.nn.relu))</span><br><span class="line"><span class="comment">#输出层 10个神经元 激活函数使用softmax</span></span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>,activation=tf.nn.softmax))</span><br></pre></td></tr></table></figure><br>方式二 ： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model=tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">512</span>, activation=tf.nn.relu),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=tf.nn.softmax)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>可以 用summary 函数  查看各层的信息 包括参数等;</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/4329a84b31e948dc82268215a010427c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>Q： 中间层参数 100480 怎么来的？</strong><br> 中间层  参数共有 100480个  ：为 784 × 128 = 100352  还要再加上 每个神经元都有的 bias 100352+128=100480<br> 输出层  参数共有 1290个 ： 同理 为 128 × 10 + 10 = 1290</p>
</blockquote>
<h2 id="归一化与训练数据"><a href="#归一化与训练数据" class="headerlink" title="归一化与训练数据"></a>归一化与训练数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_images_scaled = train_images/<span class="number">255</span>  <span class="comment">#归一化</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.optimizers.Adam(),loss=tf.losses.sparse_categorical_crossentropy,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(train_images_scaled,train_labels,epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Q：为什么只对 1875个 进行训练？ epoch 5 的 含义是什么？</strong><img src="https://img-blog.csdnimg.cn/152d19d34215451c90b946d3d3bcbf7e.png#pic_center" alt="在这里插入图片描述"><br> 训练没有问题。正在对1875批次（每批次32张图像）而不是1875张图像进行模型训练。     1875 × 32 = 60000张图像</p>
</blockquote>
<h2 id="评估模型-与-测试数据"><a href="#评估模型-与-测试数据" class="headerlink" title="评估模型 与 测试数据"></a>评估模型 与 测试数据</h2><p>评估模型的 loss 和 accuracy 使用 <font color="red">evaluate (测试集全体数据，测试集全体标签) 方法</font><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_images_scaled = test_images/<span class="number">255</span></span><br><span class="line"><span class="comment"># # 输出 loss 和 accuracy</span></span><br><span class="line">model.evaluate(test_images_scaled,test_labels)</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>如果要对 测试集图像 进行预测 需要使用<font color="red"> predict (测试集数据) 方法 </font>  输出最后的输出内容为 10维向量（因为一共0-9 10个分类 输出层已经设定好了） 然后再用 numpy的<font color="red">  argmax  </font> 取得向量中 值最大的那个 就是对应 预测的标签。<br><strong>要注意输入的维度 必须要与 输入层设定的维度 保持一致</strong><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 要满足输入的维度, 并从</span></span><br><span class="line"><span class="built_in">print</span>(model.predict((test_images[<span class="number">0</span>]/<span class="number">255</span>).reshape(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line"><span class="comment">#输出预测的标签</span></span><br><span class="line"><span class="built_in">print</span>(np.argmax(model.predict((test_images[<span class="number">0</span>]/<span class="number">255</span>).reshape(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))))</span><br><span class="line"><span class="comment">#对比一下 真实的标签是什么</span></span><br><span class="line"><span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="可以设定自动终止训练"><a href="#可以设定自动终止训练" class="headerlink" title="可以设定自动终止训练"></a>可以设定自动终止训练</h2><p>当损失值 小于 0.4 就终止 批次训练<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myCallback</span>(<span class="params">tf.keras.callbacks.Callback</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span>(<span class="params">self,epoch,logs=&#123;&#125;</span>):</span></span><br><span class="line">        <span class="keyword">if</span>(logs. get(<span class="string">&#x27;loss&#x27;</span>)&lt; <span class="number">0.4</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\ nLoss is low so cancelling training!&quot;</span>)</span><br><span class="line">            self.model.stop_training=<span class="literal">True</span></span><br><span class="line">            <span class="built_in">print</span>(model.predict((test_images[<span class="number">0</span>] / <span class="number">255</span>).reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">            <span class="built_in">print</span>(np.argmax(model.predict((test_images[<span class="number">0</span>] / <span class="number">255</span>).reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))))</span><br><span class="line">            <span class="built_in">print</span>(test_labels[<span class="number">0</span>])</span><br><span class="line">callbacks=myCallback()</span><br><span class="line">mnist=tf.keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels),(test_images, test_labels)=mnist.load_data()</span><br><span class="line">training_images_scaled=training_images/<span class="number">255.0</span></span><br><span class="line">test_images_scaled=test_images/<span class="number">255.0</span></span><br><span class="line">model=tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">512</span>, activation=tf.nn.relu),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=tf.nn.softmax)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(training_images_scaled, training_labels, epochs=<span class="number">5</span>, callbacks=[callbacks])</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title>ResNet</title>
    <url>/2021/11/20/ResNet/</url>
    <content><![CDATA[<p>@<a href="ResNet">TOC</a></p>
<h1 id="ResNet解决-网络退化问题"><a href="#ResNet解决-网络退化问题" class="headerlink" title="ResNet解决 网络退化问题"></a>ResNet解决 网络退化问题</h1><p>从经验来看，网络的深度对模型的性能至关重要，当增加网络层数后，网络可以进行更加复杂的特征模式的提取，所以当模型更深时理论上可以取得更好的结果。但研究表明，加深网络深度，会出现网络准确度 饱和甚至下降的情况，如下图1所示。 这个现象被称为 <font color="red">网络退化现象 </font><br><img src="https://img-blog.csdnimg.cn/img_convert/a4362ebe13d4e05ed73f84e3fea663d0.png#pic_center" alt="图1：20层和56层在CIFAR-10数据集上的训练error表现"><br>那网络退化问题是过拟合导致的么？当然不是，因为网络越深理论上提取特征的能力越强，越不容易过拟合。如上图1所示，56层的网络误差整体都比26层的高。</p>
<p>所以其从本质上看，其实是模型深度越大，其训练不动的情况。换句话说他可能存在<strong>一定的梯度消失问题</strong>，导致高深度网络难以训练。也就是，现在的网络训练方式肯定有点问题，让深度网络很难的反向传播找到一组很好的参数。</p>
<h1 id="ResNet-残差学习"><a href="#ResNet-残差学习" class="headerlink" title="ResNet 残差学习"></a>ResNet 残差学习</h1><p>其实网络退化的现象可以通俗的理解为，一个小孩报了更多的班，然而成绩还下降了。我们的目的应该是最起码报的班可能没作用，但是不至于成绩还下降了。</p>
<p>基于这个想法，现在我们有一个浅层网络，我们想通过堆积更多的层次来建立深层网络，一个极端的情况就是这些新的层可能作用都不起，仅仅复制了浅层网络的特征（也就是不至于退步），这样的新层可以被称为 <font color="red">恒等映射 Identity mapping </font></p>
<p>在ResNet中，何大佬想到了利用之前的 机器学习的残差 和 跳跃（短路）连接 来实现一种新的结构。</p>
<blockquote>
<p>机器学习的<strong>残差</strong>，其实就是预测值和标签值之间的距离。我们的目的其实是让预测毕竟真实的标签值。如下图2所示，大括号的部分就是所谓的残差。<br><img src="https://img-blog.csdnimg.cn/img_convert/4978f970591937eed026ea8b6992c338.png#pic_center" alt="图2：何为残差？"></p>
</blockquote>
<p>何大佬的具体想法是，对于一个堆集层结构。当输入为 $x$ 时其学习到的特征记作 $H(x)$ ，而我们要 <strong>学习的部分为 残差</strong>  $F(x) = H(x)-x$，这样原始的学习特征为 $F(x)+x$。 <font color="red">为什么这么设计？</font> <font color="purple">因为残差学习相比原始特征的直接学习容易得多。</font>  如下图3所示，为残差结构：<br><img src="https://img-blog.csdnimg.cn/img_convert/41e7e4a3768e9840bbca32443df7aa67.png#pic_center" alt="图3 残差结构"><br>当残差为0时，此时堆积层仅仅做了恒等映射，至少网络性能不会下降，实际上残差不会为0，这也会使得堆积层在输入特征基础上学习到新的特征，从而拥有更好的性能。</p>
<h2 id="为什么残差学习更容易？"><a href="#为什么残差学习更容易？" class="headerlink" title="为什么残差学习更容易？"></a>为什么残差学习更容易？</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/b1c4a0899a120d761099b2add95c77da.png#pic_center" alt="图4 为什么残差学习更容易？"></p>
<h1 id="ResNet的网络结构"><a href="#ResNet的网络结构" class="headerlink" title="ResNet的网络结构"></a>ResNet的网络结构</h1><p>ResNet网络是参考了 VGG19 网络，在其基础上进行了修改，并通过短路机制加入了残差单元，如图4所示。变化主要体现在 ResNet 直接使用 stride=2 的卷积做下采样，并且用 global average pool 层替换了全连接层。</p>
<p>ResNet 的一个重要设计原则是：当 feature map 大小降低一半时，feature map的数量增加一倍，这保持了网络层的复杂度。从图4中可以看到，ResNet相比普通网络每两层间增加了短路机制，这就形成了残差学习，其中虚线表示feature map数量发生了改变。图4展示的34-layer的ResNet，还可以构建更深的网络如表1所示。从表1中可以看到，对于18-layer和34-layer的ResNet，其进行的两层间的残差学习，当网络更深时，其进行的是三层间的残差学习，三层卷积核分别是1x1，3x3和1x1，一个值得注意的是隐含层的feature map数量是比较小的，并且是输出feature map数量的1/4。<br><img src="https://img-blog.csdnimg.cn/img_convert/f2f0cda5c64aad9bd20d77d4a67a3019.png#pic_center" alt="图4 ResNet网络结构图"><br><img src="https://img-blog.csdnimg.cn/img_convert/f110d29b9825b218ceb06b6b1263c539.png#pic_center" alt="表1 不同深度的ResNet"></p>
<blockquote>
<p>为什么ResNet50 明明模型深很多但是 参数量却和ResNet34差不多呢？<br>因为 ResNet50采用的为bottleneck残差模块。那为什么用这个模块呢？ 又因为通道数比较大，比如64直接通过变成256的。<br>相当于4倍，如果我们还是使用3×3的卷积的话，那计算复杂度会高很多。 （这也是用到1×1的优势）可以看一下 Inception 里 描述 1×1的优势 <a href="https://jks88995656.github.io/2021/09/21/Pytorch%20GoogleNet%E4%B8%AD%E7%9A%84Inception/">Inception</a></p>
</blockquote>
<p>下面我们再分析一下残差单元，ResNet使用两种残差单元，如图5所示。<br>左图对应的是浅层网络普通残差模块，而右图对应的是深层网络bottleneck残差模块。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/e03e8e41aae5616f3349e8e135f34422.png#pic_center" alt="图5 两种残差模块结构"><br>对于短路连接，当输入和输出维度一致时，可以直接将输入加到输出上。但是当维度不一致时（对应的是维度增加一倍），这就不能直接相加。</p>
<p>有2种策略：</p>
<ol>
<li>采用zero-padding增加维度，此时一般要先做一个downsamp，可以采用strde=2的pooling，这样不会增加参数；</li>
<li>采用新的映射（projection shortcut），一般采用1x1的卷积，这样会增加参数，也会增加计算量。短路连接除了直接使用恒等映射，当然都可以采用projection shortcut。（所以这里有两种选择）</li>
</ol>
<p>综上所述，理论上有3种方式A、B、C来用于增加维度：<br><strong>我们一般会选用B方案。</strong></p>
<ul>
<li>A 所有的短路连接升维度都采用 padding 补零方式。 其不增加参数量。</li>
<li>B 需要调整维度的 才有 projection shortcut 1×1卷积，其他的短路连接保持不变。 其参数量有一些。</li>
<li>C 所有的短路连接都采用 projection shortcut 1×1卷积。 引入参数量较大。</li>
</ul>
<blockquote>
<p>从实验结果看，如下图6所示。之所以我们选择B方法，是因为其效果相对A来说还不错，参数增加相比C方案来说少。<br><img src="https://img-blog.csdnimg.cn/img_convert/be137c8d1dee1ee3617bb1da03b1b9ee.png#pic_center" alt="图6 A、B、C三种方式的error"></p>
</blockquote>
<h1 id="ResNet的迁移"><a href="#ResNet的迁移" class="headerlink" title="ResNet的迁移"></a>ResNet的迁移</h1><p>其在各个领域都有不错的效果。一般都可作为backbone，例如faster R-CNN 就是这么干的。<br>作者在论文中做了很多实验，后续写。</p>
]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>ResNet</tag>
      </tags>
  </entry>
  <entry>
    <title>cv2 各类函数 详解</title>
    <url>/2021/10/25/cv2%20%E5%90%84%E7%B1%BB%E5%87%BD%E6%95%B0%20%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>@<a href="cv2 各类函数 详解">TOC</a></p>
<h1 id="cv2-rectangle-在任何图像上绘制矩形"><a href="#cv2-rectangle-在任何图像上绘制矩形" class="headerlink" title="cv2.rectangle  在任何图像上绘制矩形"></a>cv2.rectangle  在任何图像上绘制矩形</h1><p>用法： cv2.rectangle(image, start_point, end_point, color, thickness) 参数：</p>
<blockquote>
<p>image:它是要在其上绘制矩形的图像。 start_point：它是矩形的起始坐标。坐标表示为两个值的元组，即(X坐标值，Y坐标值)。<br>end_point：它是矩形的结束坐标。坐标表示为两个值的元组，即(X坐标值ÿ坐标值)。<br>color:它是要绘制的矩形的边界线的颜色。对于BGR，我们通过一个元组。例如：(255，0，0)为蓝色。<br>thickness:它是矩形边框线的粗细像素。厚度-1像素将以指定的颜色填充矩形形状。 返回值：它返回一个图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.rectangle(img,(x,y),(x+w,y+h),color,<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
</blockquote>
<h1 id="cv2-putText-在图像上加字"><a href="#cv2-putText-在图像上加字" class="headerlink" title="cv2.putText 在图像上加字"></a>cv2.putText 在图像上加字</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">string = <span class="string">&#x27;&#123;&#125;&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(class_names[i],confidence)</span><br><span class="line">cv2.putText(img,string,(x,y+<span class="number">20</span>),cv2.FONT_HERSHEY_PLAIN,<span class="number">3</span>,(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>),<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>各参数依次为：图片，添加的文字，左上角坐标，字体，字体大小，颜色，字体粗细</p>
<p>其中字体可以选择：<br>FONT_HERSHEY_SIMPLEX 、 FONT_HERSHEY_PLAIN、 FONT_HERSHEY_DUPLEX 等</p>
<h1 id="cv2-dnn-readNet-用于读取网络参数并构建网络"><a href="#cv2-dnn-readNet-用于读取网络参数并构建网络" class="headerlink" title="cv2.dnn.readNet 用于读取网络参数并构建网络"></a>cv2.dnn.readNet 用于读取网络参数并构建网络</h1><p>注意 cv2的dnn 网络库集合了多种网络<br>具体可以查看这个 博客 <a href="https://blog.csdn.net/Hellow_RMB/article/details/110070686">OpenCV中DNN支持的网络架构</a><br>如：读取 yolov3的配置文件与网络参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net = cv2.dnn.readNet(<span class="string">&#x27;yolov3.weights&#x27;</span>,<span class="string">&#x27;yolov3.cfg&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="cv2-imread-用于读取图片文件"><a href="#cv2-imread-用于读取图片文件" class="headerlink" title="cv2.imread 用于读取图片文件"></a>cv2.imread 用于读取图片文件</h1><p>imread函数有两个参数。<br>第一个参数是图片路径，第二个参数表示读取图片的形式，有三种：</p>
<ul>
<li>cv2.IMREAD_COLOR：加载彩色图片，这个是默认参数，可以直接写1。<br>cv2.IMREAD_GRAYSCALE：以灰度模式加载图片，可以直接写0。<br>cv2.IMREAD_UNCHANGED：包括alpha，可以直接写-1</li>
</ul>
<p>cv2.imread()读取图片后已多维数组的形式保存图片信息，前两维表示图片的像素坐标，最后一维表示图片的通道索引，具体图像的通道数由图片的格式来决定</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入图像 默认彩色</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;guoge_and_ shark.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="cv2-imwrite-保存图像"><a href="#cv2-imwrite-保存图像" class="headerlink" title="cv2.imwrite  保存图像"></a>cv2.imwrite  保存图像</h1><p>cv2.imwrite(file，img，num)保存一个图像。</p>
<blockquote>
<p>第一个参数是要保存的文件名，第二个参数是要保存的图像。<br>可选的第三个参数，它针对特定的格式：<br>对于JPEG，其表示的是图像的质量，用0 -100的整数表示，默认95;<br>对于png ,第三个参数表示的是压缩级别。默认为3.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存图片</span></span><br><span class="line">cv2.imwrite(<span class="string">&#x27;result-guoge.jpg&#x27;</span>,img)</span><br></pre></td></tr></table></figure>
<h1 id="cv2-imshow-显示图像"><a href="#cv2-imshow-显示图像" class="headerlink" title="cv2.imshow()  显示图像"></a>cv2.imshow()  显示图像</h1><p>cv2.imshow(窗口名字，图像名称) 显示图像。<br>窗口会自动调整为图像大小。第一个参数是窗口的名字，其次才是我们的图像。你可以创建多个窗口，只要你喜欢，但是必须给他们不同的名字。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.imwrite(<span class="string">&#x27;lena.png&#x27;</span>,img)</span><br></pre></td></tr></table></figure>
<h1 id="cv2-dnn-blobFromImage-对图像进行预处理，包括减均值，比例缩放，裁剪，交换通道等"><a href="#cv2-dnn-blobFromImage-对图像进行预处理，包括减均值，比例缩放，裁剪，交换通道等" class="headerlink" title="cv2.dnn.blobFromImage 对图像进行预处理，包括减均值，比例缩放，裁剪，交换通道等"></a>cv2.dnn.blobFromImage 对图像进行预处理，包括减均值，比例缩放，裁剪，交换通道等</h1><blockquote>
<p>参数：<br>image:输入图像（1、3或者4通道）<br>———————————————<br>可选参数 ：<br>scalefactor:图像各通道数值的缩放比例<br>size:输出图像的空间尺寸,如size=(200,300)表示高h=300,宽w=200<br>mean:用于各通道减去的值，以降低光照的影响<br> swapRB:交换RB通道，默认为False.(cv2.imread读取的是彩图是BGR通道，正常图片都为RGB)<br>crop:图像裁剪,默认为False.当值为True时，先按比例缩放，然后从中心裁剪成size尺寸<br>ddepth:输出的图像深度，可选CV_32F 或者 CV_8U.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对图像预处理</span></span><br><span class="line"><span class="comment"># 1/255把所有像素归一化 除以255 （0，0，0）表示对每个像素RGB减去常数 这里不减</span></span><br><span class="line"><span class="comment"># 因为opencv读入的为BGR 所以我们这里要反一下 swapRB=True crop不对图片进行裁剪</span></span><br><span class="line">blob = cv2.dnn.blobFromImage(img,<span class="number">1</span>/<span class="number">255</span>,(<span class="number">416</span>,<span class="number">416</span>),(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),swapRB=<span class="literal">True</span>,crop=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h1 id="cv2-dnn-NMSBoxes-非极大值抑制法"><a href="#cv2-dnn-NMSBoxes-非极大值抑制法" class="headerlink" title="cv2.dnn.NMSBoxes 非极大值抑制法"></a>cv2.dnn.NMSBoxes 非极大值抑制法</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CONF_THRES = <span class="number">0.1</span> <span class="comment">#指定置信度阈值，阈值越大，置信度过滤越强</span></span><br><span class="line">NMS_THRES = <span class="number">0.4</span> <span class="comment">#指定NMS阈值，阈值越小，NMS越强</span></span><br><span class="line"></span><br><span class="line">indexes = cv2.dnn.NMSBoxes(boxes,confidences,CONF_THRES,NMS_THRES)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>目标检测，OpenCv</tag>
      </tags>
  </entry>
  <entry>
    <title>keras 包方法集合</title>
    <url>/2021/08/29/keras%20%E5%8C%85%E6%96%B9%E6%B3%95%E9%9B%86%E5%90%88/</url>
    <content><![CDATA[<p>@<a href="keras 包方法集合">TOC</a></p>
<h1 id="keras-util-库-np-utils"><a href="#keras-util-库-np-utils" class="headerlink" title="keras.util 库  np_utils"></a>keras.util 库  np_utils</h1><h2 id="np-utils-to-categorical"><a href="#np-utils-to-categorical" class="headerlink" title="np_utils.to_categorical"></a>np_utils.to_categorical</h2><p>np_utils.to_categorical用于将标签转化为形如(nb_samples, nb_classes)的二值序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_labels_hot = np_utils.to_categorical(train_labels,num_classes=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>如将 $[1,2,3,……4]$ 转化成：<br><img src="https://img-blog.csdnimg.cn/379535ca64bc4e5987673ecd12af0c75.png#pic_center" alt="在这里插入图片描述"><br>这样的形态。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title>python 处理 nii 数据 保存为png图片</title>
    <url>/2022/04/28/python%20%E5%A4%84%E7%90%86%20nii%20%E6%95%B0%E6%8D%AE%20%E4%BF%9D%E5%AD%98%E4%B8%BApng%E5%9B%BE%E7%89%87/</url>
    <content><![CDATA[<p>@<a href="python 处理 nii 数据">TOC</a></p>
<p>nii 文件处理代码如下：</p>
<h4 id="处理代码"><a href="#处理代码" class="headerlink" title="处理代码"></a>处理代码</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os  <span class="comment"># 遍历文件夹</span></span><br><span class="line"><span class="keyword">import</span> nibabel <span class="keyword">as</span> nib  <span class="comment"># nii格式一般都会用到这个包</span></span><br><span class="line"><span class="keyword">import</span> imageio  <span class="comment"># 转换成图像</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nii_to_image</span>(<span class="params">niifile</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">filepath = <span class="string">&#x27;F:\ISIC-2017\img.nii&#x27;</span>  <span class="comment"># 读取本代码同个文件夹下所有的nii格式的文件</span></span><br><span class="line">filenames = os.listdir(filepath)</span><br><span class="line">imgfile = <span class="string">&#x27;./&#x27;</span></span><br><span class="line"></span><br><span class="line">slice_trans = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> filenames:  <span class="comment"># 开始读取nii文件</span></span><br><span class="line">    s = f[-<span class="number">4</span>:]   <span class="comment"># 获取文件的后缀名称</span></span><br><span class="line">    <span class="built_in">print</span>(s)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> s != <span class="string">&#x27;.nii&#x27;</span>:  <span class="comment"># 文件不是 .nii为结尾的就跳过</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    s1 = f[:-<span class="number">4</span>]   <span class="comment"># 读取 .nii 文件的 文件名称  如：img</span></span><br><span class="line">    <span class="built_in">print</span>(s1)</span><br><span class="line">    imgfile_path = imgfile + s1    <span class="comment"># ./img</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;imgfile_path:&quot;</span> + imgfile_path)</span><br><span class="line">    img_path = os.path.join(filepath, f)   <span class="comment"># ./img/img.nii</span></span><br><span class="line">    img = nib.load(img_path)  <span class="comment"># 读取nii</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;img:&quot;</span>)</span><br><span class="line">    <span class="comment"># print(img)   # 里面一大堆数据</span></span><br><span class="line">    img_fdata = img.get_fdata()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;**************&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;**************&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(img)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;**************&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;**************&quot;</span>)</span><br><span class="line">    fname = f.replace(<span class="string">&#x27;.nii&#x27;</span>, <span class="string">&#x27;&#x27;</span>)  <span class="comment"># 去掉nii的后缀名</span></span><br><span class="line">    img_f_path = os.path.join(imgfile, fname)      <span class="comment"># ./img</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(img_f_path):    <span class="comment"># 创建nii对应的图像的文件夹</span></span><br><span class="line">        os.mkdir(img_f_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># #开始转换为图像</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;.gz&#x27;</span> <span class="keyword">in</span> s1:</span><br><span class="line">        (x, y, z, _) = img.shape</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;img2:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(img.shape)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        (x, y, z) = img.shape     <span class="comment"># 里面没有 .gz的文件  z是图像的序列 一共 89张</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;img3:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(img.shape)   <span class="comment"># 例如：(512, 512, 89)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(z):  <span class="comment"># z是图像的序列</span></span><br><span class="line">        silce = img_fdata[:, :, i]  <span class="comment"># 选择哪个方向的切片都可以</span></span><br><span class="line">        imageio.imwrite(os.path.join(img_f_path, <span class="string">&#x27;&#123;&#125;_mask.png&#x27;</span>.<span class="built_in">format</span>(i)), silce)</span><br><span class="line">        img = Image.<span class="built_in">open</span>(os.path.join(img_f_path, <span class="string">&#x27;&#123;&#125;_mask.png&#x27;</span>.<span class="built_in">format</span>(i)))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;save&quot;</span>)</span><br><span class="line">        img.save(os.path.join(img_f_path, <span class="string">&#x27;&#123;&#125;_mask.png&#x27;</span>.<span class="built_in">format</span>(i)))</span><br></pre></td></tr></table></figure>
<h4 id="处理结果"><a href="#处理结果" class="headerlink" title="处理结果"></a>处理结果</h4><p>一共89张。<br><img src="https://img-blog.csdnimg.cn/img_convert/4da35b21eee0ca64e9225abeb53f8e88.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>医学图像</category>
      </categories>
      <tags>
        <tag>医学图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="前端性能优化"><a href="#前端性能优化" class="headerlink" title="前端性能优化"></a>前端性能优化</h1><h2 id="考点1：-CND"><a href="#考点1：-CND" class="headerlink" title="考点1： CND"></a>考点1： CND</h2><h3 id="面试题：CND的原理"><a href="#面试题：CND的原理" class="headerlink" title="面试题：CND的原理"></a>面试题：CND的原理</h3><p><strong>CND的基本原理是</strong> （其和 DSN 的过程 有点关系）</p>
<ol>
<li><strong>在用户访问相对集中的地区和网络设置一些缓存服务器。</strong></li>
<li><strong>当用户访问网站时，利用全局的负载均衡技术将用户的访问指向距离最近的缓存服务器，由缓存服务器代替源站响应用户的访问请求。</strong></li>
</ol>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/CDN工作原理.png" alt=""></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/CND原理图.png" style="zoom:50%;" /></p>
<p><strong>CNAME: 在域名解析中，实际上解析出来的指定域名对应的 IP 地址，或者该域名的一个 CNAME，然后再根据这个CNAME来查找对应的 IP 地址。</strong></p>
<p>其一般使用的场景为：</p>
<ul>
<li>使用第三方 <strong>CDN</strong> 服务，比如你想开源一些项目，给被人用</li>
<li>使用 <strong>CDN</strong> 进行静态资源的缓存，例如可以将自己网站的静态资源放在 CDN上。</li>
<li>直播传送：CDN是支持流媒体传送的</li>
</ul>
<h2 id="考点2：懒加载"><a href="#考点2：懒加载" class="headerlink" title="考点2：懒加载"></a>考点2：懒加载</h2><p>例如网页延迟加载图片数据，是一种优化网页性能的方式。</p>
<p>其具体表现为：</p>
<p><strong>如果使用图片的懒加载，就是在滚动屏幕之前，可视化区域之外的图片是不会进行加载的，再滚动屏幕到下方的时候才会加载。</strong></p>
<p>这样可以减少服务器返回数据的负担，并且可以一定的提高用户体验，另外防止加载过多的图片而影响其他资源文件的加载。</p>
<h3 id="面试题：懒加载实现的原理"><a href="#面试题：懒加载实现的原理" class="headerlink" title="面试题：懒加载实现的原理"></a>面试题：懒加载实现的原理</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/懒加载原理.png" alt=""></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/懒加载图例.png" alt=""></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/懒加载代码.png" style="zoom:150%;" /></p>
<h3 id="面试题：懒加载和预加载的区别"><a href="#面试题：懒加载和预加载的区别" class="headerlink" title="面试题：懒加载和预加载的区别"></a>面试题：懒加载和预加载的区别</h3><p>都是可以提高网页性能的方式，两个主要的区别是。</p>
<ul>
<li><p>懒加载指的是在 长网页中延迟加载图片的时机，当用户需要访问的时候，再去加载。实现的原理看上面。并且其一定程度上可以缓解服务器的响应负担。</p>
</li>
<li><p><strong>预加载指的是 所需的资源提前请求加载到本地，这样后面在需要用到的时候就直接从缓存中获取资源。</strong>通过预加载可以减少用户等待的时间。</p>
<p>比较常见的案例有，使用 js 中的 image 对象，通过对 image 对象来设置 src 属性，来实现图片的预加载。</p>
</li>
</ul>
<h2 id="考点3：回流-重排-和重绘"><a href="#考点3：回流-重排-和重绘" class="headerlink" title="考点3：回流(重排)和重绘"></a>考点3：回流(重排)和重绘</h2><h3 id="面试题：那些情况可能会导致回流"><a href="#面试题：那些情况可能会导致回流" class="headerlink" title="面试题：那些情况可能会导致回流"></a>面试题：那些情况可能会导致回流</h3><font color="blue">**回流（重排）指的是 渲染树（dom树）部分或者全部元素的尺寸、结构或者属性发生变化的时候，浏览器会重新渲染部分或者全部文档的过程。**</font>简单的说就是，你做出了一些改变影响页面元素布局的DOM操作。

引起回流的操作有：

- 页面的首次渲染、浏览器窗口大小变化
- 某个元素内容变化、某个元素的尺寸或者位置发生变化、某个元素的字体变化
- 激活CSS伪类
- 查询某些属性或者调用某些方法
- 添加或删除可见（也就是 display 不是 none）的 DOM 元素

在触发回流的时候，由于浏览器渲染页面时基于**流式布局**的，**所以会导致周围的DOM元素重新排列**，他的影响分为全局和局部两种

- 全局范围：从根节点开始，对整个 渲染树 进行重新布局
- 局部范围：从渲染树的某个部分或者一个渲染对象进行重新布局



### 面试题：那些情况可能会导致重绘

<font color="blue">**页面中某些元素的样式发生了变化，但是不会影响到<font color="red">文档流中元素的位置</font>。浏览器单独对发生样式变化的元素进行重新绘制。**</font>

<p>引起重绘的操作有：</p>
<ul>
<li>color、background 相关属性：background-color、background-image等</li>
<li>outline 相关属性：outline-color、outline-width、text-decoration</li>
<li>另外还有 border-radius、visibility、box-shadow等</li>
</ul>
<p><strong>所以，当触发回流时，重排一定触发。重排触发，回流不一定触发的。</strong></p>
<h3 id="面试题：如何避免回流和重绘，从程序员和浏览器本身两方面都说一说？"><a href="#面试题：如何避免回流和重绘，从程序员和浏览器本身两方面都说一说？" class="headerlink" title="面试题：如何避免回流和重绘，从程序员和浏览器本身两方面都说一说？"></a>面试题：如何避免回流和重绘，从程序员和浏览器本身两方面都说一说？</h3><p><strong>程序员如何避免主要有：</strong></p>
<ul>
<li><p>不要使用 table 布局，一个改动可能整个重新布局</p>
</li>
<li><p>使用 CSS 表达式</p>
</li>
<li><p><font color="blue"><strong>使用absolute 或者 fixed，让元素脱离文档流，那他们发生变化并不会影响到其他的元素</strong></font> <strong>这个操作非常适用于 的动画，因为动画会触发很多dom操作</strong></p>
</li>
<li><p><strong>避免频繁的操作dom，可以创建一个文档片段 <code>documentFragment</code>，在它上面应用所有 DOM 操作，最后添加到文档中</strong></p>
</li>
<li><p>将元素先设置为 <code>display:none</code>，操作结束后再把它显示出来。</p>
<font color="red">**因为 display 为none 的元素上进行的 DOM 操作不会引发回流和重绘。**</font>
</li>
<li><p><strong>配合浏览器 的 渲染队列机制，将DOM的多个读操作放在一起，多个写操作放在一起，读写操作不穿插写。</strong></p>
</li>
</ul>
<p><strong>浏览器做出的努力：</strong></p>
<p>浏览器针对于页面的回流和重绘，做出了自身的优化 — <strong>渲染队列</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/回流与重绘.png" alt=""></p>
<h3 id="面试题：documentFragment是什么？和直接操作-DOM-有什么区别？"><a href="#面试题：documentFragment是什么？和直接操作-DOM-有什么区别？" class="headerlink" title="面试题：documentFragment是什么？和直接操作 DOM 有什么区别？"></a>面试题：<code>documentFragment</code>是什么？和直接操作 DOM 有什么区别？</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/文档片段.png" alt=""></p>
<h2 id="考点4：节流和防抖"><a href="#考点4：节流和防抖" class="headerlink" title="考点4：节流和防抖"></a>考点4：节流和防抖</h2><h3 id="面试题：什么是防抖和节流？有什么区别？"><a href="#面试题：什么是防抖和节流？有什么区别？" class="headerlink" title="面试题：什么是防抖和节流？有什么区别？"></a>面试题：什么是防抖和节流？有什么区别？</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/节流和防抖的理解.png" alt=""></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/适用场景.png" alt=""></p>
<ul>
<li><p><strong>防抖：</strong>把中间的处理函数全部过滤掉了，<strong>只执行在规定时间内的最后一个事件</strong></p>
<p>比如我设置一个时间例如 200ms</p>
<ul>
<li>如果在200ms内没有再次触发事件，那么就执行对应的处理函数</li>
<li>如果在200ms内再次触发事件，那么当前的计时取消，重新开始计时</li>
</ul>
<p>一般是定义一个 debounce 函数，其是由闭包进行实现的：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里的 fn 也就是 我们的 事件对应的处理函数</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">debounce</span>(<span class="params">fn,delay</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> timer = <span class="literal">null</span> <span class="comment">//借助闭包</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(timer)&#123;</span><br><span class="line"><span class="comment">//进入该分支语句，说明当前正在一个计时过程中，并且又触发了相同事件。所以要取消当前的计时，重新开始计时</span></span><br><span class="line">            <span class="built_in">clearTimeout</span>(timer) </span><br><span class="line">        &#125;</span><br><span class="line">        timer = <span class="built_in">setTimeout</span>(fn,delay)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>节流：中间的处理函数被时间限制，<strong>只能在一段时间中执行一次</strong>。但是<strong>只是减少了频率</strong></p>
<p>一般是定义一个 throttle函数，其也是由闭包进行实现的：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">throttle</span>(<span class="params">fn,delay</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> valid = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">       <span class="keyword">if</span>(!valid)&#123;</span><br><span class="line">           <span class="comment">//休息时间 暂不工作</span></span><br><span class="line">           <span class="keyword">return</span> <span class="literal">false</span> </span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">// 工作时间，执行函数并且在间隔期内把状态位设为无效</span></span><br><span class="line">        valid = <span class="literal">false</span></span><br><span class="line">        <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">            fn()</span><br><span class="line">            valid = <span class="literal">true</span>;</span><br><span class="line">        &#125;, delay)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="考点5：图片优化"><a href="#考点5：图片优化" class="headerlink" title="考点5：图片优化"></a>考点5：图片优化</h2><h3 id="面试题：如何对项目中的图片进行优化？"><a href="#面试题：如何对项目中的图片进行优化？" class="headerlink" title="面试题：如何对项目中的图片进行优化？"></a>面试题：如何对项目中的图片进行优化？</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/图片优化.png" alt=""></p>
<h3 id="面试题：常见的图片格式和使用场景"><a href="#面试题：常见的图片格式和使用场景" class="headerlink" title="面试题：常见的图片格式和使用场景"></a>面试题：常见的图片格式和使用场景</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/图片格式2.png" alt=""></p>
<h2 id="考点6：-WebPack-优化"><a href="#考点6：-WebPack-优化" class="headerlink" title="考点6： WebPack 优化"></a>考点6： WebPack 优化</h2><h3 id="面试题：如何使用-WebPack-来优化前端性能？"><a href="#面试题：如何使用-WebPack-来优化前端性能？" class="headerlink" title="面试题：如何使用 WebPack 来优化前端性能？"></a>面试题：如何使用 WebPack 来优化前端性能？</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/webpack优化前端性能.png" alt=""></p>
<h3 id="面试题：如何提高-WebPack-的构建速度"><a href="#面试题：如何提高-WebPack-的构建速度" class="headerlink" title="面试题：如何提高 WebPack 的构建速度"></a>面试题：如何提高 WebPack 的构建速度</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/webpack构建速度.png" alt=""></p>
]]></content>
  </entry>
  <entry>
    <title>argparse模块用法实例详解</title>
    <url>/2021/09/22/argparse%E6%A8%A1%E5%9D%97%E7%94%A8%E6%B3%95%E5%AE%9E%E4%BE%8B%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>@<a href="argparse模块用法实例详解">TOC</a></p>
<p>argparse是python的命令行解析的标准模块，内置于python，不需要安装。这个库可以让我们直接在命令行（这边指的是 <strong>python的命令行</strong> 或者是 <strong>Anaconda Prompt</strong>）中就可以向程序中传入参数并让程序运行。<br>其实 argparse 就是一个键值对存储的方式。</p>
<h1 id="栗子一：传入一个参数并输出"><a href="#栗子一：传入一个参数并输出" class="headerlink" title="栗子一：传入一个参数并输出"></a>栗子一：传入一个参数并输出</h1><p>新建一个文件（如叫：arg_study），在该文件夹中新建一个python文件（如：demo.py）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;命令行中传入一个数字&#x27;</span>)</span><br><span class="line"><span class="comment"># type是要传入的参数的数据类型  help是该参数的提示信息</span></span><br><span class="line"><span class="comment"># integers 相当于键</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;integers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;传入的数字&#x27;</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment">#获得传入的参数</span></span><br><span class="line"><span class="built_in">print</span>(args)</span><br></pre></td></tr></table></figure>
<h2 id="查看帮助提示"><a href="#查看帮助提示" class="headerlink" title="查看帮助提示"></a>查看帮助提示</h2><p>命令行中输入<code>python demo.py -h</code>或者 <code>python demo.py --help</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python demo.py -h</span><br><span class="line">python demo.py --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">usage: demo.py [-h] integers</span><br><span class="line"></span><br><span class="line">命令行中传入数字</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  integers    传入的数字</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --<span class="built_in">help</span>  show this <span class="built_in">help</span> message <span class="keyword">and</span> exit</span><br></pre></td></tr></table></figure>
<h2 id="输入参数并输出"><a href="#输入参数并输出" class="headerlink" title="输入参数并输出"></a>输入参数并输出</h2><p>如输入5<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python demo.py <span class="number">5</span></span><br></pre></td></tr></table></figure><br>得到的结果<code>print(args)</code>为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Namespace(integers=<span class="string">&#x27;5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>如何获取其中的数据呢？</strong><br><code>Namespace(integers=&#39;5&#39;)</code> 其实是一个类似于python字典的数据类型。<br>我们可以是哟个 <code>arg.参数名</code>  来提取这个参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#获得integers参数</span></span><br><span class="line"><span class="built_in">print</span>(args.integers)</span><br></pre></td></tr></table></figure>
<h1 id="栗子二：传入多个参数并输出"><a href="#栗子二：传入多个参数并输出" class="headerlink" title="栗子二：传入多个参数并输出"></a>栗子二：传入多个参数并输出</h1><p>nargs是用来说明传入的参数个数，’+’ 表示传入至少一个参数。这时候再重新在命令行中运行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;命令行中传入一个数字&#x27;</span>)</span><br><span class="line"><span class="comment"># nargs是用来说明传入的参数个数，&#x27;+&#x27; 表示传入至少一个参数。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;integers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, nargs=<span class="string">&#x27;+&#x27;</span>,<span class="built_in">help</span>=<span class="string">&#x27;传入的数字&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(args.integers)</span><br></pre></td></tr></table></figure>
<p>这时候再重新在命令行中运行<code>python demo.py 1 2 3 4</code>得到<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;4&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<h1 id="栗子三：改变数据类型"><a href="#栗子三：改变数据类型" class="headerlink" title="栗子三：改变数据类型"></a>栗子三：改变数据类型</h1><p>add_argument中有type参数可以设置传入参数的数据类型。我们看到代码中有type这个关键词，该关键词可以传入list, str, tuple, set, dict等。例如我们把上面的type=str，改成type=int,这时候我们就可以进行四则运算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;命令行中传入一个数字&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;integers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, nargs=<span class="string">&#x27;+&#x27;</span>,<span class="built_in">help</span>=<span class="string">&#x27;传入的数字&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment">#对传入的数据进行加总</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>(args.integers))</span><br></pre></td></tr></table></figure>
<p>在命令行中输入 <code>python demo.py 1 2 3 4</code>, 运行结果为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>
<h1 id="栗子四：位置参数"><a href="#栗子四：位置参数" class="headerlink" title="栗子四：位置参数"></a>栗子四：位置参数</h1><p>在命令行中传入参数时候，传入的参数的先后顺序不同，运行结果往往会不同，这是因为采用了位置参数,例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;姓名&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;param1&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&#x27;姓&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;param2&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&#x27;名&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印姓名</span></span><br><span class="line"><span class="built_in">print</span>(args.param1+args.param2)</span><br></pre></td></tr></table></figure>
<p>输出 张三 ：在命令行中分别输入</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python demo.py 张 三</span><br></pre></td></tr></table></figure>
<h2 id="使用可选参数"><a href="#使用可选参数" class="headerlink" title="使用可选参数"></a>使用可选参数</h2><p>为了在命令行中避免上述位置参数的bug（容易忘了顺序），可以使用可选参数，这个有点像关键词传参，但是需要在关键词前面加—，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;姓名&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--family&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&#x27;姓&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&#x27;名&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印姓名</span></span><br><span class="line"><span class="built_in">print</span>(args.family+args.name)</span><br></pre></td></tr></table></figure>
<p>在命令行中输入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python demo.py --family=张 --name=三</span><br></pre></td></tr></table></figure>
<p>结果为 张三 。<br>可选参数虽然写法比较繁琐，但是增加了命令行中的可读性，不容易因为参数传入顺序导致数据错乱。</p>
<h2 id="设置默认值"><a href="#设置默认值" class="headerlink" title="设置默认值"></a>设置默认值</h2><p>add_argument中有一个<strong>default参数</strong>。有的时候需要对某个参数设置默认值，即如果命令行中没有传入该参数的值，程序使用默认值。如果命令行传入该参数，则程序使用传入的值。具体请看下面的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;姓名&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--family&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;张&#x27;</span>,<span class="built_in">help</span>=<span class="string">&#x27;姓&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;三&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;名&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印姓名</span></span><br><span class="line"><span class="built_in">print</span>(args.family+args.name)</span><br></pre></td></tr></table></figure>
<h2 id="设置该参数一定要传入"><a href="#设置该参数一定要传入" class="headerlink" title="设置该参数一定要传入"></a>设置该参数一定要传入</h2><p>add_argument有一个<strong>required参数</strong>可以设置该参数是否必需。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;姓名&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--family&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;姓&#x27;</span>)</span><br><span class="line"><span class="comment"># name 必须传入</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;名&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印姓名</span></span><br><span class="line"><span class="built_in">print</span>(args.family+args.name)</span><br></pre></td></tr></table></figure>
<h1 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h1><p><a href="https://zhuanlan.zhihu.com/p/56922793">argparse模块用法实例详解 【非常的详细】</a><br><a href="https://www.cnblogs.com/yymn/p/8059220.html">python中argparse模块用法实例详解 【比较粗糙】</a></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>argparse</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么要Deep？深而不是宽</title>
    <url>/2021/08/10/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81Deep%EF%BC%9F%E6%B7%B1%E8%80%8C%E4%B8%8D%E6%98%AF%E5%AE%BD/</url>
    <content><![CDATA[<p>@<a href="为什么要Deep？深而不是宽">TOC</a></p>
<blockquote>
<p><strong>Q：为什么要用要用深度？而不是广度？</strong><br>答：1.因为深度可以用少量的数据，就完成对数据的分类。<br>2.深度，每个层次都是基于上个层次得到的（其实就是学习的过程），我们可以将神经元的数量减少。如果层次很少的话，会导致神经元可能非常多。可以类比逻辑电路。<img src="https://img-blog.csdnimg.cn/3889abe5617e426d91f92e842ba3af83.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center=300×300" alt="在这里插入图片描述"></p>
<h1 id="模组化"><a href="#模组化" class="headerlink" title="模组化"></a>模组化</h1><p>在比较浅层网络与深层网络时，要让“矮胖”的网络和“高瘦”的网络的参数数目相等，这样比较才公平。<br><strong>但即便是在深层网络参数较少的情况下，深层网络也会比浅层网络表现好。</strong><br>这是因为<font color="red"> 深层”其实相当于“模组化”</font>，第一个隐层是最基本的分类器，第二个隐层是用第一个隐层建造的分类器，以此类推。</p>
<p><strong>举个栗子，为什么说深度好！</strong><br>左边第一幅图可以看到，我们需要分四个类，包括长发女，长发男，短发女，短发男。一共四类，其中长发男的数据样本很少，那区分这个类的能力就非常的弱。<br>这个时候，我们就可以先分为两个神经元，一个区分男女，一个区分长发短发，这样中间加一层，可以使得数据样本少的类 鉴定的效果更好。<br><img src="https://img-blog.csdnimg.cn/dc3ef77e42724c1ebbcb6d0d29067206.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>对于分类一个图像来说，深度使得模块化。</strong><img src="https://img-blog.csdnimg.cn/81cf2b79b06440e789ad2a03937c7e2e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center=300×300" alt="在这里插入图片描述"></p>
</blockquote>
<h1 id="类比逻辑电路"><a href="#类比逻辑电路" class="headerlink" title="类比逻辑电路"></a>类比逻辑电路</h1><p><img src="https://img-blog.csdnimg.cn/8635e890e73f4834900ea683446b9f0a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center=300×300" alt="在这里插入图片描述"><br>浅层网络确实可以表示任意函数，但是使用深层结构更有效率。<br><strong>好比逻辑门电路，用两层逻辑门就可以实现任何布尔函数，但是用多层结构更简单、需要的逻辑门更少。</strong><br><img src="https://img-blog.csdnimg.cn/3889abe5617e426d91f92e842ba3af83.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center=300×300" alt="在这里插入图片描述"></p>
<p>神经网络也是如此，单隐层网络可以表示任何连续函数，但是多层结构表示起来更简单、需要的神经元更少，<strong>所以比较不容易overfitting，或只需较少的data。</strong>而且，深层结构可以比较有效率地使用data。</p>
<h1 id="类比图形"><a href="#类比图形" class="headerlink" title="类比图形"></a>类比图形</h1><p><img src="https://img-blog.csdnimg.cn/e4e96dfdc69b4c47b96640efa2f70be8.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center=300×300" alt="在这里插入图片描述"><br>1层hidden layer与3层hidden layer（相同数目的参数），3层的效果更好。<br>但理论上，3层可达到的效果，1层也能达到：要在1层learn的时候，target从真实label改为3层的output，这样1层的结果会接近3层的结果。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>李宏毅</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/%E5%89%8D%E7%AB%AF%EF%BC%88JS%EF%BC%89%E4%BB%A3%E7%A0%81%E7%BC%96%E7%A8%8B%E9%A2%98/</url>
    <content><![CDATA[<h2 id="前端（JS）代码编程题"><a href="#前端（JS）代码编程题" class="headerlink" title="前端（JS）代码编程题"></a>前端（JS）代码编程题</h2><h3 id="JS-专属API"><a href="#JS-专属API" class="headerlink" title="JS 专属API"></a>JS 专属API</h3><p><a href="https://cloud.tencent.com/developer/chapter/13597">https://cloud.tencent.com/developer/chapter/13597</a></p>
<h4 id="数值定义"><a href="#数值定义" class="headerlink" title="数值定义"></a>数值定义</h4><p><strong>正数最小值 和 最大值</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 表示无穷接近于0 的最小正数</span></span><br><span class="line"><span class="built_in">Number</span>.MIN_VALUE</span><br><span class="line"><span class="built_in">Number</span>,MAX_VALUE</span><br></pre></td></tr></table></figure>
<p><strong>负无穷大 和 正无穷大</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 负无穷大</span></span><br><span class="line">-<span class="literal">Infinity</span></span><br><span class="line"><span class="built_in">Number</span>.NEGATIVE_INFINITY</span><br><span class="line"><span class="comment">// 正无穷大</span></span><br><span class="line"><span class="literal">Infinity</span></span><br><span class="line"><span class="built_in">Number</span>.POSITIVE_INFINITY</span><br></pre></td></tr></table></figure>
<h4 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h4><p><strong>创建一个二维数组</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> dp = <span class="keyword">new</span> <span class="built_in">Array</span>(prices.length).fill(<span class="number">0</span>).map(<span class="function"><span class="params">x</span> =&gt;</span> <span class="built_in">Array</span>(<span class="number">2</span>).fill(<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p><strong>数组的两个索引值交换的 ES6写法</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">[nums[i], nums[j]] = [nums[j], nums[i]];</span><br></pre></td></tr></table></figure>
<h4 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h4><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><p><strong>字符串变字符串数组，再转Number类型</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/微信截图_20230110194438.png" alt=""></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> lineObj = line.toString().split(<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 使用 map 方法 映射成 Number类型</span></span><br><span class="line"><span class="keyword">let</span> lineArray = lineStr.map(<span class="built_in">Number</span>)</span><br></pre></td></tr></table></figure>
<p><strong>将字符串逆序</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sArray = s.split(<span class="string">&quot;&quot;</span>)</span><br><span class="line">sReverseArray = sArray.reverse()</span><br><span class="line">sReverse = sReverseArray.join(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Number类型变字符串</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Number</span>.toString()</span><br></pre></td></tr></table></figure>
<p><strong>单字符和 ASCCII码</strong></p>
<p>在 JS 中 不像java  可以直接  ‘b’ -‘a’ = 1</p>
<p>因为JS不存在 char这个类型，所以我们需要利用 api  <code>charCodeAt(index)</code> 来做，例如：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;b&#x27;</span>.charCodeAt(<span class="number">0</span>) - <span class="string">&#x27;a&#x27;</span>.charCodeAt(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="哈希表-（任意类型均可）-Map"><a href="#哈希表-（任意类型均可）-Map" class="headerlink" title="哈希表 （任意类型均可） Map"></a>哈希表 （任意类型均可） <code>Map</code></h4><p>JS中不限制传入键和值的 类型 。</p>
<p>JS 使用的是 <code>Map</code>，与 Java 中的 <code>HashMap</code> 有所区别</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建一个哈希表</span></span><br><span class="line"><span class="keyword">const</span> symbolValues = <span class="keyword">new</span> <span class="built_in">Map</span>()</span><br><span class="line"><span class="comment">// 添加</span></span><br><span class="line">symbolValues.set(<span class="string">&quot;I&quot;</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">// 读取</span></span><br><span class="line"><span class="keyword">const</span> value = symbolValues.get(<span class="string">&quot;I&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第一次添加 + 遍历值</span></span><br><span class="line"><span class="keyword">for</span>(num <span class="keyword">of</span> arr)&#123;</span><br><span class="line">    <span class="comment">//利用Map的数据结构统计次数</span></span><br><span class="line">    <span class="keyword">if</span> (!map.has(num)) &#123;</span><br><span class="line">        map.set(num, <span class="number">1</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        map.set(num, map.get(num) + <span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> values = [...map.values()]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(map.entries())	<span class="comment">// 类似于 MapIterator &#123;&quot;name&quot; =&gt; &quot;An&quot;, &quot;des&quot; =&gt; &quot;JS&quot;&#125;</span></span><br><span class="line"><span class="built_in">console</span>.log(map.keys()) <span class="comment">// 类似于 MapIterator &#123;&quot;name&quot;, &quot;des&quot;&#125;</span></span><br><span class="line">size：返回字典中所包含的元素个数</span><br></pre></td></tr></table></figure>
<ol>
<li><p>Map 转 Array</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> map = <span class="keyword">new</span> <span class="built_in">Map</span>([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="comment">// ES6 的解构</span></span><br><span class="line"><span class="built_in">console</span>.log([...map])	<span class="comment">// [[1, 1], [2, 2], [3, 3]]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Array 转 Map</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> map = <span class="keyword">new</span> <span class="built_in">Map</span>([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="built_in">console</span>.log(map)	<span class="comment">// Map &#123;1 =&gt; 1, 2 =&gt; 2, 3 =&gt; 3&#125;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>将 map 形式 转化为 数组形式，并且按照 原来的 values </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 首先将字典转成数组，然后对数组中的第二个元素（频度）从大到小排序</span><br><span class="line"></span><br><span class="line">const list = Array.from(map).sort((a, b) =&gt; b[1] - a[1])</span><br></pre></td></tr></table></figure>
<h4 id="sort-函数-针对数组"><a href="#sort-函数-针对数组" class="headerlink" title="sort 函数  针对数组"></a>sort 函数  <code>针对数组</code></h4><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据绝对值大小  </span></span><br><span class="line">nums.sort(<span class="function">(<span class="params">a, b</span>) =&gt;</span> &#123;</span><br><span class="line">	<span class="comment">//从大到小</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">Math</span>.abs(b) - <span class="built_in">Math</span>.abs(a)</span><br><span class="line">	<span class="comment">//从小到大</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">Math</span>.abs(a) - <span class="built_in">Math</span>.abs(b)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h4 id="join-函数"><a href="#join-函数" class="headerlink" title="join 函数"></a>join 函数</h4><p>可以将一个数组（什么类型都可以）按照某种分隔符进行拼接，<strong>拼接成字符串</strong></p>
<p>例如我现在有一个 里面是Number类型的 数组</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr = [<span class="string">&quot;1&quot;</span>,<span class="string">&quot;2&quot;</span>,<span class="string">&quot;3&quot;</span>]</span><br><span class="line"><span class="comment">// 映射成 Number类型</span></span><br><span class="line"><span class="keyword">var</span> arrNumber = arr.map(<span class="built_in">Number</span>)</span><br><span class="line"><span class="comment">// ”123&quot; </span></span><br><span class="line">arr.join(arr)</span><br><span class="line"><span class="comment">// 转成 Number类型</span></span><br><span class="line"><span class="built_in">Number</span>(arr.join(<span class="string">&quot;&quot;</span>))</span><br><span class="line"><span class="built_in">Number</span>(arrNumber.join(<span class="string">&quot;&quot;</span>))</span><br></pre></td></tr></table></figure>
<h4 id="reduce函数"><a href="#reduce函数" class="headerlink" title="reduce函数"></a>reduce函数</h4><p>可以用于实现累加，代码最精简</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> result = candys.reduce(<span class="function">(<span class="params">a, b</span>) =&gt;</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> a + b</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h4 id="splice-函数"><a href="#splice-函数" class="headerlink" title="splice 函数"></a>splice 函数</h4><p>其可以用于截取，也可用于在指定位置添加</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(let i = 0; i &lt; people.length; i++) &#123;</span><br><span class="line">    peopleNew.splice(people[i][1], 0, people[i])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>达到下面的效果：</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/QQ截图20230117162826.png" style="zoom:50%;" /></p>
<h4 id="slice-函数-数组和字符串的截取"><a href="#slice-函数-数组和字符串的截取" class="headerlink" title="slice 函数   数组和字符串的截取"></a>slice 函数   <code>数组和字符串的截取</code></h4><p>用于 字符串和 数组的截取均可</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> str = <span class="string">&quot;kaikai&quot;</span></span><br><span class="line">str.slice(<span class="number">0</span>,<span class="number">2</span>)  <span class="comment">// &quot;ka&quot;</span></span><br><span class="line"><span class="keyword">const</span> nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">nums.slice(<span class="number">0</span>,<span class="number">2</span>) <span class="comment">// [1,2]</span></span><br></pre></td></tr></table></figure>
<h4 id="at-函数，取最后一个数组元素"><a href="#at-函数，取最后一个数组元素" class="headerlink" title="at 函数，取最后一个数组元素"></a>at 函数，<code>取最后一个数组元素</code></h4><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> arr=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>];</span><br><span class="line">arr.at(-<span class="number">1</span>) <span class="comment">//3</span></span><br><span class="line"><span class="comment">// arr[arr.length - 1]  也是可以的</span></span><br></pre></td></tr></table></figure>
<h4 id="正则表达式的使用"><a href="#正则表达式的使用" class="headerlink" title="正则表达式的使用"></a>正则表达式的使用</h4><p><strong>字符串根据 &gt;= 1个空格 进行隔开</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> tokens = line.split(<span class="regexp">/\s+/</span>);</span><br></pre></td></tr></table></figure>
<h3 id="颜色分类（来自：小米-2022-秋招-卷1）"><a href="#颜色分类（来自：小米-2022-秋招-卷1）" class="headerlink" title="颜色分类（来自：小米 2022 秋招 卷1）"></a>颜色分类（来自：小米 2022 秋招 卷1）</h3><p><strong>问题描述:</strong> 给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排 列。 </p>
<p>此题中，我们使用整数 0、 1 和 2 分别表示<strong>红色、白色和蓝色</strong>。 </p>
<p>输入描述: </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">输入：数组nums </span><br></pre></td></tr></table></figure>
<p>输出描述: </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">输出：数组nums </span><br></pre></td></tr></table></figure>
<p>输入样例: <strong>（输入字符串）</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="number">2</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> </span><br></pre></td></tr></table></figure>
<p>输出样例: <strong>（输出字符串）</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p><strong>答案做法</strong>：不适用 <strong>Array.sort()</strong> 方法的情况下</p>
<p>其实很简单，定义一个指针，就是碰到0，就与这个指针交换一下位置并且更新指针，这样最后所有的0都会再最左边。以此类推再来一次1。</p>
<p>力扣上我记得也是有这道题的，使用 Java 也非常容易实现。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">swap</span>(<span class="params">nums, i, j</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> t = nums[j];</span><br><span class="line">    nums[j] = nums[i];</span><br><span class="line">    nums[i] = t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sortColors</span>(<span class="params">nums</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> ptr = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (nums[i] === <span class="number">0</span>) &#123;</span><br><span class="line">            swap(nums, i, ptr);</span><br><span class="line">            ptr++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (nums[i] === <span class="number">1</span>) &#123;</span><br><span class="line">            swap(nums, i, ptr);</span><br><span class="line">            ptr++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nums;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id=""><a href="#" class="headerlink" title=" "></a> </h4><h3 id="罗马数字转整数（来自：小米-2022-秋招-卷1）"><a href="#罗马数字转整数（来自：小米-2022-秋招-卷1）" class="headerlink" title="罗马数字转整数（来自：小米 2022 秋招 卷1）"></a>罗马数字转整数（来自：小米 2022 秋招 卷1）</h3><p><strong>问题描述</strong>: 罗马数字包含以下七种字符: I， V， X， L，C，D 和 M, 分别对应数字：1，5， 10， 50，100，500，1000。例如， 罗马数字 2 写做 II ，即 为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。 通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于 大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况： </p>
<p>I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 </p>
<p>X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 </p>
<p>C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 </p>
<p>给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。 </p>
<p><strong>输入描述:</strong> </p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">XXVII</span><br></pre></td></tr></table></figure>
<p><strong>输出描述:</strong> </p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="number">27</span></span><br></pre></td></tr></table></figure>
<p><strong>问题解决</strong></p>
<p>这道题看起来好像要判断子问题，其实对于整体结果而言就是，特殊情况剪掉，其他正常加就ok。</p>
<p>一次循环即可，不过要判断当前位 和 下一位的大小，如果是小的在左边，那说明是总数要减去当前值的，否则就是加上当前值。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> romanToInt = <span class="function"><span class="keyword">function</span>(<span class="params">str</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> symbolValues = <span class="keyword">new</span> <span class="built_in">Map</span>()</span><br><span class="line">    symbolValues.set(<span class="string">&#x27;I&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">    symbolValues.set(<span class="string">&#x27;V&#x27;</span>, <span class="number">5</span>)</span><br><span class="line">    symbolValues.set(<span class="string">&#x27;X&#x27;</span>, <span class="number">10</span>)</span><br><span class="line">    symbolValues.set(<span class="string">&#x27;L&#x27;</span>, <span class="number">50</span>)</span><br><span class="line">    symbolValues.set(<span class="string">&#x27;C&#x27;</span>, <span class="number">100</span>)</span><br><span class="line">    symbolValues.set(<span class="string">&#x27;D&#x27;</span>, <span class="number">500</span>)</span><br><span class="line">    symbolValues.set(<span class="string">&#x27;M&#x27;</span>, <span class="number">1000</span>)</span><br><span class="line">    <span class="keyword">let</span> result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">let</span> length = str.length</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">        <span class="keyword">const</span> value = symbolValues.get(str[i]);</span><br><span class="line">        <span class="keyword">if</span> (i &lt; length - <span class="number">1</span> &amp;&amp; value &lt; symbolValues.get(str[i + <span class="number">1</span>])) &#123;</span><br><span class="line">            result -= value</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result += value</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h2 id="网络安全篇章"><a href="#网络安全篇章" class="headerlink" title="网络安全篇章"></a>网络安全篇章</h2><h3 id="考点1：网络劫持"><a href="#考点1：网络劫持" class="headerlink" title="考点1：网络劫持"></a>考点1：网络劫持</h3><h4 id="面试题：网络劫持分为哪两种"><a href="#面试题：网络劫持分为哪两种" class="headerlink" title="面试题：网络劫持分为哪两种"></a>面试题：网络劫持分为哪两种</h4><p><strong>DNS劫持：</strong></p>
<p>例子：输入京东被强制跳转到淘宝，这就属于DNS劫持</p>
<p>方式有：</p>
<ul>
<li><p>DNS强制解析：</p>
<p>通过修改运营商的本地DNS记录，来引导用户流量到缓存服务器。</p>
</li>
<li><p>302跳转的方式：</p>
<p>通过监控网路出口的流量，分析判断哪些内容是可以进行劫持处理的，再对劫持的内存发起302跳转的回复，引导用户获取内容</p>
</li>
</ul>
<p><strong>HTTP劫持：</strong></p>
<p>例子：访问谷歌，但是一直有贪玩蓝月的广告</p>
<font color="red">**由于http明文传输，运营商会修改你的http响应内容（即加广告）**</font>





<p><strong>总结</strong></p>
<p>DNS劫持由于涉嫌违法，已经监管起来，现在很少有DNS劫持，</p>
<p><strong>而http劫持依旧非常盛行，最有效的办法就是全站https，将http加密，这使得运营商无法获得明文，就无法劫持你的响应内容。</strong></p>
<h3 id="考点2：前端安全的-引起与-防御"><a href="#考点2：前端安全的-引起与-防御" class="headerlink" title="考点2：前端安全的 引起与 防御"></a>考点2：前端安全的 引起与 防御</h3><h4 id="面试题：有哪些可能引起前端安全的问题？"><a href="#面试题：有哪些可能引起前端安全的问题？" class="headerlink" title="面试题：有哪些可能引起前端安全的问题？"></a>面试题：有哪些可能引起前端安全的问题？</h4><p><strong>1.跨站脚本(Cross-Site Scripting, XSS)：</strong></p>
<p>一种代码注入方式，为了与CSS区分，所以被称为 <code>XSS</code>。</p>
<p>早期常见于网络论坛，起因是网站没有对用户的输入进行严格的限制，使得攻击者可以将脚本上传到帖子，让其他人浏览到恶意脚本的页面，其注入方式很简单，包括但不限于<code>javascript/css/flash</code>等；</p>
<p><strong>2. iframe的滥用：</strong></p>
<p>iframe中的内容是由第三方来提供的，默认情况下，他们不受控制，他们可以在iframe中运行javascript脚本、Flash插件、弹出对话框等等，这可能会破坏前端用户体验。</p>
<p><strong>3.跨站点请求伪造（Cross-Site Request Forgeries，CSRF）:</strong></p>
<p>指攻击者通过设置好的陷阱，<strong>强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新，属于被动攻击。</strong></p>
<p><strong>4.恶意第三方库：</strong></p>
<p>无论是后端服务器应用还是前端应用开发，绝大多数时候，都是在借助开发框架和各种类库进行快速开发，一旦第三方库被植入恶意代码很容易引起安全问题。</p>
<h4 id="面试题：什么是-跨站脚本-XSS攻击？"><a href="#面试题：什么是-跨站脚本-XSS攻击？" class="headerlink" title="面试题：什么是 跨站脚本 XSS攻击？"></a>面试题：什么是 跨站脚本 XSS攻击？</h4><h5 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a><strong>基本概念</strong></h5><p>XSS 攻击指的是跨站脚本攻击，是一种代码注入攻击。攻击者通过在网站注入恶意脚本，使之在用户的浏览器上运行，从而盗取用户的信息如 cookie 等。</p>
<p>XSS 的本质是因为网站没有对恶意代码进行过滤，与正常的代码混合在一起了，浏览器没有办法分辨哪些脚本是可信的，从而导致了恶意代码的执行。 </p>
<p>攻击者可以通过这种攻击方式可以进行以下操作：</p>
<blockquote>
<p><strong>获取页面的数据，如 DOM、cookie、localStorage；</strong></p>
<p><strong>DOS 攻击，发送合理请求，占用服务器资源，从而使用户无法访问服务器； 破坏页面结构；流量劫持（将链接指向某网站）；</strong></p>
</blockquote>
<h5 id="攻击类型-XSS-可以分为存储型、反射型和-DOM-型"><a href="#攻击类型-XSS-可以分为存储型、反射型和-DOM-型" class="headerlink" title="攻击类型  XSS 可以分为存储型、反射型和 DOM 型"></a>攻击类型  XSS 可以分为存储型、反射型和 DOM 型</h5><ul>
<li>存储型指的是恶意脚本会存储在目标服务器上，当浏览器请求数据时，脚本从服务器传回并执行。</li>
<li>反射型指的是攻击者诱导用户访问一个带有恶意代码的 URL 后，服务器端接收数据后处理，然后把带有恶意代码的数据发送到浏览器端，浏览器端解析这段带有 XSS 代码的数据后当做脚本执行，最终完成XSS 攻击。</li>
<li>DOM 型指的通过修改页面的 DOM 节点形成的 XSS。</li>
</ul>
<p><strong>三者的区别在于：</strong></p>
<p>DOM 型 XSS 攻击中，<strong>取出和执⾏恶意代码由浏览器端完成</strong>，属于<strong>前端JavaScript 自身的安全漏洞</strong>，</p>
<p>而其他两种 XSS 都属于<strong>服务端的安全漏洞</strong>。</p>
<h3 id="面试题：如何防御-XSS-攻击？"><a href="#面试题：如何防御-XSS-攻击？" class="headerlink" title="面试题：如何防御 XSS 攻击？"></a>面试题：如何防御 XSS 攻击？</h3><p>三种方式都可以：</p>
<ul>
<li>在服务器端对用户输入的内容进行转义，例如使用HTML实体替换敏感字符，避免浏览器将其当作HTML代码解析执行。</li>
<li>在输出时对用户输入的内容进行过滤和转义，避免用户输入的恶意脚本被执行。</li>
</ul>
<p><strong>在网站中使用 HTTP头中的Content-Security-Policy（CSP）字段 CSP ，限制可以加载的资源，例如脚本、样式表、图片等。</strong></p>
<p>通常有两种方式来开启 CSP，</p>
<ul>
<li>一种是设置 HTTP 首部中的Content-Security-Policy，</li>
<li>一种是设置 meta 标签的方式 <code>&lt;metahttp-equiv=&quot;Content-Security-Policy&quot;&gt;</code>，对一些敏感信息进行保护，比如 cookie 使用 http-only，使得脚本无法获取。也可以使用验证码，避免脚本伪装成用户执行一些操作。</li>
</ul>
<ol>
<li><p>存储型XSS</p>
<p><strong>存储型XSS是攻击者将恶意代码存储到服务器上，当用户访问包含恶意代码的页面时，恶意代码会被执行。</strong>攻击者通常会在论坛、留言板、博客等需要存储用户输入的地方进行攻击。</p>
<ul>
<li></li>
</ul>
</li>
<li><p>反射型XSS</p>
<p><strong>反射型XSS是攻击者将恶意代码注入到URL中，当用户访问包含恶意代码的URL时，恶意代码会被执行。</strong>防御通常，攻击者会通过诱骗用户点击恶意链接、在搜索引擎中搜索恶意关键字等方式进行攻击。</p>
<ul>
<li>在服务器端对URL进行过滤和验证，例如限制输入长度、过滤特殊字符等。</li>
</ul>
</li>
<li><p>DOM型XSS</p>
</li>
</ol>
<p>​        <strong>DOM型XSS是攻击者将恶意代码注入到网页的DOM节点中，当用户浏览网页时，恶意代码会被执行</strong>。防御        DOM型XSS的方法有：</p>
<ul>
<li>避免使用<code>eval</code>()函数、<code>innerHTML</code>属性、<code>document.write()</code>等容易受到攻击的API。如果必须使用这些API，可以使用一些安全的编码方式来防止注入攻击，例如使用<code>JSON.stringify()</code>函数对变量进行编码，使用正则表达式进行过滤等。</li>
</ul>
<h3 id="面试题：什么是-CSRF-攻击？"><a href="#面试题：什么是-CSRF-攻击？" class="headerlink" title="面试题：什么是 CSRF 攻击？"></a>面试题：什么是 CSRF 攻击？</h3><p>CSRF 攻击指的是跨站请求伪造攻击，攻击者诱导用户进入一个第三方网站，然后该网站向被攻击网站发送跨站请求。如果用户在被攻击网站中保存了登录状态，那么攻击者就可以利用这个登录状态，绕过后台的用户验证，冒充用户向服务器执行一些操作。</p>
<p> <strong>CSRF 攻击的本质是利用 cookie 会在同源请求中携带发送给服务器的特点，以此来实现用户的冒充。</strong></p>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><p><strong>常见的 CSRF 攻击有三种：</strong></p>
<ul>
<li>GET 类型的 CSRF 攻击：比如在网站中的一个 <code>img</code> 标签里构建一个请求，当用户打开这个网站的时候就会自动发起提交。</li>
<li>POST 类型的 CSRF 攻击：比如构建一个表单，然后隐藏它，当用户进入页面时，自动提交这个表单。 </li>
<li>链接类型的 CSRF 攻击：比如在 a 标签的 href 属性里构建一个请求，然后诱导用户去点击。</li>
</ul>
<h4 id="面试题：怎么预防-CSRF-的三种攻击"><a href="#面试题：怎么预防-CSRF-的三种攻击" class="headerlink" title="面试题：怎么预防 CSRF 的三种攻击"></a>面试题：怎么预防 CSRF 的三种攻击</h4><h5 id="1-进行同源检测"><a href="#1-进行同源检测" class="headerlink" title="1.进行同源检测"></a>1.进行同源检测</h5><p>服务器根据 http 请求头中 <strong>origin 或者 referer 信息</strong> 来判断请求是否为允许访问的站点，从而对请求进行过滤。</p>
<p>当origin 或者 referer 信息都不存在的时候，直接阻止请求。</p>
<blockquote>
<p>这种方式的缺点是有些情况下 referer 可以被伪造，同时还会把搜索引擎的链接也给屏蔽了。</p>
<p>所以一般网站会允许搜索引擎的页面请求，但是相应的页面请求这种请求方式也可能被攻击者给利用。（Referer 字段会告诉服务器该网页是从哪个页面链接过来的）</p>
</blockquote>
<h5 id="2-使用-CSRF-Token-进行验证，"><a href="#2-使用-CSRF-Token-进行验证，" class="headerlink" title="2.使用 CSRF Token 进行验证，"></a>2.使用 CSRF Token 进行验证，</h5><p>服务器向用户返回一个随机数 Token ，</p>
<p>当网站再次发起请求时，在请求参数中加入服务器端返回的 token ，</p>
<p>然后服务器对这个 token 进行验证。</p>
<p>这种方法解决了使用 cookie单一验证方式时，可能会被冒用的问题。</p>
<blockquote>
<p>但是这种方法存在一个缺点就是，我们需要给网站中的所有请求都添加上这个 token，操作比较繁琐。</p>
<p>还有一个问题是一般不会只有一台网站服务器，如果请求经过负载平衡转移到了其他的服务器，但是这个服务器的 session 中没有保留这个 token 的话，就没有办法验证了。</p>
<p>这种情况可以通过改变 token 的构建方式来解决。</p>
</blockquote>
<h5 id="3-对-Cookie-进行双重验证"><a href="#3-对-Cookie-进行双重验证" class="headerlink" title="3. 对 Cookie 进行双重验证"></a>3. 对 Cookie 进行双重验证</h5><p>服务器在用户访问网站页面时，向请求域名注入一个 Cookie，内容为随机字符串，</p>
<p>然后当用户再次向服务器发送请求的时候，从 cookie 中取出这个字符串，添加到 URL 参数中，</p>
<p>然后服务器通过对 cookie 中的数据和参数中的数据进行比较，来进行验证。</p>
<p><strong>使用这种方式是利用了攻击者只能利用 cookie，但是不能访问获取 cookie 的特点。</strong></p>
<blockquote>
<p>并且这种方法比 CSRF Token 的方法更加方便，并且不涉及到分布式访问的问题。</p>
<p>这种方法的缺点是如果网站存在 XSS 漏洞的，那么这种方式会失效。同时这种方式不能做到子域名的隔离。</p>
</blockquote>
<h5 id="4-在设置-cookie-属性的时候设置-Samesite-，"><a href="#4-在设置-cookie-属性的时候设置-Samesite-，" class="headerlink" title="4.在设置 cookie 属性的时候设置 Samesite ，"></a>4.在设置 cookie 属性的时候设置 Samesite ，</h5><p><strong>限制 cookie 不能作为被第三方使用，从而可以避免被攻击者利用。</strong></p>
<blockquote>
<p>Samesite 一共有两种模式，</p>
<p>一种是严格模式，在严格模式下 cookie 在任何情况下都不可能作为第三方 Cookie 使用，</p>
<p>在宽松模式下，cookie 可以被请求是GET 请求，且会发生页面跳转的请求所使用。</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>分类问题 Classification 案例一：神奇宝贝是水系还是普通系？</title>
    <url>/2021/08/04/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%20Classification%20%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9A%E7%A5%9E%E5%A5%87%E5%AE%9D%E8%B4%9D%E6%98%AF%E6%B0%B4%E7%B3%BB%E8%BF%98%E6%98%AF%E6%99%AE%E9%80%9A%E7%B3%BB%EF%BC%9F/</url>
    <content><![CDATA[<p>@<a href="分类问题 Classification">TOC</a></p>
<blockquote>
<p>概念：（从概率生成模型到判别模型）<br>概率生成模型：由数据学习联合概率密度分布 <em>P(X,Y)</em> ，然后求出条件概率分布<em>P(Y|X)</em> 作为预测的模型。例如：朴素贝叶斯、隐马尔可夫（em算法）<br>判别模型：由数据直接学习决策函数 <em>Y=f(X)</em> 或者条件概率分布 <em>P(Y|X)</em>  作为预测的模型。例如：k近邻法、感知机、决策树、逻辑回归、线性回归、最大熵模型、支持向量机(SVM)、提升方法、条件随机场（CRF）</p>
</blockquote>
<p><strong>分类问题的思路</strong></p>
<ol>
<li>分类问题及其解决方法的讨论<pre><code> 1. 首先，什么是分类问题？
 2. 接着，分类问题该如何解决呢？
</code></pre></li>
<li>建立概率生成模型的步骤（以朴素贝叶斯分类器为例）<br>step1：求先验概率<br>step2：确定<strong>数据属于哪一个分布，用最大似然估计出分布函数的参数</strong><br>step3：求出后验概率</li>
<li>生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出</li>
</ol>
<h1 id="分类问题及其解决方法的讨论"><a href="#分类问题及其解决方法的讨论" class="headerlink" title="分类问题及其解决方法的讨论"></a>分类问题及其解决方法的讨论</h1><h2 id="什么是分类问题？"><a href="#什么是分类问题？" class="headerlink" title="什么是分类问题？"></a>什么是分类问题？</h2><p><img src="https://img-blog.csdnimg.cn/06b2e30dc04b4fa1a871ee3acee382c3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>说白了 就是输入一个事务的一些参数特征，通过数学模型，可以得到这个东西是什么。 这也包括二分问题（结果是由两面）与多分问题。</p>
<p>案例：<br>举个栗子，输入一个神奇宝贝，输出：他是属于什么属性的？ <strong>这是一个典型的多分问题，因为属性有好几种啊。</strong><br><img src="https://img-blog.csdnimg.cn/d6dd520c2c1b4c8d9e6396369b5b1f56.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>举个栗子，输入一个神奇宝贝图片，输出：他是可达鸭么？ <strong>这是一个典型的二分问题，因为结果只有两种 是还是不是。</strong><br>举个栗子，假设有两个类别（水系和普通系），每个类别有不同的精灵，现在我抓到一个精灵，那么它是属于水系和普通系的概率分别是多少。这也是个<strong>典型的二分问题</strong>。</p>
<h2 id="如何解决分类问题？"><a href="#如何解决分类问题？" class="headerlink" title="如何解决分类问题？"></a>如何解决分类问题？</h2><h3 id="如何解决二分问题？"><a href="#如何解决二分问题？" class="headerlink" title="如何解决二分问题？"></a>如何解决二分问题？</h3><h4 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h4><p>对于二分类问题，定义一个function也就是数学model，<strong>当输出函数值大于0就划分为<em>类别1</em>，否则就为<em>类别2</em>.</strong> <strong>而损失函数定义为在测试数据上误分类的次数</strong>。<img src="https://img-blog.csdnimg.cn/3ee112c779004e5da28ca9878930b369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h4 id="那这个function我到底怎么定义呢？"><a href="#那这个function我到底怎么定义呢？" class="headerlink" title="那这个function我到底怎么定义呢？"></a>那这个function我到底怎么定义呢？</h4><p>实际上，可以将其定义为一个<strong>概率模型</strong>。<br>它可以是一个<strong>条件概率模型 <em>P(C1 | X)</em></strong>,当  <strong><em>P(C1 | X) &gt; 0.5</em></strong> ,比如在神奇宝贝二分问题中，我们定义X是这张图片的参数，而C1表示是可达鸭，整个的意思就变为了在这些图片参数的条件下这张图片是可达鸭的概率是多少，概率大于一半，说明确实很有可能就是可达鸭。或者对于第二个栗子，同样的可以规定<strong>条件概率模型 <em>P(C2 | X)</em></strong>，表示在捕捉了一个精灵后，他的参数条件下，是水系的概率是多少？（这边C2表示，捕捉的是水系）</p>
<p>这边我们以栗子2为例，假如我们捕捉了一只神奇宝贝(其实他就是可达鸭)，问他是水系的概率是多少？（理论上其实，他就是水系的，但机器需要通过概率论去推，需要包括以下的概率推导）<br><img src="https://img-blog.csdnimg.cn/dfa3d538674d4dcd8cb32ccbd52ea7f2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>如上图所示： 　 x就表示是可达鸭<br>先验概率：这里是P(C1)——训练样本中的精灵是水系的概率;同理P(C2)——训练样本中的精灵是普通系的概率<br>——————————————————————————————————————————————————————————————————<br><em>P(x | C1)</em>：这里是指在水系中是可达鸭的概率<br><em>P(x | C2)</em>：这里是指在普通系中是可达鸭的概率<br>两者可以用<strong>最大似然估计法</strong>求出——————————————————————————————————————————————————————————————————<br>后验概率：这里指抓到的神奇宝贝可达鸭是水系的概率。其用贝叶斯公式算出，公式如上图所示</p>
</blockquote>
<h5 id="求先验概率-P-C1-：训练样本中的精灵是水系的概率"><a href="#求先验概率-P-C1-：训练样本中的精灵是水系的概率" class="headerlink" title="求先验概率 P(C1)：训练样本中的精灵是水系的概率"></a>求先验概率 P(C1)：训练样本中的精灵是水系的概率</h5><p>根据训练样本，分别算出水系和普通系的概率<br><img src="https://img-blog.csdnimg.cn/67108f6b24044efbb896cb62ac2bd2c0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h5 id="选择概率分布函数，用最大似然估计出分布函数的参数（就是调参）"><a href="#选择概率分布函数，用最大似然估计出分布函数的参数（就是调参）" class="headerlink" title="选择概率分布函数，用最大似然估计出分布函数的参数（就是调参）"></a>选择概率分布函数，用最大似然估计出分布函数的参数（就是调参）</h5><blockquote>
<p>注：</p>
<ul>
<li>当样本数据x取实数值时，采用正太分布(高斯分布)</li>
<li>当每种特征的数值都在0-1内时，采用伯努利分布</li>
<li>当每种特征取值在{1, 2 , 3 , …，K}，采用多项式分布（Multinomial Distribution）</li>
</ul>
</blockquote>
<ol>
<li>　首先，我们目标是求水系样本中的79个精灵中，抓到其中一种神奇宝贝的概率 <strong>P(x | C1)</strong> ，那么这个概率应该是跟精灵的属性有关的。<br>这里我们选择<strong>两种属性（物防和法防）讨论</strong>，此时数据中（x,水系）中的x应该是一个神奇宝贝<strong>向量（[x1物防，x2法防] , 水系）。</strong><br><img src="https://img-blog.csdnimg.cn/4eaa50360e3e4c8492b900326980f697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li>2、然后，这里选择正太分布（二维）：也就是说在水系样本中的79个精灵中，抓到其中一种精灵的概率 <em>P( x | C1)</em> 呈正太分布。<br><img src="https://img-blog.csdnimg.cn/86f5ab53fd124a47918b1da54cef4c3a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li>接着，用最大似然估计法算出分布函数的参数<br>似然函数<em>L</em>：x1,x2…x79同时出现的概率函数。<br>最大似然估计：使似然函数最大时的参数估计。<img src="https://img-blog.csdnimg.cn/8ea6f6da88ba4657999c75674b70170b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>调整的参数<br><img src="https://img-blog.csdnimg.cn/528ff3d528f04fcb8a799f08f3712f4a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><h5 id="最后求出后验概率-即P-C1-x-抓到的可达鸭是水系的概率"><a href="#最后求出后验概率-即P-C1-x-抓到的可达鸭是水系的概率" class="headerlink" title="最后求出后验概率 即P(C1 | x): 抓到的可达鸭是水系的概率"></a>最后求出后验概率 即P(C1 | x): 抓到的可达鸭是水系的概率</h5>利用的就是贝叶斯公式。<br>整体每个部分的逻辑可以看下图所示：<img src="https://img-blog.csdnimg.cn/e1d5794c439749dc8e2286bfe3af4ea3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><h4 id="效果不好的解决方法"><a href="#效果不好的解决方法" class="headerlink" title="效果不好的解决方法"></a>效果不好的解决方法</h4><strong>实验结果</strong><br><img src="https://img-blog.csdnimg.cn/67640ca1732f41189f0bc43688a71a0e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>分类后，准确率并不高。理论上考虑其他因素，即增加维度可以增大准确率。但效果还是不佳，这该怎么办。<br><img src="https://img-blog.csdnimg.cn/841b72c2ccb243df9a91141dc200370f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>实验结果<br><img src="https://img-blog.csdnimg.cn/0b0ee16c14424df59cf27c80a49a0e1b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><h2 id="生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出"><a href="#生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出" class="headerlink" title="生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出"></a>生成模型解决分类问题的总结以及逻辑回归方法（判别模型）的引出</h2><h3 id="回到如何用机器学习的三大步骤解决分类问题："><a href="#回到如何用机器学习的三大步骤解决分类问题：" class="headerlink" title="回到如何用机器学习的三大步骤解决分类问题："></a>回到如何用机器学习的三大步骤解决分类问题：</h3><img src="https://img-blog.csdnimg.cn/b62ddf0753f84cce856bf1991f2d1f81.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ol>
<h3 id="逻辑回归方法（判别模型）的引出"><a href="#逻辑回归方法（判别模型）的引出" class="headerlink" title="逻辑回归方法（判别模型）的引出　"></a>逻辑回归方法（判别模型）的引出　</h3><p><img src="https://img-blog.csdnimg.cn/5b57d3ebf742485eb514f106dba3de5a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="化简推到一下（纯数学）"><a href="#化简推到一下（纯数学）" class="headerlink" title="化简推到一下（纯数学）"></a>化简推到一下（纯数学）</h3><p><img src="https://img-blog.csdnimg.cn/f2323d6bd8474f5891cf63af3f18c47e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/e8faa78abb0641adae81388745601c13.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>所以其实不用考虑，N1，N2，μ1，μ2，∑的值。 直接就是w和b两个参数，这也是为什么之前，我们将∑按权值分配后，图像由线性分类的原因。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>李宏毅</tag>
        <tag>机器学习</tag>
        <tag>分类问题</tag>
      </tags>
  </entry>
  <entry>
    <title>事件脉络第一次2.25</title>
    <url>/2022/02/25/%E4%BA%8B%E4%BB%B6%E8%84%89%E7%BB%9C%E7%AC%AC%E4%B8%80%E6%AC%A12.25/</url>
    <content><![CDATA[<h2 id="事件脉络介绍"><a href="#事件脉络介绍" class="headerlink" title="事件脉络介绍"></a>事件脉络介绍</h2><p>来源：</p>
<p>当今时代可以说是信息爆炸的时代，大大小小的事情都会引发人们的关注，而百度是我们获取新闻的第一途径，但各个事件往往展现出的信息都非常杂乱，因此就衍生出了百度事件脉络这一板块</p>
<p>实际：</p>
<p>通过对特定事件名称的检索，得到该事件的脉络，自动追溯事件的发展过程，根据时间线对热点事件的来龙去脉进行全面了解。</p>
<p>输入：</p>
<p>关于某一事件的相关新闻集合，应该是利用文本聚类(搜索等)得到的新闻簇。</p>
<p>输出：</p>
<p>事件的脉络信息，换句话说就是：给出一个重要新闻的列表，这些重要的新闻涵盖了该事件的各个重要阶段的重要信息。</p>
<p>如右边的图 就可以清晰的看到俄乌局势昨天的发展阶段，也就是这个方向应该做到的基本效果。</p>
<p>如果用于开发的话，真实的接口应该返回如图类似的json数据，包括新闻的时间、标题和链接。</p>
<h2 id="时间片聚类算法"><a href="#时间片聚类算法" class="headerlink" title="时间片聚类算法"></a>时间片聚类算法</h2><p>其主要的办法是 从<font color="red">新闻的外部属性（主要是分布事件和转载情况）</font>进行分析。</p>
<p>其前提<font color="blue">假设</font>为：在事件有重要进展的时候，一定会有一些高质量新闻的跟进报道，而且越是重要的进展情况，其报道也会越多越集中。</p>
<h6 id="如何寻找事件发展的主要阶段？"><a href="#如何寻找事件发展的主要阶段？" class="headerlink" title="如何寻找事件发展的主要阶段？"></a>如何寻找事件发展的主要阶段？</h6><font color="red">使用时间片聚类的方法</font> ，来发现事件发展的主要阶段

+ 对每一篇新闻，抽取新闻的发布时间，按照新闻的发布时间将一个新闻事件集合内的新闻进行排列并投影到时间轴上。（根据之前的<font color="blue">假设</font>，时间轴上一定会有一段新闻密集的地方）

+ 利用凝聚层次聚类方法，将时间轴分成若干个片段。将新闻聚类而分，这样我们才能明确时间的发展过程。提取每个过程的 确切新闻内容。

  + 凝聚层次聚类的基本做法：其不需要指定划分的个数（因为我也不知道到底有几次发展阶段），把每篇新闻看成一个时间片段（其实是一个点），然后**每次合并距离最近的两个片段**，直到任意两个片段之间的距离都大于一个预先设定的阈值。  
  + 获取到时间发展过程后，则要在每个进展的新闻集合中，抽取一篇代表新闻

  + 其具体的策略，可以根据具体的产品需求来定。<font color="blue">一般考虑例如：新闻来源站点是否权威，新闻的发布时间（在同一个聚类内），该新闻是否有更多的转载等等。</font>
  + 如果要求更多媒体化，还可以从新闻集合中，抽取出相应的图片，视频等相关资源。

#### 存在的问题一：自然时间距离问题？

对于新闻来说，由于新闻发布并不是在24小时内均匀分布的，所以我们认为：在新闻发布高峰期间隔1个小时，要比在新闻发布的低谷期间隔一个小时，造成的时间跨度更长。

**改进为：按照每半小时为一个小时间片，统计每个时间段内的新闻发布数，求出各个时间段新闻数占所有时间片新闻总数的比值，这个比值可以用来重新分配24小时的时间长度，计算“新闻时间距离”。**

这样的效果得到了：在0点至6点之间的1个小时，在“新闻时间距离”中只有半个小时，甚至更少，而在9：00~11：00期间的一个小时，相当于2~3个小时。

#### 存在的问题二：新闻集合的去噪

各媒体对事件跟进报道的时效性不一，比如同样的新闻内容，新华网的报道更具时效性，在当前20:00就发布了，而一些小的新闻站点，则可能要等到第二天的9:00才发布，这样就导致描述同一阶段的新闻，往往会被分到不同的阶段中去，这样就影响了时间片聚类的效果。

<font color="red">所以我们在进行时间片聚类之前，还进行了相似新闻的去重。</font>

<h6 id="去噪的方法"><a href="#去噪的方法" class="headerlink" title="去噪的方法"></a>去噪的方法</h6><p>对新闻集合内的新闻，进行一次相似度，如果碰到文本相似度很高的新闻，则归档在一起，以最早的那篇新闻为代表新闻，参加时间片聚类。具体的做法是：按照新闻的发布时间由远及近的顺序，计算每篇新闻与之前的新闻的文本相似度，如果相似度太高，则认为可能是重复的内容，则把这篇新闻标记为更早的新闻的转载或者相近报道。</p>
<h4 id="该方法总结"><a href="#该方法总结" class="headerlink" title="该方法总结"></a>该方法总结</h4><p>本方法利用了新闻媒体对新闻事件的报道行为，来挖掘出新闻事件的发展阶段以及代表新闻，从而给用户提供简单明了的新闻事件脉络。主要利用了时间片聚类算法来自动将事件划分成若干个进展阶段，然后从各个进展阶段中，抽取出代表新闻。为了改善算法，还提出了一种“新闻时间距离”的度量方法；同时，还结合了文本内容分析的手段，来对新闻集合进行精简，去噪，改善脉络抽取的效果。</p>
<h2 id="基于图结构方法"><a href="#基于图结构方法" class="headerlink" title="基于图结构方法"></a>基于图结构方法</h2><p>通过构建图的方法，将子事件之间的关系转换为图中结点的关系，寻找关键结点，连接关键结点得到最终的事件脉络。</p>
<h3 id="事件感知"><a href="#事件感知" class="headerlink" title="事件感知"></a>事件感知</h3><p>对微博数据过滤分析后，根据热点事件的关键字搜索数据库，筛选包含该关键字的微博。</p>
<p>首先对其进行文本预处理，根据中英文使用不同的工具或方法。预处理过程大致可包括，分词，去除停用词。</p>
<p>而后计算每条微博的 中每个关键词 的 TF-IDF 得分，将所有关键词的 TF-IDF 得分之和作为这条微博的 TF-IDF 得分。 然后进行排序，得分越高的与事件的相关度也就越高，从得到最后处理的库。</p>
<h3 id="事件脉络呈现"><a href="#事件脉络呈现" class="headerlink" title="事件脉络呈现"></a>事件脉络呈现</h3><p>分为3个子模块，构建图，寻找关键微博，连接关键微博。</p>
<p>整体思路是，在无向图中寻找关键结点，即关键微博。再在有向图中连接关键结点，最终得到事件脉络。</p>
<h4 id="如何构建图结构"><a href="#如何构建图结构" class="headerlink" title="如何构建图结构"></a>如何构建图结构</h4><p>需要构建两个图，一个有向图和一个无向图。每个结点的权值，为该结点微博与事件关键字集合Q的余弦相似度。无向图用来表示微博之间文本内容的关系，计算边时，2条微博文本之间的余弦相似度大于 一个阈值时。就用一条无向边将对应的2个结点连接起来。</p>
<p>有向图用来表示微博之间的时间关系，按时间顺序连接微博结点。</p>
<h4 id="如何选择关键结点"><a href="#如何选择关键结点" class="headerlink" title="如何选择关键结点"></a>如何选择关键结点</h4><p>如何选择关键结点 就是 如何寻找关键微博</p>
<p>其采用 加权相似度的方法来寻找 无向图中的关键结点。当 加权相似度越大时，表明这个结点对应的微博更具代表性，能够表示其领接结点对应微博的内容，即这个结点就是 图中的一个关键结点。</p>
<p>计算无向图中所有结点的加权相似度，选取其中加权相似度最大的结点作为一个关键结点。</p>
<p>之后采用迭代的过程，找到关键结点集合。</p>
<h4 id="如何链接关键结点"><a href="#如何链接关键结点" class="headerlink" title="如何链接关键结点"></a>如何链接关键结点</h4><p>在有向图中，对于任意2个关键结点，如果本来就是邻接结点，则直接连接。</p>
<p>如果不是的话，就需要添加过渡结点。其应该满足添加的过渡结点的加权相似度之和达到最小，</p>
<p>如右边的公式，</p>
<p>最后得到连接关键结点的边集合，即关键结点的连接结果。</p>
<p>给定一个过渡结点，可以体现事件一定程度的多样化，使得内容看起来更加的连贯。</p>
<h3 id="实验数据结果"><a href="#实验数据结果" class="headerlink" title="实验数据结果"></a>实验数据结果</h3><p>该论文爬取的数据集是 2014年 巴西世界杯的 推特数据，事件为7月14日 阿根廷与德国的实时球赛事件推特记录。大致能说清楚事件发展情况，并且存在一定的趣味事件。</p>
<p>但这里的趣味事件和整个事件发展，关系不大。  </p>
<p>并且这个数据由于本身太过于口语化，所以用户情感比较明显，对整体的事件脉络是有干扰的。</p>
<h3 id="方法总结"><a href="#方法总结" class="headerlink" title="方法总结"></a>方法总结</h3><p>这个方法在事件感知，对微博的处理方法过于单一，仅仅依靠微博中是否出现关键字来判断，过于片面。可能会漏掉一些有潜在关系的数据。</p>
<p>另外图求解关键结点和连接结点的复杂度理论上非常的高，实时性应该是比较差的。</p>
<p>另外这里只考虑到了文本属性，其他一些值的参考的评论、微博博主的权威值等其实都可以引入。</p>
<p>甚至是多模态的多媒体也值的参考。</p>
<h3 id="后续的一些问题"><a href="#后续的一些问题" class="headerlink" title="后续的一些问题"></a>后续的一些问题</h3><p>第一 如何评价事件脉络实验结果好坏？</p>
<p>之前看的有一篇中文文档，他是采用召回率和准确率来定量的描述。 他根据正确人工拟定的事件脉络，统计他的时间日期个数和 算法命中的日期个数 比值为召回率；同理也可以计算出准确率。</p>
<p>另外也有采用人调查评价是否能明白事件经过的打分情况，主观成分较大。</p>
<p>第二 就是这个方向的整体思路不够清晰</p>
<p>有之前提到的 时间片聚类的算法，构造图算法</p>
<p>也有后续的多模考虑的 基于关键字，基于概率，基于主题的方法。</p>
<p>主体上是偏向于机器学习，图论，数据挖掘。</p>
<p>第三就是 新闻数据集的获取问题。</p>
<p>做新闻类的话，可能需要爬取一些权威性较高的平台。</p>
<p>另外 存在多媒体，新浪微博、百度新闻等 的所谓的数据流特征不太类似，不确定使用同种方法是不是都试用。</p>
]]></content>
      <categories>
        <category>研究课题-事件脉络</category>
      </categories>
      <tags>
        <tag>事件脉络</tag>
      </tags>
  </entry>
  <entry>
    <title>各类 优化器(调参工具) 详解与选择</title>
    <url>/2021/08/28/%E5%90%84%E7%B1%BB%20%E4%BC%98%E5%8C%96%E5%99%A8(%E8%B0%83%E5%8F%82%E5%B7%A5%E5%85%B7)%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<p>@<a href="各类 优化器 详解与选择">TOC</a></p>
<h1 id="sgd"><a href="#sgd" class="headerlink" title="sgd"></a>sgd</h1><h1 id="adam"><a href="#adam" class="headerlink" title="adam"></a>adam</h1>]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>优化器</tag>
      </tags>
  </entry>
  <entry>
    <title>各类 损失函数 详解与选择</title>
    <url>/2021/08/23/%E5%90%84%E7%B1%BB%20%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<p>@<a href="各类 损失函数 详解与选择">TOC</a></p>
<h1 id="mean-squared-error-均方误差"><a href="#mean-squared-error-均方误差" class="headerlink" title="mean_squared_error 均方误差"></a>mean_squared_error 均方误差</h1><p><img src="https://img-blog.csdnimg.cn/a55e390e62dd4e0b8bd1c9ff5cfb7826.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title>各类 激活函数 详解与选择</title>
    <url>/2021/08/24/%E5%90%84%E7%B1%BB%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%20%E8%AF%A6%E8%A7%A3%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<p>@<a href="各类 激活函数 详解与选择">TOC</a></p>
<h1 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h1><h1 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h1><h1 id="sigmiod"><a href="#sigmiod" class="headerlink" title="sigmiod"></a>sigmiod</h1><h1 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h1>]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title>同济子豪兄 之 yolov1 详解</title>
    <url>/2021/09/26/%E5%90%8C%E6%B5%8E%E5%AD%90%E8%B1%AA%E5%85%84%20%E4%B9%8B%20yolov1%20%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>@<a href="同济子豪兄 之 yolov1 详解">TOC</a><br>yolov1 的主旨是 You Only Look Once：Unified，Real-Time Object Detection。<br>yolo 是一个典型的 将 目标检测 转化为  回归问题的方法。yolo与其他网络不同在，他的测试与训练方法不同，所以接下来我们主要 分预测以及训练两个阶段去介绍yolov1。 包括 预测阶段（以及后处理），训练阶段来讲。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6d831d5df7aff4ccf3dd13027b9fdbbb.png#pic_center" alt="训练阶段以及测试阶段"><br>将输入的图片 划分为 S×S个 grid cell<br><strong>训练阶段：</strong></p>
<ul>
<li>将标签 Ground truth 的 框 中心点落在哪个grid cell 中 就由 哪个 grid cell 来预测这个物体对象</li>
<li>每个 grid cell 可以 预测 B 个 bounding box， 与 Ground truth 的 框 IoU 最大的<br>bounding box 负责预测 这个物体对象。</li>
<li>每个 grid cell 只能 检测一个物体</li>
<li>包含和不包含 ground truth 标签的 grid cell 和 bounding box 都要依照损失函数 分别处理</li>
</ul>
<p><strong>测试阶段：</strong></p>
<ul>
<li>直接获得 S × S ×（S×B+C）向量 进行 NMS 后处理 得到目标检测结果。</li>
</ul>
<h1 id="目标检测的基础知识"><a href="#目标检测的基础知识" class="headerlink" title="目标检测的基础知识"></a>目标检测的基础知识</h1><h2 id="目标检测是什么？"><a href="#目标检测是什么？" class="headerlink" title="目标检测是什么？"></a>目标检测是什么？</h2><p>在计算机视觉领域，图像任务主要分为：图像分类，图像检测 和 图像分割（语义分割和实例分割）等<br>语义分割和实例分割的区别在于：语义分割是我对每个像素分类，我不管这个像素是属于哪几个物体的，只管他是属于什么类别的（也就是我只分类，同一个类别的不同实例不区分）；而实例分割是要把同一个类别的不同实例给区分开来</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/35b53c4cd1da18a70dca91d65e748d1b.png#pic_center" alt="任务区别图1"><br><img src="https://img-blog.csdnimg.cn/img_convert/636fe4401f3cfa7a5b8fdb3909646d63.png#pic_center" alt="任务区别图2"><br><img src="https://img-blog.csdnimg.cn/img_convert/56310ef740a07f9b2cf502c8a41f28eb.png#pic_center" alt="任务区别图3"></p>
<h2 id="目标检测主流的数据集来源"><a href="#目标检测主流的数据集来源" class="headerlink" title="目标检测主流的数据集来源"></a>目标检测主流的数据集来源</h2><p>yolo 是在  PASCAL-2007 和 MS-COCO上做的评测<br><img src="https://img-blog.csdnimg.cn/img_convert/0a3e3c44de4fb73523bc7d2026481089.png#pic_center" alt="主流目标检测数据集来源"></p>
<h2 id="目标检测的发展"><a href="#目标检测的发展" class="headerlink" title="目标检测的发展"></a>目标检测的发展</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/8199110e14455de8cd7de50658a142f6.png#pic_center" alt="目标检测的发展"><br>目前这个主要的流派由两种，上面是单阶段模型 yolo 系列  下面是两阶段模型 RCNN系列。</p>
<ul>
<li>两阶段就是先从图像中提取若干候选框，再逐一的对这些候选框进行分类、甄别以及调整它们的坐标最后得出结果。</li>
<li>单阶段就是 我不提取候选框，我直接把全图喂到算法里面，能直接输出出来目标检测的结果。是一个统一的端到端的系统</li>
</ul>
<p>对于 RCNN系列的话，他比较慢但是 正确率比较高</p>
<ul>
<li>R-CNN 使用region proposal先提取候选框，再使用卷积神经网络逐一的对每个候选款进行甄别，对 bouning box 位置调整和回归和分类</li>
<li>Fast R -CNN 是把所有的图片用卷积神经网络过一遍，在生成的feature map上找候选框 投影到 feature map 上面，再进行甄别</li>
<li>Faster R-CNN 使用了 RPN 网络，也就是找候选框这个事情由 RPN 这个专业户干了</li>
</ul>
<p>对于 yolo系列的话，他的优势在于速度，正确率相比没有那么高<font color="blue">（待补充）</font></p>
<ul>
<li>yolov1 的缺点在于，单个grid cell 只能识别一种类别。识别小目标或者密集目标 能力不足，例如羊群、人群这种。</li>
<li>yolov2 是在 yolov1 的基础上 加了<strong>Batch Normalization</strong>、High Resolution Classifer、<strong>Anchor</strong>、Dimension Cluster、Direct location prediction、Fine-Graind Features、Muti-Scale Training</li>
<li>yolov3</li>
<li>yolov4 从v4开始 作者变了，前面的大作因为感慨yolo技术被用来干坏事而退出了计算机视觉领域。</li>
<li>yolov5</li>
</ul>
<h1 id="yolo-v1-的-预测阶段"><a href="#yolo-v1-的-预测阶段" class="headerlink" title="yolo v1 的 预测阶段"></a>yolo v1 的 预测阶段</h1><h2 id="yolo-v1-网络架构"><a href="#yolo-v1-网络架构" class="headerlink" title="yolo v1 网络架构"></a>yolo v1 网络架构</h2><p>输出的 7×7×30 这个tensor 就是我们预测阶段所需要的<br><img src="https://img-blog.csdnimg.cn/img_convert/38e7f43fea47802cb9d2b7564377db4b.png#pic_center" alt="yolov1 图像处理的网络架构"><br>我们来分析一下网络结构并写出各层次的padding。<br>计算公式为</p>
<script type="math/tex; mode=display">outputsize =\lfloor {\frac{inputsize + 2padding -filtersize}{步长}}\rfloor +1</script><p><img src="https://img-blog.csdnimg.cn/img_convert/28059cdcee997d3230d56657217dce43.png#pic_center" alt="算出padding"><br>之后最后两个全连接层。<br>他是怎么转为 4096个输入的呢。也就是输入的为7×7×1024 我们全连接层输出的 是 4096 的一维向量。我们采用 4096个 7×7×1024 的卷积核，然后 变成 1×1×4096  再使用降维 变为 一维的4096。<br>然后我们再将这个 reshap 成 4096×1的列向量 中间的 参数矩阵为 4096×1470  根据 线性回归的公式：</p>
<script type="math/tex; mode=display">y=w^{T}x</script><p>可以计算得到 1470×4096×4096×1 = 1470×1  然后我们在 reshape 一下变成三维 （7,7,30）</p>
<h2 id="yolo-v1-预测阶段-内容详解"><a href="#yolo-v1-预测阶段-内容详解" class="headerlink" title="yolo v1 预测阶段 内容详解"></a>yolo v1 预测阶段 内容详解</h2><blockquote>
<p>Q：为什么 输出的是 7×7×30 呢？<br><img src="https://img-blog.csdnimg.cn/img_convert/c466565d19154b1bc714cafe0d4614c6.png#pic_center" alt="yolo v1核心内容"><br>因为在 yolo v1 中图像被划分成了<strong>7×7的网格</strong>。每个格子叫做 grid cell ，也就是由49个grid cell。</p>
</blockquote>
<p>这里的 每个 grid cell 又能预测 B个 bounding box （也就是预测框） yolo v1中 B=2 也就是每个 grid cell 可以预测 2个 bounding box。这两个预测框可能很大也可能很小 也就是这个框是啥样的不一定。（<strong>注意这个框是由前面的网络结构得到的 就是这么神奇</strong>）。这个框覆盖其他的grid cell 是很正常的，只要这个 bounding box 的中心点 是落在这个 grid cell 里就ok。</p>
<p>每个grid cell 预测 B 个 bounding box。 在yolo v1 的实验中 B=2，也就是 每个 grid cell 由 2 个 bounding box。<br>bounding box 的由 5个 数值来表示 （x,y,h,w,c）</p>
<ul>
<li>x，y 表示中心点的位置</li>
<li>h，w表示这个 bounding box 的 高 和 宽</li>
<li>c 表示这个 bounding box 框的置信度。在图像中 一般用 框线的粗细来表示置信度的大小。<strong>置信度的意思是，这个bounding box 对自己含有物体对象的自信程度。（注意是识别的对象，而不是具体的类别）</strong></li>
</ul>
<p>在yolo v1的实验中，因为由 49 个 grid cell，所以 有 98 个 bounding box 如下图所示（粗细表示置信度高低）<br><img src="https://img-blog.csdnimg.cn/img_convert/049d6ea03b1129753555d38bdb1ed2e4.png#pic_center" alt="98个bounding box"></p>
<h2 id="grid-cell-输出所有类别的条件概率"><a href="#grid-cell-输出所有类别的条件概率" class="headerlink" title="grid cell 输出所有类别的条件概率"></a>grid cell 输出所有类别的条件概率</h2><p>每个 grid cell 还能生成所有类别的 <strong>条件概率</strong>，并且选择最高的一个概率表明，预测的是这个类别。这也就是 yolo v1 最大的弊端，每个 grid cell 只能预测一个类别，那一个 49个cell 最大只能预测 49个类别；并且如果类别对象很密集，一个 grid cell 中有多个不同的小对象的话，识别效果会很差。</p>
<p><font color="red">注意这里的概率是 条件概率 比如 p(cat|object) 是在有<strong>存在类别对象的情况下 是 猫的概率</strong>。</font><br>下图可以表示 49个cell 预测的类别情况（也就是各cell 选择的最高类别的 条件概率）</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/3dd9cb0d2cf0e1391ba7688e445d4886.png#pic_center" alt="每个grid cell 选择的最高类别的 条件概率"></p>
<h2 id="7×7×30-这个30是怎么来的呢"><a href="#7×7×30-这个30是怎么来的呢" class="headerlink" title="7×7×30 这个30是怎么来的呢"></a>7×7×30 这个30是怎么来的呢</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/c8cab634a723eaab685cf39f70e88511.png#pic_center" alt="7×7×30 这个30是怎么来的呢"><br>每个grid cell 有 2个bounding box。1个bounding box 中有5个数值 那就是10个数值，然后 yolo v1 预测了20个类别的物体，所以有20个类别的概率 所以是 30个输出。然后有 7×7个 grid cell 所以 输出的 是 7×7×30 的 tensor。</p>
<blockquote>
<p>Q：<strong>那 类别真正的概率怎么算出来呢？</strong><br>只有将 对应的 bounding box 置信度 × 这个grid cell 的类别条件概率才是 这个类别真正的概率值</p>
</blockquote>
<p> $全概率 = bounding box 置信度 × $</p>
<p>将这个grid cell 的两个 bouding box 都赋予 这个grid cell 选择的最高类别。再进行一系列的后处理（指的是 置信度很低的先给过滤掉，非极大值抑制（NMS））选择最佳 bounding box</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/c928f7b0c5670984b7b21aaeabd0bd5c.png#pic_center" alt=""><br>7×7×30这个tensor中包含了 98个bounding box 49个grid cell 每个grid cell 的类别 bounding box的 5个数值   进行解析和后处理 最后得到了结果<br>以上我们说的都是 预测阶段 也就是 参数啥的已经调好了 我只要跑一跑 拿到个结果。</p>
<h1 id="预测阶段-的后处理部分"><a href="#预测阶段-的后处理部分" class="headerlink" title="预测阶段 的后处理部分"></a>预测阶段 的后处理部分</h1><p>一个 grid cell 可以得到 下图右侧中两列向量。每个向量 都表示 这个 grid cell 在其一个 bounding box 中 20个类别的全概率。<br>一个98个bounding box。 <strong>这个是由 每个bounding box 的置信度 乘以 tensor 中 输出的 该 grid cell 对20个类别的条件概率得到的。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/89ba9c3732e7722b15c9eebf175f7634.png#pic_center" alt="grid cell 输出其两个预测框的 20个类别的全概率"><br>现在我们得到如下的框框图像，一共有 98个 bounding box。不同颜色表示不同类别。（因为每个 grid cell 只会预测概率最高的那个类别 比如狗是黄色的 那他的两个bounding box 都是黄色的）</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/0b04396864fbcb9abb88839b0ca4cfce.png#pic_center" alt="需要后处理的 98个 预测框"><br>每个 bounding box  把他对20个分类的条件概率拿出来，乘以对应的置信度。得到20个分类的全概率向量。<br><img src="https://img-blog.csdnimg.cn/img_convert/62f2eb8e8436081525012232736fc888.png#pic_center" alt="拿到20个分类的条件概率"><br>我们把刚才 每个bounding box 输出的 20个分类的全概率向量拿出来。 假如第一行的是对狗的预测。我们要把98个列向量按狗的概率，从大到小排列。<font color="red"><strong>（他的意思就是 我按排列之后 每一个类别都按 NMS一遍  ）</strong> </font>整个的过程如下图所示。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2afbebe5fbb7b772cf1f63a7f2e25127.png#pic_center" alt="如何使用NMS方法"></p>
<h2 id="NMS方法详解"><a href="#NMS方法详解" class="headerlink" title="NMS方法详解"></a>NMS方法详解</h2><p>假如 我们比较下图中 98个bounding box 狗这一行 的 前两个值， 也就是左边橙色和绿色连的bounding box ，我们计算一下 IoU  这边要预先设定一个门槛值（他这里是0.5，越小排异性越高），如果IoU超过0.5的话，表明这两个框预测的都是同一类别（这里也就是狗）。这样的话，保留值高的那个，低的那个全概率改为0，把这个bounding box 干掉。<br><img src="https://img-blog.csdnimg.cn/img_convert/9b4e674106e87245c29a5712b5c82de8.png#pic_center" alt="NMS 图1"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9cc8d08e234cc4c22826f68150b8ea98.png#pic_center" alt="结果把这个位置清0"><br>下图这个就是 IoU不到门槛值  说明两个 bounding box 预测的不是一个类别 两者都保留不动。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/dce95176ac7ab31983097137667b0f1c.png#pic_center" alt="IoU不到门槛值的情况"><br>然后第一个和所有比完了 再从剩下里面最高的 再比。<br>最后我们可以得到一个稀疏的 98 列，选择有值的 列向量，找到其最大的概率的那一项，返回他的索引（也就是类别），以及他对于的概率值。然后在图片上打上对应的 bounding box。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/784a171229a817e12ba83f6e69be073a.png#pic_center" alt="然后第一个和所有比完了 再从剩下里面最高的 再比"><br><strong>注意奥 我们讲的是只是对预测阶段 需要 。在训练阶段是不需要NMS的。</strong> 因为每个框不管他是要被打入冷宫的还是负责预测物体的有用框 都要在损失函数中占据一席之地。里面的所有框的一举一动都会影响损失函数。所以不能随随便便在训练阶段 用NMS 把没用的框去掉，或者把概率抹零。</p>
<h1 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h1><p>首先奥这是个典型的 监督学习。所以我们是需要 ground truth。比如下图就是一个正确的标签：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9940687bd6b6c2f7cf5235fb14ba8369.png#pic_center" alt="正确的标签"></p>
<blockquote>
<p><font color="red">这里有个问题 每个grid cell 都有两个 bounding box 谁来 拟合 ground truth 做损失函数呢? </font><br>答：看谁和 ground truth的 IoU 更大。比如这里 就是由 外面这个大框 负责拟合 ground truth，让其尽量的逼近 调整成 ground truth 的样子，那么另外一个框就被打入冷宫了 ，它什么都不用做，尽量让他置信度降为0。<br><img src="https://img-blog.csdnimg.cn/img_convert/cfafbaa050469d1ce71b47affcdc3341.png#pic_center" alt="每个grid cell 有两个 bounding box"><br><img src="https://img-blog.csdnimg.cn/img_convert/ec519587d6180d710944340ab1713270.png#pic_center" alt="看看选择哪个 bounding box"></p>
</blockquote>
<p><strong>如果没有ground truth 中心点落下 的 grid cell 的两个 bounding box 全部打入冷宫。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/3c083d8df79294e99cf3e223e49ffd9d.png#pic_center" alt="没有ground truth 中心点落下 的 grid cell"></p>
<h2 id="yolo-v1-的-损失函数-待补充与推理"><a href="#yolo-v1-的-损失函数-待补充与推理" class="headerlink" title="yolo v1 的 损失函数 (待补充与推理)"></a>yolo v1 的 损失函数 (待补充与推理)</h2><p>下面介绍一下 yolov1损失函数误差。主要分为5个部分。<br><img src="https://img-blog.csdnimg.cn/img_convert/b4f54e2a69268e05525cd063dbb06b93.png#pic_center" alt="yolo v1 的 损失函数"><br>现在有一个问题就是 我损失函数要去调整的参数到底是谁。是为了让选中的那个bounding box 框更加拟合 ground truth ，那我们要调整的岂不是 网络结构输出的东西，那也就是改的网络了？所以到底是在调整什么呢？</p>
<p>没毛病 就是返回框的参数 然后反向传播调整网络的参数</p>
<h1 id="总结yolov1的缺点"><a href="#总结yolov1的缺点" class="headerlink" title="总结yolov1的缺点"></a>总结yolov1的缺点</h1><ol>
<li>mAP相比 R-CNN 系列比较低</li>
<li>定位性能比较差，定位错误占总错误的比例很大</li>
<li>Recall比较低，就是把全部目标全部检测出来的能力比较差</li>
<li>检测密集和小目标的能力比较差</li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.bilibili.com/video/BV15w411Z7LG?p=1">牛逼的子豪兄 yolo v1详解</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/46309428">yolo 损失函数的详解</a></li>
<li><a href="https://blog.csdn.net/weixin_44523062/article/details/104717799">yolo 置信度的概念</a></li>
</ul>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>yolo</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>如何评价目标检测的性能 MAP如何计算等</title>
    <url>/2021/10/26/%E5%A6%82%E4%BD%95%E8%AF%84%E4%BB%B7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E6%80%A7%E8%83%BD%20MAP%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E7%AD%89/</url>
    <content><![CDATA[<p>@<a href="如何评价目标检测的性能 MAP如何计算等">TOC</a><br>目标检测模型的性能指标分为速度指标和准确度指标。速度指标通常用每秒推断帧数 FPS （Frames Per Second）衡量，但受硬件影响较大。</p>
<p>目标检测输入图像，输出图像中各个目标预测框的矩形坐标及各类别预测置信度Conf。</p>
<p>采用交并比 IOU 衡量预测框和标注框的重合程度，即预测框的定位是否准确。</p>
<script type="math/tex; mode=display">IOU=\frac{area(B_{p}∩B_{gt})}{area(B_{p}∪B_{gt})}</script><p>式子中，$B<em>{p}$为预测框，$B</em>{gt}$为标准框</p>
<p>根据与标注框的关系，可将某一预测框划分为下式四类中的某一类</p>
<blockquote>
<ul>
<li>真正例（TP）：样本的预测与实际标签相同 </li>
<li>假正例（FP）：样本实际标签不是C，但模型预测成C了 </li>
<li>假负例（FN）：样本实际标签为C，模型预测错了</li>
<li>真负例（TN）：样本实际为其他类，模型也预测为其他类</li>
</ul>
</blockquote>
<p> TP： $Conf &gt; P<em>{thresh}$ 且 $IOU &gt; IOU</em>{thresh}$<br> FP： $Conf &gt; P<em>{thresh}$ 且 $IOU &lt; IOU</em>{thresh}$<br> FN： $Conf &lt; P<em>{thresh}$ 且 $IOU &gt; IOU</em>{thresh}$<br> TN： $Conf &lt; P<em>{thresh}$ 且 $IOU &lt; IOU</em>{thresh}$</p>
<p>式子中，$IOU_{thresh}$为0-1之间的常数，需人工指定。<br>对于某一特定类别，TP、FP、FN、TN 四种预测框的个数构成混淆矩阵（Confusion Matrix）。例如这边用 同济子豪兄大哥的 毕设波磨检测为例。（这里的其他类别指的是背景）<br><img src="https://img-blog.csdnimg.cn/img_convert/222b3b01bcd2ff73f2408bddfc8abf77.png#pic_center" alt="混淆矩阵"><br>进一步定义以下参数：</p>
<ol>
<li>Precison(查准率) 是指所有预测框中预测正确的比例，反应了模型“不把背景冤枉成目标”的准确性。<br><img src="https://img-blog.csdnimg.cn/img_convert/f3ae30d6a98aeb65efad9cbf82b5123e.png#pic_center" alt="在这里插入图片描述">    </li>
<li>Recall(查全率、敏感性、召回率)是指所有 应该被预测出来的标准框 中被正确预测的比例，反应了模型“不把目标放过为背景”的敏感性。<br><img src="https://img-blog.csdnimg.cn/img_convert/cfb0d9475b56951b1d78def0e79655a9.png#pic_center" alt="在这里插入图片描述"></li>
<li>Average Precision（平均精度，简称AP）：<br>将 $P<em>{thrshold}$ 阈值从0到1变化，计算每个  $P</em>{threshold}$ 阈值对应的Precision和Recall，绘制成某类别的PR性能曲线，其围成的面积为该类别的AP。<br><img src="https://img-blog.csdnimg.cn/img_convert/553b6e044b25f0efbf068d4794dedb68.png#pic_center" alt="比如猫的AP"></li>
</ol>
<p>取所有类别的AP和不同的 $IOU<em>{thresh}$ ，可分别计算 mAP@0.5 和 mAP@0.5:0.95 。                     mAP@0.5为 $IOU</em>{thresh}$ 取0.5时，各类别AP的平均值。 mAP@0.5:0.95为 $IOU_{thresh}$ 分别取以0.05为步长，从0.5增大到0.95的10个数时，各类别AP的平均值。如下式所示，j分别取 0.5、0.55、0.6、0.65、0.7、0.75、0.8、0.85、0.9、0.95，N为类别总数20（类别总数）。</p>
<script type="math/tex; mode=display">AP = \int_{0}^{1}P_{thresh}(r) dr</script><script type="math/tex; mode=display">mAP@0.5=\frac{1}{N}\sum_{i=1}^{N}AP_{i}(IOU_{thresh}=0.5)</script><script type="math/tex; mode=display">mAP@0.5:0.95=\frac{1}{N}\sum_{i=1}^{N}\sum_{j}AP_{i}(IOU_{thresh}=j)</script>]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>数据集加载的各种方式方法</title>
    <url>/2021/09/17/%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E7%9A%84%E5%90%84%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>@<a href="数据集加载的各种方式方法">TOC</a></p>
<h1 id="np-loadtxt-读取本地-csv-文件"><a href="#np-loadtxt-读取本地-csv-文件" class="headerlink" title="np.loadtxt 读取本地 csv 文件"></a>np.loadtxt 读取本地 csv 文件</h1><p>读入本地 csv 文件内容。 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    numpy读取本地文件</span></span><br><span class="line"><span class="string">    delimiter 数据的分割号</span></span><br><span class="line"><span class="string">    dtype 读取数据类型  一般机器学习类的都是float32 </span></span><br><span class="line"><span class="string">    因为显卡一般他内核里面是按32位工作的</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;./dataset/diabetes.csv&#x27;</span>,delimiter=<span class="string">&quot;,&quot;</span>,dtype=np.float32)</span><br></pre></td></tr></table></figure>
<p>用Pytorch使用<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numpy 转 张量  最后一组样本我们当测试样本吧  其余的当训练样本</span></span><br><span class="line">x_train = torch.from_numpy(xy[:-<span class="number">1</span>,:-<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(x_train.shape)</span><br><span class="line">y_train = torch.from_numpy(xy[:-<span class="number">1</span>,[-<span class="number">1</span>]])</span><br></pre></td></tr></table></figure></p>
<h1 id="批次读取-本地-csv-文件"><a href="#批次读取-本地-csv-文件" class="headerlink" title="批次读取 本地 csv 文件"></a>批次读取 本地 csv 文件</h1><p>使用 DataLoader+Dataset </p>
<h2 id="Step1：引入包"><a href="#Step1：引入包" class="headerlink" title="Step1：引入包"></a>Step1：引入包</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Dataset 是个抽象类，所以其不可以被实例化</span></span><br><span class="line"><span class="comment"># Dataset 可以为其他的子类所继承的</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br></pre></td></tr></table></figure>
<h2 id="Step2：定义一个自己的Dataset类-并继承原有的抽象类Dataset"><a href="#Step2：定义一个自己的Dataset类-并继承原有的抽象类Dataset" class="headerlink" title="Step2：定义一个自己的Dataset类 并继承原有的抽象类Dataset"></a>Step2：定义一个自己的Dataset类 并继承原有的抽象类Dataset</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># DiabetesDataset 继承 Dataset</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiabetesDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, filepath</span>):</span></span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">        <span class="comment"># 一共有几个样本</span></span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># numpy 转 张量  最后一组样本我们当测试样本吧  其余的当训练样本</span></span><br><span class="line">        self.x_train = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_train = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 继承Dataset的方法并重写</span></span><br><span class="line">    <span class="comment"># 其实用来帮助找索引位置的  dataset[index]</span></span><br><span class="line">    <span class="comment"># 函数功能是根据index索引去返回数据样本以及标签label</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.x_train[index], self.y_train[index]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 函数功能是用来查看数据的长度，也就是 dataset 样本的数量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化这个类</span></span><br><span class="line">diabetesdataset = DiabetesDataset(<span class="string">&#x27;../dataset/diabetes.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Step3：使用DataLoader"><a href="#Step3：使用DataLoader" class="headerlink" title="Step3：使用DataLoader"></a>Step3：使用DataLoader</h2><p>其返回的是 对应索引的数据<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义一个 loader</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    batch_size 就是批次大小</span></span><br><span class="line"><span class="string">    shuffle True的话就表示要打乱数据</span></span><br><span class="line"><span class="string">    num_workers  读取Mni-batch的时候要多进程</span></span><br><span class="line"><span class="string">                2就表示由2个进程进行读取</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 返回 （x,y）</span></span><br><span class="line">train_loader = DataLoader(dataset=diabetesdataset, batch_size=<span class="number">32</span>, num_workers=<span class="number">2</span>, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="Step4：用迭代的方式拿到数据"><a href="#Step4：用迭代的方式拿到数据" class="headerlink" title="Step4：用迭代的方式拿到数据"></a>Step4：用迭代的方式拿到数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># 1. Prepare data</span></span><br><span class="line">            inputs, labels = data</span><br><span class="line">            <span class="comment"># 2. Forward</span></span><br><span class="line">            y_pred = FullLeanerModel(inputs)</span><br><span class="line">            loss = criterion(y_pred, labels)</span><br><span class="line">            <span class="comment"># 3. Backward</span></span><br><span class="line">            optimizer.zero_grad()  <span class="comment"># 梯度清零</span></span><br><span class="line">            loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">            <span class="comment"># 4. Update</span></span><br><span class="line">            optimizer.step()  <span class="comment"># 更新参数</span></span><br></pre></td></tr></table></figure>
<h1 id="用-pandas-的-read-csv-方法"><a href="#用-pandas-的-read-csv-方法" class="headerlink" title="用 pandas 的 read_csv 方法"></a>用 pandas 的 read_csv 方法</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_filepath = <span class="string">r&quot;../dataset/Titanic/train.csv&quot;</span></span><br><span class="line">train_data = pd.read_csv(train_filepath)</span><br></pre></td></tr></table></figure>
<p>pandas需要使用 DataFrame 的形式<br><img src="https://img-blog.csdnimg.cn/cb5ee55c852d4a66a120888969fdb170.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>可用 pandas.DataFrame()来转换成 DataFrame 格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 是否幸存 客舱等级 性别 年龄 旁系亲友数目  直系亲友数目 票价  上船港口编号</span></span><br><span class="line">cols=[<span class="string">&#x27;Survived&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;SibSp&#x27;</span>, <span class="string">&#x27;Parch&#x27;</span>, <span class="string">&#x27;Fare&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>]</span><br><span class="line"><span class="comment"># colums表示列名  index 表示行名   选择需要的列</span></span><br><span class="line">train_data = pd.DataFrame(train_data, columns=cols)</span><br></pre></td></tr></table></figure>
<p>可以用 ndarray 将DataFrame 转为 普通的numpy 读取出来。如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># &#x27;Survived&#x27;</span></span><br><span class="line">label = ndarray[:,:<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 除了&#x27;Survived&#x27; 其他全部特征</span></span><br><span class="line">features = ndarray[:,<span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据集</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度下降算法 进阶</title>
    <url>/2021/08/04/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%20%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<p>@<a href="梯度算法 进阶">TOC</a></p>
<h1 id="回顾梯度算法"><a href="#回顾梯度算法" class="headerlink" title="回顾梯度算法"></a>回顾梯度算法</h1><p><strong>是一种迭代的算法，每看一个参数都会更新。</strong><br><img src="https://img-blog.csdnimg.cn/eee493cfe8f24755a2aa3cfd41f486f4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/62ccf5ddd84348308c79a70233b0da19.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="学习率η（Learning-Rate）"><a href="#学习率η（Learning-Rate）" class="headerlink" title="学习率η（Learning Rate）"></a>学习率η（Learning Rate）</h1><h2 id="自定义的学习率对参数选择的影响"><a href="#自定义的学习率对参数选择的影响" class="headerlink" title="自定义的学习率对参数选择的影响"></a>自定义的学习率对参数选择的影响</h2><p><img src="https://img-blog.csdnimg.cn/6c39ce49d85048098ac7303a552bc184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>学习率需要选取合适的值，过小会导致模型调参的速度太慢，但过大会导致错失掉了最佳参数点</strong></p>
<h2 id="如何调整学习率η？"><a href="#如何调整学习率η？" class="headerlink" title="如何调整学习率η？"></a>如何调整学习率η？</h2><ol>
<li><p>在最开始的时候，随机点离目标点很远，我们一般会选取一个比较大的学习率；当做了几期后，我们离目标点很近了，所以我们会减小学习率 缩减为 如下图所示的公式<img src="https://img-blog.csdnimg.cn/b9bc45580c004a6cbb708595125b1a1a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
<li><p><strong>不同的参数应该设置不同的学习率</strong></p>
</li>
</ol>
<p>下面是常用的 调整学习率的方法：</p>
<h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>Adagrad是解决不同参数应该使用不同的更新速率的问题。<strong>Adagrad自适应地为各个参数分配不同学习率的算法。</strong></p>
<blockquote>
<p><strong>其原理为：</strong><img src="https://img-blog.csdnimg.cn/4423c0afa60f462cb444f37cd1307576.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>里面比较核心的部分在 每次σ的取值。<strong>每次σ规定为之前所有<em>g</em>平方对应的之和的均方根</strong>。例如下图所示：其中 <em>g</em> 是每次的偏导值<img src="https://img-blog.csdnimg.cn/82780afd2b0347ad8505db41024b9f7d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>结合之前说的 <em>η</em> 值的变化 可以得到如下的公式推导：<img src="https://img-blog.csdnimg.cn/cf79f34d94b44c72abdd283ebb0f3431.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<p><strong>提问:</strong>    发现一个现象，本来应该是随着gradient的增大，我们的学习率是希望增大的，也就是图中的g上标t；但是与此同时随着gradient的增大，我们的分母是在逐渐增大，也就对整体学习率是减少的，这是为什么呢？<img src="https://img-blog.csdnimg.cn/64154f52e91f4486be92171800f09815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这是因为随着我们更新次数的增大，我们是希望我们的学习率越来越慢。因为我们认为在学习率的最初阶段，我们是距离损失函数最优解很远的，随着更新的次数的增多，<strong>我们认为越来越接近最优解，于是学习速率也随之变慢。</strong>  为什么化简之后是如上这个式子呢，其在图像上的意义是 一阶导数比上二阶数的值。如下图所示：<img src="https://img-blog.csdnimg.cn/90fda3afedce4958a877451546c006e2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="Stochastic-Gradient-Descent（SGD随机梯度下降法）-？？？"><a href="#Stochastic-Gradient-Descent（SGD随机梯度下降法）-？？？" class="headerlink" title="Stochastic Gradient Descent（SGD随机梯度下降法） ？？？"></a>Stochastic Gradient Descent（SGD随机梯度下降法） ？？？</h3><p>其和 普通的梯度下降算法区别在。普通遍历在求和的时候需要浪费大量时间，进而去掉求和产生了随机梯度下降算法。<img src="https://img-blog.csdnimg.cn/e92e87942f4443cbac50e52369c68151.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>和下图看到的一样：<br><img src="https://img-blog.csdnimg.cn/76673f0f26614df6a9ac37311fe015b1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p> 只是要注意一下标准的梯度下降和随机梯度下降的区别：</p>
<ol>
<li><p>标准下降时在权值更新前汇总所有样例得到的标准梯度，随机下降则是通过考察每次训练实例来更新（<strong>就是随机选择一些按顺序的后续样本点来，而不是全体数据</strong>）。<img src="https://img-blog.csdnimg.cn/32da14cad9bf4a2ba439745929b7ec11.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
<li><p>对于步长 <em>η</em> 的取值，标准梯度下降的 <em>η</em> 比随机梯度下降的大。因为标准梯度下降的是使用准确的梯度，理直气壮地走，随机梯度下降<strong>使用的是近似的梯度</strong>，就得小心翼翼地走，怕一不小心误入歧途南辕北辙了。</p>
</li>
<li>当损失函数有多个局部极小值时，随机梯度反而更可能避免进入局部极小值中。</li>
</ol>
</blockquote>
<h4 id="小批量随机梯度下降（batch-gradient-descent）"><a href="#小批量随机梯度下降（batch-gradient-descent）" class="headerlink" title="小批量随机梯度下降（batch gradient descent）"></a>小批量随机梯度下降（batch gradient descent）</h4><p>如果在每次迭代中，梯度下降是用整个训练数据集来计算梯度的话，则会带来大量的计算量。因此提出批量梯度下降来进行优化。<strong>每次优化不再是对整体数据集来计算损失，取而代之使用随机采样小批量的样本来计算梯度。</strong><img src="https://img-blog.csdnimg.cn/0d8e8d1e6c234e36b0972e5b95c9f46a.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="Feature-Scaling-（特征缩放）"><a href="#Feature-Scaling-（特征缩放）" class="headerlink" title="Feature Scaling （特征缩放）"></a>Feature Scaling （特征缩放）</h3><p>其意思就是说要<strong>将所有特征有相同的规模</strong>。例如下图所示，<em>X2</em> 的范围明显大宇 <em>X1</em>，所以要将 <em>X2</em> 进行缩放。<br><img src="https://img-blog.csdnimg.cn/2b4681ef27884c0bbf400db0624e8740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h4 id="为什么要做Feature-Scaling？"><a href="#为什么要做Feature-Scaling？" class="headerlink" title="为什么要做Feature Scaling？"></a>为什么要做Feature Scaling？</h4><blockquote>
<p>为什么要做Feature Scaling？<img src="https://img-blog.csdnimg.cn/456a5666c6bf40b7a1e5f7a8727b529f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如左图，<em>X1</em> 和 <em>X2</em> 数值规模大小相差很大，那 <em>W2</em> 这参数的变动会极大的影响损失函数，而 <em>W1</em> 影响度就很小。所以我们<strong>需要对 <em>X2</em> 进行特征缩放，使其与 <em>X1</em> 保持一个规模</strong>。并且其实从图像可以看出，如果按左图来做的话，我们很难找到一组合适的参数集合，因为他梯度下降的方法不是直线的而是曲线；而右图是近乎直线。（<strong>最里面圈的损失函数最小</strong>）</p>
</blockquote>
<h4 id="如何实现Feature-Scaling？"><a href="#如何实现Feature-Scaling？" class="headerlink" title="如何实现Feature Scaling？"></a>如何实现Feature Scaling？</h4><p><img src="https://img-blog.csdnimg.cn/f129b6a000c841ec926df684d2c77a15.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>如上图所示，假如有R个数据样本，每个样本有<em>X1 - Xi</em> 个特征。我们用上面的公式计算出其应该的scale（其实说实在的这不就是化成标准正太分布么）</p>
<h1 id="梯度下降算法数学总结"><a href="#梯度下降算法数学总结" class="headerlink" title="梯度下降算法数学总结"></a>梯度下降算法数学总结</h1><p>提出问题：如下图所示<strong>（我怎么样才能在红圈里找到最小损失的那个点呢）</strong><img src="https://img-blog.csdnimg.cn/53c25201a11349b6bc3af9e1dfc9fcc6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="首先要回顾泰勒公式"><a href="#首先要回顾泰勒公式" class="headerlink" title="首先要回顾泰勒公式"></a>首先要回顾泰勒公式</h2><p><img src="https://img-blog.csdnimg.cn/c9b154d4d14c43c8bf5e2609789bb094.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/205bb83b97d849fc9b8c7451e044fdab.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>二元泰勒：<br><img src="https://img-blog.csdnimg.cn/2efa8bf67ffa419e90221154515a3712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="用泰勒展开损失函数"><a href="#用泰勒展开损失函数" class="headerlink" title="用泰勒展开损失函数"></a>用泰勒展开损失函数</h2><p><img src="https://img-blog.csdnimg.cn/3ce8a2749e644d1f978c43d485798dde.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>理解为点乘，反向180度的时候，损失函数才是最小的：<img src="https://img-blog.csdnimg.cn/235fc97c36b74012b0663975ba0dc8a9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>最终可以表达成：<img src="https://img-blog.csdnimg.cn/83f0037797f64c048376868ee2c21fae.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="梯度下降算法缺点在哪"><a href="#梯度下降算法缺点在哪" class="headerlink" title="梯度下降算法缺点在哪"></a>梯度下降算法缺点在哪</h1><p>其不仅仅包括可能有找到是局部最优解问题，有可能在中间的时候就有偏微分为0的时候，而这时这个点可能离全局最优解点 很远。<br><img src="https://img-blog.csdnimg.cn/cd31675e6d8e4c83925852218d4f2acc.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>李宏毅</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈 VGG</title>
    <url>/2021/11/01/%E6%B5%85%E8%B0%88%20VGG/</url>
    <content><![CDATA[<p>@<a href="浅谈 VGG">TOC</a><br>《Very Deep Convolutional Networks for Large-Scale Image Recognition》</p>
<p>arXiv：<a href="https://arxiv.org/abs/1409.1556">[1409.1556] Very Deep Convolutional Networks for Large-Scale Image Recognition<br>intro：ICLR 2015</a><br>homepage：<a href="https://www.robots.ox.ac.uk/~vgg/research/very_deep/">Visual Geometry Group Home Page</a></p>
<h1 id="VGG-特点"><a href="#VGG-特点" class="headerlink" title="VGG 特点"></a>VGG 特点</h1><p>VGG 网络是在ILSVRC 2014上的相关工作，主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。<br>VGG有两种结构，分别是VGG16和VGG19，两者并没有本质上的区别，只是网络深度不一样。</p>
<ul>
<li>VGG16包含了16个隐藏层（13个卷积层和3个全连接层） 其特点为 卷积块的卷积层个数为  2 2 3 3 3<br><img src="https://img-blog.csdnimg.cn/img_convert/22de401629c305540a9f2ccaef96ba63.png#pic_center" alt="VGG16"><br><img src="https://img-blog.csdnimg.cn/img_convert/786fc264427f593ff33f5dede514a990.png#pic_center" alt="VGG16"></li>
</ul>
<ul>
<li>VGG19包含了19个隐藏层（16个卷积层和3个全连接层） 的特点为 卷积块的卷积层个数为  2 2 4 4 4</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/27f07e7317617a43f88350a560c371a6.png#pic_center" alt="VGG网络架构"><br>全连接转卷积（测试阶段）<br>这也是VGG的一个特点，在网络测试阶段将训练阶段的三个全连接替换为三个卷积，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入，这在测试阶段很重要。<br>例如，输入图像是224x224x3，如果后面三个层都是全连接，那么在测试阶段就只能将测试的图像全部都要缩放大小到224x224x3，才能符合后面全连接层的输入数量要求，这样就不便于测试工作的开展。</p>
<h1 id="VGG-原理"><a href="#VGG-原理" class="headerlink" title="VGG 原理"></a>VGG 原理</h1><p>VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（如11x11，7x7，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</p>
<p>为什么2个3×3的卷积核 可以 代替 1个5×5的卷积核？<br><img src="https://img-blog.csdnimg.cn/img_convert/5c12d10dd0738e23846584801c3a686f.png#pic_center" alt="两个3×3代替5×5"><br>因为我们知道   例如输入图片大小为C 卷积核大小为k  步长为d 那输出图片大小就是 $\lfloor \frac{C+2 * padding-k}{d} \rfloor +1$<br>那pad=0 d=1 对于2个3×3的而言 计算得到的 输出图片大小为 C-4<br>同理 一个5×5的 也为 C-4</p>
<p>总结的来说优势有3点：</p>
<ol>
<li>分成多个层的小卷积核来代替大卷积核，可以增加网络深度。而每一层都会引入非线性的激活函数，所以其非线性表达的能力会更好，模型的分类性能更好。</li>
<li>计算参数减少了。举个例子比如输入维度是C(也就是卷积核通道维度)，输出维度是C(也就是卷积核个数)，如果使用2层3×3的卷积层来代替一层5×5的，3×3的参数总量为 3×3×C×C×2 = $18C^{2}$；对应的  5×5的 为 5×5×C×C×1 = $25C^{2}$</li>
<li>使用多个层的小卷积核，相当于将一个大的感受野分成多个小感受野来学习，是一种正则化的思想。注意：正则化是一种思想方式，其目的为防止过拟合。其具体方法有：BN、dropout、L1和L2正则化项等。</li>
</ol>
<h1 id="VGG优缺点"><a href="#VGG优缺点" class="headerlink" title="VGG优缺点"></a>VGG优缺点</h1><h2 id="VGG优点"><a href="#VGG优点" class="headerlink" title="VGG优点"></a>VGG优点</h2><ul>
<li>VGG16和VGG19 的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。</li>
<li>几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：</li>
<li>验证了通过不断加深网络结构可以提升性能。</li>
<li><p>VGG 是传统的串行结构，输出的内容例如左上角提取的就是原图像左上角的特征。<br><img src="https://img-blog.csdnimg.cn/img_convert/afe80f4458553cf142cd9a8f6b7cfc40.png#pic_center" alt="FeatureMap的提取情况"></p>
</li>
<li><p>VGG 的迁移学习能力很强，一般都用来做基础模型。我们只需要修改最后1层的输出结构，冻结前面所有在ImageNet上训练VGG后的参数，再拿自己的数据集来训练最后4096神经元和最后一层输出的参数即可。</p>
</li>
<li>采用多尺度训练方式，训练的数据可以有 224、256、384、[256，512]</li>
<li>作者提出的 在test上改进的方法，将最后的全连接层改为全卷积层，但是作者训练的时候并没有这么用。这个方法可以实现多尺度输入，原始的 全神经网络的话 他层次的神经元是定死的 所以我没办法换个尺度的图片输入。<br><img src="https://img-blog.csdnimg.cn/img_convert/d2092e465499fab47e8e6587f744e396.png#pic_center" alt="test"></li>
</ul>
<h2 id="VGG缺点"><a href="#VGG缺点" class="headerlink" title="VGG缺点"></a>VGG缺点</h2><p>参数非常庞大。庞大在卷积层输出压平后与第一层全神经网络之间的参数。<br><img src="https://img-blog.csdnimg.cn/img_convert/5a91f370bba686cfa4003affe2a9eefc.png#pic_center" alt="参数计算"><br>首先看第二行，所谓的内存就是输出图片大小  而参数就是卷积核×通道数×卷积核个数64个。<br>注意这里是没有算上偏置量的，算的话就是每个卷积核一个偏置项，会增广成矩阵加上去的。</p>
<h1 id="VGG的训练和测试"><a href="#VGG的训练和测试" class="headerlink" title="VGG的训练和测试"></a>VGG的训练和测试</h1><p> 论文首先将训练图像缩放到最小边长度的方形，设缩放后的训练图像的尺寸为S×S。网络训练时对训练图像进行随机裁剪，裁剪尺寸为网络的输入尺寸224×224。如果S=224，则输入网络的图像就是整个训练图像；如果S&gt;224，则随机裁剪训练图像包含目标的部分。</p>
<p>对于训练集图像的尺寸设置，论文中使用了两种方法：</p>
<p>固定尺寸训练，设置 <strong>S=256</strong> 和 <strong>S=384</strong><br>多尺度训练，每个训练图像从一定范围内 <strong>[Smin,Smax],(Smin=256,Smax=512)</strong> 进行随机采样。由于图像中的目标可能具有不同的大小，因此在训练期间考虑到这一点是有益的。这也可以看作是通过尺度抖动进行训练集增强，其中单个模型被训练在一定尺度范围内识别对象。</p>
<h2 id="网络性能评估"><a href="#网络性能评估" class="headerlink" title="网络性能评估"></a>网络性能评估</h2><ul>
<li><strong>单尺度评估，测试图像固定尺度。结果如下表</strong><br><img src="https://img-blog.csdnimg.cn/img_convert/c06443bd58d1867902a59902e0a5b2c7.png#pic_center" alt="单一尺度评估"><br>通过评估结果，可以看出：<ul>
<li>局部归一化（A-LRN）网络，对网络A的结果并没有很大的提升。</li>
<li>网络的性能随着网络的加深而提高。应该注意到B，C，D这个网络的性能。C网络好于B网络，说明额外添加的非线性激活函数，确实是有好处的；但是，D网络好于C网络，这说明也可以使用非平凡的感受野来捕获更多的信息更有用。</li>
<li>当网络层数达到19层时，使用VGG架构的错误率就不再随着层数加深而提高了。更深的网络应该需要更多的数据集。</li>
<li>论文还将网络B与具有5×5卷积层的浅层网络进行了比较，浅层网络可以通过用单个5×5卷积层替换B中每对3×3卷积层得到。测量的浅层网络top-1错误率比网络B的top-1错误率（在中心裁剪图像上）高7％，<strong>这证实了具有小滤波器的深层网络优于具有较大滤波器的浅层网络</strong>。</li>
<li>训练时的尺寸抖动（训练图像大小S∈[256,512])得到的结果好于固定尺寸，这证实了通过尺度抖动进行的训练集增强确实有助于捕获多尺度图像统计。</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>多尺度评估，测试图像的尺度抖动对性能的影响</strong><br>  对同一张测试图像，将其缩放到不同的尺寸进行测试，然后取这几个测试结果的平均值，作为最终的结果（有点像集成学习，所不同的是，这里是测试图像的尺寸不同）。使用了三种尺寸的测试图像：Q表示测试图像，S表示训练是图像尺寸：Q=S−32，Q=S+32，前面两种是针对训练图像是固定大小的，对于训练时图像尺寸在一定范围内抖动的，则可以使用更大的测试图像尺寸。   Q={Smin,0.5(Smin+Smax),Smax}.<br>评估结果如下：<br><img src="https://img-blog.csdnimg.cn/img_convert/339fb07aaff8cf5e01ac2dab96205f39.png#pic_center" alt="多尺度评估，测试图像的尺度抖动对性能的影响"><br>评估结果表明，训练图像尺度抖动优于使用固定最小边S。</p>
</li>
<li><p><strong>稠密和多裁剪图像评估</strong><br>Dense（密集评估），即指全连接层替换为卷积层（第一FC层转换到7×7卷积层，最后两个FC层转换到1×1卷积层），最后得出一个预测的score map，再对结果求平均。<br>multi-crop，即对图像进行多样本的随机裁剪，将得到多张裁剪得到的图像输入到网络中，最终对所有结果平均.<br><img src="https://img-blog.csdnimg.cn/img_convert/925e5742f42b654fabe4bf03cf56f1b8.png#pic_center" alt="多裁剪与密度估计"><br>从上图可以看出，<strong>多裁剪的结果是好于密集估计的</strong>。而且这两种方法确实是互补的，因为它们的组合优于其中的每一种。<br>由于不同的卷积边界条件，多裁剪图像评估是密集评估的补充：当将ConvNet应用于裁剪图像时，卷积特征图用零填充，而在密集评估的情况下，相同裁剪图像的填充自然会来自于图像的相邻部分（由于卷积和空间池化），这大大增加了整个网络的感受野，因此捕获了更多的图像内容信息。</p>
</li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>在训练时，可以使用多尺度抖动的训练图像，其精度好于固定尺寸的训练集。</li>
<li>测试时，使用多裁剪和密集评估（卷积层替换全连接层）像结合的方法<img src="https://img-blog.csdnimg.cn/img_convert/d2092e465499fab47e8e6587f744e396.png#pic_center" alt="卷积层替换全连接层"></li>
</ul>
]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>模型误差的来源分析</title>
    <url>/2021/08/02/%E6%A8%A1%E5%9E%8B%E8%AF%AF%E5%B7%AE%E7%9A%84%E6%9D%A5%E6%BA%90%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>@<a href="模型误差的来源分析">TOC</a></p>
<blockquote>
<p>思路：<br>1、首先，误差的两大来源 <em>bias</em>（偏差） 和 <em>variance</em>（方差） 是指什么<br>2、然后，<em>bias</em>（偏差）和 <em>variance</em>（方差）是怎么产生的<br>3、进一步，如何判断你的模型是 <em>bias大</em>（欠拟合）还是<em>variance大</em>（过拟合），如何解决 ？</p>
</blockquote>
<h1 id="模型的两大来源bias（偏差）和variance（方差）"><a href="#模型的两大来源bias（偏差）和variance（方差）" class="headerlink" title="模型的两大来源bias（偏差）和variance（方差）"></a>模型的两大来源bias（偏差）和variance（方差）</h1><blockquote>
<p>什么是bias和variance呢？<br>思路：</p>
<ol>
<li>首先要知道什么是误差</li>
<li>在了解什么是bias和variance</li>
</ol>
</blockquote>
<h2 id="什么是误差？"><a href="#什么是误差？" class="headerlink" title="什么是误差？"></a>什么是误差？</h2><p><strong>机器学习就是寻找一个函数，然后给它一个输入，就能得到一个理想的输出。</strong><br>f head是理论上找到的最佳函数，f star 是我们用模型预测出来的函数，<strong>两者的差值就是误差</strong>。<img src="https://img-blog.csdnimg.cn/39bb552a5ba348b88a8882c744f74566.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="什么是bias和variance（偏差和方差）"><a href="#什么是bias和variance（偏差和方差）" class="headerlink" title="什么是bias和variance（偏差和方差）"></a>什么是bias和variance（偏差和方差）</h2><h3 id="什么是bias（偏差）？"><a href="#什么是bias（偏差）？" class="headerlink" title="什么是bias（偏差）？"></a>什么是bias（偏差）？</h3><p>举个栗子说明，下图是用一定样本数的均值m来估计假设的随机变量的<strong>平均值u</strong>，这是一种<strong>无偏估计（unbiased）</strong>。<img src="https://img-blog.csdnimg.cn/eaeb2438d6a645d7b1236e6a9df59da8.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>也就是说，<strong>估计值的期望等于假设值</strong>（如上文的E(m)=u），<strong>即为无偏差，反之有偏差（bias）</strong>。<br><strong>当样本数越来越大时，m就越靠近u。</strong></p>
<h3 id="什么是variance（方差）"><a href="#什么是variance（方差）" class="headerlink" title="什么是variance（方差）"></a>什么是variance（方差）</h3><p><strong>方差表达的是数据的离散程度</strong><img src="https://img-blog.csdnimg.cn/28ad8de1e99b4c91a3f16a1088968ca4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这里对于方差的估计是有差估计：<img src="https://img-blog.csdnimg.cn/c9ee7e91fff24cd498b5a21420ad1ed5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="总结直观理解"><a href="#总结直观理解" class="headerlink" title="总结直观理解"></a>总结直观理解</h3><p>最后，bias和variance的直观理解：<img src="https://img-blog.csdnimg.cn/357d51b0a7f34b06933c5a86c042c8dc.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ol>
<li>bias表示的是预测的f bar（f star预测值的期望）与f head（实际正确值）的距离</li>
<li>variance表示的是每次预测的f star（预测值）与f bar（预测值的期望）的距离（看图）</li>
</ol>
<h2 id="bias和variance是怎么产生的"><a href="#bias和variance是怎么产生的" class="headerlink" title="bias和variance是怎么产生的"></a>bias和variance是怎么产生的</h2><blockquote>
<p>下面结合实际的实验说明，bias和variance是如何产生的。<br>————————————————————————————————————————————————————<br>bias如何知晓？，就要做多次实验，确定多个f star（一次实验一个预测值），然后求出f star 样本集的期望（E(f star)）<br>那么首先，我们虚拟出100个神奇宝贝平行宇宙（相当于设置了100组实验），每个预祝<strong>一个神奇宝贝训练家捕捉10只神奇宝贝</strong>（相当于每组实验10个数据），如下图：<img src="https://img-blog.csdnimg.cn/ef3d6cfdd1ca4c179d091c2f5130a42c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>然后思考，对于这样的数据，<strong>我们选用什么model比较好</strong> ?<strong>哪一个model最后的bias比较小</strong>？<img src="https://img-blog.csdnimg.cn/c05149fd285d4c96bd182567c2d891fd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如上图，不同宇宙的神奇宝贝数据非常随机，项次越高，模型越复杂</p>
</blockquote>
<h3 id="方差-variance"><a href="#方差-variance" class="headerlink" title="方差 variance"></a>方差 variance</h3><p><img src="https://img-blog.csdnimg.cn/fea8cce3d3b64a768fbf007ddefe0021.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对于方差而言，其表示结果的离散程度，项次越高，模型越复杂，则其离散程度肯定是越大的。<strong>因为模型越简单，收到数据的影响也就越低</strong>，比如：我极端一点，f(x)=c，数据根本不会影响model最后的预测值</p>
<h3 id="偏差-bias"><a href="#偏差-bias" class="headerlink" title="偏差 bias"></a>偏差 bias</h3><p><img src="https://img-blog.csdnimg.cn/ade6e8be3e52487bafd38dd0f8e750a9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/759ad31af9b04b6a8cdeb92364abe4f7.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>图中看出，简单model可能并不包含目标，因此会造成较大的bias，而复杂的model是涵盖目标的，所以bias小。</p>
<h3 id="偏差和方差的总结"><a href="#偏差和方差的总结" class="headerlink" title="偏差和方差的总结"></a>偏差和方差的总结</h3><blockquote>
<p>简单的模型（次数小），bias会比较大，但variance会比较小，预测值更加集中。<br>复杂的模型（次数大），bias会比较小，但variance会比较大，预测值更加的离散。<br>因此，我们理想中的目标是找到一个平衡点，使bias和variance尽可能小。<img src="https://img-blog.csdnimg.cn/c5a88735d7d94da79046122ca8310740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="判断你的模型是bias大（欠拟合）还是variance大（过拟合）并解决"><a href="#判断你的模型是bias大（欠拟合）还是variance大（过拟合）并解决" class="headerlink" title="判断你的模型是bias大（欠拟合）还是variance大（过拟合）并解决"></a>判断你的模型是bias大（欠拟合）还是variance大（过拟合）并解决</h2><h3 id="如何判断"><a href="#如何判断" class="headerlink" title="如何判断"></a>如何判断</h3><p><img src="https://img-blog.csdnimg.cn/c8150c9d246e4b10841294be51ab0f4a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<h3 id="bias过大（欠拟合）"><a href="#bias过大（欠拟合）" class="headerlink" title="bias过大（欠拟合）"></a>bias过大（欠拟合）</h3><p>需要重新设计模型</p>
<ol>
<li>模型考虑的特征没有全，也就是很多其实没有作用。关键特征可能还没考虑到，需要加入进去</li>
<li>模型应该需要更加的复杂，增加更高的次项。</li>
</ol>
<h3 id="variance过大（过拟合）"><a href="#variance过大（过拟合）" class="headerlink" title="variance过大（过拟合）"></a>variance过大（过拟合）</h3><ol>
<li>需要更多的数据，有些数据不够有特点</li>
<li>可以增加一个 正则项，加强模型的平滑度，使其预测值分布不要太离散</li>
</ol>
<h3 id="解决实际测试比共有数据集误差更大的问题"><a href="#解决实际测试比共有数据集误差更大的问题" class="headerlink" title="解决实际测试比共有数据集误差更大的问题"></a>解决实际测试比共有数据集误差更大的问题</h3><p><img src="https://img-blog.csdnimg.cn/d742c18f9bc04a8ea7981b28a9c2970b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>将训练集，分为两部分。这叫做2-折交叉验证。一部分还是当做训练样本，帮助我们进行调参；另一部分用作验证，验证我的模型损失如何，是否合理（充当原来共有训练集的作用）。而现在原有训练集的部分用来充当实际样本数据，算出误差值，以便于真正在实际中误差太大。</p>
<p><img src="https://img-blog.csdnimg.cn/1c0fa7f4983a4dc585448876cab974d4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>李宏毅</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度消失和梯度爆炸的理解</title>
    <url>/2021/09/20/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>@<a href="梯度消失和梯度爆炸的理解">TOC</a></p>
<h1 id="根本原因"><a href="#根本原因" class="headerlink" title="根本原因"></a>根本原因</h1><p>梯度消失和梯度爆炸的根本原因是由于深度神经网络过长的链，在反向传播通过链式法则求导过程中产生的。 换句话说，就是<strong>反向传播先天就有一定的毛病</strong>。</p>
<h1 id="根本原因的理解"><a href="#根本原因的理解" class="headerlink" title="根本原因的理解"></a>根本原因的理解</h1><p><img src="https://img-blog.csdnimg.cn/beb6cdfcd994483c9133ee88c0763034.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="前馈和反向传播过程"><br>左上角为 正向反馈的步骤（σ 表示 激活函数 $sigmoid$ ）。 Loss 使用的是 MSE损失函数。 根据反向传播，我们可以看到最后 loss 对 b1 参数的梯度。 可以看到 连乘的情况。</p>
<ul>
<li>看这个式子里的 $w<em>{i}$ 中，一般我们初始化权重参数 $w</em>{i}$ 时，通常都小于1。</li>
<li>激活函数 $sigmoid$  的求导如下所示 <img src="https://img-blog.csdnimg.cn/9f175038b5e74cfda605e8906a194416.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_11,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="求导sigmoid函数"></li>
<li>激活函数的导数 图像如下图所示：<img src="https://img-blog.csdnimg.cn/fe08669e4f3648ea89dec0b560ba422b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="sigmoid函数求导"></li>
<li>所以$|σ’(z) × w| ≤ 0.25$，多个小于1的数连乘之后，那将会越来越小，导致靠近输入层的层的权重的偏导几乎为0，也就是说梯度几乎为0，导致参数基本不更新，这就是梯度消失的根本原因。<br>梯度爆炸的原因，也就是说如果$|σ’(z) × w| ≥ 1$，连乘下来就会导致梯度过大，导致梯度更新幅度特别大，可能会溢出，导致模型无法收敛。<br>但 $sigmoid$ 的函数是不可能大于1了，上图看的很清楚，那只能是参数 $w<em>{i}$了，故只有当 $abs(w)&gt;4$ 时才可能出现梯度爆炸，<strong>这也就是经常看到别人博客里的一句话，初始权重过大</strong>。<br>但梯度爆炸的情况一般不会发生，对于$sigmoid$ 函数来说，$σ’(z)$的大小也与 $w</em>{i}$ 有关。<br><strong>其实梯度爆炸和梯度消失问题都是因为网络太深，网络权值更新不稳定造成的，本质上是因为梯度反向传播中的连乘效应。</strong></li>
</ul>
<h1 id="如何解决梯度消失的问题（待补充）"><a href="#如何解决梯度消失的问题（待补充）" class="headerlink" title="如何解决梯度消失的问题（待补充）"></a>如何解决梯度消失的问题（待补充）</h1><ol>
<li>用 $ReLU、LeakyRelu、Elu$ 等激活函数激活函数取代 $sigmoid$ 激活函数。<br>将输出不要固定在0-1之间。$sigmoid$函数的梯度随着 $x$ 的增大或减小和消失，而 $ReLU$ 不会。<br><img src="https://img-blog.csdnimg.cn/3dc7f13adf6c402a94e53d27765e8e92.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="sigmoid与relu"></li>
<li>Batch Normalization 就是通过对每一层的输出规范为均值和方差一致的方法，消除了$w$带来的放大缩小的影响，进而解决梯度消失和爆炸的问题。</li>
<li>ResNet残差结构<br>具体待补充完善，查看 ResNet</li>
<li>LSTM结构<br>LSTM不太容易发生梯度消失，主要原因在于LSTM内部复杂的“门（gates）”，具体看LSTM基本原理解析</li>
<li>预训练加finetunning<br>此方法来自Hinton在06年发表的论文上，其基本思想是每次训练一层隐藏层节点，将上一层隐藏层的输出作为输入，而本层的输出作为下一层的输入，这就是逐层预训练。<br>训练完成后，再对整个网络进行“微调（fine-tunning）”。<br>此方法相当于是找全局最优，然后整合起来寻找全局最优，但是现在基本都是直接拿imagenet的预训练模型直接进行finetunning。</li>
<li>梯度剪切、正则<br>这个方案主要是针对梯度爆炸提出的，其思想是设值一个剪切阈值，如果更新梯度时，梯度超过了这个阈值，那么就将其强制限制在这个范围之内。这样可以防止梯度爆炸。<br>另一种防止梯度爆炸的手段是采用权重正则化，正则化主要是通过对网络权重做正则来限制过拟合，但是根据正则项在损失函数中的形式：<br>可以看出，如果发生梯度爆炸，那么权值的范数就会变的非常大，反过来，通过限制正则化项的大小，也可以在一定程度上限制梯度爆炸的发生。</li>
</ol>
<h1 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/25631496">神经网络训练中的梯度消失与梯度爆炸</a></li>
<li><a href="https://www.jianshu.com/p/3f35e555d5ba">梯度消失和梯度爆炸问题详解</a></li>
</ul>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习基础 - Batch Normalization</title>
    <url>/2021/10/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%20-%20Batch%20Normalization/</url>
    <content><![CDATA[<p>@<a href="深度学习基础 - Batch Normalization">TOC</a></p>
<p>在计算机的眼光里，对具有统一规格的数据，更能学习到其数据之间的规律特征。也就是下图所看的的这样，将杂乱的数据标准归一化。<br><img src="https://img-blog.csdnimg.cn/img_convert/7c0360d9080d48dce15371c941baea9b.png#pic_center" alt="数据标准归一化"></p>
<p>首先我们之前有Normalization（普通数据标准化），一般用作<strong>输入数据</strong>的样本归一化操作。那Batch Normalization 则可用在 每个层上包括隐藏层。</p>
<h1 id="机器学习中的Feature-Scaling"><a href="#机器学习中的Feature-Scaling" class="headerlink" title="机器学习中的Feature Scaling"></a>机器学习中的Feature Scaling</h1><p>如果特征大小差的比较远的话，loss function会很扁平，数值更大的feature的参数会对结果的影响更大，这样在训练过程中，不同的方向需要设定不同的学习率，这样子会不太方便，这不是我们想看到的，所以我们通常会去做feature scaling。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/196be414d2c05a542644613ab56c6213.png#pic_center" alt="使用Feature Scaling后"><br>具体的操作很简单，对每一维特征，我们对每一个数据减去这维特征的均值，再除以这位特征的标准差，得到缩放后的新的特征值，此时它的均值为0，方差为1。一般经过feature scaling之后，<strong>收敛速度会变快</strong>。</p>
<p><strong>那么在神经网络中又是什么情况呢？</strong></p>
<p>我们可以看到，其实在深度网络中，后一层的输入其实是前一层的输出。那么我们在做feature scaling的时候，应该对每一层的输入都去做一个feature scaling, 但是又不像传统的机器学习，由于神经网络每一层的参数都在不断变化，直接使用前面的feature scaling是不太合适的。所以我们需要一个新的技术，就是Batch Normalization了</p>
<h1 id="Batch-Normalization-放在神经网络的哪个部位？"><a href="#Batch-Normalization-放在神经网络的哪个部位？" class="headerlink" title="Batch Normalization 放在神经网络的哪个部位？"></a>Batch Normalization 放在神经网络的哪个部位？</h1><p>Batch Normalization 放在 线性层的后面，激活函数的前面。如下图所示：<br><img src="https://img-blog.csdnimg.cn/img_convert/be42f4f33882e58d12258995609ccb06.png#pic_center" alt="Batch Normalization 放在 线性层的后面，激活函数的前面"></p>
<h2 id="Batch-Normalization-基本原理"><a href="#Batch-Normalization-基本原理" class="headerlink" title="Batch Normalization 基本原理"></a>Batch Normalization 基本原理</h2><p>现在一般采用批梯度下降方法对深度学习进行优化，这种方法把数据分为若干组，按组来更新参数，一组中的数据共同决定了本次梯度的方向，下降时减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也下降了很多。</p>
<p>Batch Normalization(简称BN)中的batch就是批量数据，即每一次优化时的样本数目，通常BN网络层用在卷积层后，用于重新调整数据分布。假设神经网络某层一个batch的输入为X=[x1,x2,…,xn]，其中xi代表一个样本，n为batch size。</p>
<ol>
<li>首先，我们需要求得mini-batch里元素的均值：<script type="math/tex; mode=display">μ_{B}=\frac{1}{n}\sum_{i=1}^{n}x_{i}</script></li>
<li>接下来，求取mini-batch的方差：<script type="math/tex; mode=display">\sigma _{B}^{2} = \frac{1}{n}\sum_{i=1}^{n}(x_{i}-μ_{B})^{2}</script></li>
<li>这样我们就可以对每个元素进行归一化<script type="math/tex; mode=display">\hat{x_{i}}=\frac{x_{i}-μ_{B}}{\sqrt{\sigma _{B}^{2}+\varepsilon}}</script>这里的分母本来应该是 $\sigma$,但为了防止它为0，我们加上一个$\varepsilon$。</li>
<li>最后进行尺度缩放和偏移操作，这样可以变换回原始的分布，实现恒等变换，这样的目的是为了补偿网络的非线性表达能力，因为经过标准化之后，偏移量丢失。具体的表达如下，$y_{i}$就是网络的最终输出。$γ$与$β$是神经网络的参数，是网络自己学习的。<script type="math/tex; mode=display">y_{i}=γ\hat{x_{i}}+β</script></li>
</ol>
<p>从某种意义上来说，方差和均值代表的其实是输入数据分布的方差和偏移。对于没有BN的网络，这两个值与前一层网络带来的非线性性质有关，而经过变换后，就跟前面一层无关，变成了当前层的一个学习参数，这更加有利于优化并且不会降低网络的能力。</p>
<h1 id="举个-Batch-Normaliztion-计算栗子"><a href="#举个-Batch-Normaliztion-计算栗子" class="headerlink" title="举个 Batch Normaliztion 计算栗子"></a>举个 Batch Normaliztion 计算栗子</h1><p>他分为训练（训练 $γ$与$β$）和测试阶段（使用训练后得到的参数）。<br><img src="https://img-blog.csdnimg.cn/img_convert/ae36898be0aa225a92aaf50123680551.png#pic_center" alt="同济子豪兄的理解"><br>如下图 这个的 batch_size=8，也就是说输入的图像有8张，即8个输入；看第一个0.9 表示的是 第一张神经元对第4张图片的响应；后面的1.7就是 第一张神经元对第5张图片的响应；26.7 也就是最后一个神经元对 第4张图片的响应。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/a5c5dfbc5e9f3d93b52b31b12dec84c7.png#pic_center" alt=""><br>就是先算出 平均值 再计算 均方差，按公式得到标准化的结果。</p>
<h1 id="Batch-Normaliztion-的效果"><a href="#Batch-Normaliztion-的效果" class="headerlink" title="Batch Normaliztion 的效果"></a>Batch Normaliztion 的效果</h1><ol>
<li>因为BN可以把输入都规整化在非饱和区内，所以他可以加快收敛（因为梯度变化的大，不缓慢）比如 sigmoid 和 tanh 函数 非饱和区和饱和区。</li>
<li>减少了训练时间，而且可以进行深层网络的训练，同时可以使用更大的学习率。</li>
<li>减轻了对参数初始化的依赖，这是利于调参的</li>
<li>可以起到正则化的作用 可以防止过拟合</li>
<li>BN一定程度上增加了泛化能力，dropout等技术可以去掉。</li>
</ol>
<p><strong>注意：BN与Dropout不能一起使用。</strong> 为什么有待于补充。</p>
<h2 id="可以看一下-效果"><a href="#可以看一下-效果" class="headerlink" title="可以看一下 效果"></a>可以看一下 效果</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/275bcf4be1343343b2e006268bed2b95.png#pic_center" alt="用了Batch Normalization 的效果"></p>
<h1 id="参考论文与博客"><a href="#参考论文与博客" class="headerlink" title="参考论文与博客"></a>参考论文与博客</h1><p>Batch Normalization论文：<a href="http://proceedings.mlr.press/v37/ioffe15.pdf">Batch Normalization论文</a><br>参考的博客：<br><a href="https://zhuanlan.zhihu.com/p/24810318">什么是批标准化？</a><br><a href="https://www.zhihu.com/question/38102762/answer/607815171">知乎第一个留言 深度学习中 Batch Normalization为什么效果好？</a><br><a href="https://zhuanlan.zhihu.com/p/54073204">精选 写的很好  Batch Normalization的通俗解释 </a></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 Deep Learning 基础</title>
    <url>/2021/08/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<p>@<a href="深度学习 Deep Learning 基础">TOC</a></p>
<p><strong>深度学习需要明白的几个问题？</strong><br>思路：</p>
<ol>
<li>什么是深度学习？为什么需要深度学习？深度学习和机器学习的关系？</li>
<li>深度学习的步骤</li>
<li>确定神经网络模型的损失函数，如何优化模型，即调参问题</li>
<li>如何使用Back Propagation（反向传播） 方法 update DNN（深度神经网络）参数</li>
</ol>
<h1 id="深度学习的概念"><a href="#深度学习的概念" class="headerlink" title="深度学习的概念"></a>深度学习的概念</h1><h2 id="什么是深度学习？"><a href="#什么是深度学习？" class="headerlink" title="什么是深度学习？"></a>什么是深度学习？</h2><p>深度学习（Deep Learning，DL）是指多层的人工神经网络和训练它的方法。一层神经网络会把大量矩阵数字作为输入，通过<strong>非线性激活方法</strong>取权重，再产生另一个数据集合作为输出。这就像生物神经大脑的工作机理一样，通过合适的矩阵数量，多层组织链接一起，形成神经网络“大脑”进行精准复杂的处理，就像人们识别物体标注图片一样。</p>
<ul>
<li>深度学习的model是一个深度神经网络结构（neural structure）</li>
<li>深度学习的“深度”是指神经网络的隐层（hidden layer）数量足够多</li>
<li>深度学习是<strong>自动提取特征</strong>（Feature extractor），<strong>不需要像逻辑回归那样特征转换</strong>（Feature engineering）</li>
</ul>
<h2 id="为什么需要深度学习？-深度学习和机器学习的关系？"><a href="#为什么需要深度学习？-深度学习和机器学习的关系？" class="headerlink" title="为什么需要深度学习？ 深度学习和机器学习的关系？"></a>为什么需要深度学习？ 深度学习和机器学习的关系？</h2><ul>
<li>传统机器学习的模型结构较简单，很依赖算法工程师做特征工程甚至子模型来提升模型效果。就像我们之前上节那个栗子一样，做多分类的问题，四个角对角是一个类的情况，没办法进行分类，所以只能使用特征工程来进行特征的变换。</li>
<li>深度学习由于其层次化的结构，理论上可以拟合任意函数，整个复杂结构即可以用来对特征进行自动组合（如图像），也可以用来构建复杂的模型（如nlp领域里的LSTM，能够考虑上下文）。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/b8b8df57f814494d8199e0e7b708e597.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="深度学习的步骤"><a href="#深度学习的步骤" class="headerlink" title="深度学习的步骤"></a>深度学习的步骤</h1><p>其实和机器学习一样分为三步。<img src="https://img-blog.csdnimg.cn/514f075664384cdcb62f6062fd5bd722.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="Step-1：定义一个神经网络结构（neural-structure）"><a href="#Step-1：定义一个神经网络结构（neural-structure）" class="headerlink" title="Step 1：定义一个神经网络结构（neural structure）"></a>Step 1：定义一个神经网络结构（neural structure）</h2><p>神经网络的创建包括3部分：</p>
<ol>
<li>神经网络有多少<strong>隐层（layer）</strong></li>
<li>每一层有多少<strong>神经元（neuron）</strong></li>
<li>每个神经元之间如何连接</li>
</ol>
<p>常见的出名神经网络<img src="https://img-blog.csdnimg.cn/5394cd49b44545c8ab4b8c1191d69239.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="神经元怎么定义？"><a href="#神经元怎么定义？" class="headerlink" title="神经元怎么定义？"></a>神经元怎么定义？</h3><p>每个神经元都有一个 bias 和一个 function ，每条输入的边都有一个 weight<img src="https://img-blog.csdnimg.cn/52bc001e984c4bdf980921c7f2458fdf.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="一个神经网络的栗子"><a href="#一个神经网络的栗子" class="headerlink" title="一个神经网络的栗子"></a>一个神经网络的栗子</h3><p>下面是一个 3个隐层（layer）、六个神经元（neuron）（每个球都是一个神经元）、全连接<strong>前馈</strong>网络（Fully Connection Feedforward Network）</p>
<blockquote>
<p>“<strong>前馈</strong>”是指整个网络中无反馈，信号从输入层向输出层单向传播，可用一个有向无环图表示<br>其实我们常用的网络，都是前馈神经网络，从输入到输出是一个有向图，中间不会有环或者反向传播。<br>当然，我们在训练前馈神经网络的时候，会用到反向传播进行参数调整。但仍不影响整个网络的有向和前馈性质。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/748979f3a3c74e0ab0c19ea60bd13142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="神经网络如何工作？"><a href="#神经网络如何工作？" class="headerlink" title="神经网络如何工作？"></a>神经网络如何工作？</h3><p><img src="https://img-blog.csdnimg.cn/d685eb4da45646df93096525226bb59f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>其实 这就是矩阵运算（可以使用GPU加速计算）<img src="https://img-blog.csdnimg.cn/34294cf6a4254049b0f8bbc0aaf631a1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>总体可以归纳为：<br><img src="https://img-blog.csdnimg.cn/9baa5b003ea04ff7ad3bc25076e2bb58.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="栗子：识别手写数字图像"><a href="#栗子：识别手写数字图像" class="headerlink" title="栗子：识别手写数字图像"></a>栗子：识别手写数字图像</h3><p>从图像中识别是数字几？<br><img src="https://img-blog.csdnimg.cn/5fb1bc809a444ff5bc19325453eb703d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="制作神经网络模型-的FAQ（最容易被问得问题）"><a href="#制作神经网络模型-的FAQ（最容易被问得问题）" class="headerlink" title="制作神经网络模型 的FAQ（最容易被问得问题）"></a>制作神经网络模型 的FAQ（最容易被问得问题）</h3><ul>
<li>Q1： 神经网络需要几个隐层（layers）？每个层需要多少个神经元呢？<ul>
<li>反复试验+ 直觉 （说白了就是要慢慢试= = 看经验呗）</li>
</ul>
</li>
<li>Q2：神经网络可以自动确定结构吗？<ul>
<li>理论上其实是可以的，不过这些方法我们还没学到。Evoluntionary Artifical Neural Networks</li>
</ul>
</li>
<li>Q3：我们可以设计层次之间的结构么？<ul>
<li>意思就是说例如Layer1 链接 Layer3 这样跳着的 等等。当然可以 CNN就是不按顺序来的，具体看下一节。<br><img src="https://img-blog.csdnimg.cn/6c74000cf96a4af0b33146e9dca6efc3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ul>
</li>
</ul>
<h2 id="Step-2：确定神经网络模型的损失函数"><a href="#Step-2：确定神经网络模型的损失函数" class="headerlink" title="Step 2：确定神经网络模型的损失函数"></a>Step 2：确定神经网络模型的损失函数</h2><p>还是和逻辑回归一样，用<strong>交叉熵损失函数</strong>，调参使得交叉熵损失函数最小，如下图所示：<br><img src="https://img-blog.csdnimg.cn/29c36a171c584a36bead0693b41b9027.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>当然上面只是一个点的，把每个样本结合起来看。 <img src="https://img-blog.csdnimg.cn/ef62afa46f1248a09b17cea823c91513.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>不过这个地方有几个疑问？</p>
<blockquote>
<ul>
<li>Q1：神经网络里面有很多层，所以有很多 <em>w</em> 和 <em>b</em> 调整。那是全体都一次性调整么？</li>
<li>答：  <strong>现在不知道啊！</strong></li>
<li>Q2：上面我是把所有的 交叉熵 都加在一起 然后对 整个大的损失函数进行调参是这样嘛？ 那我的训练样本应该是 各个数字都有是吗？</li>
<li>答： <strong>现在不知道啊！</strong></li>
</ul>
</blockquote>
<h2 id="Step-3：如何找到一个最好的函数（最佳参数），即调参"><a href="#Step-3：如何找到一个最好的函数（最佳参数），即调参" class="headerlink" title="Step 3：如何找到一个最好的函数（最佳参数），即调参"></a>Step 3：如何找到一个最好的函数（最佳参数），即调参</h2><p>用的还是 <strong>梯度下降法</strong>  </p>
<ol>
<li>随机选取一组参数</li>
<li>输入所有的训练样本</li>
<li>然后样本数据不变，参数不断变，用梯度下降法更新参数</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/72b790c9e1764d88bfef2b9f447c36c3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/24ebb0869baf46e899e8f509d26ba720.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="Backpropagation（反向传播）-来优化调参速度"><a href="#Backpropagation（反向传播）-来优化调参速度" class="headerlink" title="Backpropagation（反向传播） 来优化调参速度"></a>Backpropagation（反向传播） 来优化调参速度</h1><p>神经网络可能有很多个隐层，因此可能有百万数量级的参数，为了在<strong>梯度下降时有效地快速计算梯度</strong>，使用<strong>反向传播</strong>。<br>下图是 使用的损失函数为：交叉熵损失函数 ， 梯度下降法就是对每个参数求偏导，然后根据偏导大小进行左右移动，找到偏导为0的点，就是最佳参数值。</p>
<h2 id="计算对参数偏导的表达式"><a href="#计算对参数偏导的表达式" class="headerlink" title="计算对参数偏导的表达式"></a>计算对参数偏导的表达式</h2><p><img src="https://img-blog.csdnimg.cn/52fb4c86e71843b3b44aec5e596d4324.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>交叉熵损失函数，为 正确值乘以 ln的带入x样本的线性模型 +<br>（1-正确值）乘以ln（1-带入x样本线性模型）<img src="https://img-blog.csdnimg.cn/cf25205ad5354582b0355f3aba098387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>只考虑刚输入阶段的神经元，可以得到用 <em>sigmoid</em>激活函数之前的量 <em>z</em>，而 <em>z</em> 是由线性模型（按权重分配向量 + 偏值 <em>b</em> 得到）。如下图所示，可以看到对参数 w 的偏导可以按照链式法则为  <script type="math/tex">∂C/∂w=∂z/∂w × ∂C/∂z</script>  前项为前项传递，后项为后向传递<br><img src="https://img-blog.csdnimg.cn/0438d1f3d1384270bf8a8abc93a6fe81.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<ul>
<li>前项传递非常好看出来，就是对应的输入值，比如 <code>∂C/∂w1=∂z/∂w1 × ∂C/∂z</code> 。其中<code>∂z/∂w1</code> 看图上所示，不就是对 <em>w1</em> 进行偏导么，那就是 <em>x1</em>。</li>
<li>后项过程比较复杂，根据链式法则，<code>∂C/∂z=∂a/∂z × ∂C/∂a</code>，其中<code>∂a/∂z = σ&#39;(z)</code> 如下图所示<img src="https://img-blog.csdnimg.cn/636c2b53744d478ab268bf80073be7fa.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li>归纳一下得到如下：<img src="https://img-blog.csdnimg.cn/c03a971beb4940cd93cb185b340bf470.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">这个时候我们从另一观点看待上面的式子：有另外一个神经元（下图中的三角形，表示乘法/放大器），input是<code>∂C/∂z</code>‘与<code>∂C/∂z′&#39;</code>  ，权重分别是 <em>w3,w4</em>，求和经过神经元（乘以σ′(z)），得到 <code>∂C/∂z</code>。（相当于反向传播，先线性加权再乘以一个σ′(z) 和正向非常类似）<img src="https://img-blog.csdnimg.cn/6ec05d31b6ed4eb89ab2c5bcc39b6282.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ul>
<h2 id="后项传递-的两种情况"><a href="#后项传递-的两种情况" class="headerlink" title="后项传递 的两种情况"></a>后项传递 的两种情况</h2><p>如上图所示是我们最后得到的后项传递的式子，其中我们还有两个项不知道。那我们现在需要计算这两个部分，但分为两种情况</p>
<h3 id="case-1：下一层是最终输出层"><a href="#case-1：下一层是最终输出层" class="headerlink" title="case 1：下一层是最终输出层"></a>case 1：下一层是最终输出层</h3><p>第一种情况，z′,z′′ 所接的neuron是output layer的neuron。<br>这个就比较简单，直接根据最后一层的输出反向写出即可。<img src="https://img-blog.csdnimg.cn/5683f53fae4b4b619a617d5513159510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="case-2：下一层不是最终输出层"><a href="#case-2：下一层不是最终输出层" class="headerlink" title="case 2：下一层不是最终输出层"></a>case 2：下一层不是最终输出层</h3><p>第二种情况，z′,z′′ 所接的neuron不是output layer的neuron。<img src="https://img-blog.csdnimg.cn/935435dd3b0b435c9ab31388786acd78.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">就上面那个图，我们可以推得类似后项传递的式子<img src="https://img-blog.csdnimg.cn/783ca76c842846efa9b6d89de1a874d9.png#pic_center" alt="在这里插入图片描述">就这样反复迭代(递归)，直到遇到case1的情况，就可以算出整个后项传递。然后结合之前的前项传递，就是我们要得到的对这个参数的偏微分值。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://img-blog.csdnimg.cn/9796822a131546fabd92e1a1bac1a2d1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>梯度下降时需要计算损失函数对每个参数偏微分<code>∂C/∂w</code>，<em>w</em> 代表相邻隐层之间的一条连线（即权值），每个 <em>w</em> 只有一个所指的神经元。</p>
<ul>
<li>链式法则将计算 <code>∂C/∂w</code> 拆成前向过程与后向过程。</li>
<li>前向过程计算的是<code>∂z/∂w</code> ，这里 <em>z</em> 是 <em>w</em> 所指neuron的input，<strong>计算结果是与 <em>w</em> 相连的值。</strong><br>后向过程计算的是<code>∂C/∂z</code>，这里 <em>z</em> 仍是 <em>w</em> 所指neuron的input，计算结果通过从后至前递归得到。</li>
</ul>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>李宏毅</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/%E7%BA%AF%20Mock.js%20%E6%93%8D%E4%BD%9C_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="纯-Mock-js-Vue中的操作"><a href="#纯-Mock-js-Vue中的操作" class="headerlink" title="纯 Mock.js Vue中的操作"></a>纯 Mock.js Vue中的操作</h1><h2 id="步骤1：首先在-src-中创建一个-mock文件夹"><a href="#步骤1：首先在-src-中创建一个-mock文件夹" class="headerlink" title="步骤1：首先在 src 中创建一个 mock文件夹"></a>步骤1：首先在 src 中创建一个 mock文件夹</h2><p>里面创建一个 index.js (什么名称都可以)</p>
<p>比如我们创建如下的本地接口</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 引入 Mock 必须要</span></span><br><span class="line"><span class="keyword">import</span> Mock <span class="keyword">from</span> <span class="string">&#x27;mockjs&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个 数据库 假装是个数据库</span></span><br><span class="line"><span class="keyword">const</span> &#123; newsList &#125; = Mock.mock(&#123;</span><br><span class="line">  <span class="string">&#x27;newsList|50-100&#x27;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">id</span>: <span class="string">&#x27;@increment(1)&#x27;</span>,</span><br><span class="line">      <span class="attr">title</span>: <span class="string">&#x27;@ctitle&#x27;</span>,</span><br><span class="line">      <span class="attr">content</span>: <span class="string">&#x27;@cparagraph&#x27;</span>,</span><br><span class="line">      <span class="attr">image</span>: <span class="string">&quot;@image(&#x27;200x100&#x27;, &#x27;#894FC4&#x27;, &#x27;#FFF&#x27;, &#x27;png&#x27;, &#x27;Yusi&#x27;)&quot;</span>,</span><br><span class="line">      <span class="attr">addtime</span>: <span class="string">&quot;@date(&#x27;yyyy-MM-dd hh:mm:ss&#x27;)&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个post 接口 用于添加数据</span></span><br><span class="line">Mock.mock(<span class="string">&#x27;/api/add/news&#x27;</span>, <span class="string">&#x27;post&#x27;</span>, <span class="function"><span class="params">req</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(req)</span><br><span class="line">  <span class="built_in">console</span>.log(req.body)</span><br><span class="line">  <span class="keyword">const</span> item = <span class="built_in">JSON</span>.parse(req.body)</span><br><span class="line">  <span class="comment">// 你看他这里其实模拟了 数据库的 添加操作</span></span><br><span class="line">  newsList.push(</span><br><span class="line">    Mock.mock(&#123;</span><br><span class="line">      <span class="attr">id</span>: <span class="string">&#x27;@increment(1)&#x27;</span>,</span><br><span class="line">      <span class="attr">title</span>: item.title,</span><br><span class="line">      <span class="attr">content</span>: item.content,</span><br><span class="line">      <span class="attr">image</span>: <span class="string">&quot;@image(&#x27;200x100&#x27;, &#x27;#894FC4&#x27;, &#x27;#FFF&#x27;, &#x27;png&#x27;, &#x27;Yusi&#x27;)&quot;</span>,</span><br><span class="line">      <span class="attr">addtime</span>: <span class="string">&quot;@date(&#x27;yyyy-MM-dd hh:mm:ss&#x27;)&quot;</span></span><br><span class="line">    &#125;)</span><br><span class="line">  )</span><br><span class="line">  <span class="comment">// 返回一个添加成功的信息</span></span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">    <span class="attr">status</span>: <span class="number">201</span>,</span><br><span class="line">    <span class="attr">message</span>: <span class="string">&#x27;新闻创建成功&#x27;</span>,</span><br><span class="line">    <span class="attr">list</span>: newsList,</span><br><span class="line">    <span class="attr">total</span>: newsList.length</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个 接口 用于删除数据</span></span><br><span class="line">Mock.mock(<span class="string">&#x27;/api/remove/news&#x27;</span>, <span class="string">&#x27;post&#x27;</span>, <span class="function"><span class="params">req</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// console.log(req.body)</span></span><br><span class="line">  <span class="keyword">const</span> item = <span class="built_in">JSON</span>.parse(req.body)</span><br><span class="line">  <span class="keyword">const</span> index = newsList.findIndex(<span class="function"><span class="params">x</span> =&gt;</span> x.id === item.id)</span><br><span class="line">  <span class="keyword">if</span> (index !== -<span class="number">1</span>) &#123;</span><br><span class="line">    newsList.splice(index, <span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">    <span class="attr">status</span>: <span class="number">200</span>,</span><br><span class="line">    <span class="attr">message</span>: <span class="string">&#x27;新闻删除成功&#x27;</span>,</span><br><span class="line">    <span class="attr">list</span>: newsList,</span><br><span class="line">    <span class="attr">total</span>: newsList.length</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 模拟一个 get 接口</span></span><br><span class="line">Mock.mock(<span class="string">&quot;/api/feedPost&quot;</span>,<span class="string">&quot;post&quot;</span>,<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;post 拦截&quot;</span>)</span><br><span class="line">    <span class="comment">//返回10条随机数据</span></span><br><span class="line">    <span class="keyword">return</span> Mock.mock(&#123;</span><br><span class="line">        <span class="string">&quot;data|10&quot;</span>:[</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">name</span>:<span class="string">&quot;@cname&quot;</span>,<span class="comment">//随即中文名</span></span><br><span class="line">                <span class="attr">msg</span>:<span class="string">&quot;@cparagraph(2,3)&quot;</span>,<span class="comment">//随机段落</span></span><br><span class="line">                <span class="attr">date</span>:<span class="string">&quot;@datetime&quot;</span>,<span class="comment">//随机日期</span></span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="步骤2：配置-main-js"><a href="#步骤2：配置-main-js" class="headerlink" title="步骤2：配置 main.js"></a>步骤2：配置 main.js</h2><p>在main.js 中你需要 引入刚才创建的文件，并且有引入 axios，我们才能进行访问</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在main.js中导入自定义mock文件</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">&#x27;../mock/index.js&#x27;</span>;  </span><br><span class="line"><span class="comment">// 导入axios 没有./  (axios网络请求工具:1不依赖dom,2.前后端都可以用,3. 丰富拦截,扩展功能,4可封装,复用性强)</span></span><br><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 挂载到vue的全局(原型上),在每个组件都可以使用 ,prototype是固定的,$axios是自定义的</span></span><br><span class="line">Vue.prototype.$axios = axios; </span><br><span class="line"></span><br><span class="line"><span class="comment">//给每个请求拦截一下，添加请求Token信息</span></span><br><span class="line">axios.interceptors.request.use(<span class="function"><span class="keyword">function</span>(<span class="params">config</span>) </span>&#123;</span><br><span class="line">	config.headers.Authorization = <span class="string">&#x27;Bearer &#x27;</span> + <span class="built_in">localStorage</span>.getItem(<span class="string">&quot;token&quot;</span>)</span><br><span class="line">	<span class="keyword">return</span> config</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="步骤3：组件中使用"><a href="#步骤3：组件中使用" class="headerlink" title="步骤3：组件中使用"></a>步骤3：组件中使用</h2><p>你可以在组件中通过 axios 对象，调用接口，例如：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">created</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.getFeed()</span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">methods</span>: &#123;</span><br><span class="line">    <span class="function"><span class="title">getFeed</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        <span class="comment">// 调用挂载在 Vm 上的 $axios 使用get方法，返回一个promise对象</span></span><br><span class="line">        <span class="built_in">this</span>.$axios.get(<span class="string">&quot;/api/feed&quot;</span>)</span><br><span class="line">            .then(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">                <span class="built_in">console</span>.log(res.data)</span><br><span class="line">                <span class="built_in">console</span>.log(res.data.data[<span class="number">0</span>].name)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">this</span>.test = res.data.data[<span class="number">0</span>].name</span><br><span class="line">            &#125;)</span><br><span class="line">            .catch(<span class="function"><span class="params">err</span> =&gt;</span> &#123;</span><br><span class="line">                <span class="built_in">console</span>.error(err)</span><br><span class="line">            &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>目标检测的中的指标的含义及其实现</title>
    <url>/2021/10/04/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E4%B8%AD%E7%9A%84%E6%8C%87%E6%A0%87%E7%9A%84%E5%90%AB%E4%B9%89%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>@<a href="目标检测的中的指标的含义及其实现">TOC</a></p>
<h1 id="Precision和Recall"><a href="#Precision和Recall" class="headerlink" title="Precision和Recall"></a>Precision和Recall</h1><ul>
<li>Precision是查准率、精确率的意思。预测为正的结果中，有多少真正是正样本。</li>
<li>Recall是查全率、召回率的意思。对所有正样本有多少预测出来了。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/cdb0fd90e720fb4261f93aa90c4dd2dc.png#pic_center" alt="举个栗子"><br>用另一个图理解<br><img src="https://img-blog.csdnimg.cn/img_convert/3fb660ada123e26a1f646c9962eefb8e.png#pic_center" alt="在这里插入图片描述"><br>快速记忆 左边这个是TF表示这个结果预测的对不对<br>    右边那个PN表示我预测的是正的还是负的（比如二分类 正的：是这个东西 负的：不是这个东西）<br>注意：这两个量都是：第一是你告诉我是正的里面有多少是对的，第二是关注我对ground truth是正的 也就是实际上就是正的的能力。这两个是相反的关系，一个高另一个就低。<br>比如如下图所示：<br><img src="https://img-blog.csdnimg.cn/img_convert/56443acb4016898926b67ac50eb7052a.png#pic_center" alt="提升评选的标准"><br>提升门槛值，那么也就是对的会越对。门槛值高了嘛，那我正样本预测的就越准的，那么我将负样本预测错误成正样本的概率就低了。所以我的 Precison上升了，但Recall 下降了。</p>
<h1 id="IoU-Intersection-over-Union"><a href="#IoU-Intersection-over-Union" class="headerlink" title="IoU (Intersection over Union)"></a>IoU (Intersection over Union)</h1><p><img src="https://img-blog.csdnimg.cn/img_convert/88aa2935955dddb7556f2dcbd15c4e3e.png#pic_center" alt="IoU示意图"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateIoU</span>(<span class="params">candidateBound, groundTruthBound</span>):</span></span><br><span class="line">    cx1 = candidateBound[<span class="number">0</span>]</span><br><span class="line">    cy1 = candidateBound[<span class="number">1</span>]</span><br><span class="line">    cx2 = candidateBound[<span class="number">2</span>]</span><br><span class="line">    cy2 = candidateBound[<span class="number">3</span>]</span><br><span class="line"> </span><br><span class="line">    gx1 = groundTruthBound[<span class="number">0</span>]</span><br><span class="line">    gy1 = groundTruthBound[<span class="number">1</span>]</span><br><span class="line">    gx2 = groundTruthBound[<span class="number">2</span>]</span><br><span class="line">    gy2 = groundTruthBound[<span class="number">3</span>]</span><br><span class="line"> </span><br><span class="line">    carea = (cx2 - cx1) * (cy2 - cy1) <span class="comment">#C的面积</span></span><br><span class="line">    garea = (gx2 - gx1) * (gy2 - gy1) <span class="comment">#G的面积</span></span><br><span class="line"> </span><br><span class="line">    x1 = <span class="built_in">max</span>(cx1, gx1)</span><br><span class="line">    y1 = <span class="built_in">max</span>(cy1, gy1)</span><br><span class="line">    x2 = <span class="built_in">min</span>(cx2, gx2)</span><br><span class="line">    y2 = <span class="built_in">min</span>(cy2, gy2)</span><br><span class="line">    w = <span class="built_in">max</span>(<span class="number">0</span>, x2 - x1)</span><br><span class="line">    h = <span class="built_in">max</span>(<span class="number">0</span>, y2 - y1)</span><br><span class="line">    area = w * h <span class="comment">#C∩G的面积</span></span><br><span class="line"> </span><br><span class="line">    iou = area / (carea + garea - area)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> iou</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="top1、top5-的含义"><a href="#top1、top5-的含义" class="headerlink" title="top1、top5 的含义"></a>top1、top5 的含义</h1><p>在图像分类中：</p>
<ul>
<li>Top-1 error<br>的意思是：假如模型预测某张动物图片（一只猫）的类别，且模型只输出1个预测结果，那么这一个结果正好能猜出来这个动物是只猫的概率就是Top-1正确率。猜出来的结果不是猫的概率则成为Top-1错误率。简单来说就是模型猜错的概率。</li>
<li>Top-5 error<br>的意思是：假如模型预测某张动物图片（还是刚才那只猫），但模型会输出来5个预测结果，那么这五个结果中有猫这个分类的概率成为Top-5正确率，相反，预测输出的这五个结果里没有猫这个分类的概率则成为Top-5错误率。</li>
</ul>
<p>一般来说，Top-1和Top-5错误率越低，模型的性能也就越好。且Top-5 error 在数值上会比Top-1 error 的数值要小，毕竟从1个结果猜对的几率总会比从5个结果里猜对的几率要小嘛！</p>
<p>在目标检测中：</p>
<ul>
<li>top-1正确率，就是你预测的label取最后概率向量里面最大的那一个作为预测结果，如过你的预测结果中概率最大的那个分类正确，则预测正确，否则预测错误。</li>
<li>top5就是最后概率向量最大的前五名中，只要出现了正确概率即为预测正确。否则预测错误。</li>
</ul>
<h1 id="Average-Precision-AP-与-mAP"><a href="#Average-Precision-AP-与-mAP" class="headerlink" title="Average Precision (AP)与 mAP"></a>Average Precision (AP)与 mAP</h1><p>多个类别目标检测中，每个类别都可以根据recall（召回率）和 percision（准确率）绘制一条曲线。AP就是该曲线下的面积，mAP意思是对每一类的AP再求平均。<br>mAP计算方法：<br>首先我们要先搞明白AP。<br>AP表示 整个的面积<br><img src="https://img-blog.csdnimg.cn/img_convert/56443acb4016898926b67ac50eb7052a.png#pic_center" alt="AP如右图"><br><img src="https://img-blog.csdnimg.cn/img_convert/245a8e1597441fc997ad6b64144a473b.png#pic_center" alt=""><br>我们一般用F1的值来 找到最适合的点  来均衡 Precison 和 Recall。<br>那什么是mAP呢，我们现在讨论的都是 比如预测有1和0，我们是针对1这个正样本。也可以反过来看0作为正样本呢。所以要加起来一起除以总体 数。<br><img src="https://img-blog.csdnimg.cn/img_convert/2d4feb910a3867622ae4e1c6e85d9aa8.png#pic_center" alt="mAP与AP"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络与深度学习 邱锡鹏 学习笔记（机器学习）</title>
    <url>/2021/09/11/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E9%82%B1%E9%94%A1%E9%B9%8F%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%89/</url>
    <content><![CDATA[<p>@<a href="神经网络与深度学习 邱锡鹏 学习笔记（机器学习）">TOC</a></p>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><p>机器学习看作一个从有限、高维、有噪声的数据上得到更一般性规律的泛化问题．<br><img src="https://img-blog.csdnimg.cn/b5f2ae1f8a044527984d6b7a4e1d2190.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="机器学习过程"></p>
<h2 id="机器学习的三个基本要素"><a href="#机器学习的三个基本要素" class="headerlink" title="机器学习的三个基本要素"></a>机器学习的三个基本要素</h2><p><img src="https://img-blog.csdnimg.cn/0e48590c034949c6917b8eeeb555ad30.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_19,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="机器学习三要素"></p>
<ul>
<li>模型</li>
<li>学习准则</li>
<li>优化算法</li>
</ul>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>我们不知道 输入和输出是如何对应联系的，也就是数学函数究竟是什么。 我们假设一个可能的函数集合 $ℱ$ ，称为 假设空间 。 我们根据 观测 各函数在测试集 $𝒟$ 的表现，从中选择更理想的假设模型。<br>常用的假设空间分为 <strong>线性和非线性</strong> 两种</p>
<h2 id="学习准则"><a href="#学习准则" class="headerlink" title="学习准则"></a>学习准则</h2><p>令训练集 是由 $𝑁$ 个独立同分布的样本组成，即每个样本 (𝒙, 𝑦) ∈ 𝒳 × 𝒴 是从 𝒳  和 𝒴  的联合空间中按照某个未知分布 $𝑝_{r}(𝒙, 𝑦)$ 独立地随机产生的 。</p>
<p>学习准则包括：</p>
<ul>
<li>经验风险最小化</li>
<li>结构风险最小化</li>
<li>最大似然估计</li>
<li>最大后验估计</li>
</ul>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>用来量化模型预测和真实标签之间的差异</p>
<h4 id="0-1损失函数"><a href="#0-1损失函数" class="headerlink" title="0-1损失函数"></a>0-1损失函数</h4><h4 id="平方损失函数"><a href="#平方损失函数" class="headerlink" title="平方损失函数"></a>平方损失函数</h4><p>经常用在预测标签 $𝑦$ 为实数值的任务中</p>
<script type="math/tex; mode=display">L(y,f(x;θ)) = \frac{1}{2}(y-f(x;θ))</script><p><strong>平方损失函数一般不适用于分类问题</strong> </p>
<h4 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h4><p>一般用于分类问题</p>
<script type="math/tex; mode=display">L(y,f(x;θ)) =-\sum_{c=1}^{C}y_{c}\log f_{c}(x;θ)</script><p>例如，对于一个三分类的问题，一个样本的标签向量为 $𝒚 = [0, 0, 1]^{T}$，模型预测的标签分布为 $f(x;θ) = [0.3, 0.3, 0.4]^{T}$。<br>则它们的交叉熵为 $−(0 × log(0.3) + 0 ×log(0.3) + 1 × log(0.4)) = − log(0.4)$</p>
<h3 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h3><blockquote>
<p><strong>过拟合</strong><br>模型在训练集上错误率 很低，但是在未知数据上错误率很高，这就是所谓的过拟合。<br>过拟合的 3种 方法： 参数在过拟合之前就停止更新；正则化Regularization；<br>dropout</p>
<p><strong>欠拟合</strong><br>模型不能很好地拟合训练数据，在训练集上的错误率比较高．欠拟合一般是由于模型能力不足造成的。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/0bb493818f134cfe924b74c3f5e9a772.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><h4 id="参数与超参数"><a href="#参数与超参数" class="headerlink" title="参数与超参数"></a>参数与超参数</h4><ul>
<li>参数：模型 𝑓(𝒙; 𝜃)中的 𝜃 称为模型的参数，可以通过优化算法进行学习</li>
<li>超参数：用来定义模型结构或优化策略的。 <font color="blue">常见的超参数有：聚类算法中的类别个数、梯度下降法中的步长、正则化项的系数、神经网络的层数、支持向量机中的核函数等 </font></li>
</ul>
<p>参数的优化一般都是由优化器优化，而超参数优化是机器学习的 一个经验性很强的技术 ，通常是按照人的经验设定，或者通过搜索的方法对一组超参数组合进行不断试错调整。</p>
<h4 id="批量梯度下降法"><a href="#批量梯度下降法" class="headerlink" title="批量梯度下降法"></a>批量梯度下降法</h4><p>缺点在于 局部最优问题<br>用下面的迭代公式来计算计算训练集 𝒟 上风险函数的最小值：<br><img src="https://img-blog.csdnimg.cn/4703fad601d345569a9950cc173f436d.png#pic_center" alt="批量梯度下降法"><br>𝛼 一般称为学习率（Learning Rate）．</p>
<blockquote>
<p>批量梯度下降法在  每次迭代时<strong>需要计算每个样本（也就是所有样本）</strong>上损失函数的梯度并求和。当训练集中的样本数量 𝑁 很大时，空间复杂度比较高，每次迭代的计算开销也很大．</p>
</blockquote>
<h4 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h4><p>缺点在于 局部最优问题，但相比于批量，更容易脱离局部最优</p>
<blockquote>
<p>为了减少每次迭代的计算复杂度，我们也可以在每次迭代时<strong>只采集一个样本</strong>，计算这个样本损失函数的梯度并更新参数，即随机梯度下降法。当经过足够次数的迭代时，随机梯度下降 也可以收敛到局部最优解。<br><img src="https://img-blog.csdnimg.cn/4770f90631bb4ef3aa53847f7242a206.png#pic_center" alt="随机梯度下降法"></p>
<h4 id="小批量梯度下降法"><a href="#小批量梯度下降法" class="headerlink" title="小批量梯度下降法"></a>小批量梯度下降法</h4><p><font color="red">现在 大规模的机器学习 常用这个。</font><br><strong>利用了计算机的并行计算能力</strong><br>每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率。<br><img src="https://img-blog.csdnimg.cn/36fa218d071f4a399d141fa6641232ae.png#pic_center" alt="小批量梯度下降法"></p>
<h1 id="机器学习的简单示例——线性回归"><a href="#机器学习的简单示例——线性回归" class="headerlink" title="机器学习的简单示例——线性回归"></a>机器学习的简单示例——线性回归</h1><p>自变量数量 为1时称为 <strong>简单回归</strong>， 自变量数量大于1时称为 <strong>多元回归</strong>．</p>
<script type="math/tex; mode=display">𝑓(𝒙; 𝒘) = 𝒘^{T}𝒙</script></blockquote>
<h2 id="不明白-先跳过"><a href="#不明白-先跳过" class="headerlink" title="不明白 先跳过"></a>不明白 先跳过</h2><h1 id="偏差-方差分解"><a href="#偏差-方差分解" class="headerlink" title="偏差- 方差分解"></a>偏差- 方差分解</h1><p>其用在，对如何对模型的拟合能力和复杂度之间取得一个良好的平衡，偏差与方差起这很好的分析和指导作用。</p>
<p>对于单个样本 𝒙，不同训练集 𝒟 得到模型 $𝑓_{D}(𝒙)$ 和最优模型 $𝑓^{*}(𝒙)$ 的期望  差距为：<br><img src="https://img-blog.csdnimg.cn/0568101873af46f9ac794e591d7cfb19.png#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>偏差：指一个模型在 <font color="red">不同训练集</font> 上的<strong>平均性能和最优模型的差异</strong>，可以用来衡量一个模型的<strong>拟合能力</strong></li>
<li>方差：一个模型在不同训练集上的差异 ，可以用来衡量一个模型是否容易过拟合 ．</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/99942f3b15814cacbb5dcfb5a53cb056.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_9,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="机器学习模型的四种偏差和方差组合情况"><br>每个图的中心点为<br>最优模型 $𝑓^{*}(𝒙)$，黑点为不同训练集𝐷 上得到的模型 $𝑓_{D}(𝒙)$</p>
<ul>
<li>高偏差<strong>低方差</strong>的情况，表示模型的泛化能力很好，但<strong>拟合能力不足</strong></li>
<li>低偏差<strong>高方差</strong>的情况，表示模型的<strong>拟合能力很好</strong>，但泛化能力比较差．当训练数据比较少时会导致过拟合</li>
</ul>
<p>总结的来看：<br>模型在<strong>训练集</strong>上的错误率比较高时，说明模型的<strong>拟合能力不够</strong>，<strong>偏差比较高</strong>。这种情况可以通过</p>
<ul>
<li>增加数据特征</li>
<li>提高模型复杂度</li>
<li>减小正则化系数</li>
</ul>
<p>模型在训练集上的错误率比较低，但验证集上的错误率比较高时，说明模型过拟合，方差比较高．这种情况可以通过</p>
<ul>
<li>降低模型复杂度</li>
<li>加大正则化系数</li>
<li>引入先验</li>
<li>此外，还有一种有效降低方差的方法为<strong>集成模型</strong>，即通过多个高方差模型的平均来降低方差．</li>
</ul>
<h1 id="学习算法分类"><a href="#学习算法分类" class="headerlink" title="学习算法分类"></a>学习算法分类</h1><p>按照训练样本提供的信息以及反馈方式的不同，将机器学习算法分为以下几类：</p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>机器学习的特征 𝒙 和标签 𝑦 之间可以用 数学模型表示出来，并且训练集中每个样本都有标签。（数据集标签一般都需要由人工进行标注，成本很高）<br>根据标签的类型还可以分为：</p>
<ul>
<li>回归。 标签 𝑦 与 模型的输出 都是连续值</li>
<li>分类。 标签 𝑦 是离散的类别（符号）。这种模型又叫做 分类器 。 分类问题可以分为 二分类 多分类。</li>
<li>结构化学习。 特殊的分类问题。标签 𝒚 通常是结构化的对象，比如序列、树或图等。 由于结构化学习的输出空间比较大，因此我们一般定义一个联合特征空间，将 𝒙 ,  𝒚 映射为该空间中的联合特征向量 𝜙(𝒙, 𝒚)，预测模型可以写为 <img src="https://img-blog.csdnimg.cn/e6f1ad9f44424166b35a7bf4def1dbb4.png#pic_center" alt="在这里插入图片描述"><br>其中 Gen(𝒙) 表示输入 𝒙 的所有可能的输出目标集合．计算 arg max 的过程也称为<strong>解码</strong>（Decoding）过程，一般通过<strong>动态规划</strong>的方法来计算。</li>
</ul>
<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p> 是指从不包含目标标签的训练样本中自动学习到一些有价值的信息。典型的无监督学习问题有 </p>
<ul>
<li>聚类</li>
<li>密度估计</li>
<li>特征学习</li>
<li>降维</li>
</ul>
<h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p> 是一类通过交互来学习的机器学习算法．在强化学习中，智能体根据环境的状态做出一个动作，并得到即时或延时的奖励．智能体在和环境的交互中不断学习并调整策略，以取得最大化的期望总回报．</p>
<h2 id="弱监督和半监督"><a href="#弱监督和半监督" class="headerlink" title="弱监督和半监督"></a>弱监督和半监督</h2><p>弱监督学习和半监督学习的方法，希望从大规模的无标注数据中充分挖掘有用的信息，降低对标注样本数量的要求。</p>
<p>强化学习和监督学习的不同在于，强化学习不需要显式地以“输入/输出对”的方式给出训练样本，是一种在线的学习机制。</p>
<h1 id="数据的特征表示"><a href="#数据的特征表示" class="headerlink" title="数据的特征表示"></a>数据的特征表示</h1><p><img src="https://img-blog.csdnimg.cn/deb2a7eee01647089fa86ebbd5f6acd8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p>需要将这些不同类型的数据转换为向量表示 。</p>
<p>如何选取有效的特征，具体可分为两种：特征选择和特征抽取。 <strong>传统的是和预测模型的学习分离的。</strong></p>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>特征选择就是保留有用特征，移除冗余或无关的特征。<br>方法包括 子集搜索和 L1正则化 </p>
<h3 id="子集搜索"><a href="#子集搜索" class="headerlink" title="子集搜索"></a>子集搜索</h3><ul>
<li>过滤式方法：不依赖具体机器学习模型的特征选择方法。每次增加最有信息量的特征，或删除最没有信息量的特征。</li>
<li>包裹式方法（Wrapper Method）是使用后续机器学习模型的准确率作为评价来选择一个特征子集的方法．每次增加对后续机器学习模型最有用的特征，或删除对后续机器学习任务最无用的特征。</li>
</ul>
<h3 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h3><p>由于 L1 正则化会导致稀疏特征，因此间接实现了特征选择．</p>
<h2 id="特征抽取"><a href="#特征抽取" class="headerlink" title="特征抽取"></a>特征抽取</h2><p> 构造一个新的特征空间，并将原始特征投影在新的空间中得到新的表示。 其方法分为 <strong>有监督和无监督</strong>两类。</p>
<ul>
<li><strong>监督</strong>的特征学习的目标是抽取对一个特定的预测任务最有用的特征，比如线性判别分析。</li>
<li><strong>无监督</strong>的特征学习和具体任务无关，其目标通常是减少冗余信息和噪声，比如<strong>主成分分析PCA</strong>和<strong>自编码器 AE</strong>。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://img-blog.csdnimg.cn/502589206ad64f6898d51126bd9233ba.png#pic_center" alt="传统的特征选择和特征抽取方法"><br>特征选择和特征抽取的优点是可以用较少的特征来表示原始特征中的大部分相关信息，去掉噪声信息，并进而提高计算效率和减小维度灾难。<br>对于很多没有正则化的模型，特征选择和特征抽取非常必要。 经过特征选择或特征抽取后，特征的数量一般会减少，因此特征选择和特征抽取。 也经常称为<strong>维数约减或降维</strong>。</p>
<h1 id="模型的评价指标"><a href="#模型的评价指标" class="headerlink" title="模型的评价指标"></a>模型的评价指标</h1><ul>
<li>准确率（Accuracy）</li>
<li>错误率（Error Rate）： 1 - 准确率</li>
<li>查准率（Precision）</li>
<li>查全率（Recall）</li>
<li>F值（F Measure）</li>
</ul>
<h2 id="如何理解-精确率、召回率和F值"><a href="#如何理解-精确率、召回率和F值" class="headerlink" title="如何理解 精确率、召回率和F值"></a>如何理解 精确率、召回率和F值</h2><p>模型在测试集上的结果可以分为以下四种情况：<br>比如我们现在 预测标签 C</p>
<ul>
<li>真正例（TP）：样本的预测与实际标签相同</li>
<li>假负例（FN）：样本实际标签为C，模型预测错了</li>
<li>假正例（FP）：样本实际标签不是C，但模型预测成C了</li>
<li>真负例（TN）：样本实际为其他类，模型也预测为其他类</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/e157318baff446ce9215cf7854120df2.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="查准率"><a href="#查准率" class="headerlink" title="查准率"></a>查准率</h3><p>类别 𝑐 的查准率  是所有预测为 类别C 的样本中 预测正确  的比例<br>精确率 $P_{C}$ 的计算 公式为：</p>
<script type="math/tex; mode=display">P_{C} = \frac{TP_{c}}{TP_{c}+FP_{c}}</script><h3 id="查全率"><a href="#查全率" class="headerlink" title="查全率"></a>查全率</h3><p>类别𝑐的查全率 是所有真实标签为 类别𝑐 的样本中预测正确的比例：</p>
<script type="math/tex; mode=display">R_{C} = \frac{TP_{c}}{TP_{c}+FN_{c}}</script><h3 id="F值"><a href="#F值" class="headerlink" title="F值"></a>F值</h3><p>F值（F Measure）是一个综合指标，为精确率和召回率的调和平均：</p>
<script type="math/tex; mode=display">F_{C} = \frac{(1+β^{2})×P_{C}×R_{C}}{β^{2}×P_{C}+R_{C}}</script><p>其中 𝛽 用于平衡精确率和召回率的重要性，一般取值为1．𝛽 = 1时的F值称为 <strong>F1 值</strong>，是精确率和召回率的调和平均．</p>
<h2 id="宏平均和微平均"><a href="#宏平均和微平均" class="headerlink" title="宏平均和微平均"></a>宏平均和微平均</h2><p>为了计算分类算法在<strong>所有类别上的总体查准率、查全率和 F1值</strong>，经常使用两种平均方法，分别称为 宏平均 和 微平均</p>
<ul>
<li>宏平均是每一类的性能指标的算术平均值</li>
<li>微平均是每一个样本的性能指标的算术平均值</li>
</ul>
<h1 id="理论和定理"><a href="#理论和定理" class="headerlink" title="理论和定理"></a>理论和定理</h1><h2 id="PAC学习理论："><a href="#PAC学习理论：" class="headerlink" title="PAC学习理论："></a>PAC学习理论：</h2><p>指该学习算法能够在多项式时间内从合理数量的训练数据中学习到一个近似正确的𝑓(𝒙)．</p>
<h2 id="没有免费午餐定理"><a href="#没有免费午餐定理" class="headerlink" title="没有免费午餐定理"></a>没有免费午餐定理</h2><p>没有免费午餐定理   就是不存在一种机器学习算法适合于任何领域或任务。</p>
<h2 id="奥卡姆剃刀原理"><a href="#奥卡姆剃刀原理" class="headerlink" title="奥卡姆剃刀原理"></a>奥卡姆剃刀原理</h2><p>简单的模型泛化能力更好．如果有两个性能相近的模型，我们应该选择<strong>更简单的模型</strong>。<br>因此，在机器学习的学习准则上，我们经常会引入参数正则化来限制模型能力，避免过拟合．</p>
<h2 id="丑小鸭定理"><a href="#丑小鸭定理" class="headerlink" title="丑小鸭定理"></a>丑小鸭定理</h2><p>世界上不存在相似性的客观标准，一切相似性的标准都是主观的</p>
<h2 id="归纳偏置"><a href="#归纳偏置" class="headerlink" title="归纳偏置"></a>归纳偏置</h2><p>预测模型前，先假设。<br>比如在最近邻分类器中，我们会假设在特征空间中，一个小的局部区域中的大部分样本同属一类。<br>在朴素贝叶斯分类器中，我们会假设每个特征的条件概率是互相独立的。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>邱锡鹏</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络与深度学习 学习笔记（第一章）</title>
    <url>/2021/09/10/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%89/</url>
    <content><![CDATA[<p>@<a href="神经网络与深度学习 邱锡鹏 学习笔记（第一章）">TOC</a></p>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="浅层学习"><a href="#浅层学习" class="headerlink" title="浅层学习"></a>浅层学习</h2><blockquote>
<p>学习一个预测模型．一般需要首先将数据表示为一组特征（Feature），特征的表示形式可以是连续的数值、离散的符号或其他形式．然后将这些特征输入到预测模型，并输出预测结果．这类机器学习可以看作浅层学习（Shallow  Learning）</p>
</blockquote>
<h2 id="机器学习的步骤"><a href="#机器学习的步骤" class="headerlink" title="机器学习的步骤"></a>机器学习的步骤</h2><ol>
<li>数据预处理：对数据的原始形式进行初步的数据清理（比如去掉一些有缺失特征的样本，或去掉一些冗余的数据特征等）和加工（对数值特征进行缩放和归一化等），并构建成可用于训练机器学习模型的数据集．</li>
<li>特征提取：从数据的原始特征中提取一些对特定机器学习任务有用的高质量特征．比如在图像分类中提取边缘、尺度不变特征变换（Scale Invariant<br>Feature Transform，SIFT）特征，在文本分类中去除停用词等．</li>
<li>特征转换：对特征进行进一步的加工，比如降维和升维． 很多特征转换方法也都是机器学习方法．降维包括特征抽取（Feature Extraction）和特征选择（FeatureSelection）两种途径．常用的特征转换方法有主成分分析（Principal Components Analysis，PCA）、 线性判别分析（Linear Discriminant Analysis，LDA）等．</li>
<li>预测：机器学习的核心部分，学习一个函数并进行预测．</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/f3d73fb28f1342f48a6ca08638b8da68.png#pic_center" alt="传统机器学习的数据处理流程"><br>注：很多的机器学习问题变成了特征工程（Feature Engineering）问题．开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。</p>
<h1 id="表示学习"><a href="#表示学习" class="headerlink" title="表示学习"></a>表示学习</h1><p>在表示学习中，有两个核心问题：</p>
<ul>
<li>一是“什么是一个好的表示”；即表示 需要包含更高层的语义信息</li>
<li>二是“如何学习到好的表示”．</li>
</ul>
<p>传统的特征学习一般是通过<font color="red">人为地设计一些准则</font>，然后根据这些准则来选取有效的特征。 所以 特征的学习是和最终预测模型的学习分开进行的，<font color="red">因此学习到的特征不一定可以提升最终模型的性能．</font></p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>将输入信息转换为有效的特征。<br>如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫作表示学习（Representation Learning）．</p>
<h2 id="语义鸿沟"><a href="#语义鸿沟" class="headerlink" title="语义鸿沟"></a>语义鸿沟</h2><p>语义鸿沟问题是指输入数据的底层特征和高层语义信息之间的不一致性和差异性。</p>
<blockquote>
<p>比如车，图片中每辆车的颜色和形状等属性都不尽相同，因此不同图片在像素级别上的表示（即底层特征）差异性也会非常大．但是我们理解这些图片是建立在比较抽象的高层语义概念上的</p>
</blockquote>
<h2 id="表示特征的方式"><a href="#表示特征的方式" class="headerlink" title="表示特征的方式"></a>表示特征的方式</h2><ol>
<li>局部表示：例如，one-hot向量 表示颜色。 缺点在于多个颜色就多个列或者行 </li>
<li>分布式表示：RGB 表示颜色</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/aa86242673364da09f8245d248914cbd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="局部表示和分布式表示示例"></p>
<h2 id="嵌入"><a href="#嵌入" class="headerlink" title="嵌入"></a>嵌入</h2><p>嵌入通常指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系．<font color="blue">比如自然语言中词的分布式表示，也经常叫作词嵌入 </font></p>
<p><font color="red"><strong>例如：3维one-hot向量空间和一个2维嵌入空间的对比</strong></font><br><img src="https://img-blog.csdnimg.cn/007e99163fd044348e7061ebebc1af33.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAamtzODg5OTU2NTY=,size_14,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="one-hot向量空间与嵌入空间"><br>在低维的嵌入空间中，每个样本都不在坐标轴上，样本之间可以计算相似度．</p>
<h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="什么是深度"><a href="#什么是深度" class="headerlink" title="什么是深度"></a>什么是深度</h2><p>“深度”是指原始数据进行非线性特征转换的次数</p>
<h2 id="深度学习的优点"><a href="#深度学习的优点" class="headerlink" title="深度学习的优点"></a>深度学习的优点</h2><p>深度学习，其主要目的是从数据中<font color="red">自动学习到有效的特征表示 </font><br>其抽象在 数据通过多层的特征转换，学习到的表示可以代替人工设计的特征，从而避免“特征工程”<br><img src="https://img-blog.csdnimg.cn/f678fb27e01c4d989d099cfa06afe038.png#pic_center" alt="深度学习的数据处理流程"><br>其是 一种 <font color="red"><strong>端到端的学习方式</strong></font>   在学习过程中<strong>不进行分模块或分阶段训练</strong>，直接优化任务的总体目标．在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预</p>
<h2 id="深度学习的关键问题"><a href="#深度学习的关键问题" class="headerlink" title="深度学习的关键问题"></a>深度学习的关键问题</h2><p>深度学习需要解决的关键问题是 <strong>贡献度分配问题</strong>，即一个系统中不同的 <strong>组件</strong> 或其 <strong>参数</strong> 对最终系统输出结果的贡献或影响 </p>
<p>目前，深度学习采用的模型主要是神经网络模型，其主要原因是神经网络模型可以使用 <strong>误差反向传播算法</strong> ，从而可以比较好地解决贡献度分配问题</p>
<h1 id="深度学习相关的学术会议"><a href="#深度学习相关的学术会议" class="headerlink" title="深度学习相关的学术会议"></a>深度学习相关的学术会议</h1><ul>
<li>国际表示学习会议  ICLR ：主要聚焦于深度学习</li>
<li>神经信息处理系统年会 NeurIPS ：交叉学科会议，但偏重于机器学习</li>
<li>国际机器学习会议 ICML：机器学习顶级会议</li>
<li>国际人工智能联合会议 IJCAI ：人工智能领域最顶尖的综合性会议</li>
<li>美国人工智能协会年会  AAAI ：人工智能领域的顶级会议</li>
</ul>
<h2 id="计算机视觉领域"><a href="#计算机视觉领域" class="headerlink" title="计算机视觉领域"></a>计算机视觉领域</h2><ul>
<li>计算机视觉与模式识别大会  CVPR</li>
<li>国际计算机视觉会议  ICCV</li>
</ul>
<h2 id="自然语言处理领域"><a href="#自然语言处理领域" class="headerlink" title="自然语言处理领域"></a>自然语言处理领域</h2><ul>
<li>计算语言学年会 ACL</li>
<li>自然语言处理实证方法大会  EMNLP</li>
</ul>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>邱锡鹏</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>针对 VOC2007和VOC2012 的具体用法</title>
    <url>/2021/11/01/%E9%92%88%E5%AF%B9%20VOC2007%E3%80%81VOC2012%E5%92%8CCOCO%20%E7%9A%84%E5%85%B7%E4%BD%93%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<p>@<a href="针对 VOC2007、VOC2012和COCO 的具体用法">TOC</a></p>
<p>目前广大研究者们普遍使用的是 VOC2007和VOC2012数据集，因为二者是互斥的，不相容的。</p>
<p>论文中针对 VOC2007和VOC2012 的具体用法有以下几种：</p>
<ul>
<li>只用VOC2007的trainval 训练，使用VOC2007的test测试。</li>
<li>只用VOC2012的trainval 训练，使用VOC2012的test测试，这种用法很少使用，因为大家都会结合VOC2007使用。</li>
<li>使用 VOC2007 的 train+val 和 VOC2012的 train+val 训练，然后使用 VOC2007的test测试，这个用法是论文中经常看到的 <strong>07+12</strong> ，研究者可以自己测试在VOC2007上的结果，因为VOC2007的test是公开的。</li>
<li>使用 VOC2007 的 train+val+test 和 VOC2012的 train+val训练，然后使用 VOC2012的test测试，这个用法是论文中经常看到的 <strong>07++12</strong> ，这种方法需提交到VOC官方服务器上评估结果，因为VOC2012 test没有公布。</li>
<li>先在 MS COCO 的 trainval 上预训练，再使用 VOC2007 的 train+val、 VOC2012的 train+val 微调训练，然后使用 VOC2007的test测试，这个用法是论文中经常看到的 <strong>07+12+COCO</strong> 。</li>
<li>先在 MS COCO 的 trainval 上预训练，再使用 VOC2007 的 train+val+test 、 VOC2012的 train+val 微调训练，然后使用 VOC2012的test测试 ，这个用法是论文中经常看到的 <strong>07++12+COCO</strong>，这种方法需提交到VOC官方服务器上评估结果，因为VOC2012 test没有公布。</li>
</ul>
<h1 id="代码分离-VOC训练集-的-val-和-train-数据"><a href="#代码分离-VOC训练集-的-val-和-train-数据" class="headerlink" title="代码分离 VOC训练集 的 val 和 train 数据"></a>代码分离 VOC训练集 的 val 和 train 数据</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">anchors =[<span class="number">0.57273</span>, <span class="number">0.677385</span>, <span class="number">1.87446</span>, <span class="number">2.06253</span>, <span class="number">3.33843</span>, <span class="number">5.47434</span>, <span class="number">7.88282</span>, <span class="number">3.52778</span>, <span class="number">9.77052</span>, <span class="number">9.16828</span>]</span><br><span class="line">anchors = np.array(anchors).reshape(-<span class="number">1</span>, <span class="number">2</span>) <span class="comment">#(5,2)</span></span><br><span class="line">input_shape = (<span class="number">416</span>, <span class="number">416</span>)</span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line">colors = [[<span class="number">255</span>,<span class="number">0</span>,<span class="number">255</span>],[<span class="number">218</span>,<span class="number">112</span>,<span class="number">214</span>],[<span class="number">100</span>,<span class="number">149</span>,<span class="number">237</span>],[<span class="number">95</span>,<span class="number">158</span>,<span class="number">160</span>],[<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>],[<span class="number">0</span>,<span class="number">255</span>,<span class="number">127</span>],[<span class="number">107</span>,<span class="number">142</span>,<span class="number">35</span>],</span><br><span class="line">        [<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>],[<span class="number">184</span>,<span class="number">134</span>,<span class="number">11</span>],[<span class="number">255</span>,<span class="number">165</span>,<span class="number">0</span>],[<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">224</span>,<span class="number">255</span>,<span class="number">255</span>],[<span class="number">70</span>,<span class="number">130</span>,<span class="number">180</span>],[<span class="number">255</span>,<span class="number">192</span>,<span class="number">203</span>],[<span class="number">255</span>,<span class="number">240</span>,<span class="number">245</span>],[<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>],</span><br><span class="line">        [<span class="number">240</span>,<span class="number">128</span>,<span class="number">128</span>],[<span class="number">220</span>,<span class="number">220</span>,<span class="number">220</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">169</span>,<span class="number">169</span>,<span class="number">169</span>]]</span><br><span class="line">VOCdevkit_path = <span class="string">&#x27;./VOCdevkit&#x27;</span></span><br><span class="line">classes = [<span class="string">&#x27;aeroplane&#x27;</span>,<span class="string">&#x27;bicycle&#x27;</span>,<span class="string">&#x27;bird&#x27;</span>,<span class="string">&#x27;boat&#x27;</span>,<span class="string">&#x27;bottle&#x27;</span>,<span class="string">&#x27;bus&#x27;</span>,<span class="string">&#x27;car&#x27;</span>,<span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;chair&#x27;</span>,<span class="string">&#x27;cow&#x27;</span>,<span class="string">&#x27;diningtable&#x27;</span>,<span class="string">&#x27;dog&#x27;</span>,<span class="string">&#x27;horse&#x27;</span>,<span class="string">&#x27;motorbike&#x27;</span>,<span class="string">&#x27;person&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;pottedplant&#x27;</span>,<span class="string">&#x27;sheep&#x27;</span>,<span class="string">&#x27;sofa&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;tvmonitor&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把数据集拆分成训练和测试集两部分</span></span><br><span class="line"><span class="comment"># 分别保存在 train.txt 和 val.txt 中</span></span><br><span class="line"><span class="comment"># 把数据集拆分成训练和测试集两部分</span></span><br><span class="line"><span class="comment"># 分别保存在val.txt和train.txt中</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> classes,VOCdevkit_path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">VOCdevkit_sets = [(<span class="string">&#x27;2012&#x27;</span>, <span class="string">&#x27;train&#x27;</span>), (<span class="string">&#x27;2012&#x27;</span>, <span class="string">&#x27;val&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_annotation</span>(<span class="params">year, image_id, list_file</span>):</span></span><br><span class="line">    in_file = <span class="built_in">open</span>(os.path.join(VOCdevkit_path, <span class="string">&#x27;VOC%s/Annotations/%s.xml&#x27;</span> % (year, image_id)), encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    tree = ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.<span class="built_in">iter</span>(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        difficult = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> obj.find(<span class="string">&#x27;difficult&#x27;</span>) != <span class="literal">None</span>:</span><br><span class="line">            difficult = obj.find(<span class="string">&#x27;difficult&#x27;</span>).text</span><br><span class="line">        cls = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">not</span> <span class="keyword">in</span> classes <span class="keyword">or</span> <span class="built_in">int</span>(difficult) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        b = (<span class="built_in">int</span>(<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmin&#x27;</span>).text)), <span class="built_in">int</span>(<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymin&#x27;</span>).text)),</span><br><span class="line">             <span class="built_in">int</span>(<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmax&#x27;</span>).text)), <span class="built_in">int</span>(<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymax&#x27;</span>).text)))</span><br><span class="line">        list_file.write(<span class="string">&quot; &quot;</span> + <span class="string">&quot;,&quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> b]) + <span class="string">&#x27;,&#x27;</span> + <span class="built_in">str</span>(cls_id))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    random.seed(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> year, image_set <span class="keyword">in</span> VOCdevkit_sets:  <span class="comment">#[(&#x27;2012&#x27;, &#x27;train&#x27;), (&#x27;2012&#x27;, &#x27;val&#x27;)]</span></span><br><span class="line">        image_ids = <span class="built_in">open</span>(os.path.join(VOCdevkit_path, <span class="string">&#x27;VOC%s/ImageSets/Main/%s.txt&#x27;</span> % (year, image_set)),</span><br><span class="line">                         encoding=<span class="string">&#x27;utf-8&#x27;</span>).read().strip().split()</span><br><span class="line">        <span class="built_in">print</span>(image_ids)</span><br><span class="line">        list_file = <span class="built_in">open</span>(<span class="string">&#x27;%s_%s.txt&#x27;</span> % (year, image_set), <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">            list_file.write(<span class="string">&#x27;%s/VOC%s/JPEGImages/%s.jpg&#x27;</span> % (os.path.abspath(VOCdevkit_path), year, image_id))</span><br><span class="line">            convert_annotation(year, image_id, list_file)</span><br><span class="line">            list_file.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        list_file.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>数据集</tag>
      </tags>
  </entry>
  <entry>
    <title>逻辑回归 Logistic Regression</title>
    <url>/2021/08/05/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%20Logistic%20Regression/</url>
    <content><![CDATA[<p>@<a href="逻辑回归问题 Logistic Regression">TOC</a></p>
<p><strong>逻辑回归需要明白的几个问题？</strong></p>
<p>1、逻辑回归(Logistics Regression) 与 线性回归(Linear Regression)的区别在哪<br><img src="https://img-blog.csdnimg.cn/d50c9e51dfae4dadba381f980f05752a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>2、生成模型(Generative Model) 与 判别模型(Discriminative Model）的区别在哪</p>
<ul>
<li>生成模型就是要学习 x 和 y 的联合概率分布 <em>P(x,y)</em>，然后根据贝叶斯公式来求得条件概率 <em>P(y|x)</em>，预测条件概率最大的 y。</li>
<li>判别模型就是直接学习条件概率分布 <em>P(y|x)</em>。</li>
</ul>
<p>3、逻辑回归(Logistics Regression) 与  深度学习（ VS Deep Learning）<br>逻辑回归具有缺陷，需要做特征工程来转变特征，但是这个人为步骤非常麻烦，所以引入了深度学习。</p>
<h1 id="逻辑回归与线性回归"><a href="#逻辑回归与线性回归" class="headerlink" title="逻辑回归与线性回归"></a>逻辑回归与线性回归</h1><h2 id="什么是逻辑回归？"><a href="#什么是逻辑回归？" class="headerlink" title="什么是逻辑回归？"></a>什么是逻辑回归？</h2><ul>
<li>逻辑回归是<strong>解决分类问题的一种算法</strong></li>
<li>它与 <strong>线性模型</strong> 形式上有点像（本质上是在线性模型外面“裹”一个<strong>sigmoid激活函数</strong>，来表示概率的函数）</li>
<li>它是一种<strong>判别模型</strong>，与前面说的生成模型不同</li>
<li>它是深度学习的基础</li>
</ul>
<h2 id="对比逻辑回归与线性回归"><a href="#对比逻辑回归与线性回归" class="headerlink" title="对比逻辑回归与线性回归"></a>对比逻辑回归与线性回归</h2><h3 id="区别一：模型不同"><a href="#区别一：模型不同" class="headerlink" title="区别一：模型不同"></a>区别一：模型不同</h3><p>本质上是在线性模型外面“裹”一个<strong>sigmoid激活函数</strong>，来表示概率的函数<br><img src="https://img-blog.csdnimg.cn/559dca41ef354a65b9e73ad4d8bb8222.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2c3580835cbe4497a28537f12f972bf9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>总结的来看<img src="https://img-blog.csdnimg.cn/e591d052433d421da59cc20086e67959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="区别二：损失函数Loss不同"><a href="#区别二：损失函数Loss不同" class="headerlink" title="区别二：损失函数Loss不同"></a>区别二：损失函数Loss不同</h3><p><strong>逻辑回归的</strong><br><img src="https://img-blog.csdnimg.cn/81b9e6bbaf8743c8811b04dab97ae6cd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>为什么似然函数最大，参数就越有可能，越合理？</strong><br>最大似然估计：现在已经拿到了很多个样本（你的数据集中所有因变量），这些样本值已经实现，最大似然估计就是去找到那个（组）参数估计值，使得前面已经实现的样本值发生概率最大。因为你手头上的样本已经实现了，其发生概率最大才符合逻辑。这时是求样本所有观测的联合概率最大化，是个连乘积，只要取对数，就变成了线性加总。此时通过对参数求导数，并令一阶导数为零，就可以通过解方程（组），得到最大似然估计值。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/d853c71170e743b58d68534399dbcd5a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/09f5eac31e1e4c90a1ca26b713423f2c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>总结一下：</strong><br><img src="https://img-blog.csdnimg.cn/c1c93acf9e1a46f9b6b3d821a168ebdf.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>问题：为什么逻辑回归不采用线性回归的差平方来做？<br>例如，其实目前离目标点还很远，但梯度已经为0了，这显然不合理。<img src="https://img-blog.csdnimg.cn/2dee2450c8d34bf1b56a4e5c8d305db9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="区别三：如何调参的方式是一致的"><a href="#区别三：如何调参的方式是一致的" class="headerlink" title="区别三：如何调参的方式是一致的"></a>区别三：如何调参的方式是一致的</h3></blockquote>
<ul>
<li><strong>化简逻辑回归损失函数左侧部分</strong><br><img src="https://img-blog.csdnimg.cn/5a911af3aeb7475b832369858f503b7f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li><strong>化简逻辑回归右侧部分</strong><img src="https://img-blog.csdnimg.cn/c627e39a6c9348d0a3e81c0099430536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li>化简，调参如下<img src="https://img-blog.csdnimg.cn/ccfda49ca7004f8f87fc76f238dd5337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><img src="https://img-blog.csdnimg.cn/771e437cc99945d8b884f331f09132eb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ul>
<h1 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h1><h2 id="什么是生成模型和判别模型？"><a href="#什么是生成模型和判别模型？" class="headerlink" title="什么是生成模型和判别模型？"></a>什么是生成模型和判别模型？</h2><p><strong>从本质上讲，生成模型和判别模型是解决分类问题的两类基本思路 。</strong><br><em>分类问题，就是给定一个数据 x，要判断它对应的所属标签 y</em></p>
<ul>
<li>生成模型就是要学习 x 和 y 的联合概率分布 <em>P(x,y)</em>，然后根据贝叶斯公式来求得条件概率 <em>P(y|x)</em>，预测条件概率最大的 y。</li>
<li>判别模型就是直接学习条件概率分布 <em>P(y|x)</em>。</li>
</ul>
<h2 id="两种模型案例-举个栗子？"><a href="#两种模型案例-举个栗子？" class="headerlink" title="两种模型案例 举个栗子？"></a>两种模型案例 举个栗子？</h2><blockquote>
<p>栗子1：<br>假设你从来没有见过大象和猫，连听都没有听过，这时，给你看了一张大象的照片和一张猫的照片。<br><strong>Q : 你看过之后，有人牵了一头真的大象过来，问你只是大象还是猫？</strong></p>
<ul>
<li>用<strong>判别模型</strong>的思路回答：你回想刚才看过的照片，大象比猫很明显有个长鼻子，所以眼前这个有着长鼻子的动物就是大象。</li>
<li><p>用<strong>生成模型</strong>的思路回答：你回想刚才看过的照片，然后用笔把它们画在了纸上，拿着纸和我家的大象做比较，你发现，眼前的动物更像是大象。</p>
<p>第一个解决问题的思路就是判别模型，<strong>因为你只记住了大象和猫之间的不同之处</strong>。第二个解决问题的思路就是生成模型，因为你<strong>实际上学习了什么是大象，什么是猫</strong>。</p>
</li>
</ul>
<p>栗子2：<br>有四个形式为(x,y)的样本。(1,0), (1,0), (2,0), (2,1）。假设，我们想从这四个样本中，<strong>学习到如何通过x判断y的模型</strong>。</p>
<ul>
<li>用生成模型，我们要学习 <em>P(x,y)</em>。如下所示：<img src="https://img-blog.csdnimg.cn/b435c974485141b1a36542a5c933ac01.png#pic_center" alt="在这里插入图片描述">我们学习到了四个概率值，它们的总和是1，这就是联合分布律P(x,y)。（因为这是离散的，连续的话叫联合概率密度）<ul>
<li>用判别模型，我们要学习 <em>P(y|x)</em>，如下所示：<img src="https://img-blog.csdnimg.cn/4bde84a64231412d951a1c7c31d180f1.png#pic_center" alt="在这里插入图片描述">因为这是条件分布律，每一行概率值相加都为1。</li>
</ul>
</li>
</ul>
<p><strong>Q : 当 <em>x=1</em> 时，请问 <em>y</em> 是 <em>0</em> 还是 <em>1</em> 呢？</strong></p>
<ul>
<li>用<strong>生成模型</strong>，我们会比较<br>P(x=1,y=0) = 1/2<br>P(x=1,y=1) = 0<br>我们发现 <em>P(x=1,y=0)</em>的概率要比 <em>P(x=1,y=1)</em>的概率大，所以，我们判断：<em>x=1时，y=0</em>。</li>
<li><p>用<strong>判别模型</strong>，我们会比较：<br>P(y=0|x=1) = 1<br>P(y=1|x=1) = 0<br>同样，<em>P(y=0|x=1)</em> 要比 <em>P(y=1|x=1)</em>大，所以，我们判断：<em>x=1时，y=0</em>。</p>
<p>我们看到，虽然最后预测的结果一样，但是得出结果的逻辑却是完全不同的。</p>
</li>
</ul>
</blockquote>
<h2 id="生成模型为啥叫生成模型？"><a href="#生成模型为啥叫生成模型？" class="headerlink" title="生成模型为啥叫生成模型？"></a>生成模型为啥叫生成模型？</h2><p>生成模型之所以叫生成模型，是因为：<br>它背后的思想是，x是特征，y是标签，什么样的标签就会生成什么样的特征。好比说，标签是大象，那么可能生成的特征就有大耳朵，长鼻子等等。<br>当我们来根据x来判断y时，我们实际上是在比较，<strong>什么样的y标签更可能生成特征x，我们预测的结果就是更可能生成x特征的y标签</strong>。</p>
<h2 id="为什么一般来说，判别模型表现得会比生成模型好？"><a href="#为什么一般来说，判别模型表现得会比生成模型好？" class="headerlink" title="为什么一般来说，判别模型表现得会比生成模型好？"></a>为什么一般来说，判别模型表现得会比生成模型好？</h2><p>我们举一个栗子，现在有Class1 和 Class2 两类数据。现在训练集数据如图所示：<img src="https://img-blog.csdnimg.cn/bd00dca74d524c1a83b9b90bb3745fcf.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>Q : 问请问如下的测试集，他是应该属于Class1 还是 Class2 呢？</strong><img src="https://img-blog.csdnimg.cn/a1ee9138baba426883e87dcd9b3f2358.png#pic_center" alt="在这里插入图片描述"><br>我们这边用判别模型来计算，算出如下图所示的数据：<img src="https://img-blog.csdnimg.cn/3f0b16520085492da2e7639d2646130c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>然后用贝叶斯公式算出 <em>P(C1 | x)</em> ，就是当x1和x2全为1 的情况下的概率是多少。<img src="https://img-blog.csdnimg.cn/a6f8b3138add4e2bbb548322591e0584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>算出的结果是 <em>＜ 0.5</em> 的，但从我们人的角度看，其实应该是属于Class1的，因为Class2里面压根就没有x1，x2同时为1的存在。<strong>这是为什么呢？因为我们的样本太少了，用判别模型是可以帮助我们在有限的数据样本中假象数据。</strong></p>
<blockquote>
<p><strong>那用生成模型怎么做呢？</strong></p>
</blockquote>
<p>所以判别模型的优势在于</p>
<ol>
<li>样本量少的时候表现比判别模型好，因为它能自己脑补出一个假想模型</li>
<li>噪声对它影响较小，因为它没有过分依赖数据，它是按照自己假想模型走的</li>
</ol>
<h2 id="常见的生成模型和判别模型有哪些呢？"><a href="#常见的生成模型和判别模型有哪些呢？" class="headerlink" title="常见的生成模型和判别模型有哪些呢？"></a>常见的生成模型和判别模型有哪些呢？</h2><p>生成模型</p>
<ul>
<li>HMM（隐马尔可夫模型）</li>
<li>朴素贝叶斯</li>
</ul>
<p>判别模型</p>
<ul>
<li>逻辑回归</li>
<li>SVM（支持向量机）</li>
<li>CRF（条件随机场）</li>
<li>最近邻</li>
<li>一般的神经网络</li>
</ul>
<h1 id="逻辑回归与深度学习"><a href="#逻辑回归与深度学习" class="headerlink" title="逻辑回归与深度学习"></a>逻辑回归与深度学习</h1><h2 id="逻辑回归解决多分类问题"><a href="#逻辑回归解决多分类问题" class="headerlink" title="逻辑回归解决多分类问题"></a>逻辑回归解决多分类问题</h2><p>逻辑回归是解决分类问题的，实际中的问题大多是多分类的问题，多分类问题会用到softmax。 <em>逻辑回归其实就是线性回归在外面加了个sigmoid激活函数（二分类）或者softmax激活函数（多分类）。</em></p>
<blockquote>
<p><strong>sigmoid激活函数 和 softmax函数的区别：</strong><br>通常在<strong>二分类</strong>中使用<strong>sigmoid作为最后的激活层</strong>。在<strong>多分类</strong>单标签中使用<strong>softmax作为激活层</strong>，取概率最高即可。多标签问题中使用sigmoid作为激活层，相当于把每一个类别都当成了二分类来处理。<img src="https://img-blog.csdnimg.cn/52837028507c423c97e4ba53a831270d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>多分类问题解决<br><img src="https://img-blog.csdnimg.cn/f92fa56ec4154bf687f88bc0192dcb08.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/b674d12040f14c7dacc30b4a19f3af0b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="逻辑回归的局限性"><a href="#逻辑回归的局限性" class="headerlink" title="逻辑回归的局限性"></a>逻辑回归的局限性</h2><p><img src="https://img-blog.csdnimg.cn/d1fd15ed70b44e689619a1dfecaed0f4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<h2 id="用深度学习去解决这个问题"><a href="#用深度学习去解决这个问题" class="headerlink" title="用深度学习去解决这个问题"></a>用深度学习去解决这个问题</h2><p><img src="https://img-blog.csdnimg.cn/23f73c28c3f54fa19624a03839a18958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>这个怎么变换过来的啊？</strong><br>是需要用特征工程的方法的，而特征工程是需要我们人为地去建立一个特征函数去把这些点转化，<strong>实际上是比较难的</strong>，或者说比较费工夫的<br>这个时候我们需要引入 <strong>深度学习</strong><br><img src="https://img-blog.csdnimg.cn/39cb9b68112d48e384f6958820a041c9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>逻辑回归</tag>
        <tag>李宏毅</tag>
        <tag>机器学习</tag>
        <tag>分类问题</tag>
      </tags>
  </entry>
  <entry>
    <title>线性回归Regression 案例一：宝可梦进化CP值</title>
    <url>/2021/07/31/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92Regression%20%E6%A1%88%E4%BE%8B%E4%B8%80%EF%BC%9A%E5%AE%9D%E5%8F%AF%E6%A2%A6%E8%BF%9B%E5%8C%96CP%E5%80%BC/</url>
    <content><![CDATA[<p>@<a href="线性回归Regression 案例一：宝可梦进化CP值">TOC</a></p>
<blockquote>
<p>本栗子：预测Pokemon精灵攻击力。<br>输入：进化前的CP值、物种（Bulbasaur）、血量（HP）、重量（Weight）、高度（Height）<br>输出：进化后的CP值</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/img_convert/d53b2b95d30c7af9574c7a0bbaba2c82.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="实现回归的步骤（机器学习的步骤）"><a href="#实现回归的步骤（机器学习的步骤）" class="headerlink" title="实现回归的步骤（机器学习的步骤）"></a>实现回归的步骤（机器学习的步骤）</h1><h2 id="Step1-确定一个model-线性模型"><a href="#Step1-确定一个model-线性模型" class="headerlink" title="Step1 确定一个model - 线性模型"></a>Step1 确定一个model - 线性模型</h2><blockquote>
<p>输入的特征包括：进化前的CP值（<em>Xcp</em>）、物种（Bulbasaur）（<em>Xs</em>）、血量（HP）（<em>Xhp</em>）、重量（Weight）（<em>Xw</em>）、高度（Height）（<em>Xh</em>）</p>
</blockquote>
<p>先从简单的<strong>单个特征</strong> 进化前的CP值（<em>Xcp</em>）开始（<strong>后面改进再考虑多个特征</strong>）。<br><img src="https://img-blog.csdnimg.cn/img_convert/5b4df493600379c7aa0372e103eb7d79.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="Step2-goodness-of-function（函数优化）——损失函数"><a href="#Step2-goodness-of-function（函数优化）——损失函数" class="headerlink" title="Step2 goodness of function（函数优化）——损失函数"></a>Step2 goodness of function（函数优化）——损失函数</h2><ol>
<li>确定model后（案例为线性模型），开始训练数据（使用的为训练样本集）<img src="https://img-blog.csdnimg.cn/img_convert/ebd00bf7bee79841d6c35eac2865fd61.png#pic_center" alt="在这里插入图片描述"></li>
<li>训练10个训练样本后得到10个的预测进化CP值（<em>y</em>）如下图所示。左侧为训练样本本身真实的进化CP值，右侧为横轴为进化前CP值（<em>Xcp</em>）<img src="https://img-blog.csdnimg.cn/img_convert/fbba4351217b730cd11ca92a7427cd51.png#pic_center" alt="在这里插入图片描述"></li>
<li><strong>确定损失函数</strong>。损失函数用于评价一个模型的好坏。损失函数的值越小，那么模型越好。<strong>对于本案例，损失函数采用最简单的距离表示</strong>。即求<strong>实际进化后的CP值与模型预测的CP值差</strong>，来判定模型的好坏。<img src="https://img-blog.csdnimg.cn/img_convert/3abae7108681dbad20cc15a952d20bba.png#pic_center" alt="在这里插入图片描述"><ol>
<li>List item</li>
</ol>
</li>
</ol>
<h2 id="Step3-best-function（找出最好的一个函数-即调参）——使用梯度下降法"><a href="#Step3-best-function（找出最好的一个函数-即调参）——使用梯度下降法" class="headerlink" title="Step3 best function（找出最好的一个函数 即调参）——使用梯度下降法"></a>Step3 best function（找出最好的一个函数 即调参）——使用梯度下降法</h2><ol>
<li>案例采用<strong>梯度下降法</strong>来帮助选择 <em>w</em> 和 <em>b</em> 两个参数取何值时损失函数最小，也就意味着构建的模型越准确。 <img src="https://img-blog.csdnimg.cn/img_convert/7d75962cbe0b2dc3c54f370383912138.png#pic_center" alt="在这里插入图片描述"><blockquote>
<p>什么是梯度下降法？梯度指的是？<br>………………………………………………………………………………………………………<br>梯度？<br>在<strong>单变量的函数</strong>中，梯度其实就是对应点<strong>函数的微分</strong>，代表着这个函数在<strong>某个给定点的切线的斜率</strong><br>在<strong>多变量函数</strong>中，梯度是一个<strong>向量</strong>，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向  <strong>即例如二维就是 偏导 i + 偏导 j</strong><br>………………………………………………………………………………………………………<br>梯度下降法(SGD  Stochastic gradient descent）？答： “下山最快路径”的一种算法<br>我们是尝试使用偏导来衡量函数随自变量的值变化关系，选择变化更为平缓的那一处  对应的 <em>w</em> 和 <em>b</em> 作为调整后的参数</p>
</blockquote>
</li>
</ol>
<h3 id="一维视角：只考虑一个参数-w"><a href="#一维视角：只考虑一个参数-w" class="headerlink" title="一维视角：只考虑一个参数 w"></a>一维视角：只考虑一个参数 <em>w</em></h3><p><img src="https://img-blog.csdnimg.cn/3c72961665a942ac87f066a129a30183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>如上图  learning rate（学习率）：移动的步长 一般用η来表示<br>………………………………………………………………………………………………………<br>如何寻找一个最合适的 <em>w</em> ？<br>步骤1：随机在横轴上选取一个 <em>w0</em> 。<br>步骤2：计算微分，也就是当前的斜率，根据斜率来判定移动的方向。微分大于0应向右移动（增加 <em>w</em> ）；微分小于0向左移动（减少 <em>w</em> ）<br>步骤3：根据学习率，按步骤2得到的方向移动<br>重复步骤2和步骤3，直到找到<strong>最低点</strong>。横轴即对于的最佳 <em>w</em>  参数<br>………………………………………………………………………………………………………<br>如下图，是经过迭代多次后找到的最佳点（得是全局最优解） 。注：大部分损失函数都为正<br><img src="https://img-blog.csdnimg.cn/588186b690dd43c38a10a80600802ab0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="二维视角：考虑两个参数-w-和-b"><a href="#二维视角：考虑两个参数-w-和-b" class="headerlink" title="二维视角：考虑两个参数 w 和 b"></a>二维视角：考虑两个参数 <em>w</em> 和 <em>b</em></h3><p><img src="https://img-blog.csdnimg.cn/55f2f295750242bfa35f9ac576602194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如何寻找一个最合适的 <em>w</em> ？<br>步骤1：随机在横轴上选取一个 <em>w0</em> ，<em>b0</em> 。<br>步骤2：计算各偏导，也就是当前偏导的斜率，根据斜率来判定移动的方向。微分大于0应向右移动（增加 <em>w</em> 或 <em>b</em>）；微分小于0向左移动（减少 <em>w</em> 或 <em>b</em>）<img src="https://img-blog.csdnimg.cn/6a082b40869947c2a0723b298cd36027.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>步骤3：根据学习率，按步骤2得到的方向移动<br>重复步骤2和步骤3，直到找到<strong>最低点</strong>。横轴即对于的最佳 <em>w</em> 和 <em>b</em>  参数</p>
</blockquote>
<p>二维情况：梯度下降法的效果<br>颜色约深的区域代表的损失函数越小？ <strong>为什么呢？</strong><br><img src="https://img-blog.csdnimg.cn/299d0d615f6640a6ae092e51579d09ea.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="梯度算法的优缺点"><a href="#梯度算法的优缺点" class="headerlink" title="梯度算法的优缺点"></a>梯度算法的优缺点</h3><blockquote>
<p>总结一下梯度下降法：<br>　　　我们要解决使<strong>损失函数<em>L(w,b)</em></strong> 最小时参数的最佳值，梯度下降法是每次update参数值，直到损失函数最小时找到对应最佳的参数<em>w，b</em></p>
</blockquote>
<p><strong>缺点1</strong>：求解的未必是全局最优解，有可能是局部最优解。</p>
<blockquote>
<p><strong>用下山的例子讲</strong>：<br>　　　比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在<strong>每走到一个位置的时候</strong>，<strong>求解当前位置的梯度</strong>，沿着<strong>梯度的负方向</strong>，也就是<strong>当前最陡峭的位置向下走一步</strong>，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，<strong>有可能我们不能走到山脚，而是到了某一个局部的山峰低处。</strong><br>………………………………………………………………………………………………………<br>　　　从上面的解释可以看出，<strong>梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解</strong>。当然，如果损失函数是<strong>凸函数</strong>，梯度下降法得到的解就<strong>一定是</strong>全局最优解。</p>
</blockquote>
<p><strong>优点1</strong>：无论随机从哪个点出发，得到的最佳参数一定是同一组</p>
<blockquote>
<p><strong>用下山的例子讲</strong>：<br>　　　因为山只有一处是最低点，在确保能找到全局最优解的情况下，无论人从山上哪一点出发，一定能找到这特定一处的最低洼处。</p>
</blockquote>
<h2 id="Step4-回归结果分析"><a href="#Step4-回归结果分析" class="headerlink" title="Step4 回归结果分析"></a>Step4 回归结果分析</h2><blockquote>
<p>经过上述三个步骤后，得到了<strong>训练后</strong>的“最佳参数<em>w</em>，<em>b</em>”，那么现在这个模型在<strong>测试集</strong>上是什么表现呢？<br>得到的结果是：<br><strong>测试集的误差比在训练集上得到的损失值大</strong> 这个事非常正常。因为你训练集里面可能有些数据是不典型的，同样测试集中很多也包含了训练集中没有的因素。所以一个函数模型在实际应用中，效果基本上时打折扣的。<strong>一般会采用两种方式来加强这个函数模型</strong>：<br>　　　select another model（选择另一个模型）即增加维度，增加高此项多项式<br>　　　consider the hidden factors（考虑其他隐藏因素）</p>
</blockquote>
<h3 id="优化模型方法一：增加高次项（一般用于拟合度不够的情况）"><a href="#优化模型方法一：增加高次项（一般用于拟合度不够的情况）" class="headerlink" title="优化模型方法一：增加高次项（一般用于拟合度不够的情况）"></a>优化模型方法一：增加高次项（一般用于拟合度不够的情况）</h3><p><strong>回到Step1</strong></p>
<ol>
<li>尝试二次项、三次项、四次项、五次项…… 右上图为训练集损失，下图是测试集的损失。第五次<strong>过拟合</strong>导致了，测试集损失度很高。<img src="https://img-blog.csdnimg.cn/c707638cef5c4d698813e6acfe4ec172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/ce26490bbfc64ea6967cd7b8e1e8184d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/166aef516df14c339c45fee48a78e16a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/87e7491ce6a1464dad4c023dc9004274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li><strong>选择合适的模型</strong>，即我到底要加到几次项呢？</li>
</ol>
<blockquote>
<p>越复杂的模型所包含的函数也就越多，那么它包含理想模型的可能性也就越大，但是如果过分地去拟合理想模型，就会出现<strong>过拟合</strong>的情况。<br><img src="https://img-blog.csdnimg.cn/6a394ba6b4a648a994472d8969668601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<ol>
<li>横向比较各个多项次，训练集和测试集的失误。理论上，失误会随着高次项而变小，如果变大，则表示模型<strong>过拟合</strong>了。<img src="https://img-blog.csdnimg.cn/979417ba98f6475d941753e0cb71b91c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>所以，如上图所示，在为3次的时候，训练集和测试集的误差差值最小。并且4次开始，以及存在过拟合现象了。因此本案例可选择3次项线性模型。</li>
</ol>
<h3 id="优化模型方法二：考虑其他隐藏因素"><a href="#优化模型方法二：考虑其他隐藏因素" class="headerlink" title="优化模型方法二：考虑其他隐藏因素"></a>优化模型方法二：考虑其他隐藏因素</h3><p><strong>回到Step1</strong></p>
<blockquote>
<p>输入的特征包括：进化前的CP值（<em>Xcp</em>）、物种（Bulbasaur）（<em>Xs</em>）、血量（HP）（<em>Xhp</em>）、重量（Weight）（<em>Xw</em>）、高度（Height）（<em>Xh</em>）<br>除了之前考虑的进化前的CP值（<em>Xcp</em>），其他均为隐藏因素<br>………………………………………………………………………………<br><strong>这里另外考虑的是神奇宝贝的种类</strong>？因为，有时候一个模型恰恰只能符合一种神奇宝贝，也就是<strong>不同神奇宝贝应该有不同的预测模型</strong>。<img src="https://img-blog.csdnimg.cn/72a4aadb2ba24aefb4584a8a8ca2801e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<ol>
<li>不同的神奇宝贝有不同的预测模型<img src="https://img-blog.csdnimg.cn/46fe5297bddb46a4bd511a7cea422e3a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li>拟合这个模型的曲线，可以看出不同神奇宝贝拟合成了不同的类线性直线<img src="https://img-blog.csdnimg.cn/7a55f95269d642038715e355437600f2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li>如果还考虑了其他隐藏元素。如图是横轴是对应的隐藏元素，纵轴是对应进化后的CP值。<img src="https://img-blog.csdnimg.cn/591a6aa5537443428687ba15886ab11d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
<li>如果都采用最高二次项，考虑所有其他的隐藏因素。该案例的数学模型就变成 如图所示的式子。<img src="https://img-blog.csdnimg.cn/0a80407d715e4dcc978bd86dee3451a3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><blockquote>
<p> 考虑更多的因素反而出现了过拟合的问题，<strong>说明有些因素跟本次实验的CP值预测没有关系</strong>！<br>………………………………………………………………………………<br><strong>过拟合这么讨厌，到底如何减少过拟合问题呢？往下看！</strong></p>
</blockquote>
</li>
</ol>
<h3 id="优化模型：防止过拟合（为损失函数加一个正则项）"><a href="#优化模型：防止过拟合（为损失函数加一个正则项）" class="headerlink" title="优化模型：防止过拟合（为损失函数加一个正则项）"></a>优化模型：防止过拟合（为损失函数加一个正则项）</h3><h4 id="正则项是什么"><a href="#正则项是什么" class="headerlink" title="正则项是什么?"></a>正则项是什么?</h4><blockquote>
<p><strong>方法：正则化</strong>?<br>比如先考虑一个参数w，正则化就是在损失函数上加上一个与w（斜率）相关的值（正则项），那么要是loss function越小的话，w也会越小，w越小就使function更加平滑（function没那么大跳跃）<img src="https://img-blog.csdnimg.cn/7a87a38ed54c438c8af37860e982f775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h4 id="正则化的缺点"><a href="#正则化的缺点" class="headerlink" title="正则化的缺点"></a>正则化的缺点</h4><p>正则化虽然能够减少过拟合的现象，但是因为加在损失函数后面的值是平白无故加上去的，所以正则化过度的话会导致<strong>bias偏差增大</strong>   ？？？？<img src="https://img-blog.csdnimg.cn/f4c9ea7efb144c8a89b7fee964b75fa8.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1）实现参数的稀疏有什么好处吗？<br>一个好处是可以简化模型，避免过拟合。<strong>因为一个模型中真正重要的参数可能并不多，如果考虑所有的参数起作用，那么可以对训练数据可以预测的很好，但是对测试数据表现性能极差</strong>。另一个好处是参数变少可以使整个模型获得更好的可解释性。<br>2）参数值越小代表模型越简单吗？<br>是的。为什么参数越小，说明模型越简单呢，这是因为越复杂的模型，<strong>越是会尝试对所有的样本进行拟合，甚至包括一些异常样本点</strong>，这就容易造成在<strong>较小的区间里预测值产生较大的波动</strong>，这种较大的波动也反映了在这个区间里的<strong>导数很大</strong>，而<strong>只有较大的参数值才能产生较大的导数。因此复杂的模型，其参数值会比较大。</strong></p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/9dcfac9366564857a226de8d73bf512e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>李宏毅</tag>
        <tag>机器学习</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/CSS%20%E7%AF%87%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="CSS-篇面试题"><a href="#CSS-篇面试题" class="headerlink" title="CSS 篇面试题"></a>CSS 篇面试题</h1><h2 id="考点1：常见定位"><a href="#考点1：常见定位" class="headerlink" title="考点1：常见定位"></a>考点1：常见定位</h2><h3 id="面试题：常见定位有哪些"><a href="#面试题：常见定位有哪些" class="headerlink" title="面试题：常见定位有哪些"></a>面试题：常见定位有哪些</h3><p><strong>普通流</strong></p>
<ul>
<li><p>元素按照其在 HTML 中的先后位置至上而下布局</p>
</li>
<li><p><a href="https://so.csdn.net/so/search?q=行内元素&amp;spm=1001.2101.3001.7020">行内元素</a>水平排列，直到当行被占满然后换行，块级元素则会被渲染为完整的一个新行</p>
</li>
<li><p>所有元素默认都是普通流定位</p>
</li>
</ul>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/CSS定位.png" style="zoom:50%;" /></p>
<p><strong>浮动</strong></p>
<p>元素首先按照普通流的位置出现，然后根据浮动的方向尽可能的向左边或右边偏移</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/浮动.png" style="zoom:50%;" /></p>
<p><strong>绝对定位</strong></p>
<blockquote>
<p>元素会整体脱离普通流，因此绝对定位不会对其兄弟元素造成影响</p>
</blockquote>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/绝对定位.png" style="zoom:50%;" /></p>
<h2 id="考点2：了解BFC特性"><a href="#考点2：了解BFC特性" class="headerlink" title="考点2：了解BFC特性"></a>考点2：了解BFC特性</h2><h3 id="面试题：如何理解BFS特性？怎么样才能是BFS？能够解决哪些问题？"><a href="#面试题：如何理解BFS特性？怎么样才能是BFS？能够解决哪些问题？" class="headerlink" title="面试题：如何理解BFS特性？怎么样才能是BFS？能够解决哪些问题？"></a>面试题：如何理解BFS特性？怎么样才能是BFS？能够解决哪些问题？</h3><font color="red">**如何理解 BFC特性？**</font>

<p><strong>BFC是属于普通流的</strong>，我们可以把BFC看成页面的一块<strong>渲染区</strong>，他有<strong>自己的渲染规则</strong>，简单来说就是BFC可以看做元素的属性，<font color="darkb">当元素有了BFC这个属性，这个元素可以看做<strong>隔离了的容器</strong>，容器里面的元素<strong>不会在布局上影响到外面的元素。</strong></font></p>
<ul>
<li>每一个BFC区域<strong>只包含其子元素，</strong>不包含其子元素的子元素</li>
<li>成为一个BFC区域要满足一定的<strong>条件</strong>。</li>
<li>每一个BFC区域<strong>相互独立，互不影响</strong></li>
</ul>
<font color="red">**如何触发 BFC？**</font>

<p>标签中 满足下列任一条件属性，就可以触发 BFC</p>
<blockquote>
<ol>
<li><p>根元素(<html>)</p>
</li>
<li><p>设置float浮动，不包含none</p>
</li>
<li><p>绝对定位元素 (元素的 position 为 absolute 或 fixed)</p>
</li>
<li><p>display 为 inline-block、table-cell、table-caption、table、table-row、table-row-groutable-header-group、table-footer-group、inline-table、flow-root、flex 或 inline-flex、grid 或 inline-grid</p>
</li>
<li><p><strong>设置overflow，但是不能为visible</strong></p>
</li>
<li><p>contain 值为 layout、content 或 paint 的元素</p>
</li>
<li><p>多列容器（column-count 或 column-width (en-US) 值不为 auto，包括column-count 为 1）</p>
</li>
</ol>
</blockquote>
<font color="darkblue">注意做测试的时候body千万不要设置 flex奥，不然就直接解决了，不过我也不知道是为啥。</font>

<p><strong>第一个作用：避免外边距重合</strong></p>
<font color="blue">例如产生于 两个上下相邻元素  与 嵌套块元素之间</font>

<blockquote>
<p>margin塌陷会在两个元素下边距和上边距的时候出现</p>
<p>例如上元素的 margin-bottom 是50px   下元素的 margin-top 是 20px   理论上两个元素中间的空白空隙应该是 70px 才对。</p>
<p>但是由于塌陷，浏览器只会取大的那个，也就是50px。根本原因是，浏览器认为你是重复写了，其实我们只要定义上元素的margin-bottom是 70px 就可以了。</p>
</blockquote>
<p><strong>如何解决：利用 BFC 特性，分别构建父容器并声明为 BFC</strong>  </p>
<p>利用 <code>overflow：hidden</code>  开启 BFC</p>
<blockquote>
<p><code>overflow:hidden</code> 的几种含义：</p>
<ol>
<li>溢出隐藏</li>
<li>清除浮动</li>
<li>开启 BFC</li>
</ol>
</blockquote>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">// style</span><br><span class="line">.box&#123;</span><br><span class="line">    width: 200px;</span><br><span class="line">    height: 200px;</span><br><span class="line">    background: #5aa878;</span><br><span class="line">    margin: 100px;</span><br><span class="line">&#125;</span><br><span class="line">.container&#123;</span><br><span class="line">	overflow: hidden;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&#x27;container&#x27;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;container&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>给这两个box给各自一个div包裹，然后给这个div添加 <strong>overflow: hidden;</strong></p>
<p><strong>属性触发container的BFC，两个 container div 之间没关系，所以最后就可以看到理想的结果 200px</strong></p>
</blockquote>
<p><strong>第二个作用：清除浮动</strong></p>
<p>如下所示：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.container&#123;</span><br><span class="line">    border: 2px solid yellowgreen;</span><br><span class="line">&#125;</span><br><span class="line">.content&#123;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;</span><br><span class="line">    background: #47cabf;</span><br><span class="line">    margin: 100px;</span><br><span class="line">    float: left;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;container&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>因为 content 模块是浮动，所以会脱离文档流， container的border 框的是空的东西，所以就是视口宽的 2px高度的一条线。</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/清楚浮动.png" alt=""></p>
<p><strong>如何解决：利用 BFC 特性，将父容器并声明为 BFC</strong>  </p>
<p>给父容器添加BFC属性，添加overflow: hidden;属性触发BFC。</p>
<p>这样就起到清除浮动的效果，<font color="skyBlue">因为BFC是照顾的到第一层子元素的</font>。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">// container 父容器</span><br><span class="line"><span class="selector-class">.container</span>&#123;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">2px</span> solid yellowgreen;</span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/浮动成功过.png" alt=""></p>
<p><strong>第三个作用：防止元素被浮动元素覆盖</strong></p>
<p>给两个盒子设置宽高颜色，其中一个设置浮动。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.box1&#123;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;</span><br><span class="line">    background: blue;</span><br><span class="line">    float: left;</span><br><span class="line">&#125;</span><br><span class="line">.box2&#123;</span><br><span class="line">    width: 200px;</span><br><span class="line">    height: 200px;</span><br><span class="line">    background: red;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box1&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box2&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>结果当然是两个重叠了，因为 box1 脱离文档流了 默认以 body左上角为起始点， box2 会占用原来box1的位置 </p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/重叠浮动.png" alt=""></p>
<p>这里可以看到浮动元素覆盖了没有添加浮动的元素，如果想不被覆盖，可以触发正常的元素的BFC即可。</p>
<p>所有在第二个元素添加<strong>overflow: hidden;</strong>属性，这样这两个盒子就互不干扰。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.box2</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background</span>: red;</span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/浮动不重叠.png" alt=""></p>
<p><strong>第四个作用：防止父子元素外边距塌陷</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.box1&#123;</span><br><span class="line">    width: 200px;</span><br><span class="line">    height: 200px;</span><br><span class="line">    background: blue;</span><br><span class="line">&#125;</span><br><span class="line">.box2&#123;</span><br><span class="line">    width: 100px;</span><br><span class="line">    height: 100px;</span><br><span class="line">    background: red;</span><br><span class="line">    margin-top: 20px;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box1&quot;</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box2&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/父子塌陷.png" style="zoom: 67%;" /></p>
<p>给子元素添加margin-top:20px后，影响了父元素，浏览器会以子元素和父元素 margin-top 的最大值 作为整体的 margin-top，他会错了意。</p>
<p><strong>给父元素添加BFC属性即可，将父元素和子元素的 margin-top 进行分离。</strong></p>
<p>当然你也可以父子元素都加= -= ，不过没有必要</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.box1</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background</span>: blue;</span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/父子塌陷2.png" alt=""></p>
<h2 id="考点3：盒模型"><a href="#考点3：盒模型" class="headerlink" title="考点3：盒模型"></a>考点3：盒模型</h2><h3 id="面试题：标准盒模型和怪异盒模型的区别是什么"><a href="#面试题：标准盒模型和怪异盒模型的区别是什么" class="headerlink" title="面试题：标准盒模型和怪异盒模型的区别是什么?"></a>面试题：标准盒模型和怪异盒模型的区别是什么?</h3><p>要分清楚 标准盒模型 和 怪异盒模型（IE盒模型） 的区别</p>
<p><strong>标准盒模型</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/标准盒模型1.png" style="zoom:50%;" /></p>
<font color="red">**width/height 只是内容 content（上图橙色的部分）的宽/高度**</font>

<ul>
<li>盒子总宽度 = width + padding + border + margin</li>
<li>盒子总高度 = height + padding + border + margin</li>
</ul>
<p><strong>怪异盒模型</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/标准盒模型2.png" style="zoom:50%;" /></p>
<font color="green">**width/height 包括了 content + padding + border（如上图橙色+浅绿色+黄色三部分)**</font>

<ul>
<li>盒子总宽度 = width + margin</li>
<li>盒子总高度 = height + margin</li>
</ul>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">// 默认为标准盒模型</span><br><span class="line"><span class="attribute">box-sizing</span>:content-box</span><br><span class="line">// 改为怪异盒模型</span><br><span class="line">box-sizing:border-box</span><br></pre></td></tr></table></figure>
<h2 id="考点4：隐藏元素"><a href="#考点4：隐藏元素" class="headerlink" title="考点4：隐藏元素"></a>考点4：隐藏元素</h2><h4 id="面试题：请说说隐藏一个元素的几种方法，以及它们之间的区别。"><a href="#面试题：请说说隐藏一个元素的几种方法，以及它们之间的区别。" class="headerlink" title="面试题：请说说隐藏一个元素的几种方法，以及它们之间的区别。"></a>面试题：请说说隐藏一个元素的几种方法，以及它们之间的区别。</h4><ul>
<li><code>display:none;</code> 元素在页面上将彻底消失，元素本来占有的空间就会被其他元素占有，也就是说它会导致浏览器的重排和重绘。</li>
<li><code>visibility:hidden</code>  元素在页面消失后，其占据的空间依旧会保留着，所以它只会导致浏览器重绘而不会重排，适用于那些元素隐藏后不希望页面布局会发生变化的场景。</li>
<li><code>opacity:0;</code>  元素隐藏后依旧占据着空间，但是不会重绘，就是单纯的透明度为0而看不见</li>
</ul>
<p>另外三种操作对于 dom 节点绑定的事件，有区别：</p>
<ul>
<li><code>display:none</code>：元素彻底消失，所以绑定的事件肯定也没了</li>
<li><code>visibility:hidden</code> l   <strong>看不见，也点不了，但是依旧占据页面空间</strong></li>
<li><code>opacity:0</code>：可以触发点击事件，因为没有重绘，只是单纯的透明度高到看不见。</li>
</ul>
<h2 id="考点5：清除浮动"><a href="#考点5：清除浮动" class="headerlink" title="考点5：清除浮动"></a>考点5：清除浮动</h2><h3 id="面试题：请你说出你用过清除浮动的几种办法，以及它们的优缺点"><a href="#面试题：请你说出你用过清除浮动的几种办法，以及它们的优缺点" class="headerlink" title="面试题：请你说出你用过清除浮动的几种办法，以及它们的优缺点"></a>面试题：请你说出你用过清除浮动的几种办法，以及它们的优缺点</h3><font color="blue">当元素浮动（float）时，会导致该元素脱离文档流，**并且它下方的元素可能会出现在其旁边，而不是在它下方**。。为了避免这种影响，我们可以使用“清除浮动”（clear float）的技巧。</font>

<p><strong>方法1：<code>clear:both</code></strong></p>
<p><strong>给浮动的标签添加后，新加一个标签</strong>，给其设置 <code>clear:both</code></p>
<p>使用这种办法，如果我们清除了浮动，父元素自动检测子盒子最高的高度，然后与其同高。</p>
<blockquote>
<p>“clear” 属性指示浏览器应该在元素周围的所有浮动元素之后开始新行，并防止元素与之前的浮动元素重叠。”both” 告诉浏览器清除元素左右两侧的所有浮动。</p>
<p>因此，将 “<code>clear:both</code>“ 应用于一个元素时，<strong>浏览器将在该元素下方开始新行，并确保在该元素下方的任何浮动元素都已经清除，使该元素不会与之前的浮动元素重叠</strong>。</p>
</blockquote>
<p>缺点在于，需要加一个无用标签</p>
<p><strong>方法2：给父元素添加 <code>overflow:hidden</code>。</strong></p>
<p>其实这个就是让 父元素变成 BFC结构。</p>
<font color="red">**因为浮动会脱离文档流。**</font>

<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.father</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">400px</span>; </span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">    <span class="attribute">background-color</span>: antiquewhite;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.big</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>; <span class="attribute">height</span>: <span class="number">200px</span>; <span class="attribute">float</span>: left;</span><br><span class="line">    <span class="attribute">background-color</span>: aqua;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;<span class="selector-tag">div</span> class=&quot;father&quot;&gt;</span><br><span class="line">	&lt;<span class="selector-tag">div</span> class=&quot;big&quot;&gt;big&lt;/<span class="selector-tag">div</span>&gt;</span><br><span class="line">&lt;/<span class="selector-tag">div</span>&gt;</span><br></pre></td></tr></table></figure>
<p><strong>方法3：使用 after 伪元素清除浮动。</strong></p>
<p>我们可以在包含浮动元素的容器元素上添加一个伪元素，并为该伪元素设置 <code>clear: both;</code> 属性，使其显示在浮动元素下方，从而实现清除浮动的效果。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.clearfix</span><span class="selector-pseudo">::after</span> &#123;</span><br><span class="line">    <span class="attribute">content</span>: <span class="string">&quot;&quot;</span>;</span><br><span class="line">    <span class="attribute">display</span>: block;</span><br><span class="line">    <span class="attribute">clear</span>: both;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.father</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">400px</span>; </span><br><span class="line">    <span class="attribute">background-color</span>: antiquewhite;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.big</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>; <span class="attribute">height</span>: <span class="number">200px</span>; <span class="attribute">float</span>: left;</span><br><span class="line">    <span class="attribute">background-color</span>: aqua;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;<span class="selector-tag">div</span> class=&quot;father clearfix&quot;&gt;</span><br><span class="line">	&lt;<span class="selector-tag">div</span> class=&quot;big&quot;&gt;big&lt;/<span class="selector-tag">div</span>&gt;</span><br><span class="line">&lt;/<span class="selector-tag">div</span>&gt;</span><br></pre></td></tr></table></figure>
<p>这里的 <code>::after</code> 伪元素表示在 <code>.clearfix</code> 元素的最后一个子元素之后添加一个空的块级元素，通过 <code>clear: both;</code> 属性来清除浮动。</p>
<font color="blue">其和第一种方法思想一样，但第一种会额外产生一个新的无用标签，而这种其实是用了投机取巧的方法，伪元素。</font>



<h2 id="考点6：样式优先级"><a href="#考点6：样式优先级" class="headerlink" title="考点6：样式优先级"></a>考点6：样式优先级</h2><h3 id="面试题：CSS样式有哪些-优先级排序"><a href="#面试题：CSS样式有哪些-优先级排序" class="headerlink" title="面试题：CSS样式有哪些 优先级排序"></a>面试题：CSS样式有哪些 优先级排序</h3><p>!important &gt; 内联样式 &gt; ID 选择器 &gt; 伪类 &gt; 属性选择器 &gt; 类选择器 &gt; 标签选择器 &gt; 通配符（*） 。</p>
<p><strong>如非特殊情况，慎用!important。</strong>因为使用!important 会扰乱原本层叠和权重产生正常的作用顺序，使后期维护带来麻烦。</p>
<h2 id="考点7：单位对比"><a href="#考点7：单位对比" class="headerlink" title="考点7：单位对比"></a>考点7：单位对比</h2><h3 id="面试题：请说出几个常用的CSS单位，例如：px，em，rem，vw和vh"><a href="#面试题：请说出几个常用的CSS单位，例如：px，em，rem，vw和vh" class="headerlink" title="面试题：请说出几个常用的CSS单位，例如：px，em，rem，vw和vh"></a>面试题：请说出几个常用的CSS单位，例如：px，em，rem，vw和vh</h3><ul>
<li><p>px：最常用的，它是相对于显示器屏幕分辨率而言的。</p>
<p>优缺点：比较稳定和精确，但在浏览器中放大或缩放浏览页面时会出现页面混乱的情况。</p>
</li>
</ul>
<ul>
<li><p>em：相对单位，<strong>基准点为父节点字体的大小</strong>，如果自身定义了 font-size 按自身来计算（浏览器默认字体是 16px），整个页面内 1em 不是一个固定的值。</p>
<p>优缺点：em 的值并不是固定的，它会继承父级元素的字体大小，所以不好维护</p>
</li>
</ul>
<ul>
<li><p>rem：相对单位，基于 root 元素，即根据<code>html</code> 元素的大小来计算，不受容器本身字体大小的影响，全部根据<code>html</code> 的字体大小重新计算。设定<code>根元素&lt;html&gt;</code> <strong>的font-size 属性，默认为 16px，那么 1rem = 16px</strong>。 </p>
<p>优缺点：相对大小与绝对大小相统一，适合用于制作响应式布局。</p>
</li>
</ul>
<ul>
<li><p><code>Vh：1vh</code> 等于屏幕可视区高度的百分之一。</p>
</li>
<li><p><code>Vw：1vw</code> 等于屏幕可视区宽度的百分之一。</p>
</li>
</ul>
<h2 id="考点8：-position-定位属性"><a href="#考点8：-position-定位属性" class="headerlink" title="考点8： position 定位属性"></a>考点8： position 定位属性</h2><h4 id="fixed"><a href="#fixed" class="headerlink" title="fixed"></a>fixed</h4><p><code>position: fixed</code> 元素的参考对象是浏览器窗口而非最近的定位祖先元素。</p>
<p><code>position: fixed</code> 布局的实现方式是通过计算元素的位置和尺寸，设置其 <code>left</code>、<code>top</code>、<code>right</code> 和 <code>bottom</code> 属性，使元素固定在浏览器窗口的某个位置。</p>
<h4 id="sticky"><a href="#sticky" class="headerlink" title="sticky"></a>sticky</h4><p><code>position: sticky</code> 是一种相对于滚动容器定位的布局方式，即元素在滚动到特定位置时会固定在屏幕上。与 <code>position: fixed</code> 不同的是，<code>position: sticky</code> 元素的固定位置是相对于其父元素而言，当父元素滚动到一定位置时，元素就会固定在屏幕上，不再随父元素滚动。</p>
<blockquote>
<p>position: sticky<code>布局的实现方式是通过结合</code>position: relative<code>和</code>position: fixed<code>两种定位方式来实现的。当元素距离滚动容器的顶部或底部的距离达到指定值时，元素的</code>position<code>属性会从</code>relative<code>变为</code>fixed</p>
</blockquote>
<h2 id="考点9：布局flex"><a href="#考点9：布局flex" class="headerlink" title="考点9：布局flex"></a>考点9：布局flex</h2><p><strong>什么是 flex 布局？</strong></p>
<p>答：flex 布局是一种基于弹性盒子模型的布局方式，通过设置容器和子元素的属性，可以轻松地实现水平和垂直方向的布局。Flex 布局具有灵活性、简洁性和易用性，适用于多种应用场景，例如网页布局、表单布局、导航菜单等。</p>
<p><strong>flex 布局有哪些主要的属性？</strong></p>
<p>答：flex 布局有以下主要的属性：</p>
<ul>
<li><code>display</code>：设置元素为 flex 容器。</li>
<li><code>flex-direction</code>：设置主轴方向。</li>
<li><code>justify-content</code>：设置主轴上的对齐方式。</li>
<li><code>align-items</code>：设置侧轴上的对齐方式。</li>
<li><code>flex-wrap</code>：设置是否换行。</li>
<li><code>align-content</code>：设置多行的对齐方式。</li>
<li><code>flex</code>：设置弹性元素的尺寸比例。</li>
</ul>
<p><strong>如何使一个 flex 容器水平和垂直居中？</strong></p>
<p>答：可以通过以下方式使一个 flex 容器水平和垂直居中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cssCopy code.container &#123;</span><br><span class="line">  display: flex;</span><br><span class="line">  justify-content: center; /* 水平居中 */</span><br><span class="line">  align-items: center; /* 垂直居中 */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>flex 布局的主轴和侧轴是什么？</strong></p>
<p>答：在 flex 布局中，容器内的元素排列是围绕主轴和侧轴进行的。主轴是 flex 容器的主要方向，决定了 flex 元素的排列方向。侧轴是与主轴垂直的轴，决定了 flex 元素在主轴方向上的对齐方式。</p>
<p><strong>如何设置一个 flex 元素的宽度和高度？</strong></p>
<p>答：可以通过以下方式设置一个 flex 元素的宽度和高度：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cssCopy code.item &#123;</span><br><span class="line">  flex: none; /* 不进行伸缩，保持原有尺寸 */</span><br><span class="line">  width: 200px; /* 设置宽度 */</span><br><span class="line">  height: 100px; /* 设置高度 */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>flex: none</code> 表示该元素不进行伸缩，保持原有尺寸。</p>
<p><strong>flex布局中每个元素（项目）的占比</strong>  <code>flex</code></p>
<p>这个很重要，由两种布局方式。假设我现在有3个元素，以横向为主轴。</p>
<p>第一种，左右我都设置固定的宽度，中间 flex = 1，则中间就包含所有剩下的宽度</p>
<p>第二种，左右我都设置 flex = 1， 中间 flex = 10，  则中间的宽度 为  10/12 的总宽度</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/flex占比.png" alt=""></p>
<p><strong>注意</strong></p>
<p>设为Flex布局以后，子元素的float、clear和vertical-align属性将失效。</p>
<p>布局的传统解决方案，基于盒状模型，依赖display属性+position属性+float属性。这对于那些特殊布局非常不方便，比如，垂直居中就不容易实现。</p>
<h2 id="考点10：垂直居中"><a href="#考点10：垂直居中" class="headerlink" title="考点10：垂直居中"></a>考点10：垂直居中</h2><h3 id="面试题：垂直居中的方法有哪些？"><a href="#面试题：垂直居中的方法有哪些？" class="headerlink" title="面试题：垂直居中的方法有哪些？"></a>面试题：垂直居中的方法有哪些？</h3><p>共有四种：分别为 flexBox布局 、 table-cell布局、绝对定位+transform 、grid布局</p>
<p>以下是一个例子，假设我们需要将一个宽度为 200px，高度为 200px 的子元素在其父元素（400px 高 400px宽）中垂直居中：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;container&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;child&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p><strong>使用 flexbox 实现垂直居中：</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.container</span> &#123;</span><br><span class="line">    <span class="attribute">display</span>: flex;</span><br><span class="line">    <span class="attribute">justify-content</span>: center;</span><br><span class="line">    <span class="attribute">align-items</span>: center;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">400px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">400px</span>; <span class="comment">/* 设置容器高度 */</span></span><br><span class="line">    <span class="attribute">background-color</span>: aquamarine;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="selector-class">.child</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">rgb</span>(<span class="number">100</span>, <span class="number">108</span>, <span class="number">147</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>使用 table-cell 实现垂直居中：</strong> （这个不好使。不知道为啥）</p>
</li>
</ol>
<ol>
<li><p><strong>使用 transform 实现垂直居中：</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.container</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">400px</span>; <span class="comment">/* 设置容器高度 */</span></span><br><span class="line">    <span class="attribute">width</span>: <span class="number">400px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: aquamarine;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="selector-class">.child</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: absolute;</span><br><span class="line">    <span class="comment">/* 相对于父容器 container */</span></span><br><span class="line">    <span class="attribute">top</span>: <span class="number">50%</span>;</span><br><span class="line">    <span class="attribute">left</span>: <span class="number">50%</span>;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">transform</span>: <span class="built_in">translate</span>(-<span class="number">50%</span>, -<span class="number">50%</span>);</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p><strong>使用 grid 实现垂直居中：</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.container</span> &#123;</span><br><span class="line">   <span class="attribute">display</span>: grid;</span><br><span class="line">   place-items: center;</span><br><span class="line">   <span class="attribute">height</span>: <span class="number">400px</span>; <span class="comment">/* 设置容器高度 */</span></span><br><span class="line">   <span class="attribute">width</span>: <span class="number">400px</span>;</span><br><span class="line">   <span class="attribute">background-color</span>: aquamarine;</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> <span class="selector-class">.child</span> &#123;</span><br><span class="line">   <span class="attribute">align-self</span>: center;</span><br><span class="line">   <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">   <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">   <span class="attribute">background-color</span>: red;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="考点11：-CSS3-的新特性"><a href="#考点11：-CSS3-的新特性" class="headerlink" title="考点11： CSS3 的新特性"></a>考点11： CSS3 的新特性</h2><h3 id="面试题：新特性有哪些"><a href="#面试题：新特性有哪些" class="headerlink" title="面试题：新特性有哪些"></a>面试题：新特性有哪些</h3><ul>
<li>在布局方面：新增了 flex 布局，</li>
<li>在选择器方面：新增了例如first-of-type,nth-child，: not(.input)（所有 class 不是“input”的节点） 等选择器，</li>
<li>在盒模型方面：添加了 box-sizing 来改变盒模型，</li>
<li>在动画方面：增加了 animation，2d 变换、3d 变换（如 transform ：增加了旋转,缩放,定位,倾斜,动画,多背景）等，</li>
<li>在颜色方面：添加透明，rbga 等，</li>
<li>在文本方面：文字特效 （text-shadow），文字渲染 （Text-decoration）</li>
<li>在边框方面：添加了 border-radius（圆角），box-shadow 等</li>
<li>在背景方面：添加了 background-size，background-origin 等</li>
<li>在渐变方面：线性渐变 （gradient）</li>
<li>在过渡方面：增加了transition过渡效果</li>
</ul>
<h3 id="面试题：transition和animation区别"><a href="#面试题：transition和animation区别" class="headerlink" title="面试题：transition和animation区别"></a>面试题：transition和animation区别</h3><p>Animation 和 transition 大部分属性是相同的，他们都是随时间改变元素的属性值。</p>
<p>他们的主要区别是 transition 需要触发一个事件才能改变属性，而 animation 不需要触发任何事件的情况下才会随时间改变属性值，并且 transition 为 2 帧，从 from …. to，而 animation可以一帧一帧的。</p>
<p><strong>transition是过度属性</strong>，强调过度，它的实现需要触发一个事件（比如鼠标移动上去，焦点，点击等）才执行动画。它类似于flash的补间动画，设置一个开始关键帧，一个结束关键帧。</p>
<p><strong>animation是动画属性</strong>，它的实现不需要触发事件，设定好时间之后可以自己执行，且可以循环一个动画。它也类似于flash的补间动画，但是它可以设置多个关键帧（用@keyframe定义）完成动画。</p>
<h2 id="考点12：伪元素（应该不会问，但我得知道）"><a href="#考点12：伪元素（应该不会问，但我得知道）" class="headerlink" title="考点12：伪元素（应该不会问，但我得知道）"></a>考点12：伪元素（应该不会问，但我得知道）</h2><h3 id="面试题：-伪元素和正常元素的关系？"><a href="#面试题：-伪元素和正常元素的关系？" class="headerlink" title="面试题： 伪元素和正常元素的关系？"></a>面试题： 伪元素和正常元素的关系？</h3><p>例如 span  和  span::before  两个元素之间的关系是什么？</p>
<p><code>span::before</code> 是伪元素，<strong>它本身并不存在于文档中</strong>，也就是 html里是没有这个元素的。只是在 <code>span</code> 元素内容前插入了一个虚拟元素，<font color="red"><strong>因此在文档树中它们并不是父元素和子元素的关系</strong></font>。<font color="blue">它们是<strong>同一元素的不同表现形式</strong>，可以分别设置不同的样式，从而实现更加灵活的排版和布局。</font></p>
<p>另外要注意的是，<font color="red"><strong>伪元素默认是 行内元素。</strong></font><strong>可以使用 z-index: XXX; 来控制 before 本元素 和 after 三者之间的层级关系。</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/微信图片_20230302114305.png" alt=""></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">div</span><span class="selector-pseudo">::before</span> &#123;</span><br><span class="line">	<span class="attribute">content</span>: <span class="string">&quot;我是BEFORE，&quot;</span>;</span><br><span class="line">	<span class="attribute">background-color</span>: green;</span><br><span class="line">	<span class="attribute">width</span>: <span class="number">100px</span>; <span class="comment">/*行内元素不生效的*/</span></span><br><span class="line">	<span class="attribute">height</span>: <span class="number">100px</span>;		</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">div</span><span class="selector-pseudo">::after</span> &#123;</span><br><span class="line">	<span class="attribute">content</span>: <span class="string">&quot;我是AFTER，&quot;</span>;</span><br><span class="line">	<span class="attribute">background-color</span>: red;</span><br><span class="line">	<span class="attribute">width</span>: <span class="number">100px</span>;</span><br><span class="line">	<span class="attribute">height</span>: <span class="number">100px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>div 本身无样式。<code>&lt;div&gt;我是BODY&lt;/div&gt;</code></p>
<p><strong>两者定位的关系是？</strong></p>
<p>伪元素不占据文档流，因此在进行定位时，可能需要根据其生成的元素的位置和尺寸进行计算。</p>
<p>两者设置 <code>position:absolute</code> 均是相对于，最近已定位的祖先元素。</p>
<p><strong>但是很奇怪 这边测试得到 before （absolute）相对于的还是 他原本的标签）</strong></p>
<p>而伪元素本身不定位，其定位依然是<strong>相对于生成它的元素的内容框（content box）进行的</strong>，而不是相对于其生成的元素的包含块（containing block）。也就是说，伪元素的 <code>top</code>, <code>bottom</code>, <code>left</code>, <code>right</code> 属性值的计算方式与普通元素的计算方式相同。</p>
<h2 id="CSS编程考点"><a href="#CSS编程考点" class="headerlink" title="CSS编程考点"></a>CSS编程考点</h2><h3 id="面试题1：绘制三角形"><a href="#面试题1：绘制三角形" class="headerlink" title="面试题1：绘制三角形"></a>面试题1：绘制三角形</h3><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">width</span>: <span class="number">0px</span>;</span><br><span class="line"><span class="attribute">height</span>: <span class="number">0px</span>;</span><br><span class="line"><span class="comment">/* border是240px则三角形底边长为480px  */</span></span><br><span class="line"><span class="attribute">border</span>: <span class="number">240px</span> solid;  </span><br><span class="line"><span class="comment">/*分别为上border 右border  下边border  左边border   顺时针*/</span></span><br><span class="line"><span class="attribute">border-color</span>:  gold transparent transparent transparent;</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/weixin_43974265/article/details/115427185">https://blog.csdn.net/weixin_43974265/article/details/115427185</a></p>
<h3 id="面试题2：三栏布局—手写圣杯布局"><a href="#面试题2：三栏布局—手写圣杯布局" class="headerlink" title="面试题2：三栏布局—手写圣杯布局"></a>面试题2：三栏布局—手写圣杯布局</h3><ul>
<li>左侧栏和右侧栏采用<code>float: left</code>浮动方式，两侧栏采用<code>margin-left</code>和<code>margin-right</code>  -100%负边距方式。</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">header</span>&gt;</span>我是头部<span class="tag">&lt;/<span class="name">header</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;middle&quot;</span>&gt;</span>我是中<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;left&quot;</span>&gt;</span>我是左<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;right&quot;</span>&gt;</span>我是右<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">footer</span>&gt;</span>我是底部<span class="tag">&lt;/<span class="name">footer</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">* &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-tag">header</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: cyan;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">10vh</span>;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.container</span> &#123;</span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span> <span class="number">200px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="selector-class">.container</span> <span class="selector-tag">div</span> &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">80vh</span>;</span><br><span class="line">    <span class="attribute">float</span>: left;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 中间自适应 */</span></span><br><span class="line">  <span class="selector-class">.container</span> <span class="selector-class">.middle</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: beige;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="selector-class">.container</span> <span class="selector-class">.left</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: aquamarine;</span><br><span class="line">      </span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">margin-left</span>: -<span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">left</span>: -<span class="number">200px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="selector-class">.container</span> <span class="selector-class">.right</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: cadetblue;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">margin-right</span>: -<span class="number">100%</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-tag">footer</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: green;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">10vh</span>;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题3：三栏布局—手写双飞翼布局"><a href="#面试题3：三栏布局—手写双飞翼布局" class="headerlink" title="面试题3：三栏布局—手写双飞翼布局"></a>面试题3：三栏布局—手写双飞翼布局</h3><ul>
<li>双飞翼布局是把<strong>主列嵌套在一个新的父级块中并利用主列的左、右外边距</strong>进行布局调整。</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">header</span>&gt;</span>header<span class="tag">&lt;/<span class="name">header</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;container&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;center column&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content&quot;</span>&gt;</span>middle<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;left column&quot;</span>&gt;</span>left<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;right column&quot;</span>&gt;</span>right<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">footer</span>&gt;</span>footer<span class="tag">&lt;/<span class="name">footer</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">* &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-tag">header</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: cyan;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">10vh</span>;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">10vh</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.container</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: gray;</span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.container</span> <span class="selector-class">.column</span> &#123;</span><br><span class="line">    <span class="attribute">float</span>: left;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">80vh</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.center</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.left</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#ff4d4f</span>;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">margin-left</span>: -<span class="number">100%</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.right</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#2e6da4</span>;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">margin-left</span>: -<span class="number">200px</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.content</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">margin-right</span>: <span class="number">200px</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-tag">footer</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: green;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">10vh</span>;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题4：两栏布局—手写"><a href="#面试题4：两栏布局—手写" class="headerlink" title="面试题4：两栏布局—手写"></a>面试题4：两栏布局—手写</h3><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;outer&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;left&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;right&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>方法一：</strong></p>
<p><strong>利用浮动，将左边元素宽度设置为 300px，并且设置向左浮动。将右边元素的margin-left设置为 300px，宽度设置为auto（默认为auto，撑满整个父元素）。</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">*&#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.outer</span> &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">background</span>: <span class="built_in">rgb</span>(<span class="number">42</span>, <span class="number">219</span>, <span class="number">83</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.left</span> &#123;</span><br><span class="line">    <span class="attribute">float</span>: left;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">background</span>: tomato;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.right</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">width</span>: auto;</span><br><span class="line">    <span class="attribute">background</span>: gold;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>方法二：</strong></p>
<p><strong>利用浮动，左侧元素设置固定大小，并左浮动，右侧元素设置overflow: hidden; 这样右边就触发了BFC，BFC的区域不会与浮动元素发生重叠，所以两侧就不会发生重叠。</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">*&#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.outer</span> &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.left</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">background</span>: tomato;</span><br><span class="line">    <span class="attribute">float</span>: left;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.right</span> &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">background</span>: gold;</span><br><span class="line">    <span class="comment">/* BFC 不会被左侧的浮动所影响 */</span></span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>方法三：</strong></p>
<p><strong>利用flex布局，将左边元素设置为固定宽度300px，将右边的元素设置为 flex: 1。</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">*&#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.outer</span> &#123;</span><br><span class="line">    <span class="attribute">display</span>: flex;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.left</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background</span>: tomato;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.right</span> &#123;</span><br><span class="line">    <span class="attribute">flex</span>: <span class="number">1</span>;</span><br><span class="line">    <span class="attribute">background</span>: gold;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>方法四：</strong></p>
<p><strong>利用绝对定位，将父级元素设置为相对定位。左边元素设置为absolute定位，并且宽度设置为300px。将右边元素的margin-left/ left（因为宽自适应）的值设置为300px。</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">*&#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.outer</span> &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.left</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">background</span>: tomato;</span><br><span class="line">    <span class="attribute">position</span>: absolute;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.right</span> &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100vh</span>;</span><br><span class="line">    <span class="attribute">left</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background</span>: gold;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题5：画一个90°的扇形"><a href="#面试题5：画一个90°的扇形" class="headerlink" title="面试题5：画一个90°的扇形"></a>面试题5：画一个90°的扇形</h3><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&lt;style&gt;</span><br><span class="line">    <span class="selector-class">.div</span> &#123;</span><br><span class="line">        <span class="attribute">width</span>: <span class="number">0</span>;</span><br><span class="line">        <span class="attribute">height</span>: <span class="number">0</span>;</span><br><span class="line">        <span class="attribute">border</span>: <span class="number">100px</span> solid;</span><br><span class="line">        <span class="comment">/* 上 顺时针 */</span></span><br><span class="line">        <span class="attribute">border-color</span>: red transparent transparent transparent;</span><br><span class="line">        <span class="attribute">border-radius</span>: <span class="number">100px</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/style&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;div&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/axios%20%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%B0%81%E8%A3%85_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="axios-的二次封装"><a href="#axios-的二次封装" class="headerlink" title="axios 的二次封装"></a>axios 的二次封装</h1><h2 id="拿到接口文档发起请求可能遇到的情况"><a href="#拿到接口文档发起请求可能遇到的情况" class="headerlink" title="拿到接口文档发起请求可能遇到的情况"></a>拿到接口文档发起请求可能遇到的情况</h2><h3 id="一切正常：没有出现跨域"><a href="#一切正常：没有出现跨域" class="headerlink" title="一切正常：没有出现跨域"></a>一切正常：没有出现跨域</h3><h3 id="出现跨域问题"><a href="#出现跨域问题" class="headerlink" title="出现跨域问题"></a>出现跨域问题</h3><h4 id="前端解决跨域"><a href="#前端解决跨域" class="headerlink" title="前端解决跨域"></a>前端解决跨域</h4><p>在 <code>vue.config.js</code> 中设置代理，但注意他只开发环境中生效，生产环境是无效的。</p>
<p>解决代理问题后</p>
<p>在各个模式下 路径不对的问题需要设置 项目的   <strong>环境变量</strong></p>
<ul>
<li><p>开发环境， <code>.env.develoment</code>  他实际是个隐藏文件</p>
<p>我们<strong>创建这么一个文件</strong>，然后里面配置一些内容例如：</p>
<p> <code>VUE_APP_TITLE= 开发环境</code></p>
<p> <code>VUE_APP_BASEZ_API=&quot;http://fawn.xuexiluxian.cn&quot;</code></p>
</li>
<li><p>生产环境， <code>.env.production</code>他实际是个隐藏文件</p>
<p>我们<strong>创建这么一个文件</strong>，然后里面配置一些内容例如：</p>
<p> <code>VUE_APP_TITLE= 生产环境</code></p>
<p> <code>VUE_APP_BASEZ_API=&quot;http://fawn.kaiaki.cn&quot;</code></p>
</li>
</ul>
<p>这么做就可以在 请求拦截器的时候，判断你现在处于什么模式，对应实际的接口 服务器地址究竟是是谁。</p>
<h4 id="后端解决跨域"><a href="#后端解决跨域" class="headerlink" title="后端解决跨域"></a>后端解决跨域</h4><h3 id="前端请求接口进行二次封装：只要你进公司做项目-99-封装的（注意：这个封装和有没有跨域压根没有关系）"><a href="#前端请求接口进行二次封装：只要你进公司做项目-99-封装的（注意：这个封装和有没有跨域压根没有关系）" class="headerlink" title="前端请求接口进行二次封装：只要你进公司做项目 99 % 封装的（注意：这个封装和有没有跨域压根没有关系）"></a>前端请求接口进行二次封装：只要你进公司做项目 99 % 封装的（注意：这个封装和有没有跨域压根没有关系）</h3><h4 id="axios-的二次封装-1"><a href="#axios-的二次封装-1" class="headerlink" title="axios 的二次封装"></a>axios 的二次封装</h4><p>封装 在request 封装 的意义：</p>
<ul>
<li>url统一管理方便日后更换</li>
<li>在请求拦截器中，可以判断用户是否是登录状态</li>
<li>在响应拦截器中，可以根据返回的status，进行状态选择需要做什么</li>
</ul>
<p>举个例子：<font color="red"><strong>二次封装的 request 文件  一般项目定义在 utils 文件夹中</strong></font></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&quot;axios&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> instance = axios.create(&#123;</span><br><span class="line">    <span class="comment">// baseURL: &#x27;http://testapi.xuexiluxian.cn&#x27;,</span></span><br><span class="line">    <span class="attr">baseURL</span>: <span class="keyword">import</span>.meta.env.VITE_BASE_URL</span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment">// 添加请求拦截器    ---前端给后端的东西，还没到后端</span></span><br><span class="line">axios.interceptors.request.use(<span class="function"><span class="keyword">function</span>(<span class="params">config</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 在发送请求之前做些什么</span></span><br><span class="line">    <span class="keyword">return</span> config;</span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span>(<span class="params">error</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 对请求错误做些什么</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.reject(error);</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 添加响应拦截器    ---后端给前端的东西</span></span><br><span class="line">axios.interceptors.response.use(<span class="function"><span class="keyword">function</span>(<span class="params">response</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 对响应数据做点什么</span></span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span>(<span class="params">error</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 对响应错误做点什么</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.reject(error);</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> instance</span><br></pre></td></tr></table></figure>
<h4 id="api-解耦"><a href="#api-解耦" class="headerlink" title="api 解耦"></a>api 解耦</h4><font color="red">**其一般放在 api 文件下**</font>

<p>封装在 API 解耦 的意义：</p>
<ul>
<li>单独维护 api 的请求 可以让项目中的所有的 “请求” 方便管理</li>
<li>很多页面用同一请求，所以不需要写多次，直接封装变量与一个方法请求，后面用到单独传自己对应的参数就行了。</li>
</ul>
<p><strong>src/api/course.js（对接口进行统一管理，每一个模块（比如这个模块叫course 那就是 course的相关API）的接口都用一个js来独立管理）</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> request <span class="keyword">from</span> <span class="string">&#x27;../utils/request&#x27;</span>;</span><br><span class="line"><span class="comment">// get 方式，传参使用 params</span></span><br><span class="line"><span class="comment">// post 方式，传参使用 data</span></span><br><span class="line"><span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">courseList</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> request(&#123;</span><br><span class="line">        <span class="attr">url</span>: <span class="string">&#x27;/api/course/search&#x27;</span>,</span><br><span class="line">        <span class="attr">method</span>: <span class="string">&#x27;post&#x27;</span>,</span><br><span class="line">        data</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 组件 vue 中可以 <strong>实例化</strong>进行调用</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 引入对应文件的 api 请求</span></span><br><span class="line"><span class="keyword">import</span> &#123; courseList &#125; <span class="keyword">from</span> <span class="string">&#x27;./api/course&#x27;</span></span><br><span class="line">courseList(&#123;</span><br><span class="line">    <span class="attr">pageNum</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">pageSize</span>: <span class="number">10</span></span><br><span class="line">  &#125;).then(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(res);</span><br><span class="line">  &#125;)</span><br></pre></td></tr></table></figure>
<p>所以在正常的项目中，一般定义</p>
<ul>
<li>router文件夹  也就是页面哪个是哪个</li>
<li>utils 工具类   里面 request  作为二次封装</li>
<li>api 文件夹 也就是 api解耦的 各个请求模块对应的 方法集合</li>
</ul>
<h2 id="在-ego-这个项目平台中"><a href="#在-ego-这个项目平台中" class="headerlink" title="在 ego 这个项目平台中"></a>在 ego 这个项目平台中</h2><h3 id="二次封装-axios-的-request-js-文件"><a href="#二次封装-axios-的-request-js-文件" class="headerlink" title="二次封装 axios 的 request.js 文件"></a>二次封装 axios 的 request.js 文件</h3><p>首先在 src的 request 的 <code>request.js</code> 是其二次封装 axios 的文件</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">    封装axios网络请求</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span></span><br><span class="line"><span class="keyword">import</span> qs <span class="keyword">from</span> <span class="string">&#x27;querystring&#x27;</span></span><br><span class="line"><span class="comment">//定义响应错误函数处理协议状态码信息提示</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 处理失败的方法</span></span><br><span class="line"><span class="comment"> *     status:状态</span></span><br><span class="line"><span class="comment"> *     info:错误信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> <span class="keyword">const</span> errorHandle = <span class="function">(<span class="params">status,info</span>) =&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">switch</span>(status)&#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">400</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;表示请求报文中存在语法错误&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">401</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;未经许可，需要通过HTTP认证&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">403</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;服务器拒绝该次访问（访问权限出现问题）&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">404</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;表示服务器上无法找到请求的资源&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">500</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;表示服务器在执行请求时发生了错误&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">503</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;表示服务器暂时处于超负载或正在进行停机维护&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">504</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;（网关超时）  服务器作为网关或代理，但是没有及时从上游服务器收到请求&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="built_in">console</span>.log(info);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//创建实例   一定要写  前端给后端的东西（还没到后端）</span></span><br><span class="line"><span class="keyword">const</span> instance = axios.create(&#123;</span><br><span class="line">    <span class="comment">// baseURL: &#x27;http://iwenwiki.com/&#x27;,//请求的基本的路径地址</span></span><br><span class="line">    <span class="attr">baseURL</span>:process.env.NODE_ENV==<span class="string">&#x27;production&#x27;</span>?process.env.VUE_APP_BASE_URL:<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="attr">timeout</span>:<span class="number">5000</span>,<span class="comment">//等待响应的时间5s </span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加请求拦截器 一定要写  后端给前端的东西</span></span><br><span class="line">instance.interceptors.request.use(<span class="function"><span class="keyword">function</span> (<span class="params">config</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(config.method == <span class="string">&#x27;post&#x27;</span>)&#123;</span><br><span class="line">        <span class="comment">//参数传递：&#123;useename:qq,password:123&#125;  ---&gt;字符串  username=qq&amp;password=123 </span></span><br><span class="line">        <span class="comment">// 一般用来做一些 是否为登录状态的判断</span></span><br><span class="line">        config.data = qs.stringify(config.data)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 在发送请求之前做些什么</span></span><br><span class="line">    <span class="keyword">return</span> config;</span><br><span class="line">  &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">error</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 对请求错误做些什么</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.reject(error);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加响应拦截器</span></span><br><span class="line">instance.interceptors.response.use(<span class="function"><span class="keyword">function</span> (<span class="params">response</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 对响应数据做点什么 一般根据 status 可能会有一些判断区别</span></span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">  &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">error</span>) </span>&#123;</span><br><span class="line">    <span class="comment">//解析返回的错误的状态码  给状态码解析含义 让前端更好的定位错误</span></span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;添加响应拦截器&#x27;</span>,error);</span><br><span class="line">    <span class="keyword">const</span> &#123; response &#125; = error;</span><br><span class="line">    <span class="comment">//response.status 错误状态   500 服务器错误</span></span><br><span class="line">    errorHandle(response.status,response.info)</span><br><span class="line">    <span class="comment">// 对响应错误做点什么</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.reject(error);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> instance</span><br></pre></td></tr></table></figure>
<h3 id="server-中配置路由接口和静态文件"><a href="#server-中配置路由接口和静态文件" class="headerlink" title="server 中配置路由接口和静态文件"></a>server 中配置路由接口和静态文件</h3><h4 id="Mock-js"><a href="#Mock-js" class="headerlink" title="Mock. js"></a>Mock. js</h4><p>每个对应的模块都有自己的 路由地址集合。里面的有使用  Mock.js 生成的数据，也有和数据库进行连邦的数据。</p>
<p>使用 <code>Mock.js</code> 的接口例如  <code>router.js</code> 中的</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> express = <span class="built_in">require</span>(<span class="string">&quot;express&quot;</span>);</span><br><span class="line"><span class="comment">// express 的路由中间件 用于拦截路由</span></span><br><span class="line"><span class="keyword">const</span> router = express.Router();</span><br><span class="line"><span class="comment">//导入mockjs</span></span><br><span class="line"><span class="keyword">const</span> Mock = <span class="built_in">require</span>(<span class="string">&quot;mockjs&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这个就是个 获取订单信息的路由，</span></span><br><span class="line"><span class="comment">// res.send 返回 模拟后端数据的 模拟数据 </span></span><br><span class="line"><span class="comment">// res.send 默认会变成 json格式的</span></span><br><span class="line">router.get(<span class="string">&quot;/home/orderinfo&quot;</span>, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  res.send(</span><br><span class="line">    Mock.mock(&#123;</span><br><span class="line">      <span class="attr">info</span>: <span class="string">&quot;订单统计信息&quot;</span>,</span><br><span class="line">      <span class="attr">success</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">list</span>: &#123;</span><br><span class="line">        <span class="string">&quot;orderCount|1-100000&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&quot;curOrderCount|1-1000&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">count</span>: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (<span class="built_in">this</span>.curOrderCount &gt; <span class="built_in">this</span>.orderCount) &#123;</span><br><span class="line">            [<span class="built_in">this</span>.orderCount, <span class="built_in">this</span>.curOrderCount] = [</span><br><span class="line">              <span class="built_in">this</span>.curOrderCount,</span><br><span class="line">              <span class="built_in">this</span>.orderCount,</span><br><span class="line">            ];</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;money|1-200000&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&quot;curMoney|1-1000&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">moneyfun</span>: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (<span class="built_in">this</span>.curMoney &gt; <span class="built_in">this</span>.money) &#123;</span><br><span class="line">            [<span class="built_in">this</span>.money, <span class="built_in">this</span>.curMoney] = [<span class="built_in">this</span>.curMoney, <span class="built_in">this</span>.money];</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;collect|1-99999&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&quot;curCollect|1-999&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">collectfun</span>: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (<span class="built_in">this</span>.curCollect &gt; <span class="built_in">this</span>.collect) &#123;</span><br><span class="line">            [<span class="built_in">this</span>.collect, <span class="built_in">this</span>.curCollect] = [<span class="built_in">this</span>.curCollect, <span class="built_in">this</span>.collect];</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">department</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="attr">branchSchool</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;)</span><br><span class="line">  );</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h4 id="连本地数据库"><a href="#连本地数据库" class="headerlink" title="连本地数据库"></a>连本地数据库</h4><p>首先创建一个   <code>mysql.js</code> 文件</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//连接数据库  1.npm安装mysql 2.创建连接</span></span><br><span class="line"><span class="keyword">const</span> mysql = <span class="built_in">require</span>(<span class="string">&#x27;mysql&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建数据库连接</span></span><br><span class="line"><span class="keyword">const</span> client = mysql.createConnection(&#123;</span><br><span class="line">    <span class="attr">host</span>: <span class="string">&#x27;localhost&#x27;</span>, <span class="comment">//数据域名 地址</span></span><br><span class="line">    <span class="attr">user</span>: <span class="string">&#x27;root&#x27;</span>, <span class="comment">//数据名称</span></span><br><span class="line">    <span class="attr">password</span>: <span class="string">&#x27;root&#x27;</span>, <span class="comment">//数据库密码 xampp集成  我这里是 phpStudy</span></span><br><span class="line">    <span class="attr">database</span>: <span class="string">&#x27;ego&#x27;</span>,</span><br><span class="line">    <span class="comment">// port:&#x27;3306&#x27;</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">//封装数据库操作语句 sql语句 参数数组arr  callback成功函数结果</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sqlFun</span>(<span class="params">sql, arr,callback</span>) </span>&#123;</span><br><span class="line">    client.query(sql,arr, <span class="function"><span class="keyword">function</span> (<span class="params">error, result</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (error) &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;数据库语句错误&#x27;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        callback(result)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回操作连接的对象函数 （sql语句，值，返回的结果）</span></span><br><span class="line"><span class="built_in">module</span>.exports = sqlFun</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>同样你可以和数据库进行联合</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> express = <span class="built_in">require</span>(<span class="string">&quot;express&quot;</span>);</span><br><span class="line"><span class="comment">// express 的路由中间件 用于拦截路由</span></span><br><span class="line"><span class="keyword">const</span> router = express.Router();</span><br><span class="line"><span class="keyword">const</span> sqlFn = <span class="built_in">require</span>(<span class="string">&quot;./mysql&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如为 获取分页某一页的 商品信息</span></span><br><span class="line">router.get(<span class="string">&quot;/goods/projectList&quot;</span>, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> page = req.query.page || <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">const</span> sqlLen = <span class="string">&quot;select * from project where id&quot;</span>;</span><br><span class="line">  sqlFn(sqlLen, <span class="literal">null</span>, <span class="function">(<span class="params">data</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> len = data.length;</span><br><span class="line">    <span class="keyword">const</span> sql =</span><br><span class="line">      <span class="string">&quot;select * from project order by id desc limit 8 offset &quot;</span> + (page - <span class="number">1</span>) * <span class="number">8</span>;</span><br><span class="line">    sqlFn(sql, <span class="literal">null</span>, <span class="function">(<span class="params">result</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (result.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        res.send(&#123;</span><br><span class="line">          <span class="attr">status</span>: <span class="number">200</span>,</span><br><span class="line">          <span class="attr">data</span>: result,</span><br><span class="line">          <span class="attr">pageSize</span>: <span class="number">8</span>,</span><br><span class="line">          <span class="attr">total</span>: len,</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        res.send(&#123;</span><br><span class="line">          <span class="attr">status</span>: <span class="number">500</span>,</span><br><span class="line">          <span class="attr">msg</span>: <span class="string">&quot;暂无数据&quot;</span>,</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h3 id="API-解耦"><a href="#API-解耦" class="headerlink" title="API 解耦"></a>API 解耦</h3><h4 id="base-js"><a href="#base-js" class="headerlink" title="base. js"></a>base. js</h4><p>作者将之前 server 中定义的路由，全部在 <code>base.js</code> 中进行提取，之后调用键，就可以访问对应实际的路由了</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> base =&#123;</span><br><span class="line">    <span class="attr">host</span>:<span class="string">&#x27;http://localhost:9898&#x27;</span>,</span><br><span class="line"></span><br><span class="line">    <span class="comment">//首页数据统计顶部</span></span><br><span class="line">    <span class="attr">homeCount</span>:<span class="string">&#x27;/api/home/dataCount&#x27;</span>,<span class="comment">//首页数据统计顶部  与 外部的 sever中 router.js 接口一致</span></span><br><span class="line">    <span class="attr">homeFormat</span>:<span class="string">&#x27;/api/home/format&#x27;</span>,<span class="comment">//首页折现图</span></span><br><span class="line">    <span class="attr">homeOrder</span>:<span class="string">&#x27;/api/home/orderinfo&#x27;</span>,<span class="comment">//首页今日订单</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//产品管理接口</span></span><br><span class="line">    <span class="attr">goodsList</span>:<span class="string">&#x27;/api/goods/projectList&#x27;</span>,<span class="comment">//商品列表</span></span><br><span class="line">    <span class="attr">goodsSearch</span>:<span class="string">&#x27;/api/goods/search&#x27;</span>,<span class="comment">//商品查询接口</span></span><br><span class="line">    <span class="attr">deleteGoods</span>:<span class="string">&quot;/api/goods/deleteItemById&quot;</span>,<span class="comment">//删除商品id</span></span><br><span class="line">    <span class="attr">goodsItemCategory</span>:<span class="string">&quot;/api/goods/itemCategory/selectItemCategoryByParentId&quot;</span>,<span class="comment">//商品添加类目选择</span></span><br><span class="line">    <span class="attr">addGoods</span>:<span class="string">&quot;/api/goods/item/insertTbItem&quot;</span>,<span class="comment">//商品添加地址</span></span><br><span class="line">    <span class="attr">changeGoods</span>:<span class="string">&quot;/api/goods/item/updateTbItem&quot;</span>,<span class="comment">//商品修改</span></span><br><span class="line">    <span class="attr">batchDelete</span>:<span class="string">&quot;/api/goods/batchDelete&quot;</span>,<span class="comment">//批量删除商品</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 图片上传接口</span></span><br><span class="line">    <span class="attr">uploadUrl</span>:<span class="string">&quot;/api/upload&quot;</span>,</span><br><span class="line">    <span class="comment">//富文本图片上传接口</span></span><br><span class="line">    <span class="comment">// batchUpload:&quot;/api/batchUpload&quot;,</span></span><br><span class="line">    <span class="comment">// /产品分类</span></span><br><span class="line">    <span class="attr">itemCategory</span>:<span class="string">&quot;/api/itemCategory&quot;</span>,</span><br><span class="line">    <span class="attr">insertCategory</span>:<span class="string">&quot;/api/itemCategory/insertCategory&quot;</span>,<span class="comment">//一级类目</span></span><br><span class="line">    <span class="attr">updateCategory</span>:<span class="string">&quot;/api/itemCategory/updateCategory&quot;</span>,<span class="comment">//一级分类修改</span></span><br><span class="line">    <span class="attr">deleteContentCategoryById</span>:<span class="string">&quot;/api/content/deleteContentCategoryById&quot;</span>,<span class="comment">//删除类目</span></span><br><span class="line">    <span class="attr">insertItemCategory</span>:<span class="string">&quot;/api/itemCategory/insertItemCategory&quot;</span>,<span class="comment">//新增子类目录</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//登录接口</span></span><br><span class="line">    <span class="attr">login</span>:<span class="string">&quot;/api/login&quot;</span>,<span class="comment">//登录接口 user pwd</span></span><br><span class="line">    <span class="attr">permission</span>:<span class="string">&quot;/api/permission&quot;</span>,<span class="comment">//用户权限---token </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// login:api+&quot;/login&quot;,//登录接口 user pwd</span></span><br><span class="line">    <span class="comment">// permission:api+&quot;/permission&quot;,//用户权限---token </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//广告分类</span></span><br><span class="line">    <span class="attr">getAdvertlist</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//导出单个文件</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> host=<span class="string">&#x27;http://localhost:9898&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//导出图片 上传</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> uploadUrl=<span class="string">&#x27;/api/upload&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 导出接口</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> base</span><br></pre></td></tr></table></figure>
<h4 id="index-js"><a href="#index-js" class="headerlink" title="index .js"></a>index .js</h4><p>然后在这里 引入 二次封装的axios  并创建 api 解耦的实际方法，并导出</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base <span class="keyword">from</span> <span class="string">&quot;./base&quot;</span>;</span><br><span class="line"><span class="comment">// 二次封装</span></span><br><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&quot;../request/request&quot;</span>;</span><br><span class="line"></span><br><span class="line">axios.defaults.baseURL=process.env.VUE_APP_BASE_URL</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> api = &#123;</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">        1. 首页顶部数据统计</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">getHomeCount</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.homeCount);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    2. 首页图表绘制</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="title">getHomeFormat</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.homeFormat);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">  3. 订单信息 </span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="title">getHomeOrder</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.homeOrder);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">  4. 产品列表 </span></span><br><span class="line"><span class="comment">    page </span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="function"><span class="title">getGoodsList</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.goodsList, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    5. 产品查询</span></span><br><span class="line"><span class="comment">    search  params是 goodsName</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="function"><span class="title">getGoodsSearch</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(params)</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.goodsSearch, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    6. 删除商品  </span></span><br><span class="line"><span class="comment">    params 是 id 也就是第几行</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="function"><span class="title">deleteGoods</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.deleteGoods, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">  7.商品类目选择</span></span><br><span class="line"><span class="comment">  goodsItemCategory</span></span><br><span class="line"><span class="comment">    type</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="function"><span class="title">goodsItemCategory</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.goodsItemCategory, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    8. 商品添加</span></span><br><span class="line"><span class="comment">      参数： title cid  category sellPoint price num descs paramsInfo image</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="function"><span class="title">addGoods</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.addGoods, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    9. 商品修改 title cid  category sellPoint price num descs paramsInfo image</span></span><br><span class="line"><span class="comment">    changeGoods</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  <span class="function"><span class="title">changeGoods</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.changeGoods, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    10. 批量删除商品</span></span><br><span class="line"><span class="comment">      ids=(1,2,3) 字符串 [1,2,3]=&gt;转成字符串格式</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">batchDelete</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.batchDelete, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    11. 富文本上传图片</span></span><br><span class="line"><span class="comment">    batchUpload</span></span><br><span class="line"><span class="comment">      myaxios axios本身 无二次封装---  </span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">batchUpload</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.post(base.batchUpload, params);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    12. 产品列表分类</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">itemCategory</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.itemCategory);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    13. 产品类目一级导航</span></span><br><span class="line"><span class="comment">      name</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  <span class="function"><span class="title">insertCategory</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.insertCategory, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    14. 修改一级分类名称</span></span><br><span class="line"><span class="comment">      name id </span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">updateCategory</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.updateCategory, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    15. 删除分类名称 </span></span><br><span class="line"><span class="comment">    deleteContentCategoryById</span></span><br><span class="line"><span class="comment">    id</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  <span class="function"><span class="title">deleteContentCategoryById</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.deleteContentCategoryById, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    16. 新增子类名称  cid name </span></span><br><span class="line"><span class="comment">    insertItemCategory </span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">insertItemCategory</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.insertItemCategory, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">      17. 登录   name pwd</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">login</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.post(base.login, params);</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">    18. 用户权限  token </span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="title">permission</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> axios.get(base.permission, &#123; params &#125;);</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span>  <span class="function"><span class="keyword">function</span> <span class="title">permission</span>(<span class="params">params</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> axios.get(base.permission, &#123; params &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> api;</span><br></pre></td></tr></table></figure>
<p>我们可以在 <code>main.js</code> 中挂载这个属性 我们就可以使用 this 来使用了</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">Vue.prototype.$api = api</span><br></pre></td></tr></table></figure>
<h3 id="组件中使用接口"><a href="#组件中使用接口" class="headerlink" title="组件中使用接口"></a>组件中使用接口</h3><p>因为我们之前绑定在 this 上了，所以我们不需要在各个组件中进行引入</p>
<p>直接像这样 使用 async + await 调用就可以了</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据页面 查询数据</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">getGoodsList</span>(<span class="params">page</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.getGoodsList(&#123;page&#125;)</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;表单数据 res.data&quot;</span>, res.data)</span><br><span class="line">    <span class="keyword">if</span>(res.data.status === <span class="number">200</span>)&#123;</span><br><span class="line">        <span class="built_in">this</span>.tableData = res.data.data</span><br><span class="line">        <span class="built_in">this</span>.totalPage = res.data.total</span><br><span class="line">        <span class="built_in">this</span>.pageSize = res.data.pageSize</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        alert(<span class="string">&quot;请求产品数据失败&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p><strong>当然你使用 .then也是可以的，因为 axios 实际封装返回的 还是 promise对象</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据产品名称 查询数据</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">getGoodsSearch</span>(<span class="params">goodsName</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.$api.getGoodsSearch(&#123;<span class="attr">search</span>:goodsName&#125;)</span><br><span class="line">        .then(<span class="function"><span class="params">res</span> =&gt;</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(res.data)</span><br><span class="line">        <span class="keyword">if</span>(res.data.status == <span class="number">200</span>)&#123;</span><br><span class="line">            <span class="built_in">this</span>.listTotal = res.data.result</span><br><span class="line">            <span class="comment">// 我拿到的数据是 如果超过页面上线 就要分页 </span></span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">this</span>.listTotal.length &gt; <span class="number">8</span>)&#123;</span><br><span class="line">                <span class="built_in">this</span>.seachStatus = <span class="literal">true</span></span><br><span class="line">                <span class="comment">// 截取出8个 作为第一页展示</span></span><br><span class="line">                <span class="built_in">this</span>.tableData = res.data.result.slice(<span class="number">0</span>,<span class="number">8</span>)</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">this</span>.totalPage = res.data.result.length</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">this</span>.pageSize = <span class="built_in">Math</span>.min(<span class="number">8</span>, <span class="built_in">this</span>.pageSize)</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">// 啥数据没查出来 就是空</span></span><br><span class="line">            <span class="built_in">this</span>.tableData = []</span><br><span class="line">            <span class="built_in">this</span>.totalPage = <span class="number">0</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">        .catch( <span class="function"><span class="params">err</span> =&gt;</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;请求失败&quot;</span>, err.data)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>yolov3 详解</title>
    <url>/2021/10/23/yolov3%20%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>@<a href="同济子豪兄 之 yolov3 详解">TOC</a></p>
<h1 id="yolov1v2v3系列的区别"><a href="#yolov1v2v3系列的区别" class="headerlink" title="yolov1v2v3系列的区别"></a>yolov1v2v3系列的区别</h1><p><img src="https://img-blog.csdnimg.cn/img_convert/6c76949fa52cb10efb04a7115232ec10.png" alt="yolov1v2v3系列的区别"></p>
<h1 id="yolov3-存在的问题-与-改进"><a href="#yolov3-存在的问题-与-改进" class="headerlink" title="yolov3 存在的问题 与 改进"></a>yolov3 存在的问题 与 改进</h1><blockquote>
<p>如何评判目标检测的效果好坏，以及AP如何计算？ 请看另一文章<br><a href="http://www.baidu.com">评判目标检测性能以及如何计算AP等</a></p>
</blockquote>
<p>yolov3 在 IoU 阈值为0.5的情况下，AP值较好（也就是框框并不需要和 Ground Truth 贴合的很准，条件比较宽松）。<br>但 IoU 阈值在0.5-0.95，以0.05作为步长的1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0个阶段，得到的 AP平均值 就不佳， 也就是说明 yolov3在<strong>精准定位对象的性能上仍然是比较差的</strong>，但是换来的FPS是比较不错的。</p>
<p>在检测 小目标或密集目标 能力上有所改进。</p>
<ol>
<li>grid cell 个数增加（v2 和 v3 都可以兼容任意图片大小的输入） 能检测对象的预测框多了。v2和v3 你输入的图像越大，那能用于检测对象的 预测框也就越多</li>
<li>Anchor   预先设置了一些比较小的anchor。 v1中直接生成小目标的预测框是比较难的，但在小anchor的基础上计算预测框容易的多</li>
<li>多尺度预测（FPN） 例如 52×52这个大尺度的，感受野就对应于小目标。FPN 既提取了深层网络中特化语义信息，并结合了浅层细粒度像素结构信息（边缘轮廓转角等）。对于小目标而言，边缘和轮廓等细粒度信息是很重要的。</li>
<li>损失函数 含有 惩罚小框项</li>
<li>网络结构（骨干网络 跨层链接 残差链接）</li>
</ol>
<h1 id="yolov3-相较于-v2-的改进-（即细节）"><a href="#yolov3-相较于-v2-的改进-（即细节）" class="headerlink" title="yolov3 相较于 v2 的改进 （即细节）"></a>yolov3 相较于 v2 的改进 （即细节）</h1><p>yolov2 存在的问题是,对小物体的检测精度还是不高。<br>毕竟，一张图片经过卷积层（特征提取）到最后的特征图，包含小物体的信息是会有损失的。</p>
<h2 id="多尺度输出"><a href="#多尺度输出" class="headerlink" title="多尺度输出"></a>多尺度输出</h2><p>在 yolov3 中，共设置9个宽高不同的anchor（同样是通过 K-means 聚类获取得到），每个 grid cell 的 anchor 的数量为 9/3=3 个，因为 yolov3 有3个feature_map，不同feature_map的size和感受野是不一样的，<strong>较小size的feature_map具有较大的感受野</strong>，所以负责检测较大的物体，同理，<strong>较大size的feature_map有较小的感受野</strong>，负责检测较小的物体。如下图举个例子：</p>
<blockquote>
<p><img src="https://img-blog.csdnimg.cn/img_convert/c87f61996eac9a9575d77e7adb179aef.png#pic_center" alt="yolov3 的整个网络模型"><br>上面的就是 yolov3 的整个网络模型，输出的一共有3种尺度（255 = 3×(5+80) 因为用的COCO数据集）。对于第一个 13×13×255 的输出来说，416（输入尺寸）÷ 13(输出尺寸) = 32（也就是 下采样 32），<strong>换句话说就是 对于13×13的特征图，单元网格1×1×255的特征向量 对应 输入原图 32×32×3 的信息</strong> （感受野最大，所以负责检测较大的物体）<br><img src="https://img-blog.csdnimg.cn/img_convert/cb17483efe5e14f32454f709268f27bf.png#pic_center" alt="在这里插入图片描述"><br>用如上图的例子可以看出，<strong>小特征图有大的anchor box，适合检测大物体</strong>（你可以这么理解，对于大物体我们其实只要很粗糙的像素内容就可以认出来，比如我们把一张小马图片用切片机去掉几行几列，我们还是认得出来这是匹马；而对于小物体，我们确实需要更大的特征图，因为其更能保留细度的特征，你也可以这么理解就是我裁剪的太过分了，小物体主体都快被我裁完了怎么可能认得出来）</p>
</blockquote>
<h2 id="输入图片-等比例变化"><a href="#输入图片-等比例变化" class="headerlink" title="输入图片 等比例变化"></a>输入图片 等比例变化</h2><p>v2的时候采取了多尺度训练的方式，并且使用了一个GAP层来帮助解决输入图片尺寸不一样的情况。<br>v3对输入图片本身做了一定的处理。<br>一般对图形的处理有两种方式：</p>
<ul>
<li>第一种就是把图片不管比例直接变成这边的 416×416 分辨率；</li>
<li>第二种就是先设定一个 416×416 的黑框，然后将图片等比例变化后放入黑框中，在训练和预测的时候黑色的部分会被当做成背景，不会对结果有什么影响。</li>
</ul>
<p>在实际操作中这两种方法都是可行的。</p>
<h2 id="yolov3的-预测框计算机制-未变"><a href="#yolov3的-预测框计算机制-未变" class="headerlink" title="yolov3的 预测框计算机制 未变"></a>yolov3的 预测框计算机制 未变</h2><p>yolov3的预测框，预测出来的方法与yolov2是<strong>一致的</strong>。</p>
<p><font color="red">训练过程中，都是看实际框中心点落在哪个grid cell，拿出这个grid cell 的所有anchor box 看实际框与哪个anchor box 的IoU最大</font>  <font color="green">（注意：是两个框中心点对其后的IoU）</font>，就选择这个anchor box 作为模板。 <font color="blue">然后根据这个anchor box 进行校准</font>。 </p>
<p><font color="green">注意： $t<em>{x}$ 这些才是我们网络的输出，也就是这边的 $b</em>{x}$ 我们是命令一个新的函数对其操作得到的。所以ground truth 也要将 长宽中心点这些 $b<em>{i}$ 调整成 $t</em>{i}$ 来进行计算损失</font><br>如下图所示： 其中 $c<em>{x}$ 和 $c</em>{y}$ 表示单元格长度（分别为 +2 和 +1）<br>注意：在实际运算中，为了运算方便，$b<em>{x}$ 与 $b</em>{x}^{‘}$ 都指的是<font color="red">预测框中心点到图像边界的距离</font>，而不是相对于到单元格的距离。<br>另外 因为 $c<em>{x}$和$c</em>{y}$都是以1为单位的（也就是下采样过），所以我们计算得到的 $b<em>{x}$ 与 $b</em>{y}$ 其实都是<strong>相对量</strong>，（$b<em>{h}$与$b</em>{w}$是正确尺寸的值）所以我们在最后将框还原到原图尺寸的时候，中心点需乘以grid cell 的下采样倍数，得到原始图像输入图像上预测框 中心点 的坐标。<br><img src="https://img-blog.csdnimg.cn/img_convert/9e6dfd393abd6cb189a7cbf246524bd2.png#pic_center" alt="预测框位置计算方法"></p>
<h2 id="yolov3-Anchor-box对应机制"><a href="#yolov3-Anchor-box对应机制" class="headerlink" title="yolov3 Anchor box对应机制"></a>yolov3 Anchor box对应机制</h2><p>注： yolov3 中使用的 anchor box 的数量是3个<br>如下图所示，每个 grid cell 都可以有3个 anchor box，那样就可以达到如下满满当当的效果，也就是可以检测出更多的物体对象。<br><img src="https://img-blog.csdnimg.cn/img_convert/cdd82c32539d5b3a137afa3f7abad3d2.png#pic_center" alt="每个grid cell 可以有 3个 anchor box"></p>
<h2 id="yolov3-在置信度上与yolov1和v2的区别"><a href="#yolov3-在置信度上与yolov1和v2的区别" class="headerlink" title="yolov3 在置信度上与yolov1和v2的区别"></a>yolov3 在置信度上与yolov1和v2的区别</h2><blockquote>
<p><strong>在 yolov1和v2中使用IoU作为置信度标签</strong>有何不好的地方？<br> <font color="blue">v1和v2中  $P(object)* IoU$ 来计算置信度标签 </font>，对于ground truth $P{object}=1$ 所以 就是使用 IoU最为置信度标签。这样的坏处在：<br>1.很多预测框与 ground truth 的IoU最高只有0.7（最好的只有70分）也就是置信度最高只有0.7. 换句话就是我最高就0.7了，我网络怎么学也很难超过0.7.<br>2.COCO中的小目标，IoU对像素偏移很敏感，无法有效学习</p>
</blockquote>
<p>yolov3 中使用逻辑回归来计算每个预测框的置信度，每个预测框标签的置信度均为1 （告诉网络我这个就是正样本，你得给我好好学。）<strong>正样本(也就是和GT IoU最大的那个anchor 校准得到的预测框)的置信度规定为1，负样本的置信度规定为0</strong>。下面可以参考一下什么是正负样本：<br><img src="https://img-blog.csdnimg.cn/img_convert/c7b5415b0d72118add3de4035995175a.png#pic_center" alt="正样本、不参与 与 负样本"><br>正样本：与ground truth IoU最大的anchor 校准的预测框<br>不参与（不负责预测）：anchor与ground truth IoU大于阈值（论文是0.5）但是 不是最大的  就什么也不是 。 其实本来就没考虑它，你也不是最大的。<br>负样本：anchor 与ground truth IoU 小于阈值（论文是0.5） 的  或者完全就不重叠的anchor。 其实本来也就没考虑它。</p>
<h2 id="具体-如何预测-预测框"><a href="#具体-如何预测-预测框" class="headerlink" title="具体 如何预测 预测框"></a>具体 如何预测 预测框</h2><p>yolov3的预测框，预测出来的方法与yolov2是<strong>一致的</strong>。 <strong>每个GT仅仅分配一个anchor（也就是一个预测框）负责预测</strong>，这个是相对于</p>
<p><font color="red">训练过程中，都是看实际框中心点落在哪个grid cell，拿出这个grid cell 的所有anchor box 看实际框与哪个anchor box 的IoU最大<font color="green">（注意：是两个框中心点对其后的IoU）</font>，就选择这个anchor box 作为模板。&lt;/font&gt; 然后对其进行训练修正（上面讲的计算偏移机制），<font color="green">注意：$t<em>{x}$ 这些才是我们网络的输出，也就是这边的 $b</em>{x}$我们是命令一个新的函数对其操作得到的。所以ground truth 也要将 长宽中心点这些 $b<em>{i}$调整成 $t</em>{i}$ 来进行计算损失</font>，调整模型参数后 得到最佳的预测框。</p>
<h2 id="yolov3的网络结构-变化"><a href="#yolov3的网络结构-变化" class="headerlink" title="yolov3的网络结构 变化"></a>yolov3的网络结构 变化</h2><p>最后 应该是 255维度（用的COCO） 注意<br><img src="https://img-blog.csdnimg.cn/img_convert/9e22e1993729ae01cbe5f304f4aff4b0.png#pic_center" alt="yolov3网络结构"></p>
<h3 id="Backbone-Darknet-53"><a href="#Backbone-Darknet-53" class="headerlink" title="Backbone  Darknet-53"></a>Backbone  Darknet-53</h3><blockquote>
<p><strong>53的由来</strong><br>步长为2的卷积层有5个  图中<font color="turquoise">蓝色的部分 </font><br>步长为1的卷积层有47个  （47=1+1×2+2×2+8×2+8×2+4×2 ）图中<font color="green">绿色的部分</font><br>最后 的全连接网络层 为1层 含有参数<br>所以一共53层</p>
<p><font color="red">红色的部分</font> 是残差层 和全连接层之前的下采样层一样都是没有参数的  所以不参与网络层的统计</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/img_convert/08afccd5b374fc0bd1119467928a74ed.png#pic_center" alt="Darknet-53分类网络模型"><br>作者构建了darknet-53，在<strong>ImageNet数据集上，进行分类测试</strong>。发现精度和Resnet-101和Resnet-152 精度都差不多，但计算速度比这两者快很多，而且网络层数少很多。</p>
<p>其中里面的每一个 Convolution 都是由 卷积层+BN层+Leakyrelu激活函数层。 这边统一叫做 CBL<br><img src="https://img-blog.csdnimg.cn/img_convert/652afb5491146ca97dbed44900e85413.png#pic_center" alt="CBL层"></p>
<h4 id="换句话说的-Darknet-53分类模型结构"><a href="#换句话说的-Darknet-53分类模型结构" class="headerlink" title="换句话说的 Darknet-53分类模型结构"></a>换句话说的 Darknet-53分类模型结构</h4><p><img src="https://img-blog.csdnimg.cn/img_convert/33b1068d6caaf8a31fe6bb30db83901a.png#pic_center" alt="Darknet-53 分类模型结构"><br>包括之前说的各种结构部分 Res4也就是上上图中框出来的那部分。</p>
<h3 id="Neck-层"><a href="#Neck-层" class="headerlink" title="Neck 层"></a>Neck 层</h3><p>注意 这里的 21 其实是 255 （这个作者 定义的是两种类别 实际是 80种即COCO （1+4+80）×3）<br><img src="https://img-blog.csdnimg.cn/img_convert/9e22e1993729ae01cbe5f304f4aff4b0.png#pic_center" alt="看各层的维度"><br>在主干网络提取出图像特征之后，为了能更好的融合提取的特征，还是用了Neck结构。不过因为最后的输出层有3种特征图（13×13，26×26以及52×52），而主干网络输出的矩阵尺寸为 13×13。所以要经过Neck结构中的 <font color="blue">FPN结构</font> 和前面的 26×26，52×52 特征图进行多尺度融合。</p>
<p>这里我们对上图种框出的 <font color="violet">上采样结构</font> 做分析：</p>
<ul>
<li>上面那条支路 为 骨干网络 最后的输出维度 13×13  通过CBL 再 <strong>上采样</strong>一下 变为了 26×26</li>
<li>下面那条支路 为 骨干网络种 中途输出的维度 26×26</li>
<li>所以整合Concat操作  得到还是 26×26的维度  <font color="red">注意他是通道相叠</font><br><img src="https://img-blog.csdnimg.cn/img_convert/245e8edc104a69ed5d3588936d7de912.png#pic_center" alt="在这里插入图片描述"></li>
</ul>
<p>同理后面几次操作：<br><img src="https://img-blog.csdnimg.cn/img_convert/334d06804ca1bae824c16ef34334ae28.png#pic_center" alt="后续操作"></p>
<h2 id="最后输出的-类别的条件概率-理解"><a href="#最后输出的-类别的条件概率-理解" class="headerlink" title="最后输出的 类别的条件概率 理解"></a>最后输出的 类别的条件概率 理解</h2><p>yolov3与v1和v2在 输出的类别条件概率的想法是一致的，都采用的是 各类别独立的逻辑回归（即多分类标签），每个类别的最大概率都为1，不互相干扰都互相独立。 也就是不适用softmax，因为softmax的话，输出的结果就是每个类别条件概率之和为1。</p>
<p>对于yolov3 每个预测框的每个类别逐一用逻辑回归输出概率，可有多个类别输出高概率。</p>
<p>拿分类误差，使用的损失函数，那肯定也是 二分类交叉熵损失函数（因为我每个类是分开单独考虑的 逻辑回归）</p>
<h1 id="yolov3的训练过程"><a href="#yolov3的训练过程" class="headerlink" title="yolov3的训练过程"></a>yolov3的训练过程</h1><p><img src="https://img-blog.csdnimg.cn/img_convert/0432e7404ad9328cd5878ca4cf4b9999.png#pic_center" alt="yolov3 训练过程"></p>
<p>输入416×416大小的图像，在经过主干网络darknet-53的卷积网络以及Neck中的FPN结构。可以得到输出层(P0、P1、P2)三种特征图，P0的尺寸最大为52×52，P1是中间尺寸为26×26，P2尺寸最小为13×13。</p>
<p>特征图上每个单元格的特征向量都可以对应416×416图像上的一块感受野区域，而每个区域都会生成三个初始anchor box，因此网络输出的 $t<em>{x} 、t</em>{y}、t<em>{h}、t</em>{w}$ 可以利用anchor，计算得到预测框。再加上前景背景的概率obj以及类别概率cls，就可以汇总得到，目标检测网络输出的预测信息。</p>
<p>但从监督学习的角度，我们会对训练的样本进行标注，因此我们可以知道，图片上每一个物体，它实际框的位置和类别。所以可以根据，前面讲的anchor的对应机制，分别对应到各自anchor上，并打上类别的标签。这样，就可以将预测框和 ground truth 的信息，对应关联起来。</p>
<p>从P0、P1、P2，三个特征图的角度，对前景和背景的概率以及Location位置信息，和class类别信息。从这三个方面，来计算预测框和ground truth 之间的偏差即损失函数，而总体的损失函数，等于三个特征图的损失函数之和。<br><img src="https://img-blog.csdnimg.cn/img_convert/086ebe71480140b2b7d74addd16dfec2.png#pic_center" alt="yolov3 损失函数"></p>
<p>当有了损失函数，就可以利用网络的梯度更新方式，来进行反向传播了，从而不断迭代，更新网络中的参数。使得损失函数的值，越来越小，从而越来越准确。</p>
<h2 id="详细-损失函数-介绍"><a href="#详细-损失函数-介绍" class="headerlink" title="详细 损失函数 介绍"></a>详细 损失函数 介绍</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/086ebe71480140b2b7d74addd16dfec2.png#pic_center" alt="yolov3 损失函数"><br>yolov3的损失函数主要分为3部分： 分类误差，定位误差，置信度误差</p>
<ul>
<li>正样本对 分类误差、定位误差、置信度误差 学习产生贡献</li>
<li>对不负责预测的框（其实本来就不考虑） 置信度为0 所以 它啥也不算</li>
<li><font color="blue">负样本只对置信度误差 学习产生贡献 </font> <font color="violet">为什么呢？ 负样本的置信度不是 规定为0了么？ 为什么会对置信度误差产生贡献呢？？？</font>  <h1 id="yolov3的测试过程"><a href="#yolov3的测试过程" class="headerlink" title="yolov3的测试过程"></a>yolov3的测试过程</h1></li>
</ul>
<p>yolov3的测试过程主要分为两步。<br><img src="https://img-blog.csdnimg.cn/img_convert/89a8c6292269e80936b9a1415dd918de.png#pic_center" alt="yolov3 的测试过程"></p>
<ul>
<li>第一步，先通过网络的$t<em>{x}、t</em>{y}、t_{h}、t{w}$等输出向量，计算处预测框的位置和所属的类别信息。注意预测框的得分应该为  <strong>前景和背景的概率 × class 类别的得分</strong>。<ul>
<li>并设置阈值分数 例如为0.3。将预测框分数，大于0.3的都保留下来。而分数比较低的都过滤掉，这样的好处是保留的框既是前景即目标的框，同时也是类别分数，比较大的目标。</li>
<li>第一步如上，得到了三个特征图预测框的信息<ul>
<li>但现在的框，还是太多了。因此我们需要在一定的标准下去评判这些目标框信息。所以第二步 我们需要将三个特征图上的结果，全部映射回416×416输入图像上。这时，在416×416的图片上，就有多种类别很多的框了。</li>
<li>这时需要针对每个类别，做一个NMS，即非极大值抑制处理，消除重叠度很高的框。这样到了最后，我们就可以得到最终的预测框的信息，以及得分，从而完成目标的检测和定位。</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>yolo</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/%E5%89%8D%E7%AB%AF%20JS%20%E9%80%89%E6%8B%A9%E9%A2%98%E7%AC%94%E8%AF%95/</url>
    <content><![CDATA[<h2 id="前端-JS-选择题笔试"><a href="#前端-JS-选择题笔试" class="headerlink" title="前端 JS 选择题笔试"></a>前端 JS 选择题笔试</h2><h3 id="Git-指令"><a href="#Git-指令" class="headerlink" title="Git 指令"></a>Git 指令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">https://blog.csdn.net/qq_38111015/article/details/84885809</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Git 暂存操作的API </strong>        <code>git stash</code></li>
<li><strong>利用二分法的思想，来查找哪一次代码提交引入了错误 </strong>     <code>git bisect</code></li>
<li><strong>切换</strong>    <code>git checkout</code></li>
<li><strong>合并（拉公共分支最新代码的时候使用）</strong>      <code>git rebase</code></li>
<li><strong>合并（拉代码或者push代码都可使用）</strong>         <code>git merge</code></li>
<li><strong>远程端下载至本地 </strong>    <code>git fetch/clone</code> </li>
<li><strong>本地分支-&gt;远程主机</strong>          <code>git push</code> </li>
</ul>
<h3 id="Linux-指令"><a href="#Linux-指令" class="headerlink" title="Linux 指令"></a>Linux 指令</h3><ul>
<li>Linux <code>su</code>（英文全拼：switch user）命令用于变更为其他使用者的身份 </li>
<li>Linux <code>chown</code>（英文全拼：<strong>change owner</strong>）命令用于设置文件所有者和文件关联组的命令 </li>
<li>Linux <code>chmod</code>（英文全拼：change mode）命令是控制用户对文件的权限的命令</li>
</ul>
<h3 id="JS-基础语法问题"><a href="#JS-基础语法问题" class="headerlink" title="JS 基础语法问题"></a>JS 基础语法问题</h3><h4 id="JS-的基本数据类型"><a href="#JS-的基本数据类型" class="headerlink" title="JS 的基本数据类型"></a>JS 的基本数据类型</h4><p>基本数据类型 string,number(NaN属于这里表示非数字),boolean,symbol,null,undefiend</p>
<h4 id="JS-变量的命名规则"><a href="#JS-变量的命名规则" class="headerlink" title="JS 变量的命名规则"></a>JS 变量的命名规则</h4><p>在javascript中,标识符<strong>不能以数字开头</strong>,即第一个字符不能为数字,<strong>必须是字母、下划线“_”或美元符号“$”</strong></p>
<h4 id="JS的五种模块加载方案"><a href="#JS的五种模块加载方案" class="headerlink" title="JS的五种模块加载方案"></a>JS的五种模块加载方案</h4><p><strong>详细可查看</strong>  <a href="https://juejin.cn/post/6844903808418447367?time=1673685516275">https://juejin.cn/post/6844903808418447367?time=1673685516275</a></p>
<p><a href="https://www.cnblogs.com/mingweiyard/p/13891510.html?time=1673968266192">https://www.cnblogs.com/mingweiyard/p/13891510.html?time=1673968266192</a></p>
<ul>
<li>AMD (异步模块定义)和 CMD （公共模块定义）都是<strong>浏览器端</strong>的JS模块化规范，分别由require.js和sea.js实现</li>
<li>CommonJS（缩写：CJS ）是<strong>服务器端</strong>的js模块化规范，由NodeJS实现</li>
<li>ES6 提出的方案（ESM），使用 import 和 export 的形式来导入导出模块，在nodeJS新版本中可以直接使用。</li>
<li>另外还有一些独特的例如  <strong>UMD</strong> （通用模块定义）他是 AMD 和 Common JS 糅合的产物。</li>
</ul>
<h4 id="JS-精度丢失问题"><a href="#JS-精度丢失问题" class="headerlink" title="JS 精度丢失问题"></a>JS 精度丢失问题</h4><p>在 JS 的 Number类型中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> one = <span class="number">0.1</span>;</span><br><span class="line"><span class="keyword">const</span> two = <span class="number">0.2</span>;</span><br><span class="line"><span class="keyword">const</span> three = <span class="number">0.3</span>;</span><br><span class="line"><span class="built_in">console</span>.log(two - one); <span class="comment">//0.1</span></span><br><span class="line"><span class="built_in">console</span>.log(three - two); <span class="comment">//0.09999999999999998</span></span><br></pre></td></tr></table></figure>
<p><strong>JS 数字丢失精度的原因</strong>：计算机的二进制实现和位数限制有些数无法有限表示，就像一些无理数不能有限表示，如 圆周率 3.1415926…，1.3333… 等。JS 遵循 <a href="https://hd.nowcoder.com/link.html?target=https://en.wikipedia.org/wiki/IEEE_floating_point">IEEE 754</a> 规范，采用双精度存储（double precision），占用 64 bit。</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/774B3E21DB02CD48251FE5A898DAD84A.png" alt=""></p>
<ul>
<li>1位用来表示符号位</li>
<li>11位用来表示指数</li>
<li>52位表示尾数</li>
</ul>
<h3 id="JS-API-细节问题"><a href="#JS-API-细节问题" class="headerlink" title="JS  API 细节问题"></a>JS  API 细节问题</h3><h4 id="valueOf-和-toString"><a href="#valueOf-和-toString" class="headerlink" title="valueOf 和 toString"></a>valueOf 和 toString</h4><ul>
<li><p>valueOf() 方法用于返回指定对象的原始值，<strong>若对象没有原始值，则将返回对象本身</strong>。</p>
</li>
<li><p>toString() 方法主要有3个用途</p>
<p>1.返回一个【表示对象】的【字符串】</p>
<p>2.检测对象的类型</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Object.prototype.toString.call(arr)===&quot;[object Array]&quot;</span><br></pre></td></tr></table></figure>
<p>3.返回该数字对应进制的字符串。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">console.log(10.toString(2)) //10专为为2进制&#x27;1010&#x27;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>{} 的 valueOf()方法 的值为{}</p>
<p>[] 的 valueOf() 方法 的值为 []</p>
<p>{} 的 toString()方法 的值为[object object] </p>
<p>[] 的 toString() 方法的值为””(空串)</p>
</blockquote>
<h4 id="isNaN"><a href="#isNaN" class="headerlink" title="isNaN"></a>isNaN</h4><p>这个函数接受一个参数，该参数可以是任何类型，而函数会帮我们确定这个参数是否“不是数值”。</p>
<p><strong>isNaN()</strong>在接受一个值后之后，会尝试将这个值转换为数值。某些不是数值的值会直接转换为数值，例如字符串”10”或Boolean值，会返回 false。<strong>而任何不能被转换为数值的值都会导致这个函数返回true</strong>。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">isNaN</span>(<span class="literal">NaN</span>) <span class="comment">// true  因为NaN不是数值</span></span><br><span class="line"><span class="built_in">isNaN</span>(<span class="number">10</span>)  <span class="comment">// false</span></span><br><span class="line"><span class="built_in">isNaN</span>(<span class="string">&#x27;10&#x27;</span>)  <span class="comment">// false</span></span><br><span class="line"><span class="built_in">isNaN</span>(<span class="string">&#x27;blue&#x27;</span>)  <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
<h4 id="parseFloat"><a href="#parseFloat" class="headerlink" title="parseFloat"></a>parseFloat</h4><p><strong>parseFloat()</strong> 从第一位开始检查，是数字就转换，直到一个不是数字的内容</p>
<p>开头就不是数字，那么直接返回 <code>NaN</code></p>
<p>认识小数点（但只认识第一个），没有小数点认整数,， <strong>并且其忽略前导0</strong>。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">parseFloat</span>(<span class="string">&#x27;1234blue&#x27;</span>) <span class="comment">// 1234</span></span><br><span class="line"><span class="built_in">parseFloat</span>(<span class="string">&#x27;0xA&#x27;</span>) 	   <span class="comment">//0后面都是字符（和进制无关）0</span></span><br><span class="line"><span class="built_in">parseFloat</span>(<span class="string">&#x27;22.34.5&#x27;</span>)  <span class="comment">//只认识第一个小数点，第二个当字符了所以停止 为 22.34</span></span><br><span class="line"><span class="built_in">parseFloat</span>(<span class="string">&#x27;0908.5&#x27;</span>)   <span class="comment">//忽略前导0 所以是908.5</span></span><br></pre></td></tr></table></figure>
<h3 id="HTML-相关"><a href="#HTML-相关" class="headerlink" title="HTML 相关"></a>HTML 相关</h3><h4 id="HTML中的特殊字符"><a href="#HTML中的特殊字符" class="headerlink" title="HTML中的特殊字符"></a>HTML中的特殊字符</h4><p>一般常考的特殊字符有如下几种：</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/bd83f338c6464b2ebcf7252d3473f1c0.png" alt=""></p>
<h4 id="lt-DOCTYPE-gt-的记忆点"><a href="#lt-DOCTYPE-gt-的记忆点" class="headerlink" title="&lt;!DOCTYPE&gt;  的记忆点"></a>&lt;!DOCTYPE&gt;  的记忆点</h4><ul>
<li><p>必须声明在HTML文档的第一行，在<code>&lt;html&gt;</code>之前</p>
</li>
<li><p>他是没有结束符的</p>
</li>
<li><p><strong>其对大小写不敏感，也就是大小写都可以！</strong></p>
</li>
<li><p>他不是一个 HTML 标签，是一个指令。用于指示 web 浏览器关于页面使用哪个 HTML 版本进行编写的指令。</p>
<p>如下就是声明 为 HTML5</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>之前的版本例如 HTML 4.01 Strict，是这么声明的。很复杂：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">HTML</span> <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//W3C//DTD HTML 4.01//EN&quot;</span> <span class="meta-string">&quot;http://www.w3.org/TR/html4/strict.dtd&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="HTML5-的新特性"><a href="#HTML5-的新特性" class="headerlink" title="HTML5 的新特性"></a>HTML5 的新特性</h4><p>1.语义化标签   </p>
<p>2.增强型表单包括属性以及元素 ，增加了大量的表单类型和表单属性；</p>
<p>3.新增<code>视频&lt;video&gt;和音频&lt;audio&gt;标签</code>  ，，还引入了<code>&lt;source&gt;标签</code>配合媒体标签使用；</p>
<p>4.Canvas 图形 ，新增了<code>&lt;canvas&gt;</code>，使用 JavaScript 在就可以网页上绘制图像；</p>
<p>5.地理定位  </p>
<p>6.拖放API ，增加了draggable属性设置元素可拖放；</p>
<p>7.SVG绘图 </p>
<p>8.Web Worker  </p>
<p>9.Web Storage ，提供了两种在客户端存储数据的新方法localStorage和sessionStorage；</p>
<p>10.Web Socket</p>
<p>11.增加了DOM查询操作querySelector和querySelectorAll；</p>
<h4 id="iframe-标签"><a href="#iframe-标签" class="headerlink" title="iframe 标签"></a>iframe 标签</h4><p>一个内联框架被用来在当前 HTML 文档中嵌入另一个文档。</p>
<font color="red">iframe会阻塞主页面的onload事件；</font>



<h3 id="HTML-（dom）加载与解析过程"><a href="#HTML-（dom）加载与解析过程" class="headerlink" title="HTML （dom）加载与解析过程"></a>HTML （dom）加载与解析过程</h3><ul>
<li>会阻塞dom解析的资源有：<br>1.内联css<br>2.内联js<br>3.普通外联js<br>4.外联defer js<br>5.js之前的外联css</li>
</ul>
<p>MDN解析：<strong>当初始HTML文档已完全加载和解析时</strong>，将触发<code>DOMContentLoaded</code>事件，而不需要等待样式表，图像和子框架页面加载（事件可以用来检测HTML页面是否完全加载完毕(fully-loaded)）。</p>
<h3 id="CSS-相关"><a href="#CSS-相关" class="headerlink" title="CSS 相关"></a>CSS 相关</h3><h4 id="CSS-样式优先级"><a href="#CSS-样式优先级" class="headerlink" title="CSS 样式优先级"></a>CSS 样式优先级</h4><p>右侧表示权重</p>
<ul>
<li>!important      </li>
<li>​    内联样式（1000）      </li>
<li>​    ID选择器（0100）      </li>
<li>​    类选择器/属性选择器/伪类选择器（0010）      </li>
<li>​    元素选择器/伪元素选择器（0001）      </li>
<li>​    关系选择器/通配符选择器（0000）     </li>
</ul>
<p><strong>带!important 标记的样式属性优先级最高</strong>； 样式表的来源相同时：</p>
<font color="red">**!important > 行内样式>ID选择器 > 类选择器 > 标签 > 通配符 > 继承 > 浏览器默认属性**</font>



<h4 id="CSS-样式定位归纳"><a href="#CSS-样式定位归纳" class="headerlink" title="CSS 样式定位归纳"></a>CSS 样式定位归纳</h4><p><code>div+p</code>  ： 是紧跟着div后面的p标签</p>
<h4 id="CSS-GPU加速"><a href="#CSS-GPU加速" class="headerlink" title="CSS GPU加速"></a>CSS GPU加速</h4><p>浏览器在处理下面的 css 的时候，会使用 GPU 渲染 </p>
<ul>
<li>transform（当 3D 变换的样式出现时会使用 GPU 加速）    </li>
<li>opacity 用于指定元素透明度   </li>
<li>filter 修改所有图片的颜色为黑白   </li>
<li>will-change 过告知浏览器该元素会有哪些变化，使浏览器提前做好优化准备，增强页面渲染性能。</li>
</ul>
<h4 id="CSS3-属性考法"><a href="#CSS3-属性考法" class="headerlink" title="CSS3 属性考法"></a>CSS3 属性考法</h4><h5 id="transform"><a href="#transform" class="headerlink" title="transform"></a>transform</h5><p>CSStransform属性允许旋转，缩放，倾斜或平移给定元素。<strong>只能转换由盒模型定位的元素</strong>。</p>
<p>盒模型定位元素根据经验是指具有<code>display：block；</code>的元素，<strong>对内联元素不可用</strong>。</p>
<p><code>transform</code>变形默认圆点为中心。 可通过 <code>transform-origin</code> 设置改变</p>
<p><code>transform</code>变形后占位不会变化，它会创建一个新的图层来显示。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">//定义 <span class="number">3</span>D 转换，使用 <span class="number">16</span> 个值的 <span class="number">4</span>x4 矩阵。</span><br><span class="line"><span class="attribute">transform</span>: <span class="built_in">scale</span>(<span class="number">0.5</span>) <span class="built_in">translate</span>(-<span class="number">100%</span>, -<span class="number">100%</span>); matrix3d(n,n,n,n,n,n,n,n,n,n,n,n,n,n,n,n) </span><br></pre></td></tr></table></figure>
<h4 id="CSS加载-的影响"><a href="#CSS加载-的影响" class="headerlink" title="CSS加载 的影响"></a>CSS加载 的影响</h4><ol>
<li>css加载不会阻塞DOM树的解析</li>
<li>css加载会阻塞DOM树的渲染</li>
<li>css加载会阻塞后面js语句的执行</li>
</ol>
<h3 id="计算机网络（包括JS来获取信息）相关"><a href="#计算机网络（包括JS来获取信息）相关" class="headerlink" title="计算机网络（包括JS来获取信息）相关"></a>计算机网络（包括JS来获取信息）相关</h3><h4 id="URL-地址格式"><a href="#URL-地址格式" class="headerlink" title="URL 地址格式"></a>URL 地址格式</h4><p>通常情况下，一个URL的格式是：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line">protocol :// hostname[:port] / path / [;parameters][?query]#fragment</span><br></pre></td></tr></table></figure>
<p>protocol 协议 hostname主机名 port端口号 path路径 parameters 参数 query查询 </p>
<p>协议：//主机：端口/路径名称?搜索条件#哈希标识</p>
<h5 id="window-Location-获取-Url相关信息"><a href="#window-Location-获取-Url相关信息" class="headerlink" title="window Location 获取 Url相关信息"></a>window Location 获取 Url相关信息</h5><h4 id="window-Location"><a href="#window-Location" class="headerlink" title="window Location"></a>window Location</h4><ul>
<li>location.host 返回 web 主机的域名+端口，只是如果是80 控制台不会显示而已</li>
<li>location.hostname  返回 web 主机的域名</li>
<li>location.pathname  返回当前页面的路径和文件名</li>
<li>location.port 返回 web 主机的端口 （80 或 443）</li>
<li>location.protocol 返回所使用的 web 协议（http: 或 https:）</li>
</ul>
<h4 id="七层模型和五层模型-及其对应协议"><a href="#七层模型和五层模型-及其对应协议" class="headerlink" title="七层模型和五层模型 及其对应协议"></a>七层模型和五层模型 及其对应协议</h4><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/QQ截图20230117200355.png" alt=""></p>
<h4 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h4><h5 id="进程有独立的地址空间，进程间可以通过网络通信，内存也可以共享，进程是系统进行资源分配和调度的基本单位。"><a href="#进程有独立的地址空间，进程间可以通过网络通信，内存也可以共享，进程是系统进行资源分配和调度的基本单位。" class="headerlink" title="进程有独立的地址空间，进程间可以通过网络通信，内存也可以共享，进程是系统进行资源分配和调度的基本单位。"></a>进程有独立的地址空间，进程间可以通过网络通信，内存也可以共享，进程是系统进行资源分配和调度的基本单位。</h5><p>  <strong>进程和线程的关系：</strong> </p>
<ol>
<li>​    一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。      </li>
<li>​    资源分配给进程，同一进程的所有线程共享该进程的所有资源。      </li>
<li>​    CPU 分给线程，即真正在 CPU 上运行的是线程。      </li>
<li><p>​    线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。线程是指进程内的一个执行单元,也是进程内的可调度实体.     </p>
<p><strong>进程与线程的区别：</strong> </p>
<p>（1）调度：<strong>线程</strong>作为<strong>调度</strong>和分配<strong>的基本单位</strong>，<strong>进程</strong>作为<strong>拥有资源</strong>的基本单位 </p>
<p>（2）并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行 </p>
<p>（3）拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源. </p>
<p>（4）系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，<strong>导致系统的开销明显大于创建或撤消线程时的开销</strong>。</p>
</li>
</ol>
<h4 id="UDP-和-TCP"><a href="#UDP-和-TCP" class="headerlink" title="UDP 和 TCP"></a>UDP 和 TCP</h4><p><strong>Http2.0 建立在 TCP，Http3.0 建立在 UDP</strong></p>
<p>目前题目说的，包括常用的还是 Http2.0 </p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/20210306213111446.png" alt=""></p>
<h4 id="Http-相关"><a href="#Http-相关" class="headerlink" title="Http 相关"></a>Http 相关</h4><h5 id="浏览器Http请求和响应过程"><a href="#浏览器Http请求和响应过程" class="headerlink" title="浏览器Http请求和响应过程"></a><strong>浏览器Http请求和响应过程</strong></h5><p>浏览器端构建HTTP请求，并发送 -&gt; 服务器端接收到HTTP请求，并进行解析 -&gt; 服务器端发送HTTP响应 -&gt; 浏览器端接收到响应，解析Http响应，而后进行页面渲染。</p>
<h5 id="Http-版本区别"><a href="#Http-版本区别" class="headerlink" title="Http 版本区别"></a>Http 版本区别</h5><ul>
<li><p>HTTP/0.9：功能捡漏，只支持GET方法，只能发送HTML格式字符串。   </p>
</li>
<li><p>HTTP/1.0：支持多种数据格式，增加POST、HEAD等方法，增加头信息，每次只能发送一个请求（无持久连接）   </p>
</li>
<li><p>HTTP/1.1：默认持久连接、请求管道化、增加缓存处理、增加Host字段、支持断点传输分块传输等。   </p>
</li>
<li><p>HTTP/2.0：<strong>二进制分帧、多路复用(解决了HTTP阻塞线头)、头部压缩、服务器推送</strong></p>
<p>并没有解决<font color="red"> <strong>TCP 队头阻塞的问题</strong></font></p>
</li>
</ul>
<p>​       采用HTTP/2时，浏览器一般会在单个TCP连接中创建并行的几十个乃至上百个传输。如果HTTP/2连接双方的网络中有一个数据包丢失，或者任何一方的网络出现中断，整个TCP连接就会暂停，丢失的数据包需要被重新传输。因为TCP是一个按序传输的链条，因此如果其中一个点丢失了，链路上之后的内容就都需要等待。</p>
<h5 id="客户端渲染-与-服务器渲染"><a href="#客户端渲染-与-服务器渲染" class="headerlink" title="客户端渲染 与 服务器渲染"></a>客户端渲染 与 服务器渲染</h5><p><strong>客户端渲染</strong></p>
<p>用户输入地址，客户端向服务器发送请求</p>
<p> =&gt; 服务器传给浏览器相应的网页文件 </p>
<p>  =&gt; 浏览器解析文件 </p>
<p>  =&gt; 遇到ajax请求则向服务器再次请求一些数据 </p>
<p>  =&gt; 服务器再次向浏览器发送相应的数据 </p>
<p>  =&gt; 浏览器拿到ajax请求返回的数据后，将数据渲染在页面上</p>
<p><strong>优点</strong>：</p>
<ul>
<li>可以向用户快速展示页面的内容，增加用户体验</li>
<li>给别人爬虫爬取相应的内容增加一定的困难</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>可能需要向服务器请求多次数据</li>
<li><strong>不利于</strong><font color="red">SEO（搜索引擎优化）</font>，即百度、搜狗等搜索引擎搜索不到客户端渲染的数据</li>
</ul>
<p><strong>服务器渲染</strong></p>
<p><strong>SPA（单页面）</strong>是客户端渲染的</p>
<p>客户端向服务器发送一次请求  </p>
<p>   =&gt; 服务器接收请求，并在服务端操作网页文件，将对应数据导入文件  </p>
<p>   =&gt; <strong>服务器在服务端渲染好整个网页，发送给客户端</strong>  </p>
<p>   =&gt; <strong>客户端</strong>接收服务器发送过来的网页文件，<strong>不需要做任何操作，直接呈现</strong></p>
<p><strong>优点</strong></p>
<ul>
<li>只需要向服务器请求一次</li>
<li><strong>利于</strong><font color="red">SEO 搜索引擎优化</font>，即能被搜索引擎搜索到，能向用户展示你网页的东西</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>如果数据量过大，在服务器渲染的时间就会过长，造成浏览器暂时的空白</li>
<li>容易被爬虫爬取</li>
</ul>
<p><strong>如何区分客户端渲染和服务器渲染</strong></p>
<ul>
<li>若页面做整体的刷新，即网址发生改变，就是服务器渲染</li>
<li>若页面做了局部刷新，即网址没发生改变，就是客户端渲染</li>
</ul>
<h3 id="前端安全系列"><a href="#前端安全系列" class="headerlink" title="前端安全系列"></a>前端安全系列</h3><h4 id="防止XSS"><a href="#防止XSS" class="headerlink" title="防止XSS"></a>防止XSS</h4><p>详细文档：<a href="https://tech.meituan.com/2018/09/27/fe-security.html?time=1673952294336">https://tech.meituan.com/2018/09/27/fe-security.html?time=1673952294336</a></p>
<p><strong>解决的方法有：</strong></p>
<ul>
<li>过滤用户请求种的非法字符</li>
<li>对请求种的特殊字符进行转译</li>
<li>配置 CSP（Content Security Policy）</li>
</ul>
<h3 id="浏览器相关"><a href="#浏览器相关" class="headerlink" title="浏览器相关"></a>浏览器相关</h3><h4 id="Chrome浏览器都有哪些进程"><a href="#Chrome浏览器都有哪些进程" class="headerlink" title="Chrome浏览器都有哪些进程"></a>Chrome浏览器都有哪些进程</h4><p>最新的 Chrome 浏览器包括：</p>
<ul>
<li>1 个浏览器（Browser）主进程</li>
<li>1 个 GPU 进程</li>
<li>1 个网络（NetWork）进程</li>
<li>多个渲染进程和多个插件进程。</li>
</ul>
<h4 id="浏览器缓存"><a href="#浏览器缓存" class="headerlink" title="浏览器缓存"></a>浏览器缓存</h4><p>浏览器缓存是性能优化中简单高效的一种方式，按照缓存位置划分为以下几种类型：. <strong>service Worker. Memory Cache. Disk Cache. Push Cache</strong>. 浏览器请求时，会按照如上的优先级顺序，进行查找缓存，都没有命中时，才会去请求网络</p>
<p>在浏览器中，浏览器会在<strong>js和图片等文件解析执行后直接存入内存缓存中</strong>，那么当刷新页面时只需直接从内存缓存中读取(from memory cache)；而<strong>css文件则会存入硬盘文件</strong>中，所以每次渲染页面都需要从硬盘读取缓存(from disk cache)。</p>
<h4 id="解决跨域"><a href="#解决跨域" class="headerlink" title="解决跨域"></a>解决跨域</h4><ul>
<li>webpack本地代理，即proxy反向代理</li>
<li>JSONP 是服务器与客户端跨源通信的常用方法。最大特点就是简单适用，兼容性好（兼容低版本IE），缺点是只支持get请求，不支持post请求。 </li>
<li>CORS </li>
<li>跨文档通信 API：<code>window.postMessage()</code></li>
</ul>
<h3 id="面像对象编程相关"><a href="#面像对象编程相关" class="headerlink" title="面像对象编程相关"></a>面像对象编程相关</h3><h4 id="面向对象编程设计的特点"><a href="#面向对象编程设计的特点" class="headerlink" title="面向对象编程设计的特点"></a>面向对象编程设计的特点</h4><p>面向对象编程特点：抽象、封装、继承、多态</p>
<h3 id="Vue-相关"><a href="#Vue-相关" class="headerlink" title="Vue 相关"></a>Vue 相关</h3><h4 id="Vue-路由"><a href="#Vue-路由" class="headerlink" title="Vue 路由"></a>Vue 路由</h4><p><strong>vue中的路由模式</strong></p>
<p>路由模块的本质就是建立起url和页面之间的映射关系，vue-router有3种路由模式：<strong>hash，history，abstract</strong>.</p>
<h4 id="vue组件间通信方式"><a href="#vue组件间通信方式" class="headerlink" title="vue组件间通信方式"></a>vue组件间通信方式</h4><p>(这里是 Vue2 和 Vue 3 都算上了)</p>
<ul>
<li>通过 props 传递    (父传子属性或者函数等)</li>
<li>通过 $emit 触发<strong>自定义事件</strong>  </li>
<li>使用 ref  同样需要触发 $emit</li>
<li>EventBus （事件总线）  </li>
<li>$ parent /$children 或 $ root  </li>
<li>attrs 与 listeners</li>
<li>Provide 与 Inject</li>
<li>Vuex</li>
</ul>
<h3 id="前端开发细节"><a href="#前端开发细节" class="headerlink" title="前端开发细节"></a>前端开发细节</h3><h4 id="GBK-和-UTF8-编码"><a href="#GBK-和-UTF8-编码" class="headerlink" title="GBK 和 UTF8 编码"></a>GBK 和 UTF8 编码</h4><p><strong>GBK：</strong></p>
<p>中文、英文、数字均使用双字节来表示</p>
<p><strong>UTF-8：</strong></p>
<p>汉字占3个字节、数字占1个字节、英文字母占1个字节</p>
<h3 id="加密算法"><a href="#加密算法" class="headerlink" title="加密算法"></a>加密算法</h3><p>对原来为明文的文件或数据按某种算法进行处理，加密后的数据不可读，是“密文”，只能在输入相应的密钥之后才能显示出原容</p>
<ul>
<li><p>可逆加密算法</p>
<ul>
<li><p>对称加密：发送方发送 明文+加密密钥一起打包使用特殊的加密算法得到加密密文，收信方 使用加密密钥和相同加密算法的逆算法进行解密，获取明文。<strong>其特点在：加密密钥只有一个，收发双方使用的是一个。</strong></p>
<p>优点当然是计算量小而且快，缺点也就是相对于非对称不安全。</p>
<p>用途： 一般用于保存用户手机号、身份证等敏感但能解密的信息。<br>常见的对称加密算法有: AES、DES、3DES、Blowfish、IDEA、RC4、RC5、RC6、HS256</p>
</li>
<li><p>非对称加密：公开密钥（publickey）和私有密钥，公有密钥加密，私有密钥解密。私钥加密的内容，通过公钥可以解密读取出来，反之，通过公钥加密的内容也可以由私钥解密读取出来</p>
<p>用途： 一般用于签名和认证。私钥服务器保存, 用来加密, 公钥客户拿着用于对于令牌或者签名的解密或者校验使用.</p>
<p>解释：在区块链网络上进行一笔交易时，我没有办法确定交易的是不是你本人，这个时候就可以让你用私钥加密一段内容作为数字签名发过来，然后我通过已经公开的公钥进行破解，因为私钥只有你本人保留，如果我能用语之对应的公钥成功破解，<strong>就说明是你本人在进行操作</strong>，如果不能破解，则说明是别人盗用了你的身份，因此解决了我是我，这是我在交易的问题。</p>
<p>常见的非对称加密算法有： RSA、DSA（数字签名用）、ECC（移动设备用）、RS256 (采用SHA-256 的 RSA 签名)</p>
</li>
</ul>
</li>
<li><p>不可逆加密算法：旦加密就不能反向解密得到密码原文.</p>
<p>种类: Hash加密算法, 散列算法, 摘要算法等<br><strong>用途：</strong>一般用于效验下载文件正确性，一般在网站上下载文件都能见到；存储用户敏感信息，如密码、 卡号等不可解密的信息。<br>常见的不可逆加密算法有： MD5、SHA、HMAC</p>
</li>
<li><p>特殊：Base64编码：网络上最常见的用于传输8Bit字节代码的编码方式之一。</p>
<p>Base64编码可用于在HTTP环境下传递较长的标识信息。通常用于把二进制数据编码为可写的字符形式的数据。<strong>采用Base64编码解码具有不可读性</strong>，即所编码的数据不会被人用肉眼所直接看到。注意：<strong>Base64只是一种编码方式，不算加密方法</strong>。</p>
</li>
</ul>
<h3 id="算法复杂度"><a href="#算法复杂度" class="headerlink" title="算法复杂度"></a>算法复杂度</h3><h4 id="算法稳定性与时间复杂度"><a href="#算法稳定性与时间复杂度" class="headerlink" title="算法稳定性与时间复杂度"></a>算法稳定性与时间复杂度</h4><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/QQ截图20230117185107.png" alt=""></p>
<h3 id="JS-里一些奇怪的东东，现在不知道处于哪里"><a href="#JS-里一些奇怪的东东，现在不知道处于哪里" class="headerlink" title="JS 里一些奇怪的东东，现在不知道处于哪里"></a>JS 里一些奇怪的东东，现在不知道处于哪里</h3><h4 id="Redux（react的）-Vuex同类"><a href="#Redux（react的）-Vuex同类" class="headerlink" title="Redux（react的）   Vuex同类"></a>Redux（react的）   <code>Vuex同类</code></h4><p><em>Redux</em> 是 JavaScript 状态容器，提供可预测化的状态管理。</p>
<p>其和 Vuex 实现的内容一致。 用的貌似不多。</p>
<p><strong>Redux遵循的原则</strong></p>
<ul>
<li>单一数据源：整个应用的state被存储在一棵object tree中，并且这个object tree只存在于唯一一个store中； </li>
<li>state是只读的：唯一改变state的方法就是触发action，action是一个用于描述发生事件的普通对象； </li>
<li>使用纯函数修改数据；</li>
</ul>
<h4 id="宏任务和微任务"><a href="#宏任务和微任务" class="headerlink" title="宏任务和微任务"></a>宏任务和微任务</h4><p>可查看的教程：<a href="https://blog.csdn.net/weixin_50238437/article/details/126082425">https://blog.csdn.net/weixin_50238437/article/details/126082425</a></p>
<ul>
<li>宏任务和微任务都是异步任务，都在任务队列中，但是它们在不同的队列中</li>
<li><strong>重点：在准备取出每个宏任务准备执行前要执行完所有的微任务</strong></li>
</ul>
<p>宏任务包括：</p>
<ul>
<li><p><strong>setTimeout 和 setInterval</strong>， I/O， 事件</p>
</li>
<li><p>postMessage</p>
</li>
<li><p>setImmediate (node中的特性，浏览器已经废弃该API)</p>
</li>
<li><p>requestAnimationFrame() 请求动画帧</p>
<p>他的作用就是代替定时器做更加<strong>流畅高性能</strong>的动画，做可以匹配设备刷新率的动画，他解决了<strong>定时器做动画时间间隔不稳定的问题</strong>（也就是解决定时器做动画不流畅的问题）。他的用法与setTimeout差不多。</p>
</li>
<li><p>UI渲染</p>
</li>
<li><p>ajax</p>
</li>
</ul>
<p>微任务包括：</p>
<ul>
<li>Promise.then  catch finally</li>
<li>async/await</li>
<li>MutationObserver（chrome种 node无）</li>
<li>process.nextTick (node中)</li>
</ul>
<p>所以下面这段代码的执行结果为：</p>
<p><strong>刚开始先同步代码执行，先输出开始和结束</strong></p>
<p>// 依次输出：开始 结束 佩奇（<strong>因为 promise是微任务</strong>） 定时器执行</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;开始&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;定时器执行&#x27;</span>)</span><br><span class="line">&#125;, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">    resolve(<span class="string">&#x27;佩奇&#x27;</span>)</span><br><span class="line">&#125;).then(<span class="function">(<span class="params">data</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(data)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;结束&#x27;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h3 id="前端网络相关面试题"><a href="#前端网络相关面试题" class="headerlink" title="前端网络相关面试题"></a>前端网络相关面试题</h3><h3 id="考点1-http-协议"><a href="#考点1-http-协议" class="headerlink" title="考点1:  http 协议"></a>考点1:  http 协议</h3><h4 id="面试题：浏览器Http请求和响应过程"><a href="#面试题：浏览器Http请求和响应过程" class="headerlink" title="面试题：浏览器Http请求和响应过程"></a>面试题：<strong>浏览器Http请求和响应过程</strong></h4><p>浏览器端构建HTTP请求，并发送 -&gt; 服务器端接收到HTTP请求，并进行解析 -&gt; 服务器端发送HTTP响应 -&gt; 浏览器端接收到响应，解析Http响应，而后进行页面渲染。</p>
<h4 id="面试题：客户端渲染-与-服务器渲染的区别"><a href="#面试题：客户端渲染-与-服务器渲染的区别" class="headerlink" title="面试题：客户端渲染 与 服务器渲染的区别"></a>面试题：客户端渲染 与 服务器渲染的区别</h4><p><strong>客户端渲染</strong></p>
<p><strong>SPA（单页面）</strong>是客户端渲染的</p>
<p>用户输入地址，客户端向服务器发送请求</p>
<p> =&gt; 服务器传给浏览器相应的网页文件 </p>
<p>  =&gt; 浏览器解析文件 </p>
<p>  =&gt; 遇到ajax请求则向服务器再次请求一些数据 </p>
<p>  =&gt; 服务器再次向浏览器发送相应的数据 </p>
<p>  =&gt; 浏览器拿到ajax请求返回的数据后，将数据渲染在页面上</p>
<p><strong>优点</strong>：</p>
<ul>
<li>可以向用户快速展示页面的内容，增加用户体验</li>
<li>给别人爬虫爬取相应的内容增加一定的困难</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>可能需要向服务器请求多次数据</li>
<li><strong>不利于</strong><font color="red">SEO（搜索引擎优化）</font>，即百度、搜狗等搜索引擎搜索不到客户端渲染的数据</li>
</ul>
<p><strong>服务器渲染</strong></p>
<p>客户端向服务器发送一次请求  </p>
<p>   =&gt; 服务器接收请求，并在服务端操作网页文件，将对应数据导入文件  </p>
<p>   =&gt; <strong>服务器在服务端渲染好整个网页，发送给客户端</strong>  </p>
<p>   =&gt; <strong>客户端</strong>接收服务器发送过来的网页文件，<strong>不需要做任何操作，直接呈现</strong></p>
<p><strong>优点</strong></p>
<ul>
<li>只需要向服务器请求一次</li>
<li><strong>利于</strong><font color="red">SEO 搜索引擎优化</font>，即能被搜索引擎搜索到，能向用户展示你网页的东西</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>如果数据量过大，在服务器渲染的时间就会过长，造成浏览器暂时的空白</li>
<li>容易被爬虫爬取</li>
</ul>
<p><strong>如何区分客户端渲染和服务器渲染</strong></p>
<ul>
<li>若页面做整体的刷新，即网址发生改变，就是服务器渲染</li>
<li>若页面做了局部刷新，即网址没发生改变，就是客户端渲染</li>
</ul>
<h4 id="面试题：常见http-status"><a href="#面试题：常见http-status" class="headerlink" title="面试题：常见http status"></a>面试题：常见http status</h4><p><strong>1XX系列</strong>：<font color="font">指定客户端应相应的某些动作，代表请求已被接受，需要继续处理。</font>由于 HTTP/1.0 协议中没有定义任何 1xx 状态码，所以除非在某些试验条件下，服务器禁止向此类客户端发送 1xx 响应。</p>
<p><strong>2XX系列</strong>：<font color="blue"><strong>代表请求已成功被服务器接收、理解、并接受。</strong></font>这系列中最常见的有200、201状态码。</p>
<p><strong>3XX系列</strong>：<strong>代表需要客户端采取进一步的操作才能完成请求</strong>，这些状态码用来重定向，后续的请求地址（重定向目标）在本次响应的 Location 域中指明。这系列中最常见的有301、302状态码。</p>
<p><strong>4XX系列</strong>：<strong>表示请求错误</strong>。代表了客户端看起来可能发生了错误，妨碍了服务器的处理。常见有：401、404状态码。</p>
<p><strong>5xx系列</strong>：<strong>代表了服务器在处理请求的过程中有错误或者异常状态发生</strong>，也有可能是服务器意识到以当前的软硬件资源无法完成对请求的处理。常见有500、503状态码。</p>
<p><strong>2开头 （请求成功）表示成功处理了请求的状态代码。</strong></p>
<ul>
<li><strong>200 （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。</strong></li>
<li><strong>201 （已创建） 请求成功并且服务器创建了新的资源。</strong></li>
<li><strong>202 （已接受） 服务器已接受请求，但尚未处理。</strong></li>
<li>203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。</li>
<li>204 （无内容） 服务器成功处理了请求，但没有返回任何内容。</li>
<li>205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。</li>
<li>206 （部分内容） 服务器成功处理了部分 GET 请求。</li>
</ul>
<p><strong>3开头 （请求被重定向）表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。</strong></p>
<ul>
<li>300 （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。</li>
<li><strong>301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。</strong></li>
<li><strong>302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</strong></li>
<li>303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。</li>
<li>304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。</li>
<li>305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。</li>
<li>307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</li>
</ul>
<p><strong>4开头 （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。</strong></p>
<ul>
<li>400 （错误请求） 服务器不理解请求的语法。</li>
<li><strong>401 （未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。</strong></li>
<li>403 （禁止） 服务器拒绝请求。</li>
<li><strong>404 （未找到） 服务器找不到请求的网页。</strong></li>
<li>405 （方法禁用） 禁用请求中指定的方法。</li>
<li>406 （不接受） 无法使用请求的内容特性响应请求的网页。</li>
<li>407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。</li>
<li>408 （请求超时） 服务器等候请求时发生超时。</li>
<li>409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。</li>
<li>410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。</li>
<li>411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。</li>
<li>412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。</li>
<li>413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。</li>
<li>414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。</li>
<li>415 （不支持的媒体类型） 请求的格式不受请求页面的支持。</li>
<li>416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。</li>
<li>417 （未满足期望值） 服务器未满足”期望”请求标头字段的要求。</li>
</ul>
<p><strong>5开头（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。</strong></p>
<ul>
<li><strong>500 （服务器内部错误） 服务器遇到错误，无法完成请求。</strong></li>
<li>501 （尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。</li>
<li>502 （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。</li>
<li><strong>503 （服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。</strong></li>
<li>504 （网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。</li>
<li>505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。</li>
</ul>
<h4 id="面试题：http-和-https-的区别"><a href="#面试题：http-和-https-的区别" class="headerlink" title="面试题：http 和 https 的区别"></a>面试题：http 和 https 的区别</h4><ul>
<li><p>HTTP协议传输的数据都是<strong>未加密的</strong>，也就是<strong>明文</strong>的，因此使用HTTP协议传输隐私信息非常不安全</p>
</li>
<li><p>HTTPS协议 引入了<strong>数据加密</strong>（对称加密和非对称加密相结合的方式实现）和<strong>身份验证机制</strong>（数字证书来验证服务器身份）。在开始传输数据之前，通过安全可靠的 TLS 协议进行加密，从而保证后续加密传输数据的安全性。</p>
<blockquote>
<ol>
<li>数据加密：HTTPS使用SSL/TLS协议对传输的数据进行加密，从而防止第三方窃听、篡改或伪造数据。<strong>SSL/TLS协议使用对称加密和非对称加密相结合的方式，对传输的数据进行加密和解密</strong>，确保数据的机密性和完整性。</li>
<li>证书验证：HTTPS使用SSL/TLS协议中的<strong>数字证书来验证服务器的身份，防止中间人攻击和伪造服务器</strong>。数字证书是由可信的第三方机构颁发的，它包含了服务器的公钥和其他相关信息，客户端可以通过验证数字证书来确认服务器的身份和信任服务器。</li>
<li>安全性强：HTTPS使用SSL/TLS协议对数据进行加密和解密，加密强度高，具有一定的抵抗攻击的能力。同时，HTTPS还可以使用数字证书来验证服务器的身份，可以避免中间人攻击和伪造服务器。</li>
</ol>
<p>原来是 SSL，现在 已经被废弃，使用 TLS协议了</p>
<p><strong>TLS 协议</strong>：<strong>传输层安全性协议</strong>（Transport Layer Security，<strong>TLS</strong>）及其前身<strong>安全套接层</strong>（Secure Sockets Layer，<strong>SSL</strong>）是一种安全协议，目的是为了保证<strong>网络通信安全</strong>和<strong>数据完整性</strong>。</p>
</blockquote>
</li>
</ul>
<p><strong>HTTPS和HTTP的区别主要如下：</strong></p>
<p>1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。</p>
<p>2、http是超文本传输协议，信息是<strong>明文传输</strong>，https则是具有安全性的 SSL 加密传输协议。</p>
<p>3、http和https使用的是<strong>完全不同的连接方式</strong>，用的<strong>端口也不一样</strong>，<strong>前者是80，后者是443</strong>。</p>
<p>4、http的连接很简单，是无状态的；HTTPS协议是由 TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。</p>
<h4 id="面试题：http协议-各版本的区别"><a href="#面试题：http协议-各版本的区别" class="headerlink" title="面试题：http协议 各版本的区别"></a>面试题：http协议 各版本的区别</h4><ul>
<li><p>HTTP/0.9：功能捡漏，只支持GET方法，只能发送HTML格式字符串。   </p>
</li>
<li><p>HTTP/1.0：支持多种数据格式，增加POST、HEAD等方法，增加头信息，每次只能发送一个请求（无持久连接）   </p>
</li>
<li><p>HTTP/1.1：默认持久连接、请求管道化、增加缓存处理、增加Host字段、支持断点传输分块传输等。   </p>
</li>
<li><p>HTTP/2.0：<strong>二进制分帧、多路复用(解决了HTTP阻塞线头)、头部压缩、服务器推送</strong></p>
<p>并没有解决<font color="red"> <strong>TCP 队头阻塞的问题</strong></font></p>
</li>
</ul>
<p>​       采用HTTP/2时，浏览器一般会在单个TCP连接中创建并行的几十个乃至上百个传输。如果HTTP/2连接双方的网络中有一个数据包丢失，或者任何一方的网络出现中断，整个TCP连接就会暂停，丢失的数据包需要被重新传输。因为TCP是一个按序传输的链条，因此如果其中一个点丢失了，链路上之后的内容就都需要等待。</p>
<p>http2.0 各个特点展开说就是：</p>
<ol>
<li><p><strong>HTTP2使用的是二进制传送，HTTP1.X是文本（字符串）传送。</strong></p>
<p><strong>二进制传送的单位是帧和流。帧组成了流，同时流还有流ID标示</strong></p>
</li>
<li><p><strong>HTTP2支持多路复用</strong></p>
<p>因为有流ID，所以通过同一个http请求实现多个http请求传输变成了可能，可以通过流ID来标示究竟是哪个流从而定位到是哪个http请求</p>
</li>
<li><p><strong>HTTP2头部压缩</strong></p>
<p>HTTP2通过gzip和compress压缩头部然后再发送，同时客户端和服务器端同时维护一张头信息表，所有字段都记录在这张表中，这样后面每次传输只需要传输表里面的索引Id就行，通过索引ID查询表头的值</p>
</li>
<li><p><strong>HTTP2支持服务器推送</strong></p>
<p>HTTP2支持在未经客户端许可的情况下，主动向客户端推送内容</p>
</li>
</ol>
<h4 id="面试题：http-的请求方式-有哪几种"><a href="#面试题：http-的请求方式-有哪几种" class="headerlink" title="面试题：http 的请求方式 有哪几种"></a>面试题：http 的请求方式 有哪几种</h4><ul>
<li><p>OPTIONS</p>
<p>查询服务器支持的请求方式，OPTIONS请求用于查询服务器支持的请求方式，客户端可以用这个方法来测试服务器的功能性。</p>
<font color="blue">具体的说：客户端可以对特定的 URL 使用 OPTIONS 方法，也可以对整站（通过将 URL 设置为“*”）使用该方法</font>
</li>
<li><p>HEAD</p>
<p>与GET请求类似，但是不返回响应体，只返回响应头。</p>
</li>
<li><p>GET</p>
<p>从服务器获取资源，GET请求是最常用的请求方式，用于请求服务器上的数据。</p>
<p>注意：GET方法不应当被用于产生“副作用”的操作中，例如在Web Application中，其中一个原因是GET可能会被网络蜘蛛等随意访问。Loadrunner中对应get请求函数：web_link和web_url</p>
</li>
<li><p>POST</p>
<p>向服务器提交数据，用于向服务器发送数据，例如表单数据等。）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 Loadrunner中对应POST请求函数：web_submit_data,web_submit_form</p>
</li>
<li><p>PUT</p>
<p>更新服务器上的资源，PUT请求用于更新服务器上的指定资源，客户端需要提供完整的资源数据。</p>
</li>
<li><p>DELETE</p>
<p>删除服务器上的资源，DELETE请求用于删除服务器上的指定资源。</p>
</li>
<li><p>TRACE</p>
<p>追踪请求-响应的传输路径，TRACE请求用于追踪请求-响应的传输路径，客户端可以用这个方法来诊断网络连接问题。</p>
</li>
<li><p>CONNECT </p>
<p>这个比较特殊。它不是通过传输数据来操作服务器资源，而是建立一个管道，从而支持客户端和服务器之间的数据传输。因为 CONNECT 请求方法的作用比较特殊，所以一般不在普通的 Web 应用程序中使用。</p>
</li>
</ul>
<h4 id="面试题：GET和POST区别"><a href="#面试题：GET和POST区别" class="headerlink" title="面试题：GET和POST区别"></a>面试题：GET和POST区别</h4><ol>
<li>get用来获取数据，post用来提交数据</li>
<li><font color="red">**get参数有长度限制（受限于url长度，具体的数值取决于浏览器和服务器的限制，最长2048字节），而post无限制**</font></li>
<li><font color="blue">**get请求的数据会附加在url之 ，以 " ？ "分割url和传输数据，多个参数用 "&"连接，而post请求会把请求的数据放在http请求体中。**</font></li>
<li>get是明文传输，post是放在请求体中，但是开发者可以通过抓包工具看到，也相当于是明文的。</li>
<li><strong>get请求会保存在浏览器历史记录中，还可能保存在web服务器的日志中</strong></li>
</ol>
<h3 id="考点2：-TCP-协议-与-UDP-协议"><a href="#考点2：-TCP-协议-与-UDP-协议" class="headerlink" title="考点2： TCP 协议 与 UDP 协议"></a>考点2： TCP 协议 与 UDP 协议</h3><h4 id="面试题：TCP的三次握手建立连接的过程"><a href="#面试题：TCP的三次握手建立连接的过程" class="headerlink" title="面试题：TCP的三次握手建立连接的过程"></a>面试题：TCP的三次握手建立连接的过程</h4><p>TCP三次握手的过程如下：</p>
<ol>
<li>第一次握手（SYN）：客户端向服务器发送一个SYN（Synchronize Sequence Number）报文段，表示客户端请求建立连接。SYN报文段包含一个随机的初始序列号（ISN）。</li>
<li>第二次握手（SYN+ACK）：服务器收到客户端的SYN报文段之后，会向客户端发送一个SYN+ACK报文段，表示服务器已经收到了客户端的请求，并且同意建立连接。SYN+ACK报文段包含服务器的初始序列号（ISN）和确认号（ACK）。</li>
<li>第三次握手（ACK）：客户端收到服务器的SYN+ACK报文段之后，会向服务器发送一个ACK（Acknowledgment）报文段，表示客户端已经收到了服务器的响应，并且同意建立连接。<strong>ACK报文段包含确认号（ACK），确认号的值为服务器的初始序列号（ISN）+1</strong>。</li>
</ol>
<p><img src="https://uploadfiles.nowcoder.com/images/20230131/473144517_1675143912477/F19F744F8530FAD5C8EAA62339751D08" alt="img"></p>
<p>完成三次握手后，TCP连接就建立起来了，客户端和服务器可以开始进行数据传输。三次握手的过程中，主要是为了确保客户端和服务器都知道对方的存在，并且建立一个可靠的连接，以保证数据传输的安全性和可靠性<strong>。如果有任何一次握手失败，连接就会建立失败，需要重新发起三次握手建立连接。</strong></p>
<h4 id="面试题：TCP的四次握手释放连接的过程"><a href="#面试题：TCP的四次握手释放连接的过程" class="headerlink" title="面试题：TCP的四次握手释放连接的过程"></a>面试题：TCP的四次握手释放连接的过程</h4><font color="red">**注意 客户端和服务端 都可以提出释放连接的请求**</font>。**因为 TCP是一种全双工（full-duplex）协议**

1. **发起关闭连接的一方（称为主动关闭方，Active Close）**发送一个**FIN报文段**（也就是连接释放报文段），表示停止发送数据，并请求关闭连接。主动关闭方进入FIN_WAIT_1状态，等待另一方的确认。
2. **接收到关闭请求的另一方（称为被动关闭方，Passive Close）**收到**FIN报文段**后，它会**发送一个ACK报文段**作为确认，并进入CLOSE_WAIT状态，等待关闭请求的另一方关闭连接。
3. **被动关闭方在发送完所有数据之后，也发送一个FIN报文段**，表示它已经没有数据要发送了，并请求关闭连接。被动关闭方进入LAST_ACK状态。
4. **主动关闭方收到被动关闭方的FIN报文段后，发送一个ACK报文段作为确认**，并进入TIME_WAIT状态。**在这个状态下，主动关闭方等待2倍的最长报文段寿命（Maximum Segment Lifetime, MSL）后，连接彻底关闭。**

![img](https://uploadfiles.nowcoder.com/images/20230131/473144517_1675142925083/D2B5CA33BD970F64A6301FA75AE2EB22)

#### 面试题：TCP vs UDP的区别

- TCP是一种**面向连接的**、可靠的、基于字节流的传输层通信协议，是专门为了**在不可靠的网络中提供一个可靠的端对端字节流而设计的，面向字节流。**
- UDP（用户数据报协议）是iso参考模型中一种**无连接的传输层协议**，提供**简单不可靠的非连接传输层服务**，**面向报文**

**区别：**

1. TCP是面向连接的，可靠性高；UDP是基于非连接的，可靠性低

2. 由于TCP是连接的通信，需要有三次握手、重新确认等连接过程，会有延时，实时性差，同时过程复杂，也使其易于攻击；UDP没有建立连接的过程，因而实时性较强，也稍安全

3. 在传输相同大小的数据时，

   TCP首部开销20字节；实际数据最多为 60字节

   UDP首部开销8字节，**TCP报头比UDP复杂，故实际包含的用户数据较少**。TCP在IP协议的基础上添加了序号机制、确认机制、超时重传机制等，保证了传输的可靠性，不会出现丢包或乱序，而UDP有丢包，故**TCP开销大，UDP开销较小**

4. 每条TCP连接只能时点到点的；

   UDP支持一对一、一对多、多对一、多对多的交互通信，即可多播

**应用场景选择**

- 对实时性要求高和高速传输的场合下使用UDP;在可靠性要求低，追求效率的情况下使用UDP;
- 需要传输大量数据且对可靠性要求高的情况下使用TCP







#### 面试题：七层模型和五层模型 及其对应协议

![](https://gitee.com/kaikai-superman/imgs/raw/master/img/QQ截图20230117200355.png)

- DNS (Domain Name Service 域名服务) 协议基于 UDP协议
- FTP (File Transfer Protocol 文件传输协议) 基于 TCP协议
- DNS和FTP都是应用层协议

**1.应用层**

作用：它是与其他计算机进行通信的应用，它是对应应用程序的通信服务的。各种应用软件，包括web应用。

协议：DNS、FTP、HTTP、SMTP、TELNET、IRC、WHOIS

**2.表示层**

作用：这一层的主要作用是定义数据格式和加密。

**3.会话层**

作用：控制应用程序的会话能力，它定义了一段会话的开始、控制和结束，包括对多个双向消息的控制和管理，以便在只完成一部分消息时可以通知应用。

协议：

HTTP（Hyper text Transfer Protocol）协议：超文本传输协议使用TCP的80端口

FTP（File Transfer Protocol）文本传输协议

SMTP（Simple Mail Transfer Protocol）简单邮件传输协议，TCP是我25端口用户发邮件。

POP3（Post Office Protocol version3）邮局协议版本3，TCP的110号端口，用于收邮件的。

DNS（Domain Name System）域名解析协议。使用TCP和UDP的53号端口，作用是把www的域名解析成IP地址。

**4.传输层**

作用：对差错恢复协议和无差错恢复协议的选择，对同一主机上不同数据流的输入进行复用，对数据包进行重新排序。是最关键的一层，是唯一负责整体的数据传输和数据控制的。对上三层提供可靠的传输服务，对网络层提供可靠的目的地信息。在这一层数据的单位被称为数据段。

协议：TCP、UDP等

**5.网络层**

作用：主要负责寻找地址和路由选择，网络层还可以实现阻塞控制、网际互联等。

协议：IP、IPX、RIP、OSPF等

**6.数据链路层**

作用：负责物理层面上的互联的、节点间的通信传输；该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。在这一层，数据的单位称为帧（frame）

协议：ARP、RARP、SDLC、HDLC、PPP、STP、帧中继等

**7.物理层**

作用：负责0、1 比特流（0/1序列）与电压的高低、逛的闪灭之间的转换 规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性；该层为上层协议提供了一个传输数据的物理媒体。在这一层，数据的单位称为比特（bit）。

典型规范：EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45、fddi令牌环网等



#### 面试题：DNS解析的过程

DNS是应用层协议，事实上他是为其他应用层协议工作的，包括不限于HTTP和SMTP以及FTP，用于将用户提供的主机名解析为ip地址。
具体过程如下：

1. 客户机提出域名解析请求 , 并将该请求发送给本地的域名服务器 ;
2. 当本地的域名服务器收到请求后 , 就先查询本地的缓存 , 如果有该纪录项 , 则本地的域名服务器就直接把查询的结果返回 ;
3. 如果本地的缓存中没有该纪录 , 则本地域名服务器就直接把请求发给根域名服务器 , 然后根域名服务器再返回给本地域名服务器一个所查询域 (根的子域) 的主域名服务器的地址 ;
4. 本地服务器再向上一步返回的域名服务器发送请求 , 然后接受请求的服务器查询自己的缓存 , 如果没有该纪录 , 则返回相关的下级的域名服务器的地址 ;
5. 重复第四步 , 直到找到正确的纪录 ;
6. 本地域名服务器把返回的结果保存到缓存 , 以备下一次使用 , 同时还将结果返回给客户机 ;



### 考点3： URL

#### 面试题：URL 路径包含什么, URI 是什么

**URL 路径包含什么**

通常情况下，一个URL的格式是：

<figure class="highlight http"><table><tr><td class="code"><pre><span class="line">protocol :// hostname[:port] / path / [;parameters][?query]#fragment</span><br></pre></td></tr></table></figure>

protocol 协议 hostname主机名 port端口号 path路径 parameters 参数 query查询 

协议：//主机：端口/路径名称?搜索条件#哈希标识



**URI 是什么**

**URI**是一个用于标识互联网资源名称的字符串。 该种标识允许用户对网络中（一般指[万维网](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/万维网)）的资源通过特定的协议进行交互操作。URI的最常见的形式是统一资源定位符（URL），经常指定为非正式的网址。更罕见的用法是统一资源名称（URN），其目的是通过提供一种途径。用于在特定的命名空间资源的标识，以补充网址。





#### 面试题：浏览器地址栏输入 URL 敲下回车后发生了什么？

##### Step 1：浏览器解析URL

一个`url`的结构解析如下：

![](https://gitee.com/kaikai-superman/imgs/raw/master/img/url解析.png)

##### **Step 2： DNS查询**

浏览器检查本地缓存，如果有的话，直接使用缓存中的副本。

没有就要进行 DNS查询的内容，这个部分看上面的 DNS解析过程。

<font color="red">**此步骤目的是为了，获取到了域名对应的目标服务器`IP`地址**</font>



<h5 id="Step-3：建立-TCP-连接"><a href="#Step-3：建立-TCP-连接" class="headerlink" title="Step 3：建立 TCP 连接"></a>Step 3：建立 TCP 连接</h5><p>在确定目标服务器服务器的<code>IP</code>地址后，则经历三次握手建立<code>TCP</code>连接。具体三次连接的步骤看上面。</p>
<h5 id="Step-4：客户端（浏览器）发送-HTTP-请求"><a href="#Step-4：客户端（浏览器）发送-HTTP-请求" class="headerlink" title="Step 4：客户端（浏览器）发送 HTTP 请求"></a>Step 4：客户端（浏览器）发送 HTTP 请求</h5><p>当建立<code>tcp</code>连接之后，就可以在这基础上进行通信，浏览器发送 <code>http</code> 请求到目标服务器</p>
<p>请求的内容包括：</p>
<ul>
<li>请求行：包含请求方法、URL、HTTP版本信息</li>
<li>请求头</li>
<li>请求主体（请求数据）</li>
</ul>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/111http请求2.png" alt=""></p>
<p><img src="C:\Users\96356\Desktop\前端学习\前端面试题\上传图片\111http请求2.png" alt="111http请求2" style="zoom:50%;" /></p>
<h5 id="Step-5：服务器响应请求"><a href="#Step-5：服务器响应请求" class="headerlink" title="Step 5：服务器响应请求"></a>Step 5：服务器响应请求</h5><p>当服务器接收到浏览器的请求之后，就会进行逻辑操作，处理完成之后返回一个<code>HTTP</code>响应消息，包括：</p>
<ul>
<li>状态行：包含HTTP版本、状态码、状态码的原因短语</li>
<li>响应头</li>
<li>响应正文</li>
</ul>
<p>​    <img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/响应请求.png" style="zoom: 50%;" /></p>
<p>在服务器响应之后，由于现在<code>http</code>默认开始长连接<code>keep-alive</code>，当页面关闭之后，<code>tcp</code>链接则会经过四次挥手完成断开</p>
<h5 id="Step-6-页面渲染"><a href="#Step-6-页面渲染" class="headerlink" title="Step 6 : 页面渲染"></a>Step 6 : 页面渲染</h5><p><strong>当浏览器接收到服务器响应的资源后，首先会对资源进行解析</strong>：</p>
<ul>
<li>查看响应头的信息，根据不同的指示做对应处理，比如重定向，存储cookie，解压gzip，缓存资源等等</li>
<li>查看响应头的 Content-Type的值，根据不同的资源类型采用不同的解析方式</li>
</ul>
<p>关于页面的渲染过程如下：</p>
<ul>
<li>解析 HTML 和 CSS：浏览器首先将 HTML 和 CSS 解析成 DOM（文档对象模型）和 CSSOM（CSS 对象模型）两个树形结构，这两个结构合并后便构成了渲染树（Render Tree）。</li>
<li>布局：浏览器根据渲染树中每个元素的位置和大小计算出它们在屏幕上的实际位置，这个过程叫做布局（Layout），也称为回流（Reflow）。</li>
<li>绘制：浏览器根据渲染树和布局计算出来的元素位置和大小，将它们绘制到屏幕上，这个过程叫做绘制（Paint）。</li>
<li>合成：浏览器将绘制好的层按照它们的层级关系合成成最终的图像，并显示在屏幕上。</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>卷积神经网络CNN（Convolutional Neural Network）</title>
    <url>/2021/08/12/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%EF%BC%88Convolutional%20Neural%20Network%EF%BC%89/</url>
    <content><![CDATA[<p>@<a href="卷积神经网络CNN（Convolutional Neural Network）">TOC</a></p>
<blockquote>
<p>总结CNN的要点：<br>Q1：什么是CNN？为什么要用CNN？为什么图像处理一般都采用CNN？<br>Q2：实现CNN的步骤？</p>
<p><font color="red">input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten——&gt;fully connected network——&gt;output </font><br>Q3：如何用 <em>keras</em> 搭建一个CNN?<br>Q4：CNN的应用?什么时候适用CNN效果最好？<br>满足三个图像三个特性的时候。但要考虑第三点取子样是否合理。</p>
</blockquote>
<h1 id="CNN的概述"><a href="#CNN的概述" class="headerlink" title="CNN的概述"></a>CNN的概述</h1><h2 id="什么是CNN？"><a href="#什么是CNN？" class="headerlink" title="什么是CNN？"></a>什么是CNN？</h2><p>CNN也叫convnet，中文名称为卷积神经网络，是计算机视觉领域常用的一种深度学习模型。</p>
<h2 id="为什么要用CNN？"><a href="#为什么要用CNN？" class="headerlink" title="为什么要用CNN？"></a>为什么要用CNN？</h2><p>其可以简化DNN模型，可以减少不必要的神经元节点。特别是用在图像处理上。</p>
<h3 id="为什么图像处理一般都采用CNN？"><a href="#为什么图像处理一般都采用CNN？" class="headerlink" title="为什么图像处理一般都采用CNN？"></a>为什么图像处理一般都采用CNN？</h3><font color="green">**CNN的参数比全连接神经网络少得多**，为什么CNN只用较少的参数就可以用于处理图像呢？</font>

<p>这是因为图像具有以下三点特征：<br>1、一些模式比整张图片小得多，例如“鸟喙”就比整张图片小得多；<img src="https://img-blog.csdnimg.cn/1e9efb0804a64876a33e2794d96039a0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>2、同样的模式可能出现在图像的不同区域，例如“鸟喙”可能出现在图片的左上方也可能出现在图像的中间；<img src="https://img-blog.csdnimg.cn/c4a2de1adb4d4573865ec9f20b9e4a96.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>3、对图像的降采样不会改变图像中的物体。<img src="https://img-blog.csdnimg.cn/3e746d5fef0140029fe62095452d8389.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""><br><strong>CNN的卷积层的设计对应着前两点，池化层的设计对应着第三点。</strong> 如下图所示：<br><img src="https://img-blog.csdnimg.cn/81dc5d9f161c47b4b7054b5964eda897.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""></p>
<h1 id="实现CNN的步骤"><a href="#实现CNN的步骤" class="headerlink" title="实现CNN的步骤"></a>实现CNN的步骤</h1><p>input——&gt;convolution——&gt;max pooling——&gt;…——&gt;flatten（压平）——&gt;fully connected network——&gt;output</p>
<h2 id="卷积层（减少训练参数）"><a href="#卷积层（减少训练参数）" class="headerlink" title="卷积层（减少训练参数）"></a>卷积层（减少训练参数）</h2><p><img src="https://img-blog.csdnimg.cn/81dc5d9f161c47b4b7054b5964eda897.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="CNN流程图"></p>
<ul>
<li><p>对应Property1：每一个Filter（待训练的参数，即卷积核）代表一个<strong>局部特征探测器</strong>（他是一个可以特点图形的表示器），假设现在两个特征探测器（<em>Filter1</em> 和 <em>Filter2</em>）</p>
<ul>
<li><p>卷积核1的结果 值最大的那个点所在的图片部分，就是我们要找的内容<br><img src="https://img-blog.csdnimg.cn/afe8e2823a47491bba71d054aa0ade85.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
<li><p>卷积核2的结果。与卷积核1的结构共同组成了 feature map<img src="https://img-blog.csdnimg.cn/c3841af956b24b6d8721af30d207cb4c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li>对应Property2：用 <em>Filter1</em> 就能探测出在不同位置的同一个flatten，而不需要用不同的Filter</li>
</ul>
<p>如果图片是彩色的，也就是说它是三通道的，还没卷积之前，可以说有3个通道（RGB），意味着每一个像素由3个数值表示。如下图所示：<br>卷积核是立方体3×3×3，图片为9×9×3。图片中同样选择卷积核大小，与卷积核累和，但要注意我们并不是把RGB三层，分开算，应该算合为一体的。<img src="https://img-blog.csdnimg.cn/991470ca8069474fabd2088db993f9eb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="RGB卷积"></p>
<h3 id="与全连接方式的对比"><a href="#与全连接方式的对比" class="headerlink" title="与全连接方式的对比"></a>与全连接方式的对比</h3><p>全连接层，图像处理的神经网络图如下所示，每个输入与各神经元都有链接（有固定的权值）<img src="https://img-blog.csdnimg.cn/b34b02cb98274e53a6600a5c685d3674.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="全连接层"><br>下面是CNN神经网络图，其主要的目的是减少参数（减少权值数量）。并且可以存在一定的共享权值，下面颜色相同的权值边值应该相同，这样调参可以更快。</p>
<p><img src="https://img-blog.csdnimg.cn/250d06b21d4546dea59a0a6502d3a3c0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="CNN"></p>
<h2 id="池化层（Maxpooling）"><a href="#池化层（Maxpooling）" class="headerlink" title="池化层（Maxpooling）"></a>池化层（Maxpooling）</h2><p>目的是减少每一个特征的维度，也就是减少后面flatten的输入特征数量。Maxpooling这边我们取每个框内的最大点。<img src="https://img-blog.csdnimg.cn/f52e46c700fe492ab79a470370e223ff.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="Maxpooling的规程"><br>在整理一下，变成一个新的feature map</p>
<p>合计上两步得到：<br><img src="https://img-blog.csdnimg.cn/8065213d0fff4e30b41d596b0cde4d65.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>做一次卷积+池化后，把原来的 <em>6 × 6</em> 图像变成了 <em>2 × 2</em> 图像，<em>2 × 2</em>图像的深度（每个像素点用多少个值表示）<strong>取决于有多少个过滤器，如果有 <em>50</em> 个过滤器，<em>2 × 2</em> 图像就有 <em>50</em> 维</strong>，上图是只用两个过滤器，那就是 <em>2</em> 维。<br>所以上图右边，就是一个新的比较小的图像，每个过滤器代表了一个channel(通道)。</p>
<h2 id="重复上两步操作"><a href="#重复上两步操作" class="headerlink" title="重复上两步操作"></a>重复上两步操作</h2><p>可多次重复上述两个步骤，将输出的结果变得最小化。</p>
<blockquote>
<p><strong>Q: 假设我们第一次卷积的时候，我们有25个卷积核，那输出的结果 feature map中应该有25个矩阵。那请问，第二次卷积的时候，输出的feature map 应该是 25×25=625 个矩阵么？</strong><br>答：不对，做完第一次卷积得到25个矩阵，做完第二次后还是25个矩阵。例如输入是三个通道 <em>(RGB)</em> 的 <em>6 × 6</em> 矩阵数据（即一个立方体，6 × 6  × 3），有两个过滤器（也是立方体，三个通道，<em>3 × 3 × 3</em>），则输出为<em>4  × 4 × 2</em>。（<em>4 = 6-2 ； 2</em>是过滤器个数  <strong>过滤器决定通道数</strong>）<img src="https://img-blog.csdnimg.cn/a4aeaa3dd23d4ff48bce2e89c97553c3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/e634fad522fe498a9b5cb04557fe7a05.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""></p>
<h2 id="Flatten（压平）"><a href="#Flatten（压平）" class="headerlink" title="Flatten（压平）"></a>Flatten（压平）</h2><p><img src="https://img-blog.csdnimg.cn/699741afda84434985ef450ad1cffeea.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="Flatten"><br>flatten(压平)的意思是，把特征图拉直，然后丢到一个全连接神经网络里。</p>
<h1 id="CNN-in-Keras"><a href="#CNN-in-Keras" class="headerlink" title="CNN in Keras"></a>CNN in Keras</h1><ul>
<li>卷积前，一个pixel用多少个数值表示，取决于通道数</li>
<li>卷积后，一个pixel用多少个数值表示，取决于Filter个数，而通道数决定Filter的高</li>
<li>上一个卷积层有多少个Filter，下一层卷积input就有多少个通道<br><img src="https://img-blog.csdnimg.cn/75db9d57e892418d9c68b6d52c714c4b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/686fdcfd5a734bfa998f6d84def07fea.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">25</span>,<span class="number">3</span>,<span class="number">3</span>),input_shape=(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(Conv2D(<span class="number">50</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(Dense(output_dim=<span class="number">100</span>))</span><br><span class="line">model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(output_dim=<span class="number">10</span>))</span><br><span class="line">model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Q：为什么上图第二次 每个卷积核的 参数是 225？</strong><br>答：因为是 3×3×25  那为什么是25而不是50呢？</p>
</blockquote>
<h1 id="CNN在学什么？"><a href="#CNN在学什么？" class="headerlink" title="CNN在学什么？"></a>CNN在学什么？</h1><h2 id="CNN卷积和池化部分在做什么？"><a href="#CNN卷积和池化部分在做什么？" class="headerlink" title="CNN卷积和池化部分在做什么？"></a>CNN卷积和池化部分在做什么？</h2><p><img src="https://img-blog.csdnimg.cn/919125d4f1964cb9b520a639ed94e2e6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>分析第一个层的卷积核是比较容易的，里面每个卷积核就是一个3 <em> 3 的矩阵，对应3 </em> 3 范围内的9个像素点，<strong>只要看到矩阵的值，就知道在检测什么</strong>（有明显的特征）。</li>
<li>第二层的卷积核没法知道在做什么，虽然也是 <em>3 × 3</em> 的矩阵，总共 50 个。<strong>但是这些卷积核的输入不是像素点，而是在上一层做完卷积和池化后的输出</strong>。就算知道第二层卷积核的矩阵值，也不知道在检测什么。<strong>另外第二层卷积核考虑的不是原图 <em>3 × 3</em> 的像素点，而是比原图 <em>3 × 3</em> 像素点更大的范围，因为在第一层的池化后，压缩了原图 <em>3 × 3</em> 的区域，第二层卷积核是在压缩后的图像里再选取 <em>3 × 3</em>  像素点，相当于扩大了原图检测的范围。</strong></li>
</ul>
<blockquote>
<font color="red">Q：那怎么分析第二层卷积核在做什么？</font>

<p>第二层的50个卷积核，每个卷积核的输出是一个 <em>11 × 11</em> 的矩阵。把第k个卷积核输出拿出来如上图左下，矩阵元素表示为  $a_{ij}^{k}$  (第k个卷积核，第i个行，第j个列)。接下来 定义一个“<em>Degree of the activation of the k-th  filter</em>”（第k个卷积核的激活程度），值代表第k个卷积核的被激活程度（<strong>input和第k个卷积核侦测的东西有多匹配</strong>）。</p>
<p>第k个卷积核被激活程度表示为：$a^{k}=\sum<em>{i=1}^{11}\sum</em>{j=1}^{11}a_{ij}^{k}$ ，<em>11 × 11</em> 矩阵所有元素值之和。</p>
<p><strong>Q：找一张图像，可以让第k个卷积核被激活程度最大，如果做到这件事情？</strong><br><strong>称 <em>input</em> 的图像为 <em>x</em>，目标是找一个让 $a^{k}$ 最大的 <em>x</em>，如何找到这个 <em>x</em>？</strong></p>
<p><font color="red">使用梯度上升</font>，因为我们的目标是最大化 $a^{k}$  。现在是把 <em>x</em> 当做我们要找的参数，对 <em>x</em> 用梯度上升。原来CNN的 <em>input</em> 是固定的，<em>model</em> 的参数使用梯度下降求解。现在反过来，<em>model</em> 的参数是固定的，使用个梯度上升更新 <em>x</em>，让被激活程度最大。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/b5522ea6a04d49bfa39a3f94db140610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">上图左下，是随便取12个卷积核后对 <em>x</em> 做梯度上升后的结果，每个卷积核都找到一张图像，这张图像让这个卷积核的被激活程度最高。如果有50个卷积核，理论上可以找50张图像。</p>
<blockquote>
<p><strong>Q：这12张图像有一个共同的特征：是某种纹路在图上不断反复。为什么会这样？</strong><br>看第三张图像，都是小小的斜条纹，这意味着第三个卷积核是在检测是否有斜的条纹。因为卷积核考虑的范围是很小的，所以原图像上任何地方出现一个小小的斜纹的话，这个卷积核（过滤器）就会被激活，输出值就会很大。如果原图像所有范围都是这种小小的条纹，那这个卷积核的被激活程度就最大。</p>
</blockquote>
<p>你会发现每个过滤器都是在检测某一种图案（某一种线条），例如上图左下第3个过滤器是检测斜条纹，第4个是检测短、直的线条，第6个是检测斜成一定程度的线条等等。</p>
<font color="red">每个卷积核（过滤器）都在检测不同角度的线条。</font>

<h2 id="全连接的隐藏层都在干什么？"><a href="#全连接的隐藏层都在干什么？" class="headerlink" title="全连接的隐藏层都在干什么？"></a>全连接的隐藏层都在干什么？</h2><p><img src="https://img-blog.csdnimg.cn/cc01d0cb741b4bab93047f401e34b40f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>做完卷积和池化后，会做flatten(压平)，把压平后的结果丢到神经网络里去。</p>
<blockquote>
<p><strong>Q：在这个神经网络的隐藏层里，每个神经元都在干什么？</strong><br>答：如法炮制之前的做法，定义第 <em>j</em> 个神经元的输出是 $a<em>{j}$ ，然后找一张图像 <em>x</em>，使 $a</em>{j}$ 最大。<br>找到的图像如上图左下所示，9张图像，是对应神经元的输出最大。你会发现跟刚才卷积核（过滤器）观察的图案很<strong>不一样</strong>，<font color="red"><strong>卷积核观察的是类似纹路的东西，因为卷积核只考虑了原图像的一部分区域</strong></font>。<br><strong>输出通过压平后，现在每个神经元是去看整张图像</strong>，能使神经元激活程度最高的图像不再是纹路这种小图案，而是一个完整的图形，虽然看起来完全不像是数字，但神经元被激活后也的确在侦测一个完整的数字。</p>
</blockquote>
<h2 id="考虑最后的输出？"><a href="#考虑最后的输出？" class="headerlink" title="考虑最后的输出？"></a>考虑最后的输出？</h2><p><img src="https://img-blog.csdnimg.cn/c02bf451565e4f01bacf11dc6922219c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>如果最后的输出是10维的，每一维对应一个数字。把某一维拿出来，找一张图像使那个维度的输出最大。例如现在要找一张图像，使输出层上对应数字1的神经元的输出最大，理论上这张图像看起来就是数字1<br>但是实际的图像如上图左边所示，每张图像分别代表0,1,2,3,4,5,6,7,8</p>
<blockquote>
<p><strong>Q：那为什么是这种是乱七八糟的雪花状呢，而不是我们能看清的数字呢？</strong><br>答：因为神经网络的视角，他就是和人不一样的。他就认为这些雪花图像是不一样的，对于0-8数字。与我们人的思维不同。<br><img src="https://img-blog.csdnimg.cn/f84a6c6c9e4c468a805407e8bfee004c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>Q：能不能让这些图像看起来更像数字？</strong><br>我们知道，一张图像是不是一个数字，有一些基本的假设。比如上图左边，人类看起来显示不是数字。那么我们对x做一些<strong>正则项约束</strong>，告诉机器，虽然有些 <em>x</em>（图像） 可以让  <em>y</em>  很大，但是这些 <em>x</em> 的确不是数字。<br><strong>Q：那加些什么约束呢？</strong><br>比如最简单的想法，图像上的白点是有墨水（笔画）的地方，对一个数字来说，有白点的部分是有限的，数字的笔画只占图的一小部分，所以我们要对 <em>x</em> 做一些限制。<br>假设 $x<em>{ij}$ 是图像像素点的值，每张图像有 <em>28 × 28</em> 个像素点。<strong>把所有像素点的值取绝对值并求和（相当于L1正则）</strong>，我们希望找一个 <em>x</em> ，让 $y</em>{i}$ 越大的同时，也让像素点绝对值之和越小。那我们找出来的图像大部分的地方就不是白色的。<br>最后得到的结果如上图右边所示，和左边的图看起来，已经可以隐约看出来是个数字了。</p>
</blockquote>
<h1 id="CNN的应用"><a href="#CNN的应用" class="headerlink" title="CNN的应用"></a>CNN的应用</h1><h2 id="Deep-Dream"><a href="#Deep-Dream" class="headerlink" title="Deep Dream"></a>Deep Dream</h2><p>你给机器一张图像，<strong>机器会在这张图像里面，加上它学习到的东西</strong>。<br><img src="https://img-blog.csdnimg.cn/b3c9858f5d9849d8995dd1183150f92e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>比如把上图丢到CNN里面去，然后把某个卷积核或者某个全连接隐藏层拿出来（一个向量），假设是 $\begin{bmatrix}<br>3.9\<br>-1.5\<br>2.3\<br>:\<br>\end{bmatrix}$</p>
<p>然后把3.9、2.3调大（本来是正的值调大），-1.5调小（负的值调小），正的更正，负的更负。找一个图像使卷积核或者隐藏层（拿出来的）的输出是调整后的向量。<strong>这么做的意思是让CNN夸大化它看到的东西。</strong><br><img src="https://img-blog.csdnimg.cn/0884c7de1c4e44b2ae5e302590b5ee18.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>找到的图像会变成上图所示，出现很多奇怪的东西。右边看起来是一头熊，原来是一颗石头。对机器来说，本来就觉得石头像一头熊，强化它的认知后，就学习出来更像一头熊的图案。这个就是Deep Dream。</p>
<h2 id="Deep-Style"><a href="#Deep-Style" class="headerlink" title="Deep Style"></a>Deep Style</h2><p><em>input</em> 一张图像，然后让机器去修改这张图像，让它有另一张图的风格，比如让上图看起来是呐喊。<br><img src="https://img-blog.csdnimg.cn/153f1e11b39943d8b64e7f352c289410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><img src="https://img-blog.csdnimg.cn/952a46ca31584df885c1722e5f79912d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>Q：卷积核和过滤器的区别</strong></p>
<ul>
<li><p>卷积核就是由<strong>长和宽</strong>来指定的，是一个<strong>二维</strong>的概念。</p>
<ul>
<li>过滤器是是由<strong>长、宽和深度</strong>指定的，是一个<strong>三维</strong>的概念。</li>
<li>过滤器可以看做是卷积核的集合。</li>
<li>过滤器比卷积核高一个维度——深度。</li>
</ul>
<p>——————————————————————————————————</p>
</li>
</ul>
<p><strong>Q：怎么做到图像风格转变呢？</strong><br><strong>把原来的图像丢给CNN，得到CNN过滤器的输出，代表一张图像里有什么样的内容</strong>。 然后把呐喊这张图也丢到CNN里，也得到过滤器的输出，但这时候考虑的不是过滤器输出的绝对值，而是考虑<strong>过滤器和过滤器输出之间的关系</strong>，<strong>这个关系代表了一张图像的风格</strong>。接下来用同一个CNN找一张图像，这张图像的内容像原图像的内容（过滤器的输出类似），同时这张图像的风格像呐喊的风格（过滤器输出之间的关系类似）。<br><strong>找一张图片同时<font color="red">最大化</font>内容和风格（使用<font color="red">梯度上升更新参数</font>），得到的结果就像两张图片结合一样。</strong></p>
</blockquote>
<h2 id="CNN应用在围棋上"><a href="#CNN应用在围棋上" class="headerlink" title="CNN应用在围棋上"></a>CNN应用在围棋上</h2><p><img src="https://img-blog.csdnimg.cn/d2233ab8dcdf4ca8ad1e4dc4ebf550b6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>要让机器下围棋，不一定要用CNN，一般的神经网络也可以做这件事情。只要学习一个网络，也就是找一个函数，输入是棋盘，输出是棋盘上的位置，根据棋盘的盘势，判断下一步落子的位置。<br>输入是<em>19 ×19</em> 向量，向量每一维是棋盘上的一个位置（是黑子则值为1，是白子则值为-1，反之则为0），丢到一个全连接的神经网络，输出也是<em>19 ×19</em> 的向量（每一维对应棋盘一个位置），那这样机器就可以学会下围棋了。</p>
<h3 id="为什么CNN可以用在下围棋上？"><a href="#为什么CNN可以用在下围棋上？" class="headerlink" title="为什么CNN可以用在下围棋上？"></a>为什么CNN可以用在下围棋上？</h3><p>但实际采用CNN会得到更好的效果！为什么呢？<br>之前举的例子都是把CNN用在图像上面，<em>input</em> 是一个矩阵。用到下棋上，只要把 <em>19 ×19</em>  的向量表示为 <em>19 ×19</em>  的矩阵。对CNN来说，<strong>就是把棋盘和棋子当成一个图像，然后输出下一步落子的位置</strong>。</p>
<blockquote>
<p><img src="https://img-blog.csdnimg.cn/604669df79b5475aa23db1f14d14b3e5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>收集很多棋谱，告诉CNN，看到落子在5之五，输出天元的位置为1，其他位置为0<br>看到5之五和天元都有棋子，输出就是5之五的位置为1，其他位置为0<br>这个是监督的部分，AlphaGo还有强化学习的部分</p>
</blockquote>
<h2 id="总结一下什么时候用CNN-为什么围棋适用？"><a href="#总结一下什么时候用CNN-为什么围棋适用？" class="headerlink" title="总结一下什么时候用CNN?为什么围棋适用？"></a>总结一下什么时候用CNN?为什么围棋适用？</h2><p><strong>图像要有该有的特性，开头讲过的根据<font color="red">三个特性</font>设计出了CNN的网络结构，在处理图像的时候特别有效。</strong></p>
<blockquote>
<p><strong>Q：为什么围棋很适用CNN？</strong><img src="https://img-blog.csdnimg.cn/36ddc9027bbe4537b72ff41a6553c1dd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>答：因为围棋有一些特性和图像处理是很相似的。</p>
<p><font color="red">围棋是有图像的第一个和第二个特性</font></p>
<ul>
<li><p><strong>在一张图像上面，有一些图案是比整张图像小的，比如鸟嘴。在围棋也有同样的现象</strong>，比如看到一些棋子摆放的图案，就要做一些相应的事情（比如上图黑子叫吃的时候，白子要落在下方保证不被吃）。不需要看整个棋盘，只需要看一个小小的范围，就可以侦测白子是不是属于被叫吃的状态。<br>AlphaGo里第一层的过滤器就是用的 5 × 5 过滤器，显然设计这个过滤器的人觉得围棋上最基本的图案在 5 × 5 范围内就可以被侦测出来。</p>
</li>
<li><p>图<strong>像还有个特性是相同的图案会出现在不同的区域，在围棋上也有同样的特征。</strong>例如叫吃的图案，可以出现在棋盘左上角，也可以出现在棋盘右下角，图案代表了同样的意义（叫吃），所以可以用同一个检测器来处理这些在不同位置的图案。</p>
</li>
</ul>
<p>Q：困惑的是图像的第三个特性，对原图像做子采样不会影响人看到的这张图像的样子，基于第三个特性有了池化层，但Alpha<br>并没有采用池化层（就是做子采样）？<br><strong>因为不能做子采样。比如丢弃棋盘的奇数行和偶数列，想想也应该是不可以的。</strong></p>
<p>也许AlphaGo里的CNN架构有特殊的地方。AlphaGo论文附录里描述了它的网络结构，input是一个<em>19 ×19 ×48</em> 的图像，<em>19<br>×19</em> 是棋盘可以理解，<strong>但48是怎么来的？</strong><br>对AlphaGo来说，把每一个位置都用48个值来描述（卷积后有48个通道）。本来我们只要描述一个位置是不是白子、黑子就可以了，而AlphaGo加上了领域知识（看这个位置是不是出于叫吃的状态等等）。</p>
<p>AlphaGo有做zero padding(零填充)，在原来<em>19 ×19</em> 的图像外围补上 <em>0</em> 值变成 <em>23 × 23</em> 的图像，第一层用的是 <em>5 × 5</em> 过滤器，总共 <em>k</em> 个过滤器（paper里用的是192个过滤器），步长<em>stride=1</em>，有用到 <em>ReLu</em> 作为激活函数，有2到12层的过滤器层，最后变成 <em>21 × 21</em> 的图像，接下来再使用 <em>3 × 3</em> 的过滤器，步长 <em>stride=1</em>。最后发现AlphaGo没有使用池化，针对围棋特性设计CNN结构的时候，是不需要池化这个结构的。</p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>CNN</tag>
        <tag>李宏毅</tag>
      </tags>
  </entry>
  <entry>
    <title>半监督学习 Semi-Supervised</title>
    <url>/2021/08/17/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%20Semi-Supervised/</url>
    <content><![CDATA[<p>@<a href="半监督学习 Semi-Supervised">TOC</a></p>
<blockquote>
<p>总结 半监督学习 的要点：<br>Q1：什么是Semi-Supervised？<br>Q2：Semi-Surpervised在生成模型中如何实现的（EM算法）？<br>Q3：Semi-Surpervised基于Low-density Separation（低密度分离）假设是如何实现的？<br>Q4：Semi-Surpervised基于Smoothness Assumption（平滑）假设是如何实现的？</p>
</blockquote>
<h1 id="什么是Semi-Supervised？"><a href="#什么是Semi-Supervised？" class="headerlink" title="什么是Semi-Supervised？"></a>什么是Semi-Supervised？</h1><p><img src="https://img-blog.csdnimg.cn/a671d2d30c944294a8b44fad632f7435.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>大家知道在监督学习里，有一大堆的训练数据（由input和output对组成）。例如上图所示 $x^{j}$是一张图片，$y^{r}$ 是类别的 <em>label</em>。<br><strong>半监督学习是说，在label数据上面，有另外一组unlabeled的数据</strong>，写成$x^{u}$ (只有 input 没有 output )，有U笔 unlabeled 的数据。<br>通常做半监督学习的时候，我们常见的情景是 <strong>unlabeled 的数量远大于labeled 的数量</strong>（U&gt;&gt;R)。</p>
<blockquote>
<p><strong>举个栗子：现在我们要做一个猫狗分类</strong></p>
<ul>
<li>如果只考虑 labeled data，我们分类的分界线会画在中间；    </li>
<li>如果把 unlabeled data 也考虑进去，我们可能会根据 unlabeled data 的分布，分界线画成图中的斜线； 　<br>semi-supervised earning使用 unlabel 的方式往往伴随着<strong>一些假设</strong>，学习有没有用，取决于你这个<font color="red"><strong>假设合不合理</strong></font>。（比如灰色的点也可能是个狗不过背景跟猫照片比较像）<img src="https://img-blog.csdnimg.cn/994e98b4ab274acc8f394810b34dc7bf.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ul>
</blockquote>
<p>半监督学习可以分成两种：</p>
<ul>
<li>一种叫做<strong>转换学习</strong>，unlabeled 数据就是 testing set ，使用的是testing set的特征。</li>
<li>另一种是<strong>归纳学习</strong>，不考虑testing set，学习model的时候不使用testing set。</li>
</ul>
<blockquote>
<p><strong>Q：用 testing set 作为 unlabeled 数据，不是相当于用到了未来数据吗？</strong><br><strong>答</strong>：用了 label 数据才算是用了未来数据，用 testing set 的特征不算是使用未来数据。<br><strong>Q：什么时候使用转换学习或者归纳学习？</strong><br><strong>答</strong>：看 testing set是不是给你了。在一些比赛里，testing set 它是给你的，那么就可以使用转换学习。但在真正的应用中，一般是没有 testing set 的，这时候就只能做归纳学习。<br><strong>Q：为什么使用半监督学习？</strong><br><strong>答</strong>：缺少 lable 的数据，比如图片，收集图片很容易，但是标注label很困难。半监督学习利用未标注数据做一些事。<br><strong>Q：用沙雕的简单日常语言，讲一讲什么是 半监督学习</strong><br><strong>答</strong>：对人类来说，可能也是一直在做半监督学习，比如小孩子会从父母那边做一些监督学习，看到一条狗，问父亲是什么，父亲说是狗。之后小孩子会看到其他东西，有狗有猫，没有人会告诉他这些动物是什么，需要自己学出来。</p>
</blockquote>
<h1 id="Semi-Surpervised在生成模型中如何实现的（EM算法）"><a href="#Semi-Surpervised在生成模型中如何实现的（EM算法）" class="headerlink" title="Semi-Surpervised在生成模型中如何实现的（EM算法）"></a>Semi-Surpervised在生成模型中如何实现的（EM算法）</h1><p><img src="https://img-blog.csdnimg.cn/33bc117e72974fe68bb8635b54369078.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>Q：在生成模型中为什么使用半监督学习？</strong><br><strong>答</strong>：在监督学习中，有一堆用来训练的样本（就是label），你知道它们分别属于类别1，还是类别2。会去估算类别1和类别2的先验概率<em>P(C1),P(C2)</em> ，然后计算类条件概率 <em>P(x|C1),P(x|C2)</em>  。<br>假设 <em>P(x|Ci)</em> 服从一个高斯分布。 假设类别1的数据是从均值为 <em>μ1</em>，协方差为 <em>Σ</em> 的分布中取出来的，而类别2的数据是从均值为 <em>μ2</em> ，协方差也为 <em>Σ</em> 的分布中取出来的（之前讲过共享协方差，效果会好一点）。<br>然后可以计算后验概率 <em>P(C1|x)</em> ，决定一个决策边界在哪里。<img src="https://img-blog.csdnimg.cn/81307014a68d4ae2a427e46e9212d4eb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如果今天有一些未标注数据，如上图绿点，那仍然假设均值和方差是μ1,μ2,Σ显然不合理。<br>如上图左下所示，Σ应该比较接近圆圈（蓝色圆圈），也许在类1采样的时候有问题，所以采样到奇怪的分布（蓝色椭圆）。如上图右下，类2的μ2不应该在橙色椭圆内，而应该在更下面。<br>这样会使先验概率受到影响，本来两个分布，正例数据是一样多，但是加入未标注数据之后，你可能会觉得类2的正例数据更多（先验概率就更大）。总之加入未标注数据后，会影响对均值和协方差的估测，继而影响类条件概率，最后影响了你的决策边界。</p>
</blockquote>
<p>通俗的讲，回顾有监督学习中的生成模型，由于data都是有label的，<em>P(Ci)</em> 是已知的，<em>P(x|Ci)</em> 是通过我们基于高斯分布的假设用最大似然估计出来的；现在半监督学习中的生成模型，data的一部分是unlabel的，<em>P(Ci)</em> 是不确定的（隐变量），<em>P(x|Ci)</em>的假设模型也不能套用原来的 <em>u</em> 等参数，这时候需要用<font color="red"><strong>EM算法</strong>(Expectation-Maximization algorithm，又译为期望最大化算法)</font></p>
<h2 id="EM算法-具体怎么做"><a href="#EM算法-具体怎么做" class="headerlink" title="EM算法 具体怎么做"></a>EM算法 具体怎么做</h2><p>EM算法适用于带有无法观测的隐变量的概率模型估计<br>初始化一组参数，如果是二分类任务，就是初始化类1和类2的先验概率、均值和协方差，可以随机初始化，用已经有标注的数据估测，统称为 <em>θ</em></p>
<ul>
<li><strong>第一步（E步）</strong>，用labeled data算出来的高斯模型参数 <em>θ</em> 代入公式去求出每一笔未标注数据（unlabeled data）的后验概率（属于类1 的概率）的 <em>P(C1|Xu)</em>；</li>
<li><strong>第二步（M步）</strong>，用<strong>极大似然估计</strong>更新 <em>P(Ci)</em> 以及高斯模型参数 <em>θ</em> ，求出 <em>P(x|Ci)</em>，进一步求出新的后验概率 <em>P(Ci|Xu)</em> ，重复这两步直到收敛（似然概率最大）</li>
<li>至于为什么更新参数是要加入<em>P(Ci|Xu)</em> 这一项，是因为EM算法的思想是把不确定的data用一个概率来表示label，而每一笔不确定的data都有可能来自 类C1 和 类C2，看右下图：<img src="https://img-blog.csdnimg.cn/7035355bb99c4d298af9344cdfb7614c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="**加粗样式**在这里插入图片描述"></li>
</ul>
<blockquote>
<p>Q：EM 算法背后的理论是什么？<br>答：<strong>原来只有标注数据的时候</strong>，目标是最大化一个似然函数，那么给定θ，每一笔训练数据的似然函数值是可以计算的，然后把所有的似然函数值相加，就是总的似然函数值，然后找 <em>θ</em> 最大化。<em>θ</em> 有显式解，求最大值点（导数为0）。<br><strong>现在加入未标注数据后</strong>，我们不知道未标注数据来自哪一个类别，那么未标注数据出现的概率就是和  C1的联合概率+和C2的联合概率（相当于是$\sum<em>{C}P(x^{u},C^{i})$ 。接下来目标就是最大化 $P</em>{\theta }(x^{u})$ ，但是 $P_{\theta }(x^{u})$  的式子是非凸的，所以使用<strong>EM算法求解</strong>。<img src="https://img-blog.csdnimg.cn/5872e4d039e4413295b66b457cec8e23.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<h1 id="Semi-Surpervised基于Low-density-Separation（低密度分离）"><a href="#Semi-Surpervised基于Low-density-Separation（低密度分离）" class="headerlink" title="Semi-Surpervised基于Low-density Separation（低密度分离）"></a>Semi-Surpervised基于Low-density Separation（低密度分离）</h1><p><img src="https://img-blog.csdnimg.cn/ea72d9a8bb3448088c224becd5be516f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>低密度分离的假设是，不确定的data的label要不是1，要不是0（“非黑即白”）。低密度的意思是，两个Class的分界处是低密度的（分得比较开的）</strong></p>
<blockquote>
<p><strong>Q：这个世界是非黑即白的，什么是非黑即白？</strong><br><strong>答</strong>：假设现在有一大堆的data，有标注数据，有非标注数据，在两个类别之间会有一个明显的鸿沟。给一些标注数据，可以把边界分在上图右边的线，也可以把边界分在上图左边的线。但是考虑非标注数据，那么左边的边界会好一点，在边界处，两个类别的密度是低的（不会出现data）</p>
</blockquote>
<h2 id="Self-training-Entropy-based-Regularization-基于熵的正则化"><a href="#Self-training-Entropy-based-Regularization-基于熵的正则化" class="headerlink" title="Self-training + Entropy-based Regularization(基于熵的正则化)"></a>Self-training + Entropy-based Regularization(基于熵的正则化)</h2><h3 id="self-training"><a href="#self-training" class="headerlink" title="self-training"></a>self-training</h3><p><img src="https://img-blog.csdnimg.cn/007143d015a34ef9b00537c7dfc0c066.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>低密度分离最代表性、最简单的方法是self-training，非常直觉。</p>
<p>我们有一些标注数据，和一些未标注数据。接下来：</p>
<ul>
<li>从标注数据训练一个model   f* (用DNN，deep、shallow还是其他机器学习的方法都可以)</li>
<li>根据f*  标注未标注数据，丢入$x^{u}$ ，得到$y^{u}$  ，${(x^{u} ,y^{u} )}^{R+U}_{u=l}$ 叫做伪标签数据（称为Pseudo-label伪标签）</li>
<li>接下来，从伪标签数据集移除一些数据加到标注数据集（移除哪些数据需要自己决定，设计一些启发式的规则，或者给权重，有些数据的标签比较确定，那就给大的权重）</li>
<li>有了更多的标注数据之后，回头再去训练model f*</li>
</ul>
<blockquote>
<p><strong>Q：self-training在回归上有用吗？</strong><br><strong>回归问题用self-training不影响f∗，所以回归问题不能用self-training方法。</strong><img src="https://img-blog.csdnimg.cn/16b0c52a9a89411f80d53e91dc040f16.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>self-training 很像是刚才生成模型里面用的EM算法，唯一的差别是在做 self-training 的时候，用的是<strong>硬标签</strong>，生成模型里用的是<strong>软标签（概率）</strong>。在做 self-training 的时候，会强制分配一个数据属于某一个类别，在生成模型里，使用的是<strong>后验概率</strong>，部分属于类1，部分属于类2。</p>
</blockquote>
<h3 id="Entropy-based-Regularization-基于熵的正则化-—-self-training的进阶版"><a href="#Entropy-based-Regularization-基于熵的正则化-—-self-training的进阶版" class="headerlink" title="Entropy-based Regularization(基于熵的正则化) — self-training的进阶版"></a>Entropy-based Regularization(基于熵的正则化) — self-training的进阶版</h3><p><img src="https://img-blog.csdnimg.cn/26e158dbdc714533a4f0173142f2db23.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>熵：一个事件的不确定程度</strong></p>
<p>Entropy-based Regularization（基于熵的正则化）是self-training的进阶版，self-training里用概率划分类别，可能觉得比较武断，那就可以用Entropy-based的这个方法。</p>
<p>Entropy-based是说，如果使用神经网络，output是一个分布，我们不去限制output具体属于哪一个类别，而是假设分布很集中（非黑即白的世界）。如上图，假设做5个类别分类的 model：</p>
<ul>
<li>第一个 类别1的概率为1，其他类别概率为0，是good</li>
<li>第二个 类别5的概率为1，其他类别概率为0，是good</li>
<li>第三个 所有类别的概率很平均，是bad，不符合<strong>低密度分离的假设（非黑即白）</strong></li>
</ul>
<blockquote>
<p><strong>Q：怎么用数值的方法评估分布是集中还是不集中？</strong></p>
<p><font color="red"><strong>使用熵，分布的熵告诉你集中还是不集中。可以用 每个类别的概率 乘以 log（每个类别的概率），再对类别个数求和取负数。 这个式子来评估。</strong> </font><br>这个其实就是理解成损失函数，因为这边讲究的是非黑即白，所以其实是一致的。损失函数 也可以用分布的距离来描述。<br>我们希望model的output在标注集上正确，在未标注集上的<strong>熵越小越好</strong>。</p>
<ul>
<li>第一个分布，熵为0，分布集中 <ul>
<li>第二个分布，熵也为0，分布集中 </li>
<li>第三个分布，熵为 ln(5) ，分布比较散</li>
</ul>
</li>
</ul>
<p>根据这个目标，重新设计损失函数。原来只是希望model在标注集上的output和label距离越近越好，用交叉熵来评估它们之间的距离。</p>
</blockquote>
<ul>
<li><strong>现在在原来的基础上，加上未标注集的output分布的熵。</strong></li>
<li>然后在未标注集部分乘上一个权重，来表明偏向标注部分还是未标注部分。</li>
<li>上图右下的损失函数可以算微分，那就使用<strong>梯度下降最小化这个损失函数</strong>，迭代求解参数。加入未标注部分，作用就类似于正则化（在原来损失函数后加一个L1正则或者L2正则），这里则加入一个未标注集熵来防止过拟合，所以称之为基于熵的正则化。</li>
</ul>
<h2 id="Semi-supervised-SVM（半监督SVM"><a href="#Semi-supervised-SVM（半监督SVM" class="headerlink" title="Semi-supervised SVM（半监督SVM)"></a>Semi-supervised SVM（半监督SVM)</h2><p><img src="https://img-blog.csdnimg.cn/ddbfa33ce3a4446581d49d9494a497ed.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>Q：SVM 支持向量机（Support Vector Machine）是什么？</strong><br>SVM是找边界，给你两个类别的数据，SVM找一个边界，这个边界一方面要有最大的间隔（让两个class分的越开越好），一方面要有最小的分类错误。<br>如上图，假设现在有一些未标注数据，半监督SVM会穷举所有可能的label。<br>上图中，有四笔未标注数据，每笔数据既可以属于 class1，也可以属于 class2，可能的情况如上图右边所示（还有很多种其他的可能）。然后对每个可能的结果，都去做一个SVM，边界如上图红色线。然后再去找让间隔最大，错误最小的那一种结果。在例子里可能是黑色框这种结果。</p>
</blockquote>
<h1 id="Semi-Surpervised基于Smoothness-Assumption（平滑性）假设是如何实现的"><a href="#Semi-Surpervised基于Smoothness-Assumption（平滑性）假设是如何实现的" class="headerlink" title="Semi-Surpervised基于Smoothness Assumption（平滑性）假设是如何实现的"></a>Semi-Surpervised基于Smoothness Assumption（平滑性）假设是如何实现的</h1><h2 id="平滑性假设与高密度区域"><a href="#平滑性假设与高密度区域" class="headerlink" title="平滑性假设与高密度区域"></a>平滑性假设与高密度区域</h2><font color="red">假设：x的分布是不平均的，在某些地方很集中，在某些地方又很分散。如果 x1 和 x2 在一个高密度的区域很相似的话，两者的标签也会很像。</font>

<blockquote>
<p><strong>Q：什么叫在高密度区域下呢？</strong><br> 意思是说可以用高密度的路径做连接<img src="https://img-blog.csdnimg.cn/211207011e154abc9dc1609ad946223f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>举个例子，假设数据的分布如上图右边所示，像一个血轮眼。现在有3笔数据：x1,x2,x3，x1和x2中间是一个高密度区域（x1和x2由一个高密度区域连接），有很多数据(中间想成平原地带，地势平坦，人烟很多)，而x2和x3之间数据稀少(中间想成一座山，人烟稀少)，那么走平原会比走山容易，x2走到x1更容易（更相似）。</p>
</blockquote>
<p><strong>Q：举一个现实中，相似图形的栗子？为什么会有高密度区域假设？</strong><br>因为在真实情况下，这个假设成立的可能性很高。<br><img src="https://img-blog.csdnimg.cn/a7767f1d4ea04b788d2f9f17bfcec96f.png#pic_center" alt="在这里插入图片描述"><br>我们考虑手写数字识别的例子，有两个2一个3，如果计算像素点相似度的话，可能上图右边的2和3更像。但是从所有数据中看，<strong>左边的2到右边的2中间会有很多连续的形态</strong>。所以根据平滑度假设，左边的2和右边的2更像，因为右边的2和3之间没有过渡的形态。<br><img src="https://img-blog.csdnimg.cn/dfdb44a5a6af4aad901c4185bd21b74c.png#pic_center" alt="在这里插入图片描述"><br>看人脸识别也是一样的，比如左脸像和右脸像差很多，两个人的左脸像计算像素点相似度的话，可能比同一个人的两张侧脸像更高。但是如果收集到足够多的未标注数据，会找到两个侧脸像的很多过渡形态，根据高密度区域假设，这两张侧脸像就是同一个人。</p>
<p><img src="https://img-blog.csdnimg.cn/12dc2e73270c49b08efeee9c7c8c1d74.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>高密度区域假设，在文件上非常有用，假如现在要区分天文学和旅游的文章。</p>
<p>天文学的文章会出现asteroid、bright，而旅游的文章会出现yellowstone、zion。如果未标注文章和标注文章的词语有重叠，那可以很容易分类。但真实情况情况是，未标注文章和标注文章可能没有任何词语重叠，因为世界上的词语太多了，一篇文章词汇不会很多，每篇文章的词语是非常稀疏的。<br><img src="https://img-blog.csdnimg.cn/87bec6b6bb8c4603aacffd11ce899920.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>但是收集到够多的数据的话，就可以说上图d1、d5像，d5、d6像，传播下去就可以说d1、d3是一类，d2、d4是一类。</p>
<h2 id="方法一：聚类，而后标注（图像上不太行）"><a href="#方法一：聚类，而后标注（图像上不太行）" class="headerlink" title="方法一：聚类，而后标注（图像上不太行）"></a>方法一：聚类，而后标注（图像上不太行）</h2><p><img src="https://img-blog.csdnimg.cn/45202fb11c71422c8437bdd3c23e91a5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>Q：如何实践平滑度假设？</strong><br>最简单的方法是聚类、然后标记。<br>假如数据分布如上图，橙色是class 1，绿色是class 2，蓝色是未标注数据。接下来做聚类，可能把所有数据分成3个簇。在簇1里，class 1的label最多，那簇1里所有数据标记为class 1，同样的簇2和簇3都标记为class 2。把标记后的数据拿去learn就结束了。</p>
<p>这个方式不一定有用，因为要求簇正确，这个方法有效的假设是同一个class的东西聚集在一起。但是在图像里要把同一个class的东西聚集在一起没有那么容易。之前深度学习讲过，不同class的图像可能会很像，同一个class可能会不像，只用像素点做聚类，结果八成是不好的。没办法把同一个class的数据聚集在一起，那未标注数据就没有用。</p>
<p>所以要有用，就要有一个好的方法来描述一张图像，比如用 <em>Deep Autoencoder</em> 抽特征，然后再做聚类。</p>
</blockquote>
<h2 id="方法二：基于图的方法"><a href="#方法二：基于图的方法" class="headerlink" title="方法二：基于图的方法"></a>方法二：基于图的方法</h2><p><img src="https://img-blog.csdnimg.cn/95a83cefc106475f915f00fe756c317b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>另一个方法是引入图结构，来表达通过高密度路径进行连接这件事情。</p>
<p>把现在所有的数据点都建成一个图，每个数据点就是图上的一个点，想办法计算它们之间的奇点，想办法把它们之间的边建出来。</p>
<p><strong>所谓的高密度路径的意思是说，如果有两个点，在图上是相连的，那它们就是同一个class，如果没有相连，就算距离很近，也走不到。</strong></p>
<blockquote>
<p><strong>Q：生活中，如何构建图？</strong><br>有些时候，图的表示可以很自然的得到。</p>
<ul>
<li>举例说网页的分类，你有记录网页和网页之间的超链接，那超链接就很自然的告诉你网页是怎么连接的。</li>
<li>又举例论文的分类，论文和论文之间有引用的关系，这种引用的关系也是另外一种图的边，可以很自然地把这种图画出来。</li>
</ul>
</blockquote>
<h3 id="怎么自己想办法构建图？"><a href="#怎么自己想办法构建图？" class="headerlink" title="怎么自己想办法构建图？*"></a>怎么自己想办法构建图？*</h3><p>其实的图的好坏对结果的影响是非常严重的，但是自己用什么方法做还是很启发的，用自己觉得合适的方式做就可以了。 通常的做法是：</p>
<p>先定义两个对象之间的相似度，比如图像可以是基于像素点的相似度（可能效果不好），也可以是基于自动编码器抽取出来的特征计算相似度（效果可能好一点）</p>
<p>定义完相似度后，就可以构建图了（添加边），图有很多种：</p>
<ul>
<li>K近邻的图，现在有一大堆数据，可以计算数据与数据之间的相似度，然后设置k例如3，就是3个最相似的点相连</li>
<li>e-Neighborhood的图，只有相似度超过某个阈值的点才会相连</li>
</ul>
<p><strong>所谓的边也不是只有相连和不相连这两种选择，可以给边一些权重，让边跟两个数据点的相似度成正比。</strong>相似度可以用Gaussian Radial Basis Function来定义<img src="https://img-blog.csdnimg.cn/755264db6fe240d798d40d43d90ea95f.png#pic_center" alt=""></p>
<h3 id="怎么计算这个相似度"><a href="#怎么计算这个相似度" class="headerlink" title="怎么计算这个相似度"></a>怎么计算这个相似度</h3><p>可以先算xi,xj的欧式距离，乘以一个参数取负号，再取e为底的指数函数。取exp很有必要，在经验上最后效果比较好。因为取exp，下降速度很快，只有当xi,xj非常靠近时，奇点才会大，距离远一点奇点就会下降很快变得很小。这样才能制造如上图右下方所示的，两个距离近的橙色点有连接，绿色点和橙色点虽然距离也近，但是使用了exp导致只有很近很近的点才有连接，即使远一点点就不会有连接了，有这样的机制才能避免跨海沟的连接(橙色点和绿色点连接)。</p>
<blockquote>
<p><img src="https://img-blog.csdnimg.cn/f5e991680cf44ff08f79229892cd8926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>基于图的方法是，如果现在在图上面有一些标注数据，比如上图左上方，已经知道了蓝色圈的数据属于class 1，那么跟他们有相连的数据点属于class 1的概率也会上升。每一笔数据会去影响它的邻居。</p>
<ul>
<li>光会影响邻居还不够，因为有连接说明本来就很像，那很像的input<br> ，output本来也就很像。这种方法真正的精髓是，<strong>class是会传递的</strong>，虽然一个点没有与标注数据直接相连，但是有连接路径，那么class<br> 1就会随着边传递。<ul>
<li>例如上图右上方，所有数据点构建成一个图（理想的例子），然后有一个蓝色点属于class 1，一个红色点属于class 2。经过基于图的方法，蓝色点会传递，红色点也会传递，如上图右下方所示。</li>
</ul>
</li>
</ul>
</blockquote>
<p><strong>要让基于图的这种半监督学习方法有用的话，一个重要的原则是你的数据要多，如果数据不够多，例如下图所示，中间有断开，那信息就传递不过去。</strong><img src="https://img-blog.csdnimg.cn/9ce410bae05d47f4b6a06931ef349d7a.png#pic_center" alt=""></p>
<h2 id="考试一般的考题，定量的计算图"><a href="#考试一般的考题，定量的计算图" class="headerlink" title="考试一般的考题，定量的计算图"></a>考试一般的考题，定量的计算图</h2><p>定量的使用方式是在这个图的结构上面定一个东西，叫做label的平滑度，来表明这个label有多符合平滑度假设。</p>
<h3 id="怎么定平滑度？"><a href="#怎么定平滑度？" class="headerlink" title="怎么定平滑度？"></a>怎么定平滑度？</h3><p><img src="https://img-blog.csdnimg.cn/42dc067087334546bbf3a44bdb7f9d88.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>看上图两个例子，这两个例子都有4个数据点，数据点之间连接的数字代表了边的权重。现在给两个例子的数据不同的label，左边例子的label是1,1,1,0，右边例子的label是0,1,1,0，那谁更平滑呢？</p>
<p>直观感觉就是左边例子更平滑，但我们需要定量描述。常见的方法是，考虑两两相连的点（不管有label还是没有label），在所有的配对上，计算label差值的平方，然后乘上权重 ，最后求和。</p>
<p>所以左边这个例子的S就是0.5，右边例子的S是3，S越小越平滑。</p>
<h3 id="用矩阵来表达"><a href="#用矩阵来表达" class="headerlink" title="用矩阵来表达"></a>用矩阵来表达</h3><p><img src="https://img-blog.csdnimg.cn/3993d1ab2b6b4e79baeee94790c115f3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>S可以稍微整理下，写成向量形式如上图。</strong></p>
<p>把y串成一个向量，y包括标注数据和未标注数据，所以有 R+U 维。</p>
<p><strong>L是<em>(R+U)×(R+U)</em>的矩阵，叫做图拉普拉斯，L的定义是 D−W ，W是两两数据点之间的权重，D是W每行值之和（放在对角线）。</strong></p>
<h3 id="再加一个正则化项"><a href="#再加一个正则化项" class="headerlink" title="再加一个正则化项"></a>再加一个正则化项</h3><p>现在可以用 y转置Ly 来评估现在得到的label有多平滑，<strong>式子里面的y是label的值，取决于神经网络的参数</strong>。那么如果要把平滑度考虑到神经网络里时，就是在原来的损失函数里加上λS（λ是某一个想要调的参数）。λS像一个正则化项，在调整参数时，不只是让标注数据的output跟真正的label越近越好，同时还要让output的label在标注数据和未标注数据上符合平滑度假设。平滑度假设由S衡量。</p>
<p>不一定要在output上计算平滑度，在深度神经网络里，可以把平滑度计算放在网络的任何地方。你可以假设你的output是平滑度，也可以把某个隐藏层乘上一些别的transform，它也要平滑，也可以要求每个隐藏层的output都是平滑的。</p>
<h3 id="转换的想法-Better-Representation"><a href="#转换的想法-Better-Representation" class="headerlink" title="转换的想法 Better Representation"></a>转换的想法 Better Representation</h3><p>我们观察到的世界其实是比较复杂的，在背后有一些比较简单的向量，比较简单的东西在操控这个复杂的世界。那只要看透假象，直指核心，就可以让学习变得比较容易。</p>
<p>例如上图右方剪胡子，胡子的变化是很复杂的，但是胡子受头操控，头的变化是有限的。所以胡子是观测，而头就是Better Representation。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>李宏毅</tag>
        <tag>半监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>吴恩达deeplearning.ai学习  之 目标检测</title>
    <url>/2021/09/25/%E5%90%B4%E6%81%A9%E8%BE%BEdeeplearning.ai%E5%AD%A6%E4%B9%A0%20%20%E4%B9%8B%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<p>@<a href="吴恩达deeplearning.ai学习  之 目标检测">TOC</a></p>
<h1 id="目标定位"><a href="#目标定位" class="headerlink" title="目标定位"></a>目标定位</h1><p>我们对图像的学习过程应该由 图像分类 -&gt; 图像单目标定位 -&gt; 图像多目标检测。<br><img src="https://img-blog.csdnimg.cn/img_convert/3ff5dd940674e17134f4a03d0199478d.png#pic_center" alt="目标检测的演化过程"></p>
<h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p>在图像分类中，例如，输入一张图片到多层卷积神经网络，它会输出一个特征向量，并反馈给 softmax 单元来预测图片类型。比如你正在构建汽车自动驾驶系统，你面前的对象可能包括以下4类：行人、汽车、摩托车和背景，这时 softmax 单元有四个输出（概率高的为判断的类）。如果图片里没有前三类的话，输出结果会是背景。</p>
<h2 id="图像分类基础上-发展图像内的单目标定位"><a href="#图像分类基础上-发展图像内的单目标定位" class="headerlink" title="图像分类基础上 发展图像内的单目标定位"></a>图像分类基础上 发展图像内的单目标定位</h2><p>在图像分类的基础上，我们可以对图像内的单目标定位<font
   color="red">（注意：这边的基础是图像里只有一个目标可以被检测，例如上图的车）</font>。实现定位，需要让神经网络多输出4个数字，标记为$b<em>{x},b</em>{y},b<em>{h},b</em>{w}$用于表示输出的边界框。前两者表示边界框的中心点，后两者表示的为边界框的高度和宽度。<font color="red">注意：我们定义左上角为坐标原点(0,0)，右下角为终点(1,1)</font> 例如下图所示：<br><img src="https://img-blog.csdnimg.cn/img_convert/043ac4d106c620fb7b7d1a3a300173e2.png#pic_center" alt="边界框描述"><br>还是这个例子，神经网络的输出改变为四个边界框描述数字$b<em>{x},b</em>{y},b<em>{h},b</em>{w}$ ，是否含有对象 $p<em>{c}$ ，含有对象属于哪个类标签。可以定义输出  $y$ 为 $[p</em>{c},b<em>{x},b</em>{y},b<em>{h},b</em>{w},c<em>{1},c</em>{2},c_{3}]^{T}$ </p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/82a6083e2c74937f49a25fc083131ea0.png#pic_center" alt="标签的定义与举例 左图为有车这个目标的图像  右图为没有目标对象的背景图像"><br><strong>注意我们此时假设的图片中只含有一个对象，是单目标的分类定位问题。</strong></p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>神经网络的损失函数，其参数为类别$\hat{y}$ 和网络输出 $y$ ，如果采用MSE损失函数，则 </p>
<script type="math/tex; mode=display">L(\hat{y},y)==(\hat{y_{1}} - y_{1})^{2}+(\hat{y_{2}} - y_{2})^{2}+...+(\hat{y_{8}} - y_{8})^{2}</script><p>损失值等于每个元素相应差值的平方和。<br>​</p>
<ul>
<li>如果图片内有对象（即 $p_{c}=1$），损失值就是不同元素的平方和</li>
<li>如果图片内没有对象（即 $p<em>{c}=0$），我们不用考虑其它元素，只需要关注神经网络输出 $p</em>{c}$ 的准确度。</li>
</ul>
<h2 id="图像内的单目标定位基础上-发展多目标定位"><a href="#图像内的单目标定位基础上-发展多目标定位" class="headerlink" title="图像内的单目标定位基础上 发展多目标定位"></a>图像内的单目标定位基础上 发展多目标定位</h2><p>yolo 将图像拆分成多个子图</p>
<h1 id="特征点检测（Landmark-detection）"><a href="#特征点检测（Landmark-detection）" class="headerlink" title="特征点检测（Landmark detection）"></a>特征点检测（Landmark detection）</h1><p>例如我想做人脸的情感识别，可以根据眼睛的特征点，根据嘴部的关键点输出值来确定嘴的形状，从而判断人物是在微笑还是皱眉，也可以提取鼻子周围的关键特征点。为了便于说明，你可以设定特征点的个数，<strong>假设脸部有64个特征点</strong>，有些点甚至可以帮助你定义脸部轮廓或下颌轮廓。选定特征点个数，并生成包含这些特征点的标签训练集，然后利用神经网络输出脸部关键特征点的位置。<br><img src="https://img-blog.csdnimg.cn/img_convert/2e7d94b4be44001ed6f193bc81b0303e.png#pic_center" alt="人脸情感识别的特征点示意图"><br>具体的想法是，准备一个卷积网络和一些特征点集，将人脸图片输入到卷积网络，输出1或0（1表示有人脸，0表示没有人脸），然后输出 64个特征点坐标位置 $(l<em>{1x},l</em>{1y})$ … $(l<em>{64x},l</em>{64y})$。理论上应该有129个输出（64个特征点 64×2+ 1（表示是否有人脸））。另外在人体姿态检测上也可以使用这样的特征点方法。</p>
<blockquote>
<p><strong>Q：注意点 特征点1的特性在所有图片中必须保持一致</strong><br>特征点1始终是右眼的外眼角，特征点2是右眼的内眼角，特征点3是左眼内眼角，特征点4是左眼外眼角等等。所以标签在所有图片中必须保持一致，假如你雇用他人或自己标记了一个足够大的数据集，那么神经网络便可以输出上述所有特征点，你可以利用它们实现其他有趣的效果，比如判断人物的动作姿态，识别图片中的人物表情等等。</p>
</blockquote>
<h1 id="滑动窗口目标检测法-（复杂过时）"><a href="#滑动窗口目标检测法-（复杂过时）" class="headerlink" title="滑动窗口目标检测法 （复杂过时）"></a>滑动窗口目标检测法 （复杂过时）</h1><p>这个方法简单的说就两步</p>
<ul>
<li>先构建一个卷积神经网络，能够识别出这个对象<br><img src="https://img-blog.csdnimg.cn/img_convert/e00067812bddc65aadedb32741cf0368.png#pic_center" alt="训练得到可以识别车的卷积网络"></li>
<li>滑动窗口（每次扩大窗口），选定合适的步长，从左上角开始裁剪，将其输入该卷积网络，输出是否为该对象。这样从左上角开始滑动窗口遍历整个图像。<br><img src="https://img-blog.csdnimg.cn/img_convert/4beea107cf1b1f8c359ef591dc421634.png#pic_center" alt="滑动窗口法"><br>这个方法有很明显的缺点就是。如果步长太大，误差会很大，不够精细。单如果步长太精细的话，因为我每滑动一次窗口即裁剪一次图像就要输入卷积网络输出是否是车。卷积网络时间代价很高，这么多次输入，那这个方法需要的时间成本就非常的高。</li>
</ul>
<blockquote>
<p><strong>Q：那为什么这个办法之前是可用的？</strong><br>因为之前神经网络还没兴起，每个裁剪对象判断都是由SVM来完成的。线性分类器速度比较快一些。</p>
</blockquote>
<p>解决的办法是不要使用滑动窗口，使用卷积来实现滑动窗口的效果。详见下章节。</p>
<h1 id="滑动窗口的卷积实现（Convolutional-implementation-of-sliding-windows）"><a href="#滑动窗口的卷积实现（Convolutional-implementation-of-sliding-windows）" class="headerlink" title="滑动窗口的卷积实现（Convolutional implementation of sliding windows）"></a>滑动窗口的卷积实现（Convolutional implementation of sliding windows）</h1><p>首先你要了解，如何将全神经网络转化为用卷积网络来实现，如下图：<br><img src="https://img-blog.csdnimg.cn/img_convert/a9f14a0c1c5045527b4838803ea88b64.png#pic_center" alt="全神经网络转化为用卷积网络来实现"><br><strong>那我们现在来看 为什么要可以使用卷积来简化滑动窗口呢？</strong><br><img src="https://img-blog.csdnimg.cn/img_convert/cf87ee71357e6a873d064bf0bea812b6.png#pic_center" alt="用卷积来简化滑动窗口"><br>如上图所示，假如输入给卷积网络的图像大小为14×14×3，测试集图片是16×16×3。<br>现在给这个输入图片加上黄色条块（padding = 2），在最初的滑动窗口算法中，设置窗口大小为14×14，步长为2，可以滑出4个窗口，对应输入到卷积网络中，输出4个标签。 <strong>可以发现，这4次卷积操作中由很多像素点的计算都是重复的。</strong> 所以执行滑动窗口的卷积时使得卷积网络在这4次前向传播过程中共享很多计算。<br>如果我们使用如上的卷积方式的话，最后输出的4个方块，刚好就对应我们的4个窗口。如上面绿色的小框框，假设你剪切出这块区域（编号1），传递给卷积网络，第一层的激活值就是这块区域（编号2），最大池化后的下一层的激活值是这块区域（编号3），这块区域对应着后面几层输出的右上角方块（编号4，5，6）。<br><img src="https://img-blog.csdnimg.cn/img_convert/18e139d467f97830a238b06725a67f68.png#pic_center" alt="更复杂的例子"><br>但是正如在前一页所看到的，我们不能依靠连续的卷积操作来识别图片中的汽车，比如，我们可以对大小为28×28的整张图片进行卷积操作，一次得到所有预测值，如果足够幸运，神经网络便可以识别出汽车的位置。28×28的图像按照 图像14×14的来划定窗口，那么将有 64个窗口（行列均为8 8×8）所以最后输出的也是个 8×8。<br><strong>说白了这个办法，就是用卷积，将最后的输出每个格子表示当初划定的一个窗口。</strong><br>这个算法，效率是提高了，但是仍然存在一个缺点，就是边界框的位置可能不够准确。可以Bounding Box预测解决，详见下一章。<br><img src="https://img-blog.csdnimg.cn/img_convert/b16106fb0d740de6fffa3bd64dec09bc.png#pic_center" alt="识别是正确的，但是框和车的具体位置不符合哎"></p>
<h1 id="Bounding-Box预测（Bounding-box-predictions）"><a href="#Bounding-Box预测（Bounding-box-predictions）" class="headerlink" title="Bounding Box预测（Bounding box predictions）"></a>Bounding Box预测（Bounding box predictions）</h1><p>如何能精准边界框呢。比较出名的一个算法就是 Yolo 算法。Yolo 算法是这样的，简单的说就是 （如下图）比如你输入的图像是100×100的，然后在图像上放一个3×3网格（自己定应该更精细一点）。一共9个网格，每个网格都采取我们之前说的图像分类再定位的算法。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/15a1fb69f8ac47568bb742c1dfa7a7af.png#pic_center" alt="100×100 化为3×3网格"><br>对于9个格子中的每一个指定一个标签 $y$ ，$y$ 是8维的。$y=[p<em>{c},b</em>{x},b<em>{y},b</em>{h},b<em>{w},c</em>{1},c<em>{2},c</em>{3}]^{T}$。 看这个九宫格的第一个格子，里面没有检测的目标（也就是只有背景），所以左上格子的标签向量 $y=[0,?,?,?,?,?,?,?]^{T}$，同样右边的两个格子也是一样的。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/237ff5b5bf58e20651f7444ba194c017.png#pic_center" alt="取中点的格子"><br>再看第二层，有两辆车，也就是有2个对象。<strong>YOLO算法</strong>做的就是，取两个对象的中点，然后将这个对象分配给<strong>包含对象中点</strong>的格子。所以左边的汽车就分配到左边这个格子上（编号4），然后这辆长条车中点在这里，分配给右侧这个格子（编号6）。所以即使中心格子（编号5）同时有两辆车的一部分，我们就假装中心格子没有任何我们感兴趣的对象，所以对于中心格子，的输出标签向量 就是$y=[0,?,?,?,?,?,?,?]^{T}$。而左右编号为4和6的格子，输出标签向量均为$y=[1,b<em>{x},b</em>{y},b<em>{h},b</em>{w},0,1,0]^{T}$  由此得到，最后这张图片的目标输出为 3×3×8 （因为这里有3×3格子，然后对于每个格子，你都有一个8维向量，所以目标输出尺寸是3×3×8。） </p>
<h2 id="怎么得到框的精确位置呢？"><a href="#怎么得到框的精确位置呢？" class="headerlink" title="怎么得到框的精确位置呢？"></a>怎么得到框的精确位置呢？</h2><p>因为我们是将每个样本格子都作为考虑对象，所以每个格子的左上角均为（0，0），右下角为（1，1）。如下图所示，右侧长条车为栗子：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/7da7c4e5e6d9c2602b659e5db0342407.png#pic_center" alt="精确外框"><br>可以看到橙色为对象的中点处，而后$b<em>{x},b</em>{y},b<em>{h},b</em>{w}$单位是相对于格子尺寸的比例，所以$b<em>{x},b</em>{y}$必须在0和1之间；$b<em>{h},b</em>{w}$ 可能会大于1，特别是如果有一辆汽车的边界框是这样的（左下大红框），那么边界框的宽度和高度有可能大于1。</p>
<h1 id="交并比（Intersection-over-union）"><a href="#交并比（Intersection-over-union）" class="headerlink" title="交并比（Intersection over union）"></a>交并比（Intersection over union）</h1><p>业界都用交并比（IOU）来衡量 框框打的对不对。如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/e3544013b01c3b80ee75324e9967a629.png#pic_center" alt="IoU"></p>
<script type="math/tex; mode=display">IOU = \frac{∩ size}{∪size}</script><p>一般规定≥0.5即可，这个是人为定的，你也可以严格一点，选0.6及其以上。</p>
<h1 id="非极大值抑制（NMS）减少同一对象的-多个检测结果"><a href="#非极大值抑制（NMS）减少同一对象的-多个检测结果" class="headerlink" title="非极大值抑制（NMS）减少同一对象的 多个检测结果"></a>非极大值抑制（NMS）减少同一对象的 多个检测结果</h1><font color="blue">到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。</font>

<p><img src="https://img-blog.csdnimg.cn/img_convert/5ccaf433e145ea11d38bd12830c2d86d.png#pic_center" alt="多个检测结果"><br>非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6f0cc70b5cfd976204bc8e5d2d4c7b7c.png#pic_center" alt="图像分成19×19"></p>
<blockquote>
<p>就比如上面这个图。<br>在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。<br>实<strong>践中当你运行对象分类和定位算法时，对于每个格子都运行一次，所以这个格子（编号1）可能会认为这辆车中点应该在格子内部，这几个格子（编号2、3）也会这么认为。</strong>对于左边的车子也一样，所以不仅仅是这个格子，如果这是你们以前见过的图像，不仅这个格子（编号4）会认为它里面有车，也许这个格子（编号5）和这个格子（编号6）也会，也许其他格子也会这么认为，觉得它们格子内有车。</p>
</blockquote>
<p>我们分步介绍一下非极大抑制是怎么起效的，因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的 $p_{c}$ ，我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。所以当你运行算法的时候，最后可能会对同一个对象做出多次检测，所以非极大值抑制做的就是清理这些检测结果。这样一辆车只检测一次，而不是每辆车都触发多次检测。</p>
<p>所以具体上，这个算法做的是，首先看看每次报告每个检测结果相关的概率$p<em>{c}$，实际上$p</em>{c}$ 是 $p<em>{c}=1$ 乘以 $c</em>{1}、c<em>{2}$或 $c</em>{3}$得到的。首先看概率最大的那个，这个例子（右边车辆）中是0.9，然后就说这是最可靠的检测，所以我们就用<strong>高亮标记</strong>，就说我这里找到了一辆车。这么做之后，<strong>非极大值抑制就会逐一审视剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框，那么这些输出就会被抑制。</strong><br>因为其他两个矩形 $p_{c}$ 分别是0.6和0.7，这两个矩形和 0.9矩形重叠程度很高，所以会被抑制而变暗。<br>接下来，逐一审视剩下的矩形，找出概率最高，最高的一个，在这种情况下是0.8，我们就认为这里检测出一辆车（左边车辆），然后非极大值抑制算法就会去掉其他 loU 值很高的矩形。所以现在每个矩形都会被高亮显示或者变暗，如果你直接抛弃变暗的矩形，那就剩下高亮显示的那些，这就是最后得到的两个预测结果。</p>
<p>简单的说就是：先消除$p_{c} ≤ 0.6$的框，当多个检测框重叠面积IOU占据最大框面积的比例超过了这个设定的非最大值抑制这个值的时候，那么就只保留置信度（概率）最高的那个框，冗余的框都去掉。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ed191a6c686ba1c76835b774e6435eaa.png#pic_center" alt="NMS的操作"></p>
<h1 id="Anchor-Boxes"><a href="#Anchor-Boxes" class="headerlink" title="Anchor Boxes"></a>Anchor Boxes</h1><h2 id="为什么要使用-anchor-box"><a href="#为什么要使用-anchor-box" class="headerlink" title="为什么要使用 anchor box"></a>为什么要使用 anchor box</h2><p>到目前为止，对象检测中存在一个问题就是每个格子只能预测一个对象，如果想让一个格子检测出多个对象，你可以这么做，就是使用anchor box这个概念。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/69bf3aff7963180bba13f024ee328d30.png#pic_center" alt="同一个格子对象重叠"><br>假设我们有这样一张图片，对于这个例子，我们使用3x3的网格，可以观察到，行人和汽车的中心几乎在同一个网格，然而我们以前的方法一个格子只能预测一个对象，而且对于 y 输出的向量 $y=[p<em>{c},b</em>{x},b<em>{y},b</em>{h},b<em>{w},c</em>{1},c<em>{2},c</em>{3}]^{T}$ ，你可以检测这三个类别，行人、汽车和摩托车，它将无法输出检测结果，所以我必须从两个检测结果中选一个，这便影响了模型性能，导致一些对象被丢弃无法检测出来。</p>
<h2 id="anchor-box-的引入和使用"><a href="#anchor-box-的引入和使用" class="headerlink" title="anchor box 的引入和使用"></a>anchor box 的引入和使用</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/2efc6386311540659396db7cb148d63f.png#pic_center" alt="Anchor box"><br>我们按以下图片的方式，重新定义输出即可：（右边的话是因为 anchor box2 的IoU更高）<br><img src="https://img-blog.csdnimg.cn/img_convert/05633034404323320e005d2c553d8b99.png#pic_center" alt="anchor box 的使用"><br>所以，总的来说，anchor box是这么来做的，现在每个对象和以前一样根据中心点分配到一个格子中，然后看和每个anchor box的IoU（交并比），选择IoU最高的那个，用这个anchor box来进行预测。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/1355bdea1f0916386ef754d2ae81a28b.png#pic_center" alt=""></p>
<h2 id="如何选择-anchor-box？"><a href="#如何选择-anchor-box？" class="headerlink" title="如何选择 anchor box？"></a>如何选择 anchor box？</h2><ol>
<li>一般手工指定anchor box形状，根据要检测的对象，指定有针对性地anchor box，可选择5-10个anchor box，使其尽可能覆盖到不同形状。</li>
<li>使用K-means聚类算法获得anchor box。</li>
</ol>
<h1 id="anchor-box-NMS-的总过程"><a href="#anchor-box-NMS-的总过程" class="headerlink" title="anchor box + NMS 的总过程"></a>anchor box + NMS 的总过程</h1><p><img src="https://img-blog.csdnimg.cn/img_convert/00001fa607902111940cd50a61e2c0a6.png#pic_center" alt="步骤"></p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>无监督学习（Unsupervised Learning）之 聚类与降维</title>
    <url>/2021/08/19/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%88Unsupervised%20Learning%EF%BC%89%E4%B9%8B%20%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/</url>
    <content><![CDATA[<p>@<a href="无监督学习 Unsupervised  Learning">TOC</a></p>
<p><img src="https://img-blog.csdnimg.cn/9d69260c8d1442429d24ca7190dd4e5f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>总结 无监督学习 的要点：<br>1、无监督学习的概念</p>
<pre><code> - 什么叫无监督学习（输入都是无label的数据，没有训练集之说，也就是**只能从一些无label的数据中自己寻找规律**）
 - 无监督学习的两大任务：“化繁为简”（聚类、降维）、“无中生有”
</code></pre><p>2、聚类Clustering（K-means、HAC）<br>3、降维Dimension Reduction（PCA）</p>
</blockquote>
<h1 id="无监督学习的具体分类？"><a href="#无监督学习的具体分类？" class="headerlink" title="无监督学习的具体分类？"></a>无监督学习的具体分类？</h1><p><img src="https://img-blog.csdnimg.cn/a3a3f30810614f508add1fd431cb5047.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="无监督学习的分类"></p>
<ul>
<li>化繁为简：找一个函数，将本来复杂的输入，变成比较简单的输出。<strong>比如找一个函数，可以把所有的树都变成抽象的树</strong>。因此我们拥有一大堆各种不同的图像的数据，但不知它的 output 长什么样子。</li>
<li>无中生有：找一个函数，随机给它一个input（比如一个数字1），然后output一棵树，输入数字2，output另外一棵树，输入3，又是另外一棵树。<strong>输入一个随机数，就自动画一张图出来，不同的数画出来的图不一样</strong>。这个任务里面，要找的可以画图的函数，只有output没有input。只有一大堆的图像，但是不知道输入什么数字才可以得到这些图像。</li>
</ul>
<h2 id="化繁为简包括-聚类"><a href="#化繁为简包括-聚类" class="headerlink" title="化繁为简包括 聚类"></a>化繁为简包括 聚类</h2><p><img src="https://img-blog.csdnimg.cn/436d9bf4a5a94f78b4ed65378066bcec.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="K-means聚类"></p>
<blockquote>
<p><strong>Q：什么是 聚类？</strong></p>
<p><font color="red"><strong>假设做图像的聚类，现在有一大堆的图像，然后把它们分成各类</strong>。</font>如上图左边的图像都属于 簇1，右边的图像都属于 簇2，上方的图像都属于 簇3。<strong>这就像给图像贴标签，把类似的图像，都用同一个簇表示</strong>，就做到化繁为简这件事情。</p>
<p><strong>Q：聚类的注意点是什么？</strong><br> 是 这些数据到底有多少个簇！ 这和神经网络需要设计几层一样，是需要算法工程师的个人经验的。</p>
<p><font color="red"><strong>这个簇不能太多也不能太少。</strong> </font>比如多到说9张图像9个簇，那聚类就没有意义，直接每个图像一个簇就好了，或者说全部图像都是一个簇，也跟没有做一样。</p>
</blockquote>
<p>聚类方法最常用的就是K-means，有一大堆未标注数据 $x^{1}$ 到 $x^{n}$ ，每一个 $x$ 代表一张图像，做成 K 个簇。</p>
<h3 id="K-means聚类算法怎么做？"><a href="#K-means聚类算法怎么做？" class="headerlink" title="K-means聚类算法怎么做？"></a>K-means聚类算法怎么做？</h3><p>先找簇的中心，假如每一个对象都用一个向量表示，有 K 个簇就需要 $c^{1}$  到 $c^{K}$  个中心。可以从训练数据里<strong>随机找 K个对象出来作为初始化中心。</strong><br>而后对所有数据，决定属于哪一个簇。假设 $x^{n}$  和 $c^{i}$  最接近，那么 $x^{n}$ 就属于 $c^{i}$ ，用 $b_{n}^{i}$ 表示。然后更新簇，所有属于 $c^{i}$ 的数据做平均，就是第 $i$ 个簇新的中心，更新要反复进行。</p>
<blockquote>
<p><strong>Q：为什么 是从数据集中挑选 K 个样本做初始化 簇中心？</strong><br><strong>答</strong>：之所以从数据集挑选K个样本做初始化簇中心，有一个很重要的原因是，如果是纯粹随机的（不从数据集里挑），那很可能在第一次分配这个簇中心的时候，没有任何一个样本跟这个中心很像，也可以说这个簇没有任何样本，再次更新就会出错。</p>
</blockquote>
<p>K-means 用更简单的话来说：<br>其算法思想大致为：先从样本集中随机选取 K 个样本作为簇中心，并计算所有样本与这 K 个“簇中心”的距离，对于每一个样本，将其划分到与其距离最近的“簇中心”所在的簇中，对于新的簇计算各个簇的新的“簇中心”。循环反复。</p>
<blockquote>
<p><strong>Q：总结一下 K-means 算法的 主要流程</strong></p>
<ol>
<li>簇个数 K 的选择</li>
<li>初始化簇中心（可以从你的train data里面随机找K个x出来，就是你的k个center）</li>
<li>while（收敛——聚类结果不再变化）<br>　　{<br>　　　　 各个样本点到“簇中心”的距离 ；<br>  　　 根据新划分的簇，更新“簇中心”（求均值）;<br>　　}</li>
</ol>
</blockquote>
<h3 id="层次凝聚聚类算法（HAC）怎么做？"><a href="#层次凝聚聚类算法（HAC）怎么做？" class="headerlink" title="层次凝聚聚类算法（HAC）怎么做？"></a>层次凝聚聚类算法（HAC）怎么做？</h3><p>首先 我们要做一个树结构 （<strong>其过程 非常像 哈夫曼树的构造</strong>）<br><img src="https://img-blog.csdnimg.cn/463ed5f3dfb84f1bb525e37a39dfd42b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="HAC构建树"></p>
<p>假设有5个样本做层次聚类，先要做一个树结构。计算两两样本的相似度，挑出最相似的数据对。</p>
<p>比如第一个和第二个样本最相似，那就合并（比如用平均值代表），5个样本变为4个样本；再计算相似度，配对的是4，5样本，然后把他们合并（平均值），变成3个样本；接着计算相似度，配对的是黄色数据点和剩下的蓝色数据点，再次合并（平均），最后只剩红色和绿色，那么最后平均起来得到root。根据5笔数和之间的相似度，就建立出了一个树结构。</p>
<p><strong>但树结构只是告诉我们说哪些样本比较像，还没有做聚类。</strong></p>
<blockquote>
<p><strong>Q：那怎么做聚类呢？或者说我怎么看我分的那几个聚类？</strong><br><strong>答</strong>： 看你怎么切，如图上面不同颜色的切线。</p>
<ul>
<li>比如在上图蓝线初切一刀，意味着把数据分成3簇，1、2为一簇，3单独为一簇，4、5为一簇。</li>
<li>在红色线切一刀，则1、2、3为一簇，4、5为一簇。</li>
<li>在绿色点切一刀，则1、2为一簇，3、 4、 5单独为一簇。</li>
</ul>
<p><strong>Q：层次聚类 和 K-means的差别？</strong></p>
<ul>
<li>在K-means里要自己决定K的值，也就是你要分多少个簇。<ul>
<li>在层次聚类里要决定的是在哪里切一刀，如果切比较容易考虑的话，那层次聚类可能更好。</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="化繁为简包括-降维"><a href="#化繁为简包括-降维" class="headerlink" title="化繁为简包括 降维"></a>化繁为简包括 降维</h2><blockquote>
<p><strong>Q：什么是降维？</strong><br><strong>答</strong>：降维意思是说，原本高维的东西，其实是可以用低维去表示它。就是找出数据里最主要的方面，用数据里最主要的方面来代替原始数据。换句话说，可以减少数据的维度。就是 </p>
<script type="math/tex; mode=display">z = Wx</script><p><img src="https://img-blog.csdnimg.cn/0f4adf004785425fa8e753ffc1e8c025.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>Q：为什么降维有用？</strong><br><strong>答</strong>：假设数据分布如上图左边，在3D空间里分布是螺旋的样子，但是用3D描述数据分布比较浪费的，直觉上也可以感觉可以摊开变成右边2D的样子，只需要2D的空间就可以描述3D的信息。在3D空间里面解比较麻烦，那就在2D里做这个任务。<br>考虑一个实际的简单栗子：<br>每一个input的数字都是28 × 28的矩阵来描述。但是实际上，多数28 × 28矩阵转成一个图像看起来都不像数字，在28 × 28空间里是数字的矩阵是很少的。所以要描述一个数字，或许不需要用到28 × 28维，远比28 × 28维少。<br><img src="https://img-blog.csdnimg.cn/1d2cd0f03fb540a886301947ef7bef60.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>所以举一个极端的例子，有一堆3，从像素点看要用28 × 28维来描述每张图像。实际上，只要用一个维度就可以表示，中间的是3，其他的3都是中间的3左转右转10、 20度。所以唯一需要记录的就是中间的3，左转和右转了多少度，即只需要角度的变化，就可以知道28维空间中的变化。</p>
<p><strong>Q：怎么做降维？</strong><br><strong>答</strong>：找一个函数，input是一个向量x，output是另外一个向量z（z的维度比x小）。</p>
<ul>
<li><p>在降维里最简单的方法是特征选择，把数据的分布拿出来看一下，    如在二维平面上发现数据集中在 $x$ 维度，所以 $y$ 这个维度没什么用，那么就把他拿掉，等于是降维这件事。<strong>特征选择不一定有用，有可能case里面任何一个维度都不能拿掉。</strong></p>
</li>
<li><p>另一个常见的方法是<strong>PCA</strong>，函数是一个很简单的线性函数，input x和output z之间的关系就是一个线性的transform，即 $x$ 乘上一个矩阵 $W$ 得到 $z$ 。现在不知道  $z$ 长什么样子，要根据一大堆的 $x$ 把 $W$ 找出来。</p>
</li>
</ul>
</blockquote>
<h3 id="分布式表示（Distributed-Representation）"><a href="#分布式表示（Distributed-Representation）" class="headerlink" title="分布式表示（Distributed Representation）"></a>分布式表示（Distributed Representation）</h3><blockquote>
<p><strong>Q：光做聚类的话是非常以偏概全的。为什么呢？</strong><br><strong>答</strong>：因为在聚类思想中，每个样本都必须属于某一个簇。就好像念力分成6大类，每个人都会被分配到6个大类其中一类。但这样分配太过粗糙，比如某个人的能力既有强化系的特性又有放出系的特性，只分为一类就会丢失很多信息。<img src="https://img-blog.csdnimg.cn/1ee8b3f2f1754e63bdc4826eba1aa3dc.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<font color="red">**只分为一类就是以偏概全了，应该要用一个向量来表示每个对象，向量的每个维度代表了某一种特质（属性）。这件事情叫做Distributed Representation**。</font> 比如上图所示，这个人每个系都可以有固定的能力占比。

<font color="green">如果对象是一个高维的东西，例如图像，现在用它的特性来表示，就会把它从高维空间变成低维空间，这件事情叫做降维。</font> Distributed Representation和**降维**是一样的东西，不同的称呼。


### 主成分分析（PCA）
函数是一个很简单的线性函数，input x和output z之间的关系就是一个线性的transform，即 $x$ 乘上一个矩阵 $W$ 得到 $z$ 。现在不知道  $z$ 长什么样子，要根据一大堆的 $x$ 把 $W$ 找出来。

PCA的实现一般有两种：
 - 一种是用特征值分解去实现的
 - 一种是用奇异值分解去实现的

#### PCA-用特征值分解实现
![在这里插入图片描述](https://img-blog.csdnimg.cn/3acdbf6ffca44f85b12bb6a0719ae8c9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
刚才讲过PCA要做的事是找 $W$ ，假设一个比较简单的case，考虑一个维度的case。假设要把我们的数据投射到一维空间上，即 $z$ 只是一维的向量。 $w^{1}$ 是W的第一行，和 $x$ （列向量）做内积得到一个标量 $z_{1}$ 。

> **Q：$w^{1}$应该长什么样子？**
> 首先假设 $w^{1}$ 的长度是1，即 $||w^{1}||_{2}=1$ 。如果$||w^{1}||_{2}=1$，$w^{1}$ 是高维空间中的一个向量，那么 $z_{1}$ 就是就是 $x$ 在 $w^{1}$ 上的投影长度。现在要求出每一个 $x$ 在 $w^{1}$ 上的投影，那 $w^{1}$ 应该长什么样子？
举个例子，假设上图右上方是 $x$ 的分布，$x$ 都是二维的，每个点代表一只宝可梦，横坐标是攻击力，纵坐标是防御力。<font color="blue">现在要把二维投影到一维，应该要选什么样的 $w^{1}$ ?</font>  可以选 $w^{1}$ 为上图右上方右斜方向，也可以选左斜方向，**选不同的方向，最后得到的投影的结果会不一样**。

那总要给我们一个目标，我们才知道要选什么样的 $w^{1}$ ，现在目标是经过投影后得到的 $z_{1}$ 的分布越大越好。我们不希望投影后所有的点都挤在一起，把本来数据点之间的奇异度消去。我们希望投影后，数据点之间的区别仍然看得出来，那么我们可以找投影后方差越大的那个 $w^{1}$ 。

看上面的例子，如果是右斜方向，那么方差较大，左斜方向方差则较小，所以更可能选择右斜方向作为 $w^{1}$ 。

从上面的例子里看， $w^{1}$ 代表了宝可梦的强度，宝可梦可能有一个隐藏的向量代表它的强度，这个隐藏的向量同时影响了防御力和攻击力，所以防御力和攻击力会同时上升。
![在这里插入图片描述](https://img-blog.csdnimg.cn/dd45a73b7b0640d1bbb675b9132e5044.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
开始计算：
　　　　1、把方差式子展开，转化成协方差（具体转化过程不描述了）
　　　　2、<font color="red">结论：我们要找的 $w^{1}$ 就是协方差矩阵 $S$ 的最大特征值所对应的特征向量， $w^{2}$ 就是协方差矩阵 $S$ 的第二大特征值所对应的特征向量，以此类推 .</font>

<h4 id="PCA-用奇异值分解（SVD）"><a href="#PCA-用奇异值分解（SVD）" class="headerlink" title="PCA - 用奇异值分解（SVD）"></a>PCA - 用奇异值分解（SVD）</h4><p>特征值分解是一个提取矩阵特征很不错的方法，但是<strong>特征值分解只是对方阵而言的</strong>，在现实的世界中，我们看到的<strong>大部分矩阵都不是方阵</strong>。奇异值分解是一个能适用于任意的矩阵的一种分解的方法。<br><img src="https://img-blog.csdnimg.cn/31679a1b2ba54844b2799661d9c1ff6c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>假设现在考虑手写数字识别，我们知道手写数字其实是由一些基本成分组成的，这些基本成分可能是笔画。例如斜的直线，横的直线，比较长的直线，小圈、大圈等等，这些基本成分加起来以后得到一个数字。</p>
<p>基本成分我们写作 $u^{1},u^{2},u^{3}…$，这些基本的成分其实就是一个一个的向量。考虑 MNIST数据集 ，一张图像是28 × 28像素，就是28 × 28维的向量。基本成分其实也是28 × 28维的向量，把这些基本成分向量加起来，得到的向量就代表了一个数字。</p>
<p>如果写成公式的话，就如上图最下方所示的公式。$x$ 代表某一张图像的像素，用向量表示。$x$ 会等于 $u^{1}$ 这个成分乘上 $c<em>{1}$ ，加上 $u^{2}$ 这个成分乘上 $c</em>{2}$，一直加到 $u^{K}$ 这个成分乘上$c_{K}$，再加上 $\bar{x}$（$\bar{x}$ 是所有图像的平均）。所以每一张图像，就是一堆成分的线性组合加上所有图像的平均所组成的。</p>
<p>例如数字7是 $u^{1},u^{3},u^{5}$ 加起来的结果，那么对数字7来说，公式里的 $c<em>{1}=1 ,c</em>{2}=0, c<em>{3}=1…$，所以可以用  $c</em>{1},c<em>{2},c</em>{3}…,c<em>{K}$ 来表示一张图像，如果成分远比像素维度小的话，那么用$\begin{bmatrix}<br>c</em>{1}\<br>c<em>{2}\<br>…\<br>c</em>{K}\<br>\end{bmatrix}$表示一张图片是会比较有效的比如7可以由向量 $\begin{bmatrix}<br>1\<br>0\<br>1\<br>0\<br>1\<br>…\<br>\end{bmatrix}$ 描述。</p>
<p><img src="https://img-blog.csdnimg.cn/dc78fa3c54bc4b2f94be1efcc5bdf034.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们把公式里的 $\bar{x}$ 移到左边，$x$ 减 $\bar{x}$ 等于一堆成分的线性组合，写作 $\hat{x}$  。</p>
<blockquote>
<p><strong>Q：如果我们不知道K个u（成分）是什么，那怎么找出这K个向量？</strong> 找K个u，让$x−\bar{x}$ 和 $\hat{x}$  越接近越好，$||(x-\bar{x})-\hat{x}||<em>{2}$ 称为重构误差，代表没办法用成分描述的部分。接下来，最小化 $||(x-\bar{x})-\hat{x}||</em>{2}$，损失函数如上图 $L$。</p>
<p>回忆下PCA，$w<em>{1},w</em>{2},w<em>{3}…w</em>{K}$ 是 $x$ 协方差矩阵的特征向量，事实上 $L$ 的解就是PCA的 $w<em>{1},w</em>{2},w<em>{3}…w</em>{K}$。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/cf51702d73ef4fa3ac7f2dd6c47ec6d6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="PCA实例"><a href="#PCA实例" class="headerlink" title="PCA实例"></a>PCA实例</h1><h2 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h2><p><img src="https://img-blog.csdnimg.cn/9581a527b4a0468f97458d5954e6bb89.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>以把每一张数字图像拆成成分的线性组合，每一个成分也是一张图像（28 × 28 维的向量），所以可以把成分画在图上变成一张图像。</p>
<font color="blue">通过PCA画出前30个成分如上图所示，白色的地方代表有笔画。用这些成分做线性组合，就可以得到0-9的数字，所以这些成分叫做Eigen-digit。</font> 
Eigen（本征）是说，这些成分都是协方差矩阵的特征向量。

## 人脸识别
![在这里插入图片描述](https://img-blog.csdnimg.cn/9e97b877a5114592ac90e2b7f5f3c0f6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
上图右上方有一大堆人脸，找它们前30个主成分。找出来就如上图最下方所示，每张图像都是哀怨的脸，叫做Eigen-face。把这些脸做线性组合，就可以得到所有的脸。


> **Q：但这边有没有觉得有问题，因为主成分找出来的是成分，但是现在找出来的几乎都是完整的脸，也不像是成分啊？像前面的数字识别，成分看起来也像是玛雅文字，而不是笔画，看起来也不是成分啊？**
![在这里插入图片描述](https://img-blog.csdnimg.cn/1215e23adb994fd6b8380a73b1e64527.png#pic_center)> **答**：仔细想想PCA的特性，$α_{1},α_{2}$ 这种权重可以是任何值，可以是正的，也可以是负的。所以当我们用这些主成分组成一张图像的时候，<font color="blue">可以把这些成分相加，也可以把这些成分相减，这就会导致你找出的东西不见得是一个图的基本的结构。</font>> > 比如我画一个9，那可以先画一个8，然后把下面的圆圈减掉，再把一杠加上去。我们不一定是把成分加起来，也可以相减，<font color="blue">所以说就可以先画一个很复杂的图，然后再把多余的东西减掉。这些成分不见得就是类似笔画的这种东西。</font>
> 
> 如果要得到类似笔画的东西，就要用另一个技术*NMF（非负矩阵分解）*。PCA可以看成是对矩阵X做SVD，SVD就是一种矩阵分解的技术。**如果使用NMF，就会强迫所有成分的权重都是正的，正的好处就是一张图像必须由成分叠加得到，不能说先画一个复杂的东西再去掉一部分，再来就是所有成分的每个维度都必须是正的。**


所以在同样的任务上，例如手写数字的测试上，使用NMF时，找出来的主成分会如下图所示。
![在这里插入图片描述](https://img-blog.csdnimg.cn/ac0fc298e03847819527bc49a3198b45.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
你会发现，白色图案类似于笔画，找出来的主成分就成了笔画了。
![在这里插入图片描述](https://img-blog.csdnimg.cn/36c61755d6ce40318f4df22c47721ab5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
看脸的话，会发现如上图所示。比较像脸的一部分，比如人中、眉毛、嘴唇、下巴。

## 宝可梦
![在这里插入图片描述](https://img-blog.csdnimg.cn/c19d6fca60984ad6a435fd0750f485fa.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
有800种宝可梦，每种宝可梦可以用6个特征来表示。所以每个宝可梦就是6维的数据点，6维向量。

现在用PCA来分析，PCA里常有的问题是到底需要几个成分，即到底要把数据降到几维。这个一般取决于你的目的是什么，比如你想做可视化，分析宝可梦特性之间的关系，6维没办法可视化的，那就投影到二维。要用几个主成分就好像是神经网络需要几层，每层几个神经元一样。

一个常见决定使用几个主成分的方法是，去计算每个主成分（特征向量）对应的特征值，这个特征值代表在该主成分上投影数据的方差。

现在的例子里宝可梦是6维的，那就有6 × 6维的协方差矩阵，所以有6个特征值，如上图计算每个特征值比例，结果是0.45，0.18，0.13，0.12，0.07，0.04。那第5、6个主成分的作用比较小，意味着投影数据的方差很小，宝可梦的特性在这两个主成分上信息很少。那么分析宝可梦特性只需要前4个主成分。
![在这里插入图片描述](https://img-blog.csdnimg.cn/8fcb23f86b76476e9b66585379b04cbb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

PCA后选择4个主成分，每个主成分是一个6维向量（因为原来每个特征都要投影，那就有6种投影数据）。

每个宝可梦可以想成是4主成分向量做线性组合的结果，且每只宝可梦组合的权重不同。

看第一个主成分PC1，数值都是正的，如果给它的权重大，意味着宝可梦6维都是强的，给它的权重小，意味着宝可梦6维都是弱的，所以第一个主成分，代表了这只宝可梦的强度。

看第二个主成分PC2，Def防御力是正值，速度是负值，那么增加权重的时候，会增加防御力并减小速度。

把第一个和第二个主成分画出来如上图最下方，图上有800个点，每个点代表一只宝可梦。
![在这里插入图片描述](https://img-blog.csdnimg.cn/995d8f5d622b4b3691e432d0e2554a0e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
第三个主成分PC3，特殊防御力是正的，攻击力和HP都是负的，也就是说这是用攻击力和HP来换取特殊防御力的宝可梦。

第四个主成分PC4，HP是正的，攻击力和防御力是负的，这是用攻击力和防御力换取生命值的宝可梦。

把第三、第四主成分画出来如上图最下方，维度是去相关的。


## 矩阵分解-推荐系统
有时候，你会有两种东西，两种对象，它们之间受到某种共通的潜在因素操控。
假设现在做一个调查，调查每个人手上买的公仔的数目，有5个宅男同学A,B,C,D,E，横轴的公仔人物是凉宫春日、御坂美琴、小野寺、小唯，调查结果如下图。
![在这里插入图片描述](https://img-blog.csdnimg.cn/7557d3f48de34c97be70ec2ca4212e74.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
看这个矩阵可以发现，买凉宫春日的人，比较有可能有御坂美琴；买小野寺的人，也比较有可能买小唯。这说明人和公仔有一些共同的特性，有共同的因素在操控这些事情发生。

动漫宅获取可以分成两种，一种是萌傲娇的，一种萌天然呆的。每个人都是萌傲娇和萌天然呆平面上的一个点，可以用一个向量表示，那么看上图，A是偏萌傲娇。每一个公仔角色，可能有傲娇属性或者天然呆属性，所以每一个角色，也是平面上一个点，可以用一个向量描述。

如果某个人的属性和角色的属性匹配的话，他们背后的向量就很像（比如做内积的时候值很大），那么A就会买很多的凉宫春日。他们匹配的程度取决于潜在因素是不是匹配的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/d5f8553af83f4034bbcff5b07c95251a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)


所以ABC的属性如上图最左边所示，A、B是萌傲娇的，B稍微没有那么傲娇，C是萌天然呆。每个动漫角色后面也有傲娇、天然呆这两种属性，如果人物属性和角色属性匹配的话，人买角色的可能性就很大。
![在这里插入图片描述](https://img-blog.csdnimg.cn/006698ec686f439ea7e5161e55e7213f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
上图中右下方矩阵公式中，右边两个矩阵的N应该是M，代表M个人。
我们知道的只有人买的角色的数目，然后凭着这种关系去推论每个人和每个动漫人物背后的潜在因素。每个人背后都有一个向量，代表萌傲娇或者萌天然呆的程度。每个角色后面也有一个序列，代表是傲娇或天然呆的属性。

我们可以把购买的公仔数量合起来看做是一个矩阵X ，行数是人的数量，列数是公仔角色的数量。

现在有一个假设，矩阵X里的每个元素都来自于两个向量的内积。为什么A会有5个凉宫春日的公仔，是因为 $r^{A}·r^{1}$ 的内积很大，约等于5。这件事情用数学公式表达的话，可以把 $r^{A}$ 到 $r^{M}$ 按列排起来，把 $r^{1}$ 到 $r^{4}$ 按行排起来，<font color="red">K是潜在因素的个数，一般没办法知道，需要自己测试出来。</font>

<blockquote>
<p><strong>Q：矩阵X的每个维度是什么？</strong><br>我们要做的事情就是找一组rA到rE，找一组r1到r4 ，让两个矩阵相乘后和矩阵X越接近越好，就是最小化重构误差。这个就可以用SVD来解，把Σ并到左边或右边变成两个矩阵就可以了。<br><img src="https://img-blog.csdnimg.cn/b2a2e51b938840b49fad8bcf3521f71b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>有时候有些信息是缺失的，比如上图所示的，你不知道A、B、C手上有没有小野寺，可能在那个地区没有发行，所以不知道发行的话到底会不会买。那用SVD就很怪，也可以把缺失值用0代替，但也很奇怪。</p>
<p>Q：那有缺失值怎么办呢？<br>可以用梯度下降的方法来做，写一个损失函数，让$r^{i}$（每个人背后的潜在因素）和$r^{j}$（角色背后的潜在因素）的内积和角色购买数量越接近越好。现在重点是，在<br>summation over<br>元素的时候，可以避开缺失的数据，如果值是缺失的，就不计算。有了损失函数后，就可以使用梯度下降了。<img src="https://img-blog.csdnimg.cn/7da15f3364a64482b6e8a8ed3d751acb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>根据刚才的方法实际计算一下，假设潜在因素的数量是2。那么A到E都是二维的向量，每个角色也是二维的向量。<br>数值代表了属性的程度，把大的用红色框框圈出来，会发现A、B萌同一组属性，C、D、E萌同一种属性，1,2有同样的属性，3,4有同样的属性。没有办法知道每个属性代表什么，要先找出这些潜在因素，再去分析它的结果。有了这些潜在因素数据，就可以用来预测缺失值。已经知道了$r^{A}$和$r^{3}$，那只要$r^{A}$和$r^{3}$做内积就可以了。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/d1cb16fb971b456ebe4b9e64b666e212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>之前的model可以做得更精致一点，刚才说A背后的潜在因素乘上 春日 背后的潜在因素，得到的结果就是矩阵里的数值。但是事实上，可能还会有其他因素操控这些数值。<br>那么更精确的写法就可以写成。</p>
<script type="math/tex; mode=display">r^{A}⋅r^{1}+b_{A}+b_{1}≈5</script><p>$b<em>{A}$是跟 $A$ 有关的标量，代表了 $A$ 有多喜欢买公仔，有的人就是喜欢买公仔，也不是喜欢某个角色。$b</em>{1}$是跟 春日 有关的标量，代表了角色有多想让人购买，这个事情是跟属性无关的，本来人就会买这个角色。</p>
<p>然后修改损失函数如上图所示，使用梯度下降求解即可。</p>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>李宏毅</tag>
        <tag>无监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>同济子豪兄 之 yolov2 详解</title>
    <url>/2021/10/08/%E5%90%8C%E6%B5%8E%E5%AD%90%E8%B1%AA%E5%85%84%20%E4%B9%8B%20yolov2%20%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>@<a href="同济子豪兄 之 yolov2 详解">TOC</a></p>
<font color="blue">蓝色： 表示还不明白什么意思</font> 

<p>v1存在 一些性能和原理上的问题：</p>
<ol>
<li>mAP相比 R-CNN 系列比较低</li>
<li>定位性能比较差，定位错误占总错误的比例很大</li>
<li>Recall比较低，就是把全部目标全部检测出来的能力比较差</li>
<li>检测密集和小目标的能力比较差</li>
</ol>
<p>这篇文章其实主要有两个模型，即Yolov2 和 Yolo9000. 9000这个只是一个想法，不太实用。<br>Yolov2 是在此基础上做了很多的 tricks，作者分别归为了三个类，分别是Better（更准确），Faster（更快的），Stronger（类别更多的）。其中Stronger这块 作者说他可以预测9000种，但其实效果不好的，他只是提供一个想法。我们的重点在 前面的Better（更准确）和Faster（更快）（换用了Darknet-19网络）上。</p>
<blockquote>
<p>总结来看，虽然YOLOv2做的改进，基本都是借鉴其它论文的一些tricks，比如Faster R-CNN的anchor box，YOLOv2采用anchor box和卷积做预测，这基本上与SSD模型（单尺度特征图的SSD）非常类似了，而且SSD也是借鉴了Faster R-CNN的RPN网络。<br>从某种意义上来说，YOLOv2和SSD这两个one-stage模型与RPN网络本质上无异，<strong>只不过RPN不做类别的预测，只是简单地区分物体与背景</strong>。在two-stage方法中，RPN起到的作用是给出region proposals，其实就是作出粗糙的检测，所以另外增加了一个stage，即采用R-CNN网络来进一步提升检测的准确度（包括给出类别预测）。<br>而对于one-stage方法，它们想要一步到位，直接采用“RPN”网络作出精确的预测，要因此要在网络设计上做很多的tricks。<br>YOLOv2的一大创新是采用Multi-Scale Training策略，这样同一个模型其实就可以适应多种大小的图片了。</p>
</blockquote>
<p>提问：他的模型是 首先是个分类模型（带 global average pooling）可以实现输入多维尺度 这个网络不是用来检测的<br>但他又调整 这个网络，去掉了GAP 然后加了3个卷积 和 passthrough 来做检测 ？？== 那我之前分类的意义在哪？ </p>
<font color="red">答：它相当于就是分类对模型做了个预训练，先大致确定好参数。然后再去检测训练的时候fine-tune，可以加快训练的速度，并且提升实际效果（实际上这个就是有用，但不知道为什么有用呢）</font>


<h1 id="Better（更准确）"><a href="#Better（更准确）" class="headerlink" title="Better（更准确）"></a>Better（更准确）</h1><p>作者为使yolo的精度更高，使用了很多个tricks。包括<br><strong>Batch Normalization</strong>、High Resolution Classifer、<strong>Anchor</strong>、Dimension Cluster、Direct location prediction、Fine-Graind Features、Muti-Scale Training</p>
<h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>Batch Normalization可以提升模型收敛速度，而且可以起到一定正则化效果，降低模型的过拟合。在YOLOv2中，每个卷积层后面都添加了Batch Normalization层，并且不再使用droput。使用Batch Normalization后，YOLOv2的mAP提升了2.4%。</p>
<blockquote>
<p>Batch Normalization 的详细内容请看<br><a href="https://jks88995656.github.io/2021/10/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%20-%20Batch%20Normalization/">一只柴犬 深度学习基础 - Batch Normalization </a></p>
</blockquote>
<h2 id="High-Resolution-Classifier"><a href="#High-Resolution-Classifier" class="headerlink" title="High Resolution Classifier"></a>High Resolution Classifier</h2><p>目前大部分的检测模型都会在先在ImageNet分类数据集上预训练模型的主体部分（CNN特征提取器），由于历史原因，ImageNet分类模型基本采用大小为 224×224 的图片作为输入，分辨率相对较低，不利于检测模型。</p>
<p>  Yolov1中 </p>
<ul>
<li>所以 YOLOv1 在采用 224×224 分类模型预训练后，将分辨率增加至448×448，并使用这个高分辨率在检测数据集上finetune。<strong>但是直接切换分辨率，检测模型可能难以快速适应高分辨率。</strong></li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/803c6a4d557bf242831be696587816d0.png#pic_center" alt="Yolov1中作者模型训练和测试 输入图片大小情况"></p>
<p> Yolov2中</p>
<ul>
<li><strong>YOLOv2增加了在ImageNet数据集上使用 448×448 输入来finetune分类网络这一中间过程（10 epochs）</strong>（也就是他先是224×224 分辨率训练了一会，再用 448×448<br>分辨率上训练了10个epoch，），这可以使得模型在检测数据集上finetune之前已经适用高分辨率输入。使用高分辨率分类器后，YOLOv2的mAP提升了约4%。</li>
</ul>
<h2 id="Convolutional-With-Anchor-Boxes"><a href="#Convolutional-With-Anchor-Boxes" class="headerlink" title="Convolutional With Anchor Boxes"></a>Convolutional With Anchor Boxes</h2><p>  Yolov1中</p>
<ul>
<li>在YOLOv1中，输入图片最终被划分为 7×7 个 grid cell，每个grid cell预测2个边界框（bounding box）。YOLOv1最后采用的是全连接层直接对边界框进行预测，其中边界框的宽与高是相对整张图片大小的，而由于各个图片中<strong>存在不同尺度和长宽比（scales and ratios）的物体</strong>，YOLOv1在训练过程中学习适应不同物体的形状是比较困难的，这也导致YOLOv1在<strong>精确定位方面表现较差</strong>。In another word, v1中并没有对框和对象的关系做匹配，也就是我的框可能都是长的或者都是宽的没个标准，这样匹配起来就比较麻烦。另外Yolov1 左上角的bounding box 有可能预测在右下角，这就导致了训练起来非常不稳定，需要加以限制。<br><img src="https://img-blog.csdnimg.cn/img_convert/4059677c62015c45885ecfff1025240b.png" alt="v1中的bounding box 野蛮生长"><br>比如上图所示，长的那个符合人这个物体，但对车就不太符合了。</li>
<li>对于YOLOv1，每个grid cell都预测2个 bounding box，每个box包含5个值： (中心点横坐标，中心店纵坐标，框宽度，框高度，置信度)，最后一个置信度（confidence scores，包含两部分：含有物体的概率以及预测框与ground truth的IOU）。<strong>但是每个cell只预测一套分类概率值（class predictions，其实是置信度下的条件概率值）,供2个boxes共享。</strong></li>
</ul>
<p> Yolov2</p>
<ul>
<li>v2中引入了先验参考框这个概念。（其实可以理解为一个公共的模板bounding box集合，生成的bounding box 都是这个集合里的）所有的预测框其实都是 先验参考框的<strong>偏移</strong>。每个anchor都对应一个预测框，每个预测框只要 预测出 其相对于Anchor的偏移量。例如下图所示，就是5个先验参考框：<br><img src="https://img-blog.csdnimg.cn/img_convert/0152b5d1eba3e64713e8bf34f771fc17.png#pic_center" alt="5个先验参考框（anchor box）"></li>
<li><p>所以<strong>YOLOv2移除了YOLOv1中的全连接层而采用了卷积和anchor boxes来预测边界框(bounding box)</strong>。为了使检测所用的特征图分辨率更高，<strong>移除</strong>其中的一个<strong>pool层</strong>。在检测模型中，YOLOv2不是采用 448×448 图片作为输入，而是采用 <strong>416×416 大小</strong>。因为YOLOv2模型下采样的总步长为 32，对于 416×416 大小的图片，<font color="red">最终得到的特征图大小为 13×13 ，维度是<strong>奇数</strong></font>，这样特征图恰好只有一个中心位置。对于一些大物体，它们中心点往往落入图片中心位置，此时使用特征图的一个中心点去预测这些物体的边界框相对容易些。<strong>所以在YOLOv2设计中要保证最终的特征图有奇数个位置。</strong><br><img src="https://img-blog.csdnimg.cn/img_convert/6b72bf553115ff5febd1abb903f7d010.png#pic_center" alt="使用anchor box 假如为2（因为其实就2类物体）"></p>
</li>
<li><p>YOLOv2使用了anchor box之后，每个位置的各个anchor box都单独预测一套分类概率值，这和SSD比较类似（但SSD没有预测置信度，而是把background作为一个类别来处理）。</p>
</li>
<li>在YOLOv2中，<strong>每个grid cell 预测 5个bounding box</strong> （也就是对应的 5个anchor box）。为什么选5呢后面会说（用的聚类）。所以网络结构输出的特征结果 变为了 <strong>13×13×（5+20）× 5  = 13×13×125</strong> ，不是一个grid cell 的bounding box 共享一套分类概率值（条件概率），现在是每个bounding box 都要有自己单独的一套。如下图所示：<br><img src="https://img-blog.csdnimg.cn/img_convert/a56fa6771fcd8496670697f9005ee125.png" alt="v1与v2特征输出的区别"></li>
</ul>
<h3 id="anchor-box-在v2的效果"><a href="#anchor-box-在v2的效果" class="headerlink" title="anchor box 在v2的效果"></a>anchor box 在v2的效果</h3><p>使用anchor boxes之后，<strong>YOLOv2的mAP有稍微下降</strong>（这里下降的原因，有博主猜想是YOLOv2虽然使用了anchor boxes，但是依然采用YOLOv1的训练方法）。YOLOv1只能预测98个边界框（ 7×7×2 ），而YOLOv2使用anchor box之后可以预测更多个边界框（ 13×13×5 ）。所以使用anchor box之后，<strong>YOLOv2的召回率recall大大提升，由原来的81%升至88%</strong>。也就是说yolo检测出物体的能力更强了，但准确性下降了一些。</p>
<h2 id="Dimension-Clusters"><a href="#Dimension-Clusters" class="headerlink" title="Dimension Clusters"></a>Dimension Clusters</h2><p> 在Faster R-CNN和SSD中，先验框的维度（长和宽）都是<strong>手动设定</strong>的，带有一定的主观性。如果选取的先验框维度比较合适，那么模型更容易学习，从而做出更好的预测。</p>
<font color="red">这里的这个功能就是 为了选取 对于所训练的数据集，我选择anchor box 为几个？ 才能最好的效果。</font>

<blockquote>
<p>那这里 总结一下 v2为什么选择 anchor box =5 呢？<br>答：<strong>所谓的anchor box 的数量 说白了 就是 你的数据集到底有多少个类</strong>，把物体对象框大小差不多的归为一类。<br>v2 采用 的是k-means聚类方法（我们用这个方法确定了<strong>anchor的数量以及长宽比</strong>）对训练集中的边界框标签做了聚类分析。因为设置先验框的主要目的是为了使得预测框与ground truth的IOU更好，所以聚类分析时选用box与聚类中心box之间的IOU值作为距离指标：</p>
<script type="math/tex; mode=display">d(box,centroid) = 1 - IoU(box,centroid)</script><font color="green">IoU这部分表示数据集中的某个ground truth框和他所在的聚类中心框的IoU  这个越大说明我的聚类中心选的越好（接近于1 刚好把所有样本分散的好）</font>
在**VOC 2007 和COCO数据集上的聚类分析结果**，随着聚类中心数目的增加，平均IOU值（各个边界框与聚类中心的IOU的平均值）是增加的，但是综合考虑模型复杂度和召回率，作者最终选取**5个聚类中心作为先验框** (也就是 anchor box = 5)
但是这里先验框的大小具体指什么作者并没有说明，但肯定不是像素点，从代码实现上看，应该是相对于预测的特征图大小（ 13×13）。对比两个数据集，也可以看到COCO数据集上的物体相对小点。这个策略作者并没有单独做实验，但是作者对比了采用聚类分析得到的先验框与手动设置的先验框在平均IOU上的差异，发现前者的平均IOU值更高，因此模型更容易训练学习。 
![数据集VOC和COCO上的边界框聚类分析结果  右侧中 黑框是voc2007 的 长宽比聚类  蓝色的是 coco 的长宽比聚类](https://img-blog.csdnimg.cn/img_convert/5f91f5d74220601c5e3f6d7cb34b81c1.png#pic_center)
注：anchor 的长宽比才有意义，至于图上所示，其位置在哪无所谓，其位置没有任何的意义（这里作者调整过了，怕叠在一起不好看）
<font color="blue">聚类中心怎么看的呢？这边的先验框大小到底是什么意思呢？</font>




</blockquote>
<h2 id="Direct-location-prediction-直接位置预测"><a href="#Direct-location-prediction-直接位置预测" class="headerlink" title="Direct location prediction 直接位置预测"></a>Direct location prediction 直接位置预测</h2><font color="green">Direct location prediction 可以解决v1中bounding box 乱窜野蛮生长的问题（比如：左上角的grid cell 的bounding box 在右下角 偏移量有点大。。）</font>
<font color="red">**已知 YOLOv2借鉴RPN网络使用anchor box来预测边界框bounding box相对先验框anchor box的偏移量offsets。**</font> 
预测边界框 bounding box 的中心位置 $(x,y)$ ，需要根据预测的坐标偏移量<font color="blue">（感觉是个比例）</font> $(t_{x},t_{y})$，先验框 anchor box 的宽高 $(w_{a},h_{a})$ 以及Anchor 中心坐标 $(x_{a},y_{a})$ （特征图（边长是奇数）每个位置的中心点）来计算：
![faster R-CNN 中计算预测框的中心坐标的方法](https://img-blog.csdnimg.cn/img_convert/fda3e2548e0e8778e2506eb6bbbdbe56.png#pic_center)
这个公式是**无约束的，预测的边界框很容易向任何方向偏移**，如当 $t_{x}=1$ 时边界框将向右偏移先验框的一个宽度大小，而当 $t_{x}=-1$ 时边界框将向左偏移先验框的一个宽度大小，因此每个位置**预测的边界框可以落在图片任何位置**，$t_{x},t_{y}$没有约束而可能移动幅度过大，这导致模型的**不稳定性**，在训练时需要很长时间来预测出正确的offsets。

所以，YOLOv2弃用了这种预测方式，而是沿用YOLOv1的方法，就是**预测边界框中心点相对于对应grid cell左上角位置$(c_{x},c_{y})$的相对偏移值**，<font color="blue">为了将边界框 bounding box 中心点约束在当前cell中 </font>，使用sigmoid函数处理偏移值，这样预测的偏移值在(0,1)范围内（每个cell的尺度看做1）。总结来看，根据边界框预测的4个offsets $t_{x},t_{y},t_{w},t_{h}$ ，可以按如下公式计算出边界框实际位置和大小$(b_{x},b_{y},b_{w},b_{h})$：
![](https://img-blog.csdnimg.cn/img_convert/920c51b2db6727365725e3fb831d027e.png#pic_center)
其中 $(c_{x},c_{y})$ 为grid cell的左上角坐标，如下图所示。
![边界框位置与大小的计算示例图](https://img-blog.csdnimg.cn/img_convert/9a65ac9119d2ed7d3c1af623efd34b76.png)
在计算时每个grid cell的尺度为1，所以当前grid cell的左上角坐标为$(0,0)$。由于 sigmoid函数 的处理  **边界框的中心位置会约束在当前grid cell内部，防止偏移过多**。而 $p_{w}$ 和 $p_{h}$ 是先验框 anchor box 的宽度与长度，前面说过它们的值也是相对于特征图大小的，在特征图中每个cell的长和宽均为1。这里记特征图的大小为 $(W,H)$ （v2中为 (13,13) )，这样我们可以将边界框相对于整张图片的位置和大小计算出来 。
![得到的四个 尺度值](https://img-blog.csdnimg.cn/img_convert/92cbcacaeb84e01c3ecde7db7fe3a155.png)
**如果再将上面的4个值分别乘以图片的宽度和长度（像素点值）就可以得到边界框的最终位置和大小了**。这就是YOLOv2边界框的整个解码过程。约束了边界框的位置预测值使得模型更容易稳定训练，结合聚类分析得到先验框与这种预测方法，YOLOv2的mAP值提升了约5%。

## Fine-Grained Features 细粒度特征图
<font color="green">Fine-Grained Features 细粒度特征图 用于帮助检测小目标以及密集目标</font>
YOLOv2的输入图片大小为 416×416 ，经过5次maxpooling之后得到 13×13大小的特征图，并以此特征图采用卷积做预测。 13×13大小的特征图对检测大物体是足够了，但是**对于小物体还需要更精细的特征图（Fine-Grained Features）**。因此SSD使用了多尺度的特征图来分别检测不同大小的物体，前面更精细的特征图可以用来预测小物体。YOLOv2提出了一种pass through层来利用更精细的特征图。如下图为整体的网络结构：
![Darknet19检测模型+passthrough操作](https://img-blog.csdnimg.cn/img_convert/989dde6af769da5bd9ba6012e8bef92e.png#pic_center)
passthrough层与ResNet网络的shortcut类似，以前面**更高分辨率的特征图为输入**，然后将其**连接到后面的低分辨率特征图**上。
前面的特征图维度是后面的特征图的2倍，passthrough层抽取前面层的每个 2×2 的局部区域，然后将其转化为channel维度，对于26×26×512 的特征图，经passthrough层处理之后就变成了 13×13×2048 的新特征图（特征图大小降低4倍，而channles增加4倍。操作如下图所示：

![passthrough 增加通道数的操作栗子](https://img-blog.csdnimg.cn/img_convert/4051f9f715281e7658ab01fb6557807b.png#pic_center)
这样也就得到了 13×13×2048 的输出，可以与后面的 13×13×1024 低分辨率特征图连接在一起形成 13×13×3072 大小的特征图，然后在此特征图基础上卷积做预测。

![就是这样](https://img-blog.csdnimg.cn/img_convert/8a808bf40d6b819b196d7d348c755dca.png)
<font color="blue">在TensorFlow中，可以使用tf.extract_image_patches或者tf.space_to_depth来实现passthrough层：</font>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out = tf.extract_image_patches(<span class="keyword">in</span>, [<span class="number">1</span>, stride, stride, <span class="number">1</span>], [<span class="number">1</span>, stride, stride, <span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], padding=<span class="string">&quot;VALID&quot;</span>)</span><br><span class="line">// <span class="keyword">or</span> use tf.space_to_depth</span><br><span class="line">out = tf.space_to_depth(<span class="keyword">in</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

这是v2论文中刚开始的想法，作者后期借鉴了ResNet网络，**不是直接对高分辨特征图处理**，而是增加了一个**中间1×1卷积层**，先采用64个1×1 卷积核进行卷积，然后再进行passthrough处理，这样 26×26×512的特征图得到 13×13×256 的特征图。最后再高和低分辨率合并，得到13×13×1280的特征图做预测。这算是实现上的一个trick。使用Fine-Grained Features之后YOLOv2的性能有1%的提升。

![作者改进后的 也就是真实的代码设计](https://img-blog.csdnimg.cn/img_convert/cd777947365d746debcde922ad285dfb.png#pic_center)
## Multi-Scale Training 多尺度训练
YOLOv2的一大创新是采用Multi-Scale Training策略，**这样同一个模型其实就可以适应多种大小的图片**。
<font color="blue">由于YOLOv2模型中采用了global average pooling 全局平均池化层 ，所以YOLOv2的输入可以不限于 416×416 大小的图片。</font>为了增强模型的鲁棒性，YOLOv2采用了多尺度输入训练策略，具体来说就是在训练过程中每间隔10个 iterations 之后改变模型的输入图片大小。由于YOLOv2的下采样总步长为32，输入图片大小选择一系列为32倍数的值：{320,352，...608}。在训练过程，每隔10个iterations随机选择一种输入图片大小，然后只需要修改对最后检测层的处理就可以重新训练。
![Multi-Scale Training 多尺度输入训练](https://img-blog.csdnimg.cn/img_convert/8a03850706857e9f5a4cd666bae33301.png#pic_center)
YOLOv2在 VOC2007和2012的训练集上，可以看到采用较小分辨率时，YOLOv2的mAP值略低，但是速度更快，而采用高分辨输入时，mAP值更高，但是速度略有下降，对于 544×544 ，mAP高达78.6%。**注意，这只是训练时输入图片大小不同，而实际上用的是同一个模型（采用Multi-Scale Training训练）。** 
这里也可以看出，多尺度训练的一个副作用：如果你输入的是一个高分辨率的大图片 yolo会预测的比较慢但是比较准 如果你输入的是低分辨率的小图片，yolo会预测的非常快但是精度没有那么高。因此yolo可以通过输入图片的大小尺度，来做到精度和速度的权衡。

# Faster
##  New Network: Darknet-19
YOLOv2采用了一个新的基础模型（特征提取器），称为Darknet-19，包括19个卷积层和5个maxpooling层，如下图所示。下面这个是 用于分类的模型， 就是预训练模型啦。
![Darknet-19 的分类模型 预训练输入的为 224×224](https://img-blog.csdnimg.cn/img_convert/10c9041bf90f9c2d7a3de23f4b571706.png)
Darknet-19与VGG16模型设计原则是一致的，主要采用 3×3 卷积，采用 2×2 的maxpooling层之后，特征图维度降低2倍，而同时将特征图的channles增加两倍。与NIN(Network in Network)类似，Darknet-19最终采用**global avgpooling做预测**，并且在 3×3 卷积之间使用 1×1 卷积来压缩特征图channles以降低模型计算量和参数。Darkxnet-19每个卷积层后面同样使用了Batch Normalization层以加快收敛速度，降低模型过拟合。在ImageNet分类数据集上，Darknet-19的top-1准确度为72.9%，top-5准确度为91.2%，但是模型参数相对小一些。使用Darknet-19之后，YOLOv2的mAP值没有显著提升，但是计算量却可以减少约33%。

# YOLOv2的训练
YOLOv2的训练主要包括三个阶段。

 1. 第一阶段就是先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为 224×224 ，共训练160个epochs。
 2. 第二阶段将网络的输入调整为 448×448 ，继续在ImageNet数据集上finetune分类模型，训练10个epochs，此时分类模型的top-1准确度为76.5%，而top-5准确度为93.3%。
 3. **第三个阶段就是修改Darknet-19分类模型为检测模型**，并在检测数据集上继续finetune网络。网络修改包括（网路结构可视化）：<font color="red">移除最后一个卷积层、global average pooling层以及softmax层，并且新增了三个 3×3×1024 卷积层，同时增加了一个passthrough层，最后使用 1×1 卷积层输出预测结果，输出的channels数为： $anchor个数 × (5+类别个数)$（在v2中 为 5×（5+20）） ，和训练采用的数据集有关系。</font>由于anchors数为5，对于VOC数据集输出的channels数就是125，而对于COCO数据集则为425（因为COCO是80个分类）。

这里以VOC数据集为例，最终的预测矩阵为 $T$（shape为 （batch_size,13,13,125）），可以先将其reshape为 （batch_size,13,13,5,25），<font color="blue">其中 $T[:,:,:,:,0:4]$ 为边界框的位置和大小 $t_x,t_y,t_w,t_h$， $T[:,:,:,:,4]$ 为边界框的置信度，而 $T[:,:,:,:,5:]$为类别预测值。 </font>
![YOLOv2训练的三个阶段](https://img-blog.csdnimg.cn/img_convert/533f8c8dcc9da79ea03a5ca90bd00f4a.png#pic_center)
![YOLOv2 检测网络结构示意图](https://img-blog.csdnimg.cn/img_convert/89c0c117e6648f93753cc6416d0bbadf.png#pic_center)
## YOLOv2的损失函数
v2的预测框和类别的想法其实与v1是一致的，对于训练图片中的ground truth，若其中心点落在某个grid cell内，那么该grid cell内的5个先验框 anchor box 所对应的预测框 bounding box 负责预测它，具体是哪个bounding box预测它，需要在训练中确定，即由那个与ground truth的IoU最大的 bounding box 预测它，而剩余的4个 bounding box 不与该ground truth匹配。
![YOLOv2的损失函数](https://img-blog.csdnimg.cn/img_convert/68b2ccd52bf5d18fd4a234ac07c12057.png#pic_center)

 1. 首先 $W、H$分别指的是特征图（ 13×13 ）的宽13与高13，而 $A$ 指的是先验框anchor box数目（这里是5），各个 $λ$ 值是各个 loss 部分的权重系数（即超参数）。
![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/2b4666868ab3c549bf793cfa3acf9e59.png#pic_center)
 2. <font color="red">第一项loss是计算 该预测框不负责检测物体(background) 的置信度误差(越小越好)</font>，但是哪些预测框不负责检测物体对象而预测背景呢，需要先计算各个预测框和**所有ground truth的IOU值**，并且取**最大值Max_IOU**，如果该值**小于**一定的**阈值**（YOLOv2使用的是0.6），那么这个预测框就标记为background，<font color="blue">需要计算$λ_{noobj}$ 的置信度误差。</font>
![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/b0b4307ec6cdad8bde6ec679a55b6d8b.png#pic_center)
 3. <font color="red">第二项是计算先验框anchor box与预测框bounding box的坐标误差</font>，<font color="blue">但是只在前12800个iterations间计算，该博客博主认为 这项应该是在训练前期使预测框快速学习到先验框的位置和形状。</font> 
![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/fdd54195cbe12c0fc17d3ac02a61a179.png#pic_center)
> Q1: 为什么是 前12800个iterations？

 4. <font color="red">第三大项计算与某个ground truth匹配的预测框各部分loss值，包括定位（坐标）误差、置信度误差以及分类误差。</font>先说一下匹配原则，对于某个ground truth，首先要确定其中心点要落在哪个grid cell上，然后计算这个grid cell的5个先验框 anchor box 与ground truth的IoU值<font color="blue">（YOLOv2中bias_match=1）</font>，**计算IoU值时不考虑坐标，只考虑形状**，所以先将先验框与ground truth的中心点都偏移到同一位置（原点），然后计算出对应的IoU值，IoU值最大的那个先验框与ground truth匹配，对应形状的预测框用来预测这个ground truth。 说白了就是 我先看看 anchorbox 模板里面哪个和 ground truth形状比较像，这样我的框比较对嘛。然后选出这个框 找到 这个grid cell 里面 5个bounding box 和这个anchor 形状一样的那个框 去匹配ground truth。 说白了就是 弄了个中间商去选 形状 匹配。
 <font color="blue">在计算obj置信度时，target=1，但与YOLOv1一样而增加了一个控制参数rescore，当其为1时，target取预测框与ground truth的真实IOU值（cfg文件中默认采用这种方式）。 ???什么意思</font>
 对于那些没有与ground truth匹配的先验框（与预测框对应），除去那些Max_IOU低于阈值的，其它的就全部忽略，不计算任何误差。这点在YOLOv3论文中也有相关说明：**YOLO中一个ground truth只会与一个先验框匹配（IOU值最好的）**，对于那些IOU值超过一定阈值的先验框，其预测结果就忽略了。


 尽管YOLOv2和YOLOv1计算loss处理上有不同，但都是采用均方差来计算loss。另外需要注意的一点是，在计算boxes的 $w$ 和 $h$ 误差时，YOLOv1中采用的是平方根以降低boxes的大小对误差的影响，而YOLOv2是直接计算，<font color="blue">但是根据ground truth的大小对权重系数进行修正：l.coord_scale * (2 - truth.w*truth.h)（这里w和h都归一化到(0,1))</font>，这样对于尺度较小的boxes其权重系数会更大一些，可以放大误差，起到和YOLOv1计算平方根相似的效果（参考[YOLO v2 损失函数源码分析](https://www.cnblogs.com/YiXiaoZhou/p/7429481.html)）。 

最终的YOLOv2模型在速度上比YOLOv1还快（采用了计算量更少的Darknet-19模型），而且模型的准确度比YOLOv1有显著提升，详情见paper。

# Yolov2的预测
同Yolov1 的预测 同样是消除多余的框。可以看一下Yolov1 是怎么 在网络提取出特征图 后 如何 消除多余的框的。 [Yololv1的详解](https://jks88995656.github.io/2021/09/26/%E5%90%8C%E6%B5%8E%E5%AD%90%E8%B1%AA%E5%85%84%20%E4%B9%8B%20yolov1%20%E8%AF%A6%E8%A7%A3/)


# Yolo9000
YOLO9000是在YOLOv2的基础上提出的一种可以检测超过9000个类别的模型，其主要贡献点在于提出了一种分类和检测的联合训练策略。
ImageNet分类数据集比VOC等检测数据集高出几个数量级。在YOLO中，边界框的预测其实并不依赖于物体的标签，所以YOLO可以实现在分类和检测数据集上的联合训练。对于检测数据集，可以用来学习预测物体的边界框、置信度以及为物体分类，而对于分类数据集可以仅用来学习分类，但是其可以大大扩充模型所能检测的物体种类。

# Yolo9000 的训练
## WordTree与联合训练
这个装逼不成的作者 **选择在COCO检测数据集和ImageNet分类数据集上进行联合训练**，但是遇到的第一问题是<font color="red">两者的类别并不是完全互斥的（而常规的softmax方法认定各神经元是互斥的），</font>比如"Norfolk terrier"明显属于"dog"，所以作者提出了一种层级分类方法（Hierarchical classification），主要思路是根据各个类别之间的从属关系（根据WordNet）建立一种树结构WordTree，结合COCO和ImageNet建立的WordTree如下图所示：
![基于COCO和ImageNet数据集建立的WordTree](https://img-blog.csdnimg.cn/img_convert/e081b98313870f03c620f2d8fb0ddb7e.png#pic_center)
WordTree中的根节点为"physical object"，每个节点的子节点都属于同一子类，可以对它们进行softmax处理。在给出某个类别的预测概率时，需要找到其所在的位置，遍历这个path，然后计算path上各个节点的概率之积。计算某个节点的概率，比如说 Norfolk terrier 节点（根据他的物种从上到下遍历），计算步骤如下所示（分层概率计算完整概率）：

![计算Norfolk terrier结点概率](https://img-blog.csdnimg.cn/img_convert/802124190e6b707e7cd21def3a0f0cd7.png#pic_center)
上面是 做 分类的时候，概率的计算方式。他用了 ImageNet1000个类别构建的WordTree，当然中间需要一些中间层结点（比如 并不代表物种的  hunting dog这个类等）一共1369个结点。 按同层次的类别softmax的方法如下图，**计算结果其实不如 全部互斥的分类结果。**
![ImageNet与WordTree预测的对比](https://img-blog.csdnimg.cn/img_convert/63cf274736bb7b43970301aa7d192431.png#pic_center)
![Yolo9000](https://img-blog.csdnimg.cn/img_convert/e6f7edd74a243934d58718fd27e46d23.png#pic_center)
<font color="blue">当其是应用于 图像检测上时，需要将上面的 Pr(physical object)替换成 v2的置信度预测。</font>

<h2 id="实际训练与损失函数"><a href="#实际训练与损失函数" class="headerlink" title="实际训练与损失函数"></a>实际训练与损失函数</h2><p>Yolo9000 使用 ImageNet的分类数据集的前9000个类别和COCO的检测数据集构建WordTree 进行训练，测试用的是 ImageNet检测竞赛数据。</p>
<p>其用v2输出的 Tensor应该为 （13,13,3,5+9418），做Yolo9000时，作者将anchor box 变成了3个，因为5个的话张量实在太大了。5+9418 也就是 bounding box预测的4个左边偏移量和含有对象置信度，以及9418个分类。</p>
<p>在训练时，如果是检测样本，按照YOLOv2的loss计算误差，而对于分类样本，只计算分类误差。在预测时，YOLOv2给出的置信度就是 $Pr(physical    -object)$ ，同时会给出边界框位置以及一个树状概率图。<strong>在这个概率图中找到概率最高的路径，当达到某一个阈值时停止，就用当前节点表示预测的类别（也就是只会有1个）。</strong>而其他与Ground Truth 的IoU 高于0.3的预测框，本不应该具有这么高的置信度（IoU),通通都作为负样本。</p>
<h2 id="Yolo9000-检测上的实验效果"><a href="#Yolo9000-检测上的实验效果" class="headerlink" title="Yolo9000 检测上的实验效果"></a>Yolo9000 检测上的实验效果</h2><p>通过联合训练策略，YOLO9000可以快速检测出超过9000个类别的物体，总体mAP值为19.7%。事实上，ImageNet检测类别中大部分类别仅在ImageNet分类数据集上见过，并不是检测数据集，（这里可以看做迁移效果）。所以效果一般般，很多类别检测不出来，特别是物体类；但动物类尚可。估计原因就是，COCO检测数据集中大部分都是动物，所以迁移过来的对动物的效果当然也会比较好的。<br><img src="https://img-blog.csdnimg.cn/img_convert/ebf757ed8dcdec3f000ab814355f10b3.png#pic_center" alt="在这里插入图片描述"><br>作者提出的 yolo9000 算是一个开创的想法，但是效果不佳（不然他早就在youtube上装逼了）</p>
<h1 id="参考论文和博客"><a href="#参考论文和博客" class="headerlink" title="参考论文和博客"></a>参考论文和博客</h1><p>参考博客：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/35325884">转载来源 目标检测|YOLOv2原理与实现</a></li>
<li><a href="https://www.cnblogs.com/YiXiaoZhou/p/7429481.html">YOLO v2 损失函数源码分析 源码c版的</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/54073204">Batch Normalization的通俗解释</a></li>
</ul>
<p>参考视频：</p>
<ul>
<li><a href="https://www.bilibili.com/video/BV1Q64y1s74K?p=1">同济子豪兄v2算法讲解</a></li>
<li><p><a href="https://www.bilibili.com/video/BV1Q64y1s74K?p=2">同济子豪兄v2论文精讲</a></p>
<p>keras代码 github：YAD2K-master<br>参考论文：YOLO9000 Better, Faster, Stronger</p>
</li>
</ul>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>yolo</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 Deep Learning 后续优化</title>
    <url>/2021/08/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E5%90%8E%E7%BB%AD%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>@<a href="深度学习 Deep Learning 后续优化">TOC</a></p>
<p><strong>深度学习  怎么评价效果与改进？</strong></p>
<ol>
<li>先检查 训练阶段 是否有比较好的结果<br>training优化方法：
　<ol>
<li>换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax）</li>
<li>优化器——优化梯度下降和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）</li>
</ol>
</li>
<li>training没问题了，再检查testing是否有比较好的结果<br>　testing（过拟合）优化：<ol>
<li>参数在过拟合之前就停止更新</li>
<li>正则化Regularization</li>
<li>dropout</li>
</ol>
</li>
</ol>
<h1 id="如何优化模型"><a href="#如何优化模型" class="headerlink" title="如何优化模型"></a>如何优化模型</h1><h2 id="谈什么才是overfitting？"><a href="#谈什么才是overfitting？" class="headerlink" title="谈什么才是overfitting？"></a>谈什么才是overfitting？</h2><p>首先我们在明确一下，深度学习的流程，其与机器学习基本一致。如下图所示：<img src="https://img-blog.csdnimg.cn/0f42918289e14d23a7c8eada3056de07.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>判断  <em>过拟合</em> 需要看两个数据集上的结果（training set → good， testing set → bad）。<br><strong>在试图解决overfitting之后仍要再看一下training set上的结果！</strong></p>
<blockquote>
<p><strong>误区：</strong><br>不能看见所有不好的 <em>performance</em> 都归因到 <em>overfitting</em>。如只看下右图，不能断言56-layer有 <em>overfitting</em>，要看模型在training set上的表现。根据下左图，可以发现原因是训练的时候没有训练好，即这个层次设计可能本身就是有问题的，不然为啥20层的挺好，56层没道理差啊（这不能叫 <em>underfitting</em>，<em>underfitting</em>：参数不够多，模型能力不足）。<img src="https://img-blog.csdnimg.cn/d9f2b9e2e027466286e85d6b3998b713.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="对症下药：训练error，测试error分别用什么方法"><a href="#对症下药：训练error，测试error分别用什么方法" class="headerlink" title="对症下药：训练error，测试error分别用什么方法"></a>对症下药：训练error，测试error分别用什么方法</h2><p>在读到深度学习的方法时，要思考该方法是解决什么问题。<br><strong>是解决training set上的performance不好，还是解决testing set上的performance不好。</strong>比如，Dropout是为了解决testing set上结果不好的问题，如果是training set上结果不好而用Dropout，不会有好的结果。<br>下图是 分别解决各问题，可以采用的方法：<img src="https://img-blog.csdnimg.cn/f74d3b5a294e40648e9f9646b7c8e063.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="模型Train阶段Error-具体解决"><a href="#模型Train阶段Error-具体解决" class="headerlink" title="模型Train阶段Error 具体解决"></a>模型Train阶段Error 具体解决</h2><p>如下图是，MNIST手写数字识别，激活函数用sigmoid，training data上的accuracy与层数的关系曲线：<img src="https://img-blog.csdnimg.cn/91b2987e4b43432f88b04cd027a9ec56.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>层数&gt;7时，performance下降，<strong>原因不是 <em>overfitting</em>! 因为train的时候就没train好。</strong><br>那模型压根没有训练好，可以采用的方法上面也给出了包括：换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax）。激活函数可能会带来什么样的问题？以sigmoid为例说：会出现梯度消失。</p>
<h3 id="方法一：换激活函数的问题-——-梯度消失"><a href="#方法一：换激活函数的问题-——-梯度消失" class="headerlink" title="方法一：换激活函数的问题 —— 梯度消失"></a>方法一：换激活函数的问题 —— 梯度消失</h3><h4 id="什么是梯度消失"><a href="#什么是梯度消失" class="headerlink" title="什么是梯度消失"></a>什么是梯度消失</h4></blockquote>
<p>有梯度时，参数才会往梯度最小的地方改变；没有梯度了，参数就停止更新了。<br>前面层的学习速率明显低于后面层（后向传播），这就是梯度消失。<img src="https://img-blog.csdnimg.cn/f82182495a2f4ec5bd000941331d346a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h4 id="为什么会有梯度消失？"><a href="#为什么会有梯度消失？" class="headerlink" title="为什么会有梯度消失？"></a>为什么会有梯度消失？</h4><blockquote>
<p>角度一： 用sigmoid会出现梯度消失的问题（<strong>参数的变化经过sigmoid会逐层衰减，对最后的loss影响很小</strong>）<br><img src="https://img-blog.csdnimg.cn/052d1db3b2ef4b628a984db51778bf5a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如上图所示，我刚开始增加的△w，由于 <em>sigmoid函数</em> ，自变量越大，改变量越小的缘故。数的变化经过sigmoid会逐层衰减，对最后的loss影响很小。也就是对C的偏导会越来越小，导致梯度接近于0，而消失。</p>
<p>角度二：<br>假设现在存在一个网络结构：<br><img src="https://img-blog.csdnimg.cn/2de3a4da8a8c4ad1b0c6ca4fe6f5787d.png#pic_center" alt="在这里插入图片描述"><br>其整个数学模型可以表示为：<img src="https://img-blog.csdnimg.cn/f0e9bab2192e48d5b30ff91f0cb7ac58.png#pic_center" alt="在这里插入图片描述"><br>若要对于 <em>w1</em><br>求梯度，根据链式求导法则，得到的解为：<img src="https://img-blog.csdnimg.cn/f685ef885b0541198b35f65f257e4296.png#pic_center" alt="在这里插入图片描述"><br>这明显数学模型的值，随着隐层的增加，越来越小。不过这个前提是 原先的w（权重）并不是很大，原本相乘就是小于1的。如果w太大的话，第一项相乘就大于1，这就会导致最后的梯度爆炸。</p>
</blockquote>
<h4 id="如何解决梯度消失问题-——-换ReLU激活函数"><a href="#如何解决梯度消失问题-——-换ReLU激活函数" class="headerlink" title="如何解决梯度消失问题 —— 换ReLU激活函数"></a>如何解决梯度消失问题 —— 换ReLU激活函数</h4><h5 id="ReLU-与-MaxOut"><a href="#ReLU-与-MaxOut" class="headerlink" title="ReLU 与 MaxOut"></a>ReLU 与 MaxOut</h5><p>梯度消失是因为 <em>sigmoid</em> 引起的，要解决当然要换一个激活函数。采用的方法是换 <em>ReLU激活函数</em>（原型 input<0时，输出为0，input>0,输出为原值；可变型）<img src="https://img-blog.csdnimg.cn/44d11711c43a4495af5a232ba87f8df6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>ReLU输出0或x，输出0的ReLU神经元相当于不存在，网络变得瘦长，但是整个网络仍然是<strong>非线性的</strong>，只有当input改变十分微小的时候才是线性的，因为input不同，输出为0的ReLU神经元也不同。</p>
<blockquote>
<p><strong>Q : 为什么ReLU是非线性？明明两端都是线性直线啊？</strong><br>因为ReLU在0点没有导数定义，线性讲究的是在整个定义域内。而在0点处，不可微，所以整体是非线性的。</p>
</blockquote>
<p> ReLU是<strong>Maxout</strong>的特例，Maxout可以学出激活函数。<br><img src="https://img-blog.csdnimg.cn/436e424d5bf8460a9eaecb263ffdc73d.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h5 id="MaxOut-的训练是怎样的？好在哪？"><a href="#MaxOut-的训练是怎样的？好在哪？" class="headerlink" title="MaxOut 的训练是怎样的？好在哪？"></a>MaxOut 的训练是怎样的？好在哪？</h5><p>下面是一个神经网络的栗子，我们将激活函数换成 <em>MaxOut</em>激活函数。<br><img src="https://img-blog.csdnimg.cn/6b39a8e35978476e96d1eb7d9580c49d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>上面的图 可以删除不需要的边和点，变为如下的神经网络：<br><img src="https://img-blog.csdnimg.cn/92fa0460f9a84b0689ef391fc257ade0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>Q ：如果和上图所示，那我去掉的那些边不是啥用没有？也就是这个权值压根和神经网络没关系呢，不是吗？</strong><br>答 ：当然有关系，因为我们的任务是调参，每个权值和偏值得变化，都会导致 <em>MaxOut激活函数</em> 选择的不同。比如说改变一下 <em>w</em>，他可能会选择 <em>z2</em>呢。</p>
</blockquote>
<h3 id="方法二：优化器-——-优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）"><a href="#方法二：优化器-——-优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）" class="headerlink" title="方法二：优化器 —— 优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）"></a>方法二：优化器 —— 优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）</h3><p>寻找最佳参数的方法，调节学习率的方法有（<strong>SGD、Adagrad、RMSProp、Momentum、Adam</strong>）<br>SGD、Adagrad 可以看之前关于 梯度算法进阶的部分 <a href="#">Post not found: 梯度下降算法 进阶</a><br>这边主要讲解一下 RMSProp 和 Momentum</p>
<h4 id="关于-RMSProp"><a href="#关于-RMSProp" class="headerlink" title="关于 RMSProp"></a>关于 RMSProp</h4><h5 id="为什么要使用RMSProp"><a href="#为什么要使用RMSProp" class="headerlink" title="为什么要使用RMSProp"></a>为什么要使用RMSProp</h5><p>　在 <em>Adagrad</em> 中，<font color="red">学习率是跟损失函数对 <em>w</em> 的<strong>二次微分</strong>有关。</font>那么对于图中蓝绿相交的一点来说，因为 <em>w1</em> 所在的曲率相对于 <em>w2</em> 要小，所以 <em>w1</em> 的学习率会比 <em>w2</em> 大。现在单考虑 <em>w1</em>（只看横向），那么二次微分是固定的（碗状），也就是说 <em>w1</em>是根据固定的规则去自动调整 <em>η</em> 的。但是现实中同一方向的二次微分是不固定的，因此对于同一方向去 <em>w1</em>，需要不同的规则去调 <em>η</em>。</p>
<font color=" turquoise">对于一个参数来说，*Adagrad* 是用固定的规则去调 *η*，*RMSProp* 是用变化的规则去调 *η*</font>![在这里插入图片描述](https://img-blog.csdnimg.cn/cc6becd55c104daaa6f8eddadc55eb9d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
##### 如何实现RMSProp
在原来分母这一项中，在过去梯度平方和前面加上权值 *a*，现有的梯度平方加上 *1-a*。
<font color=" turquoise">其在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小），并且能够使得**陡峭的方向变得平缓**，从而加快训练速度）</font>
![在这里插入图片描述](https://img-blog.csdnimg.cn/1377f4da7b564c9a89ede8f17577f241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
#### 关于 Momentum
##### Momentum（动量）是用来解决什么问题的？
<font color="red">**这个是用来解决局部最优解的问题的**</font>

<p>说白了就是要延续他的惯性<br><img src="https://img-blog.csdnimg.cn/85f0e0d5d9a540eaa4f68d7c2e13c4ab.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h5 id="如何实现Momentum"><a href="#如何实现Momentum" class="headerlink" title="如何实现Momentum"></a>如何实现Momentum</h5><p>考虑他此时的方向，并保留他的惯性。来调整下一步，最大可能的避免局部最优解。<br><img src="https://img-blog.csdnimg.cn/0201be68528b443bb4b5596d5f27b58d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h4 id="关于-Adam"><a href="#关于-Adam" class="headerlink" title="关于 Adam"></a>关于 Adam</h4><p>他其实是一种 <em>Momentum + RMSProp</em> 结合的方法。其具体算法可以看如下图所示：<img src="https://img-blog.csdnimg.cn/c3aff899691d4155b8e47e51420c868e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="模型Train阶段OK-Test阶段Error，即过拟合"><a href="#模型Train阶段OK-Test阶段Error，即过拟合" class="headerlink" title="模型Train阶段OK Test阶段Error，即过拟合"></a>模型Train阶段OK Test阶段Error，即过拟合</h2><h3 id="方法一-：参数在过拟合之前就停止更新（Early-Stopping）"><a href="#方法一-：参数在过拟合之前就停止更新（Early-Stopping）" class="headerlink" title="方法一 ：参数在过拟合之前就停止更新（Early Stopping）"></a>方法一 ：参数在过拟合之前就停止更新（Early Stopping）</h3><font color="red">这里的testing set指的是有label的testing set（即validation set ）。</font>
如果learning rate设得对的话，training set的loss会逐渐降低，而testing set与training set可能分布不同，所以testing set的loss可能先降后升，这时就不要一直train下去，而是要在testing loss最小的地方停止train。这里的testing set 实际指的是**validation set**。

### 方法二 ：正则化Regularization

**Q ： 首先理解什么是范数，L1（范数为1）和L2（范数为2）是什么？** 
范数：向量在不同空间中“长度”的计算公式 L1：绝对值之和 L2：平方和


#### L2正则化（权值衰减）
![](https://img-blog.csdnimg.cn/8a8facf4f6bf42ebb56f4f657102b5ed.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

> **Q ： 为什么通常 不考虑 bias？**
> L2正则化让function更平滑，而bias与函数平滑程度没有关系。



![在这里插入图片描述](https://img-blog.csdnimg.cn/35cbdf14ab7049bd9967fcabc1223ae2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

参数更新：
因为η、λ、n都是正的，**所以 *1−ηλ*小于1，它的效果是减小w，这也就是权重衰减（weight decay）的由来**。**当然考虑到后面的导数项，w最终的值可能增大也可能减小**。

<font color="red">正则化在NN中虽有用但不明显。</font>
NN参数初始值一般接近0，update参数即是要参数原理0。L2正则化（让参数接近0）的作用可能与early stopping类似。

> **Q : 为什么参数w衰减能防止过拟合?**
> 答 ：模型过于复杂会导致过拟合。那么越小的w（可以想象成0理解），表示网络复杂度低，越简单的网络结构，就越不会过拟合。比如模型  *y=w1×w1 + w2×w2* 的平方  中把 *w2=0* 代入，模型就会简化，就不会引起过拟合。![在这里插入图片描述](https://img-blog.csdnimg.cn/c8fc90454614466ebee4a2d5a549a25e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
> **Q : 对正则化解决过拟合问题的一些本质理解？**
> 正则化防止过拟合的本质：减少“没用参数”的权值（防止过拟合），同时也减少“有用参数”的权值（会增加bias误差）
> **Q : 什么是有用参数，什么是没用参数？如上图中，怎么就把 *x2* 删去，不把 *x1* 删去呢？**
> 我们姑且假设 *w1* 是有用参数， *w2* 是无用参数，由公式知参数更新值跟权值、梯度值两个因素有关，实际上，无论是 *x1* 还是 *x2* ，权值都会衰减，每update一次参数，权值 *w* 就会衰减一次，但如果是下图的情况，*损失函数Loss* 的减少跟 *w2* 没关系的，所以对其偏导为0，那么 *w2* 的参数更新只跟权值有关了，随着更新次数叠加，权值就会逐渐衰减接近0；对于***有用参数 w1*** ，虽然它权值衰减，但是它其作用的是后面的偏导值，所以它还是不会变成0的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/50e060cb7bc24fbe896ef111e287092b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

#### L1正则化
L1是在Loss函数加上绝对值之和，求偏导后比原始的更新规则多出了η ×λ ×sgn(w)这一项。<font color="turquoise">**当w为正时，更新后的w变小。当w为负时，更新后的w变大（一加一减）——因此它的效果就是让w往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合**</font>
![在这里插入图片描述](https://img-blog.csdnimg.cn/113c9ac61f5946c783a434a07f8d52e9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

#### L1和L2相比
L1 update的速度是*|ηλ||ηλ|* （划横线那项每次改变量是一定的）。而 L2 update 的速度与w的t有关（如果wt  很大，那么改变量也很大）。
用L1做training，结果比较sparse(稀疏的)，参数中有很多接近0的值，也有很多很大的值。
L2 learn的结果：参数值平均来讲比较小。

### Dropout 
**Dropout也是为了简化神经网络结构的目的**，但L1、L2正则化是通过修改代价函数来实现的，而Dropout则是通过修改神经网络本身来实现的。

#### dropout是如何实现的
在training的时候，每次update参数之前，对每一个Neuron（包括input_layer）做sampling，决定这个Neuron按一定几率p丢掉，跟它相连的weight也被丢掉，结果得到一个细长的Network。（每一次update一个mini-batch之前，拿来traing的Network structure是不一样的）。

换句话说input layer中每个element也算是一个neuron.
每次更新参数之前都要resample.
**用dropout，在training上的结果会变差，但在testing上的结果会变好。**
![在这里插入图片描述](https://img-blog.csdnimg.cn/196bfc65730b4cb6b5877bcbc0a40729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
<font color="red">在**testing的时候不做dropout，所有neuron都要用**。
如果training时的删除神经元的概率为p%，则在testing时，所有的weight都要乘以（1-p）%</font>
![在这里插入图片描述](https://img-blog.csdnimg.cn/2c2491b39cef4452b88c9c465a8a1cbe.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
#### Dropout的原理 
![在这里插入图片描述](https://img-blog.csdnimg.cn/27c81c02d95847c2a5776da769696c54.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

> **Q : 为什么当在做 *testing* 的时候，weights需要都乘以 *(1-p)%*  (p是Dropout的概率)？**
>
> 答：如下图所示，左侧是在 *Traing* 阶段，*w2* 与 *w4* 由于丢失几率和丢掉(几率是这里是0.5)，假设神经元此时都是1，这时输出的应该是 *w1+w3*；右侧是在 *Testing* 阶段，在这个阶段要保证所有的神经元都不做 *Dropout* 。所以变成了w1+w2+w3+w4，约等于变成了左侧的两倍；所有取所有weight都要乘以（1-0.5）。

实际上，dropout是利用ensemble思想，把一个复杂神经网络的训练转化为，训练很多个简单的神经网络，然后再把多个简单神经网络训练出来的参数做平均。
![在这里插入图片描述](https://img-blog.csdnimg.cn/96b24fb760ee4d65b18862bc7bcf4ee0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
一个复杂model, bias准，但variance大，把多个复杂model ensemble起来，variance变小。
每个dropout后的结构由一个batch来train，但是权重是共享的，每个权重是由多个batch 来train的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/32d269be253c4f1790664d3b5c88caca.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
<font color="red">**在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的。**
**Dropout用在ReLU、Maxout上效果较好。**</font>

<blockquote>
<p><strong>Q : 为什么 Dropout 在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的？ 而不是相同</strong><br>答：因为神经元之间的层次，使用的激活函数不一定都是线性的，只有线性的情况下才会是相同的。</p>
</blockquote>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 Deep Learning 模型优化</title>
    <url>/2021/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20Deep%20Learning%20%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>@<a href="深度学习 Deep Learning 后续优化">TOC</a></p>
<p><strong>深度学习  怎么评价效果与改进？</strong></p>
<ol>
<li>先检查 训练阶段 是否有比较好的结果<br>training优化方法：
　<ol>
<li>换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax）</li>
<li>优化器——优化梯度下降和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）</li>
</ol>
</li>
<li>training没问题了，再检查testing是否有比较好的结果<br>　testing（过拟合）优化：<ol>
<li>参数在过拟合之前就停止更新</li>
<li>正则化Regularization</li>
<li>dropout</li>
</ol>
</li>
</ol>
<h1 id="如何优化模型"><a href="#如何优化模型" class="headerlink" title="如何优化模型"></a>如何优化模型</h1><h2 id="谈什么才是overfitting？"><a href="#谈什么才是overfitting？" class="headerlink" title="谈什么才是overfitting？"></a>谈什么才是overfitting？</h2><p>首先我们在明确一下，深度学习的流程，其与机器学习基本一致。如下图所示：<img src="https://img-blog.csdnimg.cn/0f42918289e14d23a7c8eada3056de07.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>判断  <em>过拟合</em> 需要看两个数据集上的结果（training set → good， testing set → bad）。<br><strong>在试图解决overfitting之后仍要再看一下training set上的结果！</strong></p>
<blockquote>
<p><strong>误区：</strong><br>不能看见所有不好的 <em>performance</em> 都归因到 <em>overfitting</em>。如只看下右图，不能断言56-layer有 <em>overfitting</em>，要看模型在training set上的表现。根据下左图，可以发现原因是训练的时候没有训练好，即这个层次设计可能本身就是有问题的，不然为啥20层的挺好，56层没道理差啊（这不能叫 <em>underfitting</em>，<em>underfitting</em>：参数不够多，模型能力不足）。<img src="https://img-blog.csdnimg.cn/d9f2b9e2e027466286e85d6b3998b713.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="对症下药：训练error，测试error分别用什么方法"><a href="#对症下药：训练error，测试error分别用什么方法" class="headerlink" title="对症下药：训练error，测试error分别用什么方法"></a>对症下药：训练error，测试error分别用什么方法</h2><p>在读到深度学习的方法时，要思考该方法是解决什么问题。<br><strong>是解决training set上的performance不好，还是解决testing set上的performance不好。</strong>比如，Dropout是为了解决testing set上结果不好的问题，如果是training set上结果不好而用Dropout，不会有好的结果。<br>下图是 分别解决各问题，可以采用的方法：<img src="https://img-blog.csdnimg.cn/f74d3b5a294e40648e9f9646b7c8e063.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="模型Train阶段Error-具体解决"><a href="#模型Train阶段Error-具体解决" class="headerlink" title="模型Train阶段Error 具体解决"></a>模型Train阶段Error 具体解决</h2><p>如下图是，MNIST手写数字识别，激活函数用sigmoid，training data上的accuracy与层数的关系曲线：<img src="https://img-blog.csdnimg.cn/91b2987e4b43432f88b04cd027a9ec56.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>层数&gt;7时，performance下降，<strong>原因不是 <em>overfitting</em>! 因为train的时候就没train好。</strong><br>那模型压根没有训练好，可以采用的方法上面也给出了包括：换激活函数（Sigmoid、ReLU、Maxout、Tanh、Softmax）。激活函数可能会带来什么样的问题？以sigmoid为例说：会出现梯度消失。</p>
<h3 id="方法一：换激活函数的问题-——-梯度消失"><a href="#方法一：换激活函数的问题-——-梯度消失" class="headerlink" title="方法一：换激活函数的问题 —— 梯度消失"></a>方法一：换激活函数的问题 —— 梯度消失</h3><h4 id="什么是梯度消失"><a href="#什么是梯度消失" class="headerlink" title="什么是梯度消失"></a>什么是梯度消失</h4></blockquote>
<p>有梯度时，参数才会往梯度最小的地方改变；没有梯度了，参数就停止更新了。<br>前面层的学习速率明显低于后面层（后向传播），这就是梯度消失。<img src="https://img-blog.csdnimg.cn/f82182495a2f4ec5bd000941331d346a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h4 id="为什么会有梯度消失？"><a href="#为什么会有梯度消失？" class="headerlink" title="为什么会有梯度消失？"></a>为什么会有梯度消失？</h4><blockquote>
<p>角度一： 用sigmoid会出现梯度消失的问题（<strong>参数的变化经过sigmoid会逐层衰减，对最后的loss影响很小</strong>）<br><img src="https://img-blog.csdnimg.cn/052d1db3b2ef4b628a984db51778bf5a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如上图所示，我刚开始增加的△w，由于 <em>sigmoid函数</em> ，自变量越大，改变量越小的缘故。数的变化经过sigmoid会逐层衰减，对最后的loss影响很小。也就是对C的偏导会越来越小，导致梯度接近于0，而消失。</p>
<p>角度二：<br>假设现在存在一个网络结构：<br><img src="https://img-blog.csdnimg.cn/2de3a4da8a8c4ad1b0c6ca4fe6f5787d.png#pic_center" alt="在这里插入图片描述"><br>其整个数学模型可以表示为：<img src="https://img-blog.csdnimg.cn/f0e9bab2192e48d5b30ff91f0cb7ac58.png#pic_center" alt="在这里插入图片描述"><br>若要对于 <em>w1</em><br>求梯度，根据链式求导法则，得到的解为：<img src="https://img-blog.csdnimg.cn/f685ef885b0541198b35f65f257e4296.png#pic_center" alt="在这里插入图片描述"><br>这明显数学模型的值，随着隐层的增加，越来越小。不过这个前提是 原先的w（权重）并不是很大，原本相乘就是小于1的。如果w太大的话，第一项相乘就大于1，这就会导致最后的梯度爆炸。</p>
</blockquote>
<h4 id="如何解决梯度消失问题-——-换ReLU激活函数"><a href="#如何解决梯度消失问题-——-换ReLU激活函数" class="headerlink" title="如何解决梯度消失问题 —— 换ReLU激活函数"></a>如何解决梯度消失问题 —— 换ReLU激活函数</h4><h5 id="ReLU-与-MaxOut"><a href="#ReLU-与-MaxOut" class="headerlink" title="ReLU 与 MaxOut"></a>ReLU 与 MaxOut</h5><p>梯度消失是因为 <em>sigmoid</em> 引起的，要解决当然要换一个激活函数。采用的方法是换 <em>ReLU激活函数</em>（原型 input<0时，输出为0，input>0,输出为原值；可变型）<img src="https://img-blog.csdnimg.cn/44d11711c43a4495af5a232ba87f8df6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>ReLU输出0或x，输出0的ReLU神经元相当于不存在，网络变得瘦长，但是整个网络仍然是<strong>非线性的</strong>，只有当input改变十分微小的时候才是线性的，因为input不同，输出为0的ReLU神经元也不同。</p>
<blockquote>
<p><strong>Q : 为什么ReLU是非线性？明明两端都是线性直线啊？</strong><br>因为ReLU在0点没有导数定义，线性讲究的是在整个定义域内。而在0点处，不可微，所以整体是非线性的。</p>
</blockquote>
<p> ReLU是<strong>Maxout</strong>的特例，Maxout可以学出激活函数。<br><img src="https://img-blog.csdnimg.cn/436e424d5bf8460a9eaecb263ffdc73d.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h5 id="MaxOut-的训练是怎样的？好在哪？"><a href="#MaxOut-的训练是怎样的？好在哪？" class="headerlink" title="MaxOut 的训练是怎样的？好在哪？"></a>MaxOut 的训练是怎样的？好在哪？</h5><p>下面是一个神经网络的栗子，我们将激活函数换成 <em>MaxOut</em>激活函数。<br><img src="https://img-blog.csdnimg.cn/6b39a8e35978476e96d1eb7d9580c49d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>上面的图 可以删除不需要的边和点，变为如下的神经网络：<br><img src="https://img-blog.csdnimg.cn/92fa0460f9a84b0689ef391fc257ade0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>Q ：如果和上图所示，那我去掉的那些边不是啥用没有？也就是这个权值压根和神经网络没关系呢，不是吗？</strong><br>答 ：当然有关系，因为我们的任务是调参，每个权值和偏值得变化，都会导致 <em>MaxOut激活函数</em> 选择的不同。比如说改变一下 <em>w</em>，他可能会选择 <em>z2</em>呢。</p>
</blockquote>
<h3 id="方法二：优化器-——-优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）"><a href="#方法二：优化器-——-优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）" class="headerlink" title="方法二：优化器 —— 优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）"></a>方法二：优化器 —— 优化gd和自适应调学习率（SGD、Adagrad、RMSProp、Momentum、Adam）</h3><p>寻找最佳参数的方法，调节学习率的方法有（<strong>SGD、Adagrad、RMSProp、Momentum、Adam</strong>）<br>SGD、Adagrad 可以看之前关于 梯度算法进阶的部分 <a href="#">Post not found: 梯度下降算法 进阶</a><br>这边主要讲解一下 RMSProp 和 Momentum</p>
<h4 id="关于-RMSProp"><a href="#关于-RMSProp" class="headerlink" title="关于 RMSProp"></a>关于 RMSProp</h4><h5 id="为什么要使用RMSProp"><a href="#为什么要使用RMSProp" class="headerlink" title="为什么要使用RMSProp"></a>为什么要使用RMSProp</h5><p>　在 <em>Adagrad</em> 中，<font color="red">学习率是跟损失函数对 <em>w</em> 的<strong>二次微分</strong>有关。</font>那么对于图中蓝绿相交的一点来说，因为 <em>w1</em> 所在的曲率相对于 <em>w2</em> 要小，所以 <em>w1</em> 的学习率会比 <em>w2</em> 大。现在单考虑 <em>w1</em>（只看横向），那么二次微分是固定的（碗状），也就是说 <em>w1</em>是根据固定的规则去自动调整 <em>η</em> 的。但是现实中同一方向的二次微分是不固定的，因此对于同一方向去 <em>w1</em>，需要不同的规则去调 <em>η</em>。</p>
<font color=" turquoise">对于一个参数来说，*Adagrad* 是用固定的规则去调 *η*，*RMSProp* 是用变化的规则去调 *η*</font>![在这里插入图片描述](https://img-blog.csdnimg.cn/cc6becd55c104daaa6f8eddadc55eb9d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
##### 如何实现RMSProp
在原来分母这一项中，在过去梯度平方和前面加上权值 *a*，现有的梯度平方加上 *1-a*。
<font color=" turquoise">其在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小），并且能够使得**陡峭的方向变得平缓**，从而加快训练速度）</font>
![在这里插入图片描述](https://img-blog.csdnimg.cn/1377f4da7b564c9a89ede8f17577f241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
#### 关于 Momentum
##### Momentum（动量）是用来解决什么问题的？
<font color="red">**这个是用来解决局部最优解的问题的**</font>

<p>说白了就是要延续他的惯性<br><img src="https://img-blog.csdnimg.cn/85f0e0d5d9a540eaa4f68d7c2e13c4ab.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h5 id="如何实现Momentum"><a href="#如何实现Momentum" class="headerlink" title="如何实现Momentum"></a>如何实现Momentum</h5><p>考虑他此时的方向，并保留他的惯性。来调整下一步，最大可能的避免局部最优解。<br><img src="https://img-blog.csdnimg.cn/0201be68528b443bb4b5596d5f27b58d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h4 id="关于-Adam"><a href="#关于-Adam" class="headerlink" title="关于 Adam"></a>关于 Adam</h4><p>他其实是一种 <em>Momentum + RMSProp</em> 结合的方法。其具体算法可以看如下图所示：<img src="https://img-blog.csdnimg.cn/c3aff899691d4155b8e47e51420c868e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="模型Train阶段OK-Test阶段Error，即过拟合"><a href="#模型Train阶段OK-Test阶段Error，即过拟合" class="headerlink" title="模型Train阶段OK Test阶段Error，即过拟合"></a>模型Train阶段OK Test阶段Error，即过拟合</h2><h3 id="方法一-：参数在过拟合之前就停止更新（Early-Stopping）"><a href="#方法一-：参数在过拟合之前就停止更新（Early-Stopping）" class="headerlink" title="方法一 ：参数在过拟合之前就停止更新（Early Stopping）"></a>方法一 ：参数在过拟合之前就停止更新（Early Stopping）</h3><font color="red">这里的testing set指的是有label的testing set（即validation set ）。</font>
如果learning rate设得对的话，training set的loss会逐渐降低，而testing set与training set可能分布不同，所以testing set的loss可能先降后升，这时就不要一直train下去，而是要在testing loss最小的地方停止train。这里的testing set 实际指的是**validation set**。

### 方法二 ：正则化Regularization

> **Q ： 首先理解什么是范数，L1（范数为1）和L2（范数为2）是什么？**
> 范数：向量在不同空间中“长度”的计算公式
> L1：绝对值之和
> L2：平方和

#### L2正则化（权值衰减）
![在这里插入图片描述](https://img-blog.csdnimg.cn/8a8facf4f6bf42ebb56f4f657102b5ed.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
> **Q ： 为什么通常 不考虑 bias？**
> L2正则化让function更平滑，而bias与函数平滑程度没有关系。

![在这里插入图片描述](https://img-blog.csdnimg.cn/35cbdf14ab7049bd9967fcabc1223ae2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

参数更新：
因为η、λ、n都是正的，**所以 *1−ηλ*小于1，它的效果是减小w，这也就是权重衰减（weight decay）的由来**。**当然考虑到后面的导数项，w最终的值可能增大也可能减小**。

<font color="red">正则化在NN中虽有用但不明显。</font>
NN参数初始值一般接近0，update参数即是要参数原理0。L2正则化（让参数接近0）的作用可能与early stopping类似。

> **Q : 为什么参数w衰减能防止过拟合?**
> 答 ：模型过于复杂会导致过拟合。那么越小的w（可以想象成0理解），表示网络复杂度低，越简单的网络结构，就越不会过拟合。比如模型  *y=w1×w1 + w2×w2* 的平方  中把 *w2=0* 代入，模型就会简化，就不会引起过拟合。![在这里插入图片描述](https://img-blog.csdnimg.cn/c8fc90454614466ebee4a2d5a549a25e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
> **Q : 对正则化解决过拟合问题的一些本质理解？**
> 正则化防止过拟合的本质：减少“没用参数”的权值（防止过拟合），同时也减少“有用参数”的权值（会增加bias误差）
> **Q : 什么是有用参数，什么是没用参数？如上图中，怎么就把 *x2* 删去，不把 *x1* 删去呢？**
> 我们姑且假设 *w1* 是有用参数， *w2* 是无用参数，由公式知参数更新值跟权值、梯度值两个因素有关，实际上，无论是 *x1* 还是 *x2* ，权值都会衰减，每update一次参数，权值 *w* 就会衰减一次，但如果是下图的情况，*损失函数Loss* 的减少跟 *w2* 没关系的，所以对其偏导为0，那么 *w2* 的参数更新只跟权值有关了，随着更新次数叠加，权值就会逐渐衰减接近0；对于***有用参数 w1*** ，虽然它权值衰减，但是它其作用的是后面的偏导值，所以它还是不会变成0的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/50e060cb7bc24fbe896ef111e287092b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
#### L1正则化
L1是在Loss函数加上绝对值之和，求偏导后比原始的更新规则多出了η ×λ ×sgn(w)这一项。<font color="turquoise">**当w为正时，更新后的w变小。当w为负时，更新后的w变大（一加一减）——因此它的效果就是让w往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合**</font>
![在这里插入图片描述](https://img-blog.csdnimg.cn/113c9ac61f5946c783a434a07f8d52e9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

#### L1和L2相比
L1 update的速度是*|ηλ||ηλ|* （划横线那项每次改变量是一定的）。而 L2 update 的速度与w的t有关（如果wt  很大，那么改变量也很大）。
用L1做training，结果比较sparse(稀疏的)，参数中有很多接近0的值，也有很多很大的值。
L2 learn的结果：参数值平均来讲比较小。

### Dropout 
**Dropout也是为了简化神经网络结构的目的**，但L1、L2正则化是通过修改代价函数来实现的，而Dropout则是通过修改神经网络本身来实现的。
#### dropout是如何实现的
在training的时候，每次update参数之前，对每一个Neuron（包括input_layer）做sampling，决定这个Neuron按一定几率p丢掉，跟它相连的weight也被丢掉，结果得到一个细长的Network。（每一次update一个mini-batch之前，拿来traing的Network structure是不一样的）。

换句话说input layer中每个element也算是一个neuron.
每次更新参数之前都要resample.
**用dropout，在training上的结果会变差，但在testing上的结果会变好。**
![在这里插入图片描述](https://img-blog.csdnimg.cn/196bfc65730b4cb6b5877bcbc0a40729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
<font color="red">在**testing的时候不做dropout，所有neuron都要用**。
如果training时的删除神经元的概率为p%，则在testing时，所有的weight都要乘以（1-p）%</font>
![在这里插入图片描述](https://img-blog.csdnimg.cn/2c2491b39cef4452b88c9c465a8a1cbe.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
#### Dropout的原理 
![在这里插入图片描述](https://img-blog.csdnimg.cn/27c81c02d95847c2a5776da769696c54.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

> **Q : 为什么当在做 *testing* 的时候，weights需要都乘以 *(1-p)%*  (p是Dropout的概率)？**
>
> 答：如下图所示，左侧是在 *Traing* 阶段，*w2* 与 *w4* 由于丢失几率和丢掉(几率是这里是0.5)，假设神经元此时都是1，这时输出的应该是 *w1+w3*；右侧是在 *Testing* 阶段，在这个阶段要保证所有的神经元都不做 *Dropout* 。所以变成了w1+w2+w3+w4，约等于变成了左侧的两倍；所有取所有weight都要乘以（1-0.5）。

实际上，dropout是利用ensemble思想，把一个复杂神经网络的训练转化为，训练很多个简单的神经网络，然后再把多个简单神经网络训练出来的参数做平均。
![在这里插入图片描述](https://img-blog.csdnimg.cn/96b24fb760ee4d65b18862bc7bcf4ee0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
一个复杂model, bias准，但variance大，把多个复杂model ensemble起来，variance变小。
每个dropout后的结构由一个batch来train，但是权重是共享的，每个权重是由多个batch 来train的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/32d269be253c4f1790664d3b5c88caca.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
<font color="red">**在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的。**
**Dropout用在ReLU、Maxout上效果较好。**</font>

<blockquote>
<p><strong>Q : 为什么 Dropout 在testing的时候，把多个结构的结果取平均，与把所有参数乘以(1 - p%)，效果是近似的？ 而不是相同</strong><br>答：因为神经元之间的层次，使用的激活函数不一定都是线性的，只有线性的情况下才会是相同的。</p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>李宏毅</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/VuePurchase%E6%98%93%E8%B4%AD%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="VuePurchase易购平台项目笔记"><a href="#VuePurchase易购平台项目笔记" class="headerlink" title="VuePurchase易购平台项目笔记"></a>VuePurchase易购平台项目笔记</h1><h2 id="安装前端包与配置环境"><a href="#安装前端包与配置环境" class="headerlink" title="安装前端包与配置环境"></a>安装前端包与配置环境</h2><p><strong>Step1：首先在当前地址中，创建我们的 项目文件  vue-purchase</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vue create vue-purchase</span><br></pre></td></tr></table></figure>
<p>默认选择  Default  Vue2.0 的版本。  <strong>我当前脚手架的版本是  5.0.8。</strong></p>
<p><strong>Step2：进入该项目文件   <code>cd vue-purchase</code></strong></p>
<p>并配置我们需要依赖的库  例如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">// 前端安装依赖</span><br><span class="line">npm i axios -S</span><br><span class="line">npm i querystring -S</span><br><span class="line">npm i echarts -S</span><br><span class="line">// 路由</span><br><span class="line">npm i vue-router@3</span><br><span class="line">// 配置后端服务 </span><br><span class="line">// 技术：node.js + mysql + mock.js</span><br><span class="line">npm i express -S</span><br><span class="line">npm i cors -S</span><br><span class="line">npm i mockjs -S</span><br><span class="line">npm i mysql -S</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中 可以在事先就引入 Element UI</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vue add element</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/引入Element.png" alt=""></p>
<font color="red">选择部分导入  import on demand</font>  再选择  **zh-CN**

出现  `Successfully invoked generator for plugin: vue-cli-plugin-element` 表示成功

**Step3：`vue-purchase ` 项目中专门配置一个 server 文件夹用于配置服务器相关代码** 



**Step4：启动前端项目**

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm run serve</span><br></pre></td></tr></table></figure>



**Step5：删除初试项目中没用部分**

例如 App.vue 全部初始为啥也没有，组件里原本的东西都不要。



**Step6：添加所需部分**

**assets**  静态资源

然后 assets 文件夹内，创建 css  和 images 文件夹，方便以后使用。

并再 css 文件中引入`reset.css` 、`iconfont.css`

-  `reset.css`，其是重置浏览器标签的样式表，百度可以直接搜到里面的内容。

- `iconfont.css` ，其是作者自己创建的一个图标库内容

  其css的内容为 引入外部css文件。

  <figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@import</span> url(<span class="string">&quot;https://at.alicdn.com/t/font_2448847_ogyed8on8j.css&quot;</span>);</span><br></pre></td></tr></table></figure>

然后这两个库需要再 main.js 入口文件中进行 注册：

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//css 初始化</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;./assets/css/reset.css&quot;</span></span><br><span class="line"><span class="comment">// iconfont</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;./assets/css/iconfont.css&quot;</span></span><br></pre></td></tr></table></figure>



**plugins**  Element UI

另外就是 需要补全 `plugins` 文件夹中  element.js 文件引入的内容。

其实可以需要用到然后再引入，但是为了方便嘛这里全部引入算了。

引入的内容需要取 Element2.0的官网，快速入手中找到

`完整组件列表和引入方式（完整组件列表以 [components.json](https://github.com/ElemeFE/element/blob/master/components.json) 为准）`将其后面代码中所有的内容 都放到 element.js 中就进行替换即可。



**request**   axios封装

另外就是要创建 request 文件夹，里面 request.js 。

里面实现 axios 的二次封装。



**views**  布局文件

再创建一个 views文件夹，内部创建两个布局（因为我有一个登录界面 和 一个后端页面）所以呈现的结构为：

![](https://gitee.com/kaikai-superman/imgs/raw/master/img/views.png)



**router 路由**  

<font color="blue">另外就是 router，store 文件夹需要自己初始化配置好。</font>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// // 该文件专门用于创建整个应用的路由器</span></span><br><span class="line"><span class="keyword">import</span> Vue <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span><br><span class="line"><span class="keyword">import</span> VueRouter <span class="keyword">from</span> <span class="string">&#x27;vue-router&#x27;</span></span><br><span class="line"><span class="keyword">import</span> Layout <span class="keyword">from</span> <span class="string">&#x27;@/views/Layout&#x27;</span></span><br><span class="line"><span class="keyword">import</span> Login <span class="keyword">from</span> <span class="string">&#x27;@/views/Login&#x27;</span></span><br><span class="line"><span class="comment">//引入组件</span></span><br><span class="line"></span><br><span class="line">Vue.use(VueRouter)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> routes = [</span><br><span class="line">	&#123;&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建并暴露一个路由器</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">new</span> VueRouter(&#123;</span><br><span class="line">	<span class="attr">mode</span>:<span class="string">&quot;history&quot;</span>,</span><br><span class="line">	<span class="attr">base</span>:process.env.BASE_URL,</span><br><span class="line">	routes</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="配置数据库用于后端服务"><a href="#配置数据库用于后端服务" class="headerlink" title="配置数据库用于后端服务"></a>配置数据库用于后端服务</h2><p>首先你需要有一个 Apache  + mysql  我这里使用的是  phpStudy， 作者用的那个 服务在我这开不起来。</p>
<blockquote>
<p>APACHE就是一个网络服务器，这个服务器侦听一个TCP端口，一般是80，对端口收到的命令进行解释，然后提交一些结果。APACHE解释的最主要的命令就是GET和POST，一般对应客户端在浏览器输入地址、浏览器里面点击链接和提交一个表单。</p>
<p>APACHE对GET和POST命令进行解释的时候，如果GET和POST的对象是一个HTML、CSS、JS、RAR、TXT等一般文件，就直接把文件的内容发回客户端；</p>
</blockquote>
<p><a href="https://blog.csdn.net/Quantum_Dog/article/details/109270685">https://blog.csdn.net/Quantum_Dog/article/details/109270685</a></p>
<p><strong>Step1：先开启 Apache 和 mysql</strong></p>
<p>Apache 映射的端口为 80</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/phpStudy.png" style="zoom: 50%;" /></p>
<p><strong>Step2：需要下载 phpMyAdmin</strong></p>
<p>需要打开软件管理，下载 phpMyAdmin</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/下载phpMyAdmin.png" alt=""></p>
<p>然后点击第一张图的数据库工具，打开按钮进入 phpMyAdmin</p>
<p>默认账号和密码 都是 root</p>
<p><strong>Step3：创建ego数据库 并载入数据表</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/创建ego数据库.png" alt=""></p>
<p>并载入数据表</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/载入ego数据表.png" alt=""></p>
<h2 id="使用-Element-UI-实现侧边栏页面"><a href="#使用-Element-UI-实现侧边栏页面" class="headerlink" title="使用 Element UI 实现侧边栏页面"></a>使用 Element UI 实现侧边栏页面</h2><p>侧边栏去  ElementUI中进行复制，保留自己想要的部分。</p>
<p>主要功能是要实现配置侧边导航栏的路由跳转，需要和 Element UI 进行级联</p>
<p>配置 router 文件夹 中的 index.js 如下</p>
<p>需要注意的点为 </p>
<ul>
<li>/ 为一级路由， 后面 home页面路由、 产品管理路由、订单管理路由、广告分类路由均为同级别的二级路由，其各自里面的组件配置为三级路由</li>
</ul>
<p>以 产品管理路由为例子</p>
<ul>
<li><p>GoodsManage 作为路由的出口 用于显示三级路由的内容</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">  &lt;div&gt;</span><br><span class="line">    &lt;!-- 路由出口 --&gt;</span><br><span class="line">    &lt;router-view&gt;&lt;/router-view&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>其里面包含两个三级路由 GoodsCategory 和 GoodsList</p>
</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> VueRouter <span class="keyword">from</span> <span class="string">&#x27;vue-router&#x27;</span></span><br><span class="line"><span class="comment">//引入组件</span></span><br><span class="line"><span class="keyword">import</span> Layout <span class="keyword">from</span> <span class="string">&#x27;../views/Layout/layout.vue&#x27;</span></span><br><span class="line"><span class="keyword">import</span> Login <span class="keyword">from</span> <span class="string">&#x27;../views/Login/login.vue&#x27;</span></span><br><span class="line"><span class="keyword">import</span> Home <span class="keyword">from</span> <span class="string">&#x27;../views/Home/home.vue&#x27;</span></span><br><span class="line"><span class="comment">// 产品管理</span></span><br><span class="line"><span class="keyword">import</span> GoodsManage <span class="keyword">from</span> <span class="string">&quot;../views/GoodsManage/goodsManage.vue&quot;</span></span><br><span class="line"><span class="keyword">import</span> GoodsCategory <span class="keyword">from</span> <span class="string">&quot;../views/GoodsManage/GoodsCategory/goodsCategory.vue&quot;</span></span><br><span class="line"><span class="keyword">import</span> GoodsList <span class="keyword">from</span> <span class="string">&quot;../views/GoodsManage/GoodsList/goodsList.vue&quot;</span></span><br><span class="line"><span class="comment">// 订单管理</span></span><br><span class="line"><span class="keyword">import</span> OrderManage <span class="keyword">from</span> <span class="string">&quot;../views/OrderManage/orderManage.vue&quot;</span></span><br><span class="line"><span class="keyword">import</span> OrderCollect <span class="keyword">from</span> <span class="string">&quot;../views/OrderManage/OrderCollect/orderCollect.vue&quot;</span></span><br><span class="line"><span class="keyword">import</span> OrderList <span class="keyword">from</span> <span class="string">&quot;../views/OrderManage/OrderList/orderList.vue&quot;</span></span><br><span class="line"><span class="keyword">import</span> OrderAudit <span class="keyword">from</span> <span class="string">&quot;../views/OrderManage/OrderAudit/orderAudit.vue&quot;</span></span><br><span class="line"><span class="comment">// 广告分类</span></span><br><span class="line"><span class="keyword">import</span> AdvertiseCategory <span class="keyword">from</span> <span class="string">&quot;../views/AdvertiseCategory/advertiseCategory.vue&quot;</span></span><br><span class="line"><span class="keyword">import</span> AdvertiseList <span class="keyword">from</span> <span class="string">&quot;../views/AdvertiseCategory/AdvertiseList/advertiseList.vue&quot;</span></span><br><span class="line"><span class="keyword">import</span> AdvertiseMagage <span class="keyword">from</span> <span class="string">&quot;../views/AdvertiseCategory/AdvertiseMagage/advertiseMagage.vue&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//创建并暴露一个路由器</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">new</span> VueRouter(&#123;</span><br><span class="line">	<span class="attr">routes</span>:[</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="attr">path</span>:<span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">			<span class="attr">component</span>:Layout,</span><br><span class="line">			<span class="attr">children</span>:[</span><br><span class="line">				<span class="comment">// 配置 home页面路由</span></span><br><span class="line">				&#123;	</span><br><span class="line">					<span class="attr">name</span>:<span class="string">&quot;home&quot;</span>,</span><br><span class="line">					<span class="attr">path</span>:<span class="string">&quot;home&quot;</span>,</span><br><span class="line">					<span class="attr">component</span>:Home</span><br><span class="line">				&#125;,</span><br><span class="line">				<span class="comment">// 配置 产品管理路由	</span></span><br><span class="line">				&#123;</span><br><span class="line">					<span class="attr">name</span>:<span class="string">&quot;goodsManage&quot;</span>,</span><br><span class="line">					<span class="attr">path</span>:<span class="string">&quot;goodsManage&quot;</span>,</span><br><span class="line">					<span class="attr">component</span>:GoodsManage,</span><br><span class="line">					<span class="attr">children</span>:[</span><br><span class="line">						&#123;</span><br><span class="line">							<span class="attr">name</span>:<span class="string">&quot;goodsCategory&quot;</span>,</span><br><span class="line">							<span class="attr">path</span>:<span class="string">&quot;goodsCategory&quot;</span>,</span><br><span class="line">							<span class="attr">component</span>:GoodsCategory</span><br><span class="line">						&#125;,</span><br><span class="line">						&#123;</span><br><span class="line">							<span class="attr">name</span>:<span class="string">&quot;goodsList&quot;</span>,</span><br><span class="line">							<span class="attr">path</span>:<span class="string">&quot;goodsList&quot;</span>,</span><br><span class="line">							<span class="attr">component</span>:GoodsList</span><br><span class="line">						&#125;</span><br><span class="line">					]</span><br><span class="line">				&#125;,</span><br><span class="line">				<span class="comment">// 配置 订单管理路由</span></span><br><span class="line">				&#123;</span><br><span class="line">					<span class="attr">name</span>:<span class="string">&quot;orderManage&quot;</span>,</span><br><span class="line">					<span class="attr">path</span>:<span class="string">&quot;orderManage&quot;</span>,</span><br><span class="line">					<span class="attr">component</span>:OrderManage,</span><br><span class="line">					<span class="attr">children</span>:[</span><br><span class="line">						&#123;</span><br><span class="line">							<span class="attr">name</span>:<span class="string">&quot;orderCollect&quot;</span>,</span><br><span class="line">							<span class="attr">path</span>:<span class="string">&quot;orderCollect&quot;</span>,</span><br><span class="line">							<span class="attr">component</span>:OrderCollect</span><br><span class="line">						&#125;,</span><br><span class="line">						&#123;</span><br><span class="line">							<span class="attr">name</span>:<span class="string">&quot;orderList&quot;</span>,</span><br><span class="line">							<span class="attr">path</span>:<span class="string">&quot;orderList&quot;</span>,</span><br><span class="line">							<span class="attr">component</span>:OrderList</span><br><span class="line">						&#125;,</span><br><span class="line">						&#123;</span><br><span class="line">							<span class="attr">name</span>:<span class="string">&quot;orderAudit&quot;</span>,</span><br><span class="line">							<span class="attr">path</span>:<span class="string">&quot;orderAudit&quot;</span>,</span><br><span class="line">							<span class="attr">component</span>:OrderAudit</span><br><span class="line">						&#125;</span><br><span class="line">					]</span><br><span class="line">				&#125;,</span><br><span class="line">				<span class="comment">// 配置 广告分类路由</span></span><br><span class="line">				&#123;</span><br><span class="line">					<span class="attr">name</span>:<span class="string">&quot;advertiseCategory&quot;</span>,</span><br><span class="line">					<span class="attr">path</span>:<span class="string">&quot;advertiseCategory&quot;</span>,</span><br><span class="line">					<span class="attr">component</span>:AdvertiseCategory,</span><br><span class="line">					<span class="attr">children</span>:[</span><br><span class="line">						&#123;</span><br><span class="line">							<span class="attr">name</span>:<span class="string">&quot;advertiseList&quot;</span>,</span><br><span class="line">							<span class="attr">path</span>:<span class="string">&quot;advertiseList&quot;</span>,</span><br><span class="line">							<span class="attr">component</span>:AdvertiseList</span><br><span class="line">						&#125;,</span><br><span class="line">						&#123;</span><br><span class="line">							<span class="attr">name</span>:<span class="string">&quot;advertiseMagage&quot;</span>,</span><br><span class="line">							<span class="attr">path</span>:<span class="string">&quot;advertiseMagage&quot;</span>,</span><br><span class="line">							<span class="attr">component</span>:AdvertiseMagage</span><br><span class="line">						&#125;</span><br><span class="line">					]</span><br><span class="line">				&#125;</span><br><span class="line">			]</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="attr">path</span>:<span class="string">&#x27;/login&#x27;</span>,</span><br><span class="line">			<span class="attr">component</span>:Login</span><br><span class="line">		&#125;</span><br><span class="line">	]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在 Element UI 中进行路由联动的属性为 <code>router</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*default-active 用于根据路由 选择高亮哪一个*/        </span><br><span class="line">&lt;el-menu default-active=&quot;$route.path&quot; router class=&quot;el-menu-vertical-demo&quot; :collapse=&quot;isCollapse&quot;   </span><br><span class="line">        background-color= &quot;#252236&quot;</span><br><span class="line">        text-color=&quot;#fff&quot;</span><br><span class="line">        active-text-color=&quot;#ffd04b&quot; &gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/router.png" alt=""></p>
<p>所以我们需要修改后面的 index 索引来配置路由，其实挺简单的</p>
<p>如下所示为 menu组件中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- 点击跳转的路由 产品管理为 home  二级路由--&gt;</span><br><span class="line">&lt;el-submenu index=&quot;/goodsManage&quot;&gt;</span><br><span class="line">    &lt;template slot=&quot;title&quot;&gt;</span><br><span class="line">        &lt;i class=&quot;el-icon-location&quot;&gt;&lt;/i&gt;</span><br><span class="line">        &lt;span slot=&quot;title&quot;&gt;产品管理&lt;/span&gt;</span><br><span class="line">    &lt;/template&gt;</span><br><span class="line">    &lt;!-- 点击跳转的路由   三级路由--&gt;</span><br><span class="line">    &lt;el-menu-item-group&gt;</span><br><span class="line">        &lt;el-menu-item index=&quot;/goodsManage/goodsList&quot;&gt;产品列表&lt;/el-menu-item&gt;</span><br><span class="line">        &lt;el-menu-item index=&quot;/goodsManage/goodsCategory&quot;&gt;产品分类&lt;/el-menu-item&gt;</span><br><span class="line">    &lt;/el-menu-item-group&gt;</span><br><span class="line">&lt;/el-submenu&gt;</span><br></pre></td></tr></table></figure>
<h2 id="实现上方菜单导航折叠"><a href="#实现上方菜单导航折叠" class="headerlink" title="实现上方菜单导航折叠"></a>实现上方菜单导航折叠</h2><ul>
<li><p>首先修改 content.vue 中的 顶部区域 header 添加标签效果，并配置样式</p>
</li>
<li><p>另外左侧 Menu.vue 你会发现有空隙，你查看css样式，发现导航栏被渲染为li了，里面有个 border。你需要修改：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.el-menu</span>&#123;</span><br><span class="line">    <span class="attribute">border-right</span>: <span class="number">0px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>而后导航的折叠，其实是由 Element UI 中的一个属性 collapse   所决定的</p>
<p><code>collapse   是否水平折叠收起菜单（仅在 mode 为 vertical 时可用）  boolean —  false</code></p>
<p>所以我们动态的 修改collapse 就可以实现这个效果。</p>
<p>不过这涉及到 子组件中的通信</p>
<ul>
<li><p>iscollapse 属性写在父组件 layout.vue中，传递给 menu组件。 menu组件可 v-model动态判断</p>
</li>
<li><p>在content组件标签上，父组件需要挂载一个 <strong>自定义事件</strong> , 这里让这个事件去修改 iscollapse 的状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Content @OperateCollapse=&quot;OperateCollapse()&quot; &gt;&lt;/Content&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在content组件中 触发函数中去调用他，这里不用传递参数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">changeMenu</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">	<span class="built_in">this</span>.$emit(<span class="string">&#x27;OperateCollapse&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>另外要实现点击改变 样式的效果 这里使用了一个 动态 class  <code>:class=&quot;&#123;active:isCollapse&#125;</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;content&quot; :class=&quot;&#123;active:isCollapse&#125;&quot;&gt;</span><br><span class="line">   &lt;Content @OperateCollapse=&quot;OperateCollapse()&quot;  :isCollapse=&quot;isCollapse&quot; &gt;</span><br><span class="line">   &lt;/Content&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.content</span>&#123;</span><br><span class="line">  <span class="attribute">padding-left</span>: <span class="number">200px</span>;</span><br><span class="line">  <span class="comment">/* transition: all 1s; */</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*被触发的时候 改变 padding-left*/</span></span><br><span class="line"><span class="selector-class">.active</span>&#123;</span><br><span class="line">  <span class="attribute">padding-left</span>: <span class="number">64px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="实现上方右侧的-当前时间"><a href="#实现上方右侧的-当前时间" class="headerlink" title="实现上方右侧的 当前时间"></a>实现上方右侧的 当前时间</h3><p>需要用到  day.js 库  官网： <a href="https://dayjs.fenxianglu.cn/">https://dayjs.fenxianglu.cn/</a></p>
<p>具体安装看 我的安装笔记，用法也同安装里写的一样。</p>
<p>如下 获取我们想要的时间，不过这还是静态数据，插值语法引入界面，是不会动的。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">this</span>.nowTime = dayjs(<span class="keyword">new</span> <span class="built_in">Date</span>()).format(<span class="string">&#x27;YYYY-MM-DD HH:mm:ss&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="实现后端部署"><a href="#实现后端部署" class="headerlink" title="实现后端部署"></a>实现后端部署</h3><p>涉及到 express </p>
<p>首先要先配置  index.js 其涉及到 express 创建本地服务器 </p>
<p>server 文件夹里面的所有东西 <strong>这里我直接全复制过来了，不懂这个的编写</strong>  ，需要先把没讲到的注释掉，这个看 nodemon 报错就好了，注掉需要下载的东西和对应的路由。</p>
<p>vscode 控制台路径 到 server文件夹 </p>
<p>需要下载 库 <code>nodemon</code>  进行全局配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install nodemon -g</span><br></pre></td></tr></table></figure>
<p>然后在命令行中输入  <code>nodemon</code> ，就会打开 定义的 9898端口</p>
<p>使用 <code>http://localhost:9898/home/dataCount</code>  做个测试，出来就 ok</p>
<h2 id="实现主页首页"><a href="#实现主页首页" class="headerlink" title="实现主页首页"></a>实现主页首页</h2><h3 id="实现顶部数据统计信息"><a href="#实现顶部数据统计信息" class="headerlink" title="实现顶部数据统计信息"></a>实现顶部数据统计信息</h3><p>首先需要在 src 中 创建一个  api 文件， 并在其中创建文件 base.js  和  index.js</p>
<ul>
<li>base.js 映射了之前 在 server 中配置的 接口路由</li>
<li>index.js 根据base.js 提供的接口路由地址，使用 axios get 获取数据，并封装到对应的方法中，用于调用</li>
</ul>
<p>而后 我们需要在 入口文件 main.js 中引入 index.js 中的 api，自己写项目的话需要自己写哦。</p>
<p>在 home 组件中我们需要请求数据 配置 axios 请求</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">    <span class="attr">name</span>:<span class="string">&quot;HomeVue&quot;</span>,</span><br><span class="line">    <span class="function"><span class="title">data</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">      <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="attr">objCount</span>:[]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment">// 防止数据还没有请求过来 显示为空的情况</span></span><br><span class="line">    <span class="attr">filters</span>: &#123;</span><br><span class="line">      <span class="function"><span class="title">num</span>(<span class="params">val</span>)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!val) <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">        <span class="keyword">return</span> val.toLocaleString();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="title">mounted</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="comment">//-获取顶部统计数据信息</span></span><br><span class="line">        <span class="built_in">this</span>.getHomeCount();</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">methods</span>:&#123;</span><br><span class="line">      <span class="comment">//-获取顶部统计数据信息----------------------------------------</span></span><br><span class="line">      <span class="keyword">async</span> <span class="function"><span class="title">getHomeCount</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.getHomeCount()</span><br><span class="line">        <span class="built_in">console</span>.log(res.data.data.list);</span><br><span class="line">        <span class="built_in">this</span>.objCount = res.data.data.list;</span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而后 上面使用 对objCount 使用插值语法就可以了。</p>
<p>作者这里 Mock.js 产生的数据格式有点问题，一个list就包含这8个值了。</p>
<p> 另外他还配置了一个 过滤器 filter，所以其插值语法，举个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div class=&#x27;num&#x27;&gt;&#123;&#123;objCount.saleTotal  | num&#125;&#125;&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<h3 id="用-echarts-画图"><a href="#用-echarts-画图" class="headerlink" title="用 echarts 画图"></a>用 echarts 画图</h3><p>将原项目中 plugins 里的 echarts 整个包 复制到 我这里的 plugin中</p>
<p>在 入口文件 main.js 中引入</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> echarts <span class="keyword">from</span> <span class="string">&#x27;echarts&#x27;</span>;</span><br><span class="line"><span class="comment">// 身上就会挂载一个  $myEcharts</span></span><br><span class="line">Vue.use(echarts)</span><br></pre></td></tr></table></figure>
<p>去 echarts 官网中 查看完整代码</p>
<p>在 Home.vue中 引入 echarts 整个引入就好了</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> echarts <span class="keyword">from</span> <span class="string">&#x27;echarts&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>然后折线图绘制的代码，写在methods里</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 绘制折线图</span></span><br><span class="line"><span class="function"><span class="title">drawline</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">  <span class="comment">// 需要绘制的区域</span></span><br><span class="line">  <span class="keyword">var</span> chartDom = <span class="built_in">document</span>.getElementById(<span class="string">&#x27;main&#x27;</span>);</span><br><span class="line">  <span class="keyword">var</span> myChart = echarts.init(chartDom);</span><br><span class="line">  <span class="keyword">var</span> option;</span><br><span class="line"></span><br><span class="line">  option = &#123;</span><br><span class="line">    <span class="attr">xAxis</span>: &#123;</span><br><span class="line">      <span class="attr">type</span>: <span class="string">&#x27;category&#x27;</span>,</span><br><span class="line">      <span class="attr">data</span>: [<span class="string">&#x27;Mon&#x27;</span>, <span class="string">&#x27;Tue&#x27;</span>, <span class="string">&#x27;Wed&#x27;</span>, <span class="string">&#x27;Thu&#x27;</span>, <span class="string">&#x27;Fri&#x27;</span>, <span class="string">&#x27;Sat&#x27;</span>, <span class="string">&#x27;Sun&#x27;</span>]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">yAxis</span>: &#123;</span><br><span class="line">      <span class="attr">type</span>: <span class="string">&#x27;value&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">series</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">data</span>: [<span class="number">820</span>, <span class="number">932</span>, <span class="number">901</span>, <span class="number">934</span>, <span class="number">1290</span>, <span class="number">1330</span>, <span class="number">1320</span>],</span><br><span class="line">        <span class="attr">type</span>: <span class="string">&#x27;line&#x27;</span>,</span><br><span class="line">        <span class="attr">smooth</span>: <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  option &amp;&amp; myChart.setOption(option);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同理画饼图也是一样的操作。</p>
<p>获取数据</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 绘制 Mock.js 模拟数据 的折线图</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">getHomeFormat</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.getHomeFormat()</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;-获取绘制折线图--------&#x27;</span>, res.data.result.data.sale_money);</span><br><span class="line">    <span class="keyword">let</span> arr = res.data.result.data.sale_money;</span><br><span class="line">    <span class="comment">//声明变量存储x轴 y轴数据</span></span><br><span class="line">    <span class="keyword">let</span> xData = [], yData = [], yBarData = [], pieData = [];</span><br><span class="line">    arr.forEach(<span class="function"><span class="params">ele</span> =&gt;</span> &#123;</span><br><span class="line">        xData.push(ele.name)</span><br><span class="line">        yData.push(ele.total_amount)</span><br><span class="line">        yBarData.push(ele.num)</span><br><span class="line">        <span class="comment">//获取对象结构存储饼图数据-----</span></span><br><span class="line">        <span class="keyword">let</span> obj = &#123;&#125;</span><br><span class="line">        obj.name = ele.name;</span><br><span class="line">        obj.value = ele.total_amount;</span><br><span class="line">        pieData.push(obj)</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">// 绘制折线图---动态数据---------------</span></span><br><span class="line">    <span class="built_in">this</span>.drawline(xData, yData, yBarData);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 绘制饼图--动态数据-------[&#123;name:&#x27;&#x27;,value:&#x27;&#x27;&#125;,&#123;&#125;]----</span></span><br><span class="line">    <span class="built_in">this</span>.drawPie(pieData)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p>看着将数据填充入 echarts中，并修改一些属性就可以了。</p>
<p>然后再 mounted 生命周期函数中使用</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">mounted</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">//-获取顶部统计数据信息</span></span><br><span class="line">    <span class="built_in">this</span>.getHomeCount()</span><br><span class="line">    <span class="comment">// 获取数据并 绘制折线图和饼图</span></span><br><span class="line">    <span class="built_in">this</span>.getHomeFormat()</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<h3 id="实现下方的订单"><a href="#实现下方的订单" class="headerlink" title="实现下方的订单"></a>实现下方的订单</h3><p>这个通过接口获取数据 添加到data中  很简单</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取订单数据</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">getHomeOrder</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.getHomeOrder()</span><br><span class="line">    <span class="built_in">this</span>.Orderlist = res.data.list</span><br></pre></td></tr></table></figure>
<p>然后插值语法显示即可</p>
<h3 id="实现产品管理"><a href="#实现产品管理" class="headerlink" title="实现产品管理"></a>实现产品管理</h3><h4 id="实现产品分类页面"><a href="#实现产品分类页面" class="headerlink" title="实现产品分类页面"></a>实现产品分类页面</h4><p>这个页面没啥好说的 就是引 elementUI，然后显示和查询特定都是有接口的</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">created</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.getGoodsList(<span class="number">1</span>)</span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">methods</span>: &#123;</span><br><span class="line">    <span class="comment">// 根据产品名称 查询数据</span></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="title">getGoodsList</span>(<span class="params">page</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.getGoodsList(&#123;page&#125;)</span><br><span class="line">        <span class="built_in">console</span>.log(res.data)</span><br><span class="line">        <span class="keyword">if</span>(res.data.status === <span class="number">200</span>)&#123;</span><br><span class="line">            <span class="built_in">this</span>.tableData = res.data.data</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            alert(<span class="string">&quot;请求产品数据失败&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>就这个表单中 <strong>prop 指的是 tableData中直接的键</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;list-table&quot;&gt;</span><br><span class="line">    &lt;el-table</span><br><span class="line">    :data=&quot;tableData&quot;</span><br><span class="line">    border</span><br><span class="line">    style=&quot;width: 100%&quot;&gt;</span><br><span class="line">    &lt;el-table-column</span><br><span class="line">      type=&quot;selection&quot;</span><br><span class="line">      width=&quot;55&quot;&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;id&quot; label=&quot;商品ID&quot; width=&quot;100&quot;&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;title&quot; label=&quot;商品名称&quot; width=&quot;180&quot;&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;price&quot; label=&quot;商品价格&quot; width=&quot;100&quot;&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;num&quot; label=&quot;商品数量&quot; width=&quot;180&quot;&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;category&quot; label=&quot;商品类目&quot; width=&quot;100&quot;&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;image&quot; label=&quot;商品图片&quot; width=&quot;180&quot; &gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;sellPoint&quot; label=&quot;商品卖点&quot; width=&quot;180&quot;  show-overflow-tooltip&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column prop=&quot;descs&quot; label=&quot;商品描述&quot; width=&quot;180&quot; show-overflow-tooltip&gt;</span><br><span class="line">    &lt;/el-table-column&gt;</span><br><span class="line">    &lt;el-table-column label=&quot;操作&quot;&gt;</span><br><span class="line">      &lt;template slot-scope=&quot;scope&quot;&gt;</span><br><span class="line">        &lt;el-button</span><br><span class="line">          size=&quot;mini&quot;</span><br><span class="line">          type=&quot;primary&quot;</span><br><span class="line">          icon=&quot;el-icon-edit&quot;</span><br><span class="line">          @click=&quot;handleEdit(scope.$index, scope.row)&quot;&gt;编辑&lt;/el-button&gt;</span><br><span class="line">        &lt;el-button</span><br><span class="line">          size=&quot;mini&quot;</span><br><span class="line">          type=&quot;danger&quot;</span><br><span class="line">          icon=&quot;el-icon-delete&quot;</span><br><span class="line">          @click=&quot;handleDelete(scope.$index, scope.row)&quot;&gt;删除&lt;/el-button&gt;</span><br><span class="line">      &lt;/template&gt;</span><br><span class="line">  &lt;/el-table-column&gt;</span><br><span class="line">  &lt;/el-table&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<h4 id="实现公共分页器"><a href="#实现公共分页器" class="headerlink" title="实现公共分页器"></a>实现公共分页器</h4><p>另外比较特殊的就是实现分页器，因为后面每个页面都需要用到。</p>
<p>所以分页器是一个  components。</p>
<p>再 components 文件夹中创建 Pagination 文件夹，里面创建一个 pagination.vue</p>
<p>这个分页器同样是由 element UI 来做</p>
<p>主要有两个功能</p>
<ol>
<li><p>我请求的数据分页每个多少个啊 总共多少啊  goodList.vue 需要传递给 pagination.vue 当然采用的是 props 因为是父传子</p>
</li>
<li><p>然后子这边页面发生变化 ，elementUi提供的方法为 <code>@current-change=&quot;getPagination&quot;</code>，绑定我们的自定义事件<code>getPagination</code>，这个事件应该把 再子组件中的数据传给父组件。可以使用自定义事件，再getPagination方法中我们触发自定义事件</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// current 为当前页</span></span><br><span class="line"><span class="function"><span class="title">getPagination</span>(<span class="params">current</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.$emit(<span class="string">&#x27;getPagination&#x27;</span>,current)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那对应的 父组件中 注册子组件的标签上 应该配有自定义事件 <code>getPagination</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- 部分三 ：分页器组件部分 --&gt;</span><br><span class="line">&lt;pagination :totalPage=&quot;totalPage&quot; :pageSize=&quot;pageSize&quot; @getPagination=&quot;getPagination&quot;&gt;&lt;/pagination&gt;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取点击页码：</span></span><br><span class="line"><span class="function"><span class="title">getPagination</span>(<span class="params">page</span>)</span>&#123;</span><br><span class="line">    <span class="comment">//默认产品列表的分页功能</span></span><br><span class="line">    <span class="built_in">this</span>.getGoodsList(page)</span><br><span class="line">&#125;,</span><br><span class="line">    <span class="comment">// 根据页面 查询数据</span></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="title">getGoodsList</span>(<span class="params">page</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.getGoodsList(&#123;page&#125;)</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;表单数据 res.data&quot;</span>, res.data)</span><br><span class="line">        <span class="keyword">if</span>(res.data.status === <span class="number">200</span>)&#123;</span><br><span class="line">            <span class="built_in">this</span>.tableData = res.data.data</span><br><span class="line">            <span class="built_in">this</span>.totalPage = res.data.total</span><br><span class="line">            <span class="built_in">this</span>.pageSize = res.data.pageSize</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            alert(<span class="string">&quot;请求产品数据失败&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure>
<h4 id="实现搜索产品名-显示数据功能"><a href="#实现搜索产品名-显示数据功能" class="headerlink" title="实现搜索产品名 显示数据功能"></a>实现搜索产品名 显示数据功能</h4><p>查询其实就是 调用接口很简单，这里要注意 传过去的对象，键一定要是 research</p>
<p>另外就是 有一些特殊的情况，例如如果查出来的数据是大于 页面容量8的话，需要截断显示。</p>
<p>接口调用如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据产品名称 查询数据</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">getGoodsSearch</span>(<span class="params">goodsName</span>)</span>&#123;</span><br><span class="line">    <span class="comment">// let res = await this.$api.getGoodsSearch(&#123;goodsName&#125;)</span></span><br><span class="line">    <span class="comment">//   console.log(res.data)</span></span><br><span class="line">    <span class="comment">// if(res.data.status === 200)&#123;</span></span><br><span class="line">    <span class="comment">//   console.log(res.data)</span></span><br><span class="line">    <span class="comment">// &#125;else&#123;</span></span><br><span class="line">    <span class="comment">//   alert(&quot;没有这个表单数据&quot;)</span></span><br><span class="line">    <span class="built_in">this</span>.$api.getGoodsSearch(&#123;<span class="attr">search</span>:goodsName&#125;)</span><br><span class="line">    .then(<span class="function"><span class="params">res</span> =&gt;</span>&#123;</span><br><span class="line">      <span class="built_in">console</span>.log(res.data)</span><br><span class="line">      <span class="keyword">if</span>(res.data.status == <span class="number">200</span>)&#123;</span><br><span class="line">        <span class="built_in">this</span>.listTotal = res.data.result</span><br><span class="line">        <span class="comment">// 我拿到的数据是 如果超过页面上线 就要分页 </span></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">this</span>.listTotal.length &gt; <span class="number">8</span>)&#123;</span><br><span class="line">          <span class="comment">// 截取出8个 作为第一页展示</span></span><br><span class="line">          <span class="built_in">this</span>.tableData = res.data.result.slice(<span class="number">0</span>,<span class="number">8</span>)</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">          <span class="built_in">this</span>.totalPage = res.data.result.length</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">this</span>.pageSize = <span class="built_in">Math</span>.min(<span class="number">8</span>, <span class="built_in">this</span>.pageSize)</span><br><span class="line">      &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">// 啥数据没查出来 就是空</span></span><br><span class="line">        <span class="built_in">this</span>.tableData = []</span><br><span class="line">        <span class="built_in">this</span>.totalPage = <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    .catch( <span class="function"><span class="params">err</span> =&gt;</span>&#123;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">&quot;请求失败&quot;</span>, err.data)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;,</span><br><span class="line"><span class="function"><span class="title">onSubmit</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span>(!<span class="built_in">this</span>.formInline.goodsName)&#123;</span><br><span class="line">      <span class="built_in">this</span>.$message.error(<span class="string">&#x27;请输入信息再去搜索&#x27;</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">this</span>.getGoodsSearch(<span class="built_in">this</span>.formInline.goodsName)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p>另外又有一个新的bug，就是我如果截取了前8个，剩下点第二页的时候，由于前面的事件绑定是显示全部数据的第二页，此时我应该显示的是查询剩下的内容。</p>
<p>我们在 data 中添加一个 searchStatus 用来标识，我是不是处于查询状态</p>
<p>然后根据状态执行对应修改页码的逻辑即可，分页逻辑是归纳的</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取点击页码：</span></span><br><span class="line"><span class="function"><span class="title">getPagination</span>(<span class="params">page</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!<span class="built_in">this</span>.seachStatus)</span><br><span class="line">        <span class="comment">//默认产品列表的分页功能</span></span><br><span class="line">        <span class="built_in">this</span>.getGoodsList(page)</span><br><span class="line">    <span class="comment">// 在查询状态下，显示查询剩余内容</span></span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">// 0-7 8-15 </span></span><br><span class="line">        <span class="built_in">this</span>.tableData = <span class="built_in">this</span>.listTotal.slice((page - <span class="number">1</span>) * <span class="number">8</span>, page * <span class="number">8</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<h4 id="实现选择时间的格式修改"><a href="#实现选择时间的格式修改" class="headerlink" title="实现选择时间的格式修改"></a>实现选择时间的格式修改</h4><p>时间需要进行格式的转换，这里还是使用 dayJS</p>
<p>首先需要先 导入 dayJS</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dayjs <span class="keyword">from</span> <span class="string">&quot;dayjs&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后由于 el-table-colum 属性的title 是由prop 这个属性来定义的，不能修改，可以再下面使用template进行修改，例如如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;el-table-column label=&quot;载入时间&quot; width=&quot;180&quot;&gt;</span><br><span class="line">  &lt;!--prop=&quot;create_time&quot;  prop获取列字段标识/template  slot-scope=&quot;scope&quot;当前作用域下 scope获取当前行的数据信息 --&gt;</span><br><span class="line">   &lt;template slot-scope=&quot;scope&quot;&gt;</span><br><span class="line">  &#123;&#123; dayjs(scope.row.create_time).format(&#x27;YYYY-MM-DD HH:mm:ss&#x27;) &#125;&#125; </span><br><span class="line">  &lt;/template&gt;</span><br><span class="line">&lt;/el-table-column&gt;</span><br></pre></td></tr></table></figure>
<h4 id="实现删除商品-指的是每一行的右侧"><a href="#实现删除商品-指的是每一行的右侧" class="headerlink" title="实现删除商品 指的是每一行的右侧"></a>实现删除商品 指的是每一行的右侧</h4><font color="red">我现在的实现有问题 得以后解决，因为我现在没有第5页数据了，我得学会了添加才能回来再试对不对</font>

<p>触发删除的按钮为 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;el-button</span><br><span class="line">           size=&quot;mini&quot;</span><br><span class="line">           type=&quot;danger&quot;</span><br><span class="line">           icon=&quot;el-icon-delete&quot;</span><br><span class="line">           @click=&quot;handleDelete(scope.$index, scope.row)&quot;&gt;删除&lt;/el-button&gt;</span><br></pre></td></tr></table></figure>
<p>定义这个函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 实现 数据某一行 删除方法</span></span><br><span class="line"><span class="function"><span class="title">handleDelete</span>(<span class="params">index, row</span>)</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(index, row);</span><br><span class="line">  <span class="built_in">this</span>.$confirm(<span class="string">&#x27;确定删除这一行的商品数据?&#x27;</span>, <span class="string">&#x27;提示&#x27;</span>, &#123;</span><br><span class="line">    <span class="attr">confirmButtonText</span>: <span class="string">&#x27;确定&#x27;</span>,</span><br><span class="line">    <span class="attr">cancelButtonText</span>: <span class="string">&#x27;取消&#x27;</span>,</span><br><span class="line">    <span class="attr">type</span>: <span class="string">&#x27;warning&#x27;</span></span><br><span class="line">  &#125;).then(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// 删除这个数据  这里就是请求后端的删除接口</span></span><br><span class="line">    <span class="built_in">this</span>.deleteItemById(row.id)</span><br><span class="line">    <span class="comment">// 删除成功了之后 应该重新渲染页面 dom</span></span><br><span class="line">    <span class="comment">// 理论上现在是第几页 就重新再渲染一次第几页</span></span><br><span class="line">    <span class="comment">// 要考虑到这次删掉是最后一条，那我应该跳到上一页</span></span><br><span class="line">    <span class="comment">// 这个判断需要判断 我删除之后 此时条的总数是不是 pageSize 的倍数，是的话就应该渲染上一页</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.tableData.length % <span class="built_in">this</span>.pageSize == <span class="number">0</span>)</span><br><span class="line">      <span class="built_in">this</span>.getGoodsList(<span class="built_in">this</span>.currentPage - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">this</span>.getGoodsList(<span class="built_in">this</span>.currentPage)</span><br><span class="line"></span><br><span class="line">  &#125;).catch(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.$message(&#123;</span><br><span class="line">      <span class="attr">type</span>: <span class="string">&#x27;info&#x27;</span>,</span><br><span class="line">      <span class="attr">message</span>: <span class="string">&#x27;已取消删除&#x27;</span></span><br><span class="line">    &#125;);          </span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中定义了 删除数据接口 <code>deleteItemById</code></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 删除数据的接口 ------</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">deleteItemById</span>(<span class="params">id</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.deleteGoods(&#123;id&#125;)</span><br><span class="line">    <span class="keyword">if</span>(res.data.status == <span class="number">200</span>)&#123;</span><br><span class="line">        <span class="built_in">this</span>.$message(&#123;</span><br><span class="line">            <span class="attr">type</span>: <span class="string">&#x27;success&#x27;</span>,</span><br><span class="line">            <span class="attr">message</span>: <span class="string">&#x27;删除成功!&#x27;</span></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="实现数据的添加页面"><a href="#实现数据的添加页面" class="headerlink" title="实现数据的添加页面"></a>实现数据的添加页面</h4><h5 id="先配置路由"><a href="#先配置路由" class="headerlink" title="先配置路由"></a>先配置路由</h5><p>数据添加是一个新的页面，逻辑上应该是 点击添加商品按钮后，跳转到新的页面</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;el-button type=&quot;warning&quot; icon=&quot;el-icon-check&quot;  @click=&quot;toProductPage() &quot;&gt;添加商品&lt;/el-button&gt;</span><br></pre></td></tr></table></figure>
<p>并再 GoodList 文件中 再创建一个 <code>goodsAddPage.vue</code></p>
<p>然后需要配置路由，打开 router 的 index.js 中配置在 goodsManage下配置一个新的子路由</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">name</span>:<span class="string">&quot;goodsAddPage&quot;</span>,</span><br><span class="line">    <span class="attr">pat</span>:<span class="string">&quot;goodsAddPage&quot;</span>,</span><br><span class="line">    <span class="attr">component</span>:GoodsAddPage</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/配置路由.png" style="zoom:50%;" /></p>
<p>配置 click 方法</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 点击跳转 增添商品页面 ++++</span></span><br><span class="line"><span class="function"><span class="title">togoodsAddPage</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.$router.push(<span class="string">&quot;/goodsManage/goodsAddPage&quot;</span>)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<h5 id="配置数据添加页面"><a href="#配置数据添加页面" class="headerlink" title="配置数据添加页面"></a><font color="orange">配置数据添加页面</font></h5><p>碰到一个问题就是，我这个路由并没有在左侧的 导航栏中有对应的 index高亮。我们还是想要在产品列表对应高亮，所以这个怎么办呢？</p>
<p>首先应该在路由中配置 <strong>meta</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">name</span>:<span class="string">&quot;goodsAddPage&quot;</span>,</span><br><span class="line">    <span class="attr">path</span>:<span class="string">&quot;goodsAddPage&quot;</span>,</span><br><span class="line">    <span class="attr">component</span>:GoodsAddPage,</span><br><span class="line">    <span class="attr">meta</span>:&#123; <span class="comment">// 配置高亮标识 对应的路由路径</span></span><br><span class="line">          <span class="attr">activeMenu</span>:<span class="string">&quot;/goodsManage/goodsList&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>做法：当目前的访问path 为<code>/goodsManage/goodsAddPage</code>时，我会自动的先变成 <code>/goodsManage/goodsList</code>。 这样我的 Menu 激活就能实现了。</strong></p>
<p>刷新并且打印这个添加页面的 $route，你可以看到此页面是存在 meta的。</p>
<p>我们就利用这个东西，来实现上面的变换功能。</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/meta.png" style="zoom:50%;" /></p>
<font color="red">**这里实现方式，是使用 `watch` 来监听路由的变化，获取 meta 里的值。**</font>

<p>在 <strong>Menu.vue</strong> 中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">watch:&#123;</span><br><span class="line">    $route(to, <span class="keyword">from</span>)&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;watch--to&quot;</span>, to)</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;watch--from&quot;</span>, <span class="keyword">from</span>)</span><br><span class="line">        <span class="comment">// 判断当前的路由里面 meta 中是否有值</span></span><br><span class="line">        <span class="comment">// 我只拿里面的 meta 和 path</span></span><br><span class="line">        <span class="keyword">let</span> &#123;meta, path&#125; = to</span><br><span class="line">        <span class="built_in">console</span>.log()</span><br><span class="line">        <span class="keyword">if</span>(meta.activeMenu)&#123;</span><br><span class="line">            <span class="built_in">this</span>.active = meta.activeMenu</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">this</span>.active = path</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后将上面 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;el-menu :default-active=&quot;active&quot; router class=&quot;el-menu-vertical-demo&quot; :collapse = &quot;isCollapse&quot;   </span><br><span class="line">       background-color= &quot;#252236&quot;</span><br><span class="line">       text-color=&quot;#fff&quot;</span><br><span class="line">       active-text-color=&quot;#ffd04b&quot; &gt;</span><br></pre></td></tr></table></figure>
<font color="orange">**但是这样有个问题，就是刚进入的时候，menu的 active 会失效，因为watch 并没有监听到路由的改变。**</font>

<p>所以可以在 created()  中先初始化一下最初的状态</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">created</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.$route.meta.activeMenu)&#123;</span><br><span class="line">        <span class="built_in">this</span>.active = <span class="built_in">this</span>.$route.meta.activeMenu</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.active = <span class="built_in">this</span>.$route.path</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<h5 id="实现产品类型列表-的-树形菜单"><a href="#实现产品类型列表-的-树形菜单" class="headerlink" title="实现产品类型列表 的 树形菜单"></a>实现产品类型列表 的 树形菜单</h5><p>首先我们需要创建一个新的 vue组件，goodsTreeProdct.vue 。然后需要找到 Element UI 中的 树形菜单， 选择懒加载的组件。</p>
<p>将这个组件作为我们 goodsAddPage的子组件，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;nav&quot;&gt;</span><br><span class="line">    &lt;div class=&quot;title&quot;&gt;产品类型列表&lt;/div&gt;</span><br><span class="line">    &lt;div class=&quot;tree&quot;&gt;</span><br><span class="line">        &lt;goodsTreeProdct&gt;&lt;/goodsTreeProdct&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>具体属性需要看 Element 文案</p>
<p>我们需要实现的就是 每一层点击，都要进行一次数据后端读取 api 为 <code>this.$api.goodsItemCategory()</code>。整体该组件代码如下所示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">&lt;!-- </span><br><span class="line">    树状懒加载结构</span><br><span class="line">        show-checkbox 节点是否可被选择  boolean  默认为 false</span><br><span class="line">        props 配置选项 具体看下表   object</span><br><span class="line">            label	指定节点标签为节点对象的某个属性值	string, function(data, node)	—	—</span><br><span class="line">            children	指定子树为节点对象的某个属性值	string	—	—</span><br><span class="line">            disabled	指定节点选择框是否禁用为节点对象的某个属性值	boolean, function(data, node)	—	—</span><br><span class="line">            isLeaf	指定节点是否为叶子节点，仅在指定了 lazy 属性的情况下生效	boolean, function(data, node)	—	—</span><br><span class="line">        load  加载子树数据的方法，仅当 lazy 属性 为 true 时生效  并且其是一个函数 function(node, resolve)</span><br><span class="line">        lazy	是否懒加载子节点，需与 load 方法结合使用	boolean	—	false</span><br><span class="line"> --&gt;</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        &lt;el-tree</span><br><span class="line">        :props=&quot;props&quot;</span><br><span class="line">        :load=&quot;loadNode&quot;</span><br><span class="line">        lazy&gt;</span><br><span class="line">        &lt;/el-tree&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">  export default &#123;</span><br><span class="line">    data() &#123;</span><br><span class="line">      return &#123;</span><br><span class="line">        props: &#123;</span><br><span class="line">          label: &#x27;name&#x27;,</span><br><span class="line">          children: &#x27;zones&#x27;,</span><br><span class="line">          isLeaf: &#x27;leaf&#x27;</span><br><span class="line">        &#125;,</span><br><span class="line">      &#125;;</span><br><span class="line">    &#125;,</span><br><span class="line">    methods: &#123;</span><br><span class="line">      loadNode(node, resolve) &#123;</span><br><span class="line">        // 初始上来就是 第0层，然后展开第一层的内容</span><br><span class="line">        if (node.level === 0) &#123;</span><br><span class="line">          // 这个 data 应该来自于 ajax请求</span><br><span class="line">          // let data = [&#123; name: &#x27;region&#x27; &#125;]</span><br><span class="line">          this.$api.goodsItemCategory().then(</span><br><span class="line">              res =&gt; &#123;</span><br><span class="line">                if(res.data.status == 200)</span><br><span class="line">                  return resolve(res.data.result);  </span><br><span class="line">                else</span><br><span class="line">                  return resolve([])</span><br><span class="line">              &#125;</span><br><span class="line">          )</span><br><span class="line">        &#125;</span><br><span class="line">        if (node.level &gt;= 1) &#123;</span><br><span class="line">          // 请求下一级别</span><br><span class="line">          this.$api.goodsItemCategory(&#123;type:node.data.cid&#125;).then(</span><br><span class="line">              res =&gt; &#123;</span><br><span class="line">                if(res.data.status == 200)</span><br><span class="line">                  return resolve(res.data.result);  </span><br><span class="line">                else</span><br><span class="line">                  return resolve([])</span><br><span class="line">              &#125;</span><br><span class="line">          )</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line"></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">  &#125;;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>
<h5 id="实现产品类型列表-的-右侧添加表单"><a href="#实现产品类型列表-的-右侧添加表单" class="headerlink" title="实现产品类型列表 的 右侧添加表单"></a>实现产品类型列表 的 右侧添加表单</h5><h6 id="用全局总线来实现-左侧分类右侧显示"><a href="#用全局总线来实现-左侧分类右侧显示" class="headerlink" title="用全局总线来实现 左侧分类右侧显示"></a>用全局总线来实现 左侧分类右侧显示</h6><p>首先第一行这个 所属分类，我们需要拿到左侧导航栏这个node的名称。在element的回调方法中有 <code>@node-click = &quot;clickHandle&quot;</code>，我们配置自定义函数 clickHandle，<strong>用来触发全局总线传递数据（因为这里是 子传子）</strong></p>
<p>在 树结构Vue中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 点击tree的节点触发的事件</span></span><br><span class="line"><span class="function"><span class="title">clickHandle</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.$bus.$emit(<span class="string">&#x27;sendTreeNode&#x27;</span>,data)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p>在  FormVue 组件中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">mounted</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.$bus.$on(<span class="string">&#x27;sendTreeNode&#x27;</span>,<span class="built_in">this</span>.sendTreeNode)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="然后右侧表单整体的布局需要修改为需要效果"><a href="#然后右侧表单整体的布局需要修改为需要效果" class="headerlink" title="然后右侧表单整体的布局需要修改为需要效果"></a>然后右侧表单整体的布局需要修改为需要效果</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;el-form :model=&quot;ruleForm&quot; :rules=&quot;rules&quot; ref=&quot;ruleForm&quot; label-width=&quot;100px&quot; class=&quot;demo-ruleForm&quot;&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;所属分类&quot; prop=&quot;name&quot;&gt;</span><br><span class="line">            &#123;&#123;ruleForm.category&#125;&#125;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;商品名称&quot; prop=&quot;title&quot;&gt;</span><br><span class="line">            &lt;el-input v-model=&quot;ruleForm.title&quot;&gt;&lt;/el-input&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;商品价格&quot; prop=&quot;price&quot;&gt;</span><br><span class="line">            &lt;el-input v-model=&quot;ruleForm.price&quot;&gt;&lt;/el-input&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;商品数量&quot; prop=&quot;num&quot;&gt;</span><br><span class="line">            &lt;el-input v-model=&quot;ruleForm.num&quot;&gt;&lt;/el-input&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;商品卖点&quot; prop=&quot;sellPoint&quot;&gt;</span><br><span class="line">            &lt;el-input v-model=&quot;ruleForm.sellPoint&quot;&gt;&lt;/el-input&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;上传图片&quot; prop=&quot;image&quot;&gt;</span><br><span class="line">            &lt;!-- &lt;GoodsUpload @sendImage=&quot;sendImage&quot; :fileList=&quot;fileList&quot;&gt;&lt;/GoodsUpload&gt; --&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;商品描述&quot; prop=&quot;descs&quot;&gt;</span><br><span class="line">            &lt;!-- 富文本编辑器 --&gt;</span><br><span class="line">            &lt;!-- &lt;WangEditor @sendEditor=&quot;sendEditor&quot; :editorData=&quot;editor&quot; ref=&quot;myEditor&quot;&gt;&lt;/WangEditor&gt; --&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;首页轮播推荐&quot; prop=&quot;isBanner&quot;&gt;</span><br><span class="line">            &lt;el-switch v-model=&quot;ruleForm.isBanner&quot; active-color=&quot;#13ce66&quot;&gt;&lt;/el-switch&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;是否推荐商品&quot; prop=&quot;recommend&quot;&gt;</span><br><span class="line">            &lt;el-switch v-model=&quot;ruleForm.recommend&quot; active-color=&quot;#13ce66&quot;&gt;&lt;/el-switch&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item label=&quot;是否上架商品&quot; prop=&quot;shelves&quot;&gt;</span><br><span class="line">            &lt;el-switch v-model=&quot;ruleForm.shelves&quot; active-color=&quot;#13ce66&quot;&gt;&lt;/el-switch&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">        &lt;el-form-item&gt;</span><br><span class="line">            &lt;el-button v-show=&quot;ruleForm.title!=&#x27;详情&#x27;&quot; type=&quot;primary&quot; @click=&quot;submitForm(&#x27;ruleForm&#x27;)&quot;&gt;保存&lt;/el-button&gt;</span><br><span class="line">            &lt;el-button  v-show=&quot;ruleForm.title!=&#x27;详情&#x27;&quot;  @click=&quot;resetForm(&#x27;ruleForm&#x27;)&quot;&gt;重置&lt;/el-button&gt;</span><br><span class="line">            &lt;el-button @click=&quot;goGoodsList()&quot; type=&quot;info&quot; plain&gt;取消&lt;/el-button&gt;</span><br><span class="line">        &lt;/el-form-item&gt;</span><br><span class="line">    &lt;/el-form&gt;</span><br></pre></td></tr></table></figure>
<p>其中data的内容为</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">data</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="attr">ruleForm</span>: &#123;</span><br><span class="line">          <span class="attr">category</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">          <span class="attr">title</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">          <span class="attr">price</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">          <span class="attr">num</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">          <span class="attr">sellPoint</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">          <span class="attr">image</span>: [],</span><br><span class="line">          <span class="attr">descs</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">          <span class="attr">isBanner</span>: <span class="literal">true</span>,<span class="comment">//轮推荐</span></span><br><span class="line">          <span class="attr">recommend</span>: <span class="literal">true</span>,<span class="comment">//推荐</span></span><br><span class="line">          <span class="attr">shelves</span>: <span class="literal">true</span>,<span class="comment">//商品上架</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">rules</span>: &#123;</span><br><span class="line">          <span class="attr">title</span>: [</span><br><span class="line">            &#123; <span class="attr">required</span>: <span class="literal">true</span>, <span class="attr">message</span>: <span class="string">&#x27;请输入商品名称&#x27;</span>, <span class="attr">trigger</span>: <span class="string">&#x27;blur&#x27;</span> &#125;,</span><br><span class="line">            &#123; <span class="attr">min</span>: <span class="number">3</span>, <span class="attr">max</span>: <span class="number">5</span>, <span class="attr">message</span>: <span class="string">&#x27;长度在 3 到 5 个字符&#x27;</span>, <span class="attr">trigger</span>: <span class="string">&#x27;blur&#x27;</span> &#125;</span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">price</span>: [</span><br><span class="line">            &#123; <span class="attr">required</span>: <span class="literal">true</span>, <span class="attr">message</span>: <span class="string">&#x27;请输入产品的价格&#x27;</span>, <span class="attr">trigger</span>: <span class="string">&#x27;blur&#x27;</span> &#125;</span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">num</span>: [</span><br><span class="line">            &#123; <span class="attr">required</span>: <span class="literal">true</span>, <span class="attr">message</span>: <span class="string">&#x27;请输入产品的数量&#x27;</span>, <span class="attr">trigger</span>: <span class="string">&#x27;blur&#x27;</span> &#125;</span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">sellPoint</span>: [</span><br><span class="line">            &#123; <span class="attr">required</span>: <span class="literal">true</span>, <span class="attr">message</span>: <span class="string">&#x27;请输入商品的卖点&#x27;</span>, <span class="attr">trigger</span>: <span class="string">&#x27;blur&#x27;</span> &#125;</span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">type</span>: [</span><br><span class="line">            &#123; <span class="attr">type</span>: <span class="string">&#x27;array&#x27;</span>, <span class="attr">required</span>: <span class="literal">true</span>, <span class="attr">message</span>: <span class="string">&#x27;请至少选择一个活动性质&#x27;</span>, <span class="attr">trigger</span>: <span class="string">&#x27;blur&#x27;</span> &#125;</span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">descs</span>: [</span><br><span class="line">            &#123; <span class="attr">required</span>: <span class="literal">true</span>, <span class="attr">message</span>: <span class="string">&#x27;请输入商品的描述&#x27;</span>, <span class="attr">trigger</span>: <span class="string">&#x27;blur&#x27;</span> &#125;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;;</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure>
<h6 id="实现表单-Form-中的图片上传-并回调存储信息"><a href="#实现表单-Form-中的图片上传-并回调存储信息" class="headerlink" title="实现表单 Form 中的图片上传 并回调存储信息"></a>实现表单 Form 中的图片上传 并回调存储信息</h6><p>首先又要创建一个 组件 <code>upLoadImg.vue</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;el-form-item label=&quot;上传图片&quot; prop=&quot;image&quot;&gt;</span><br><span class="line">    &lt;upLoadImgVue&gt;&lt;/upLoadImgVue&gt;</span><br><span class="line">&lt;/el-form-item&gt;</span><br></pre></td></tr></table></figure>
<p>随后我们去 ElmentUI 中寻找 图片上传的 组件。<font color="blue"><strong>选用的是 Upload 上传中的  照片墙。</strong></font></p>
<p>其中 vue 模板中的代码如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;el-upload</span><br><span class="line">           action=&quot;https://jsonplaceholder.typicode.com/posts/&quot;</span><br><span class="line">           list-type=&quot;picture-card&quot;</span><br><span class="line">           :on-preview=&quot;handlePictureCardPreview&quot;</span><br><span class="line">           :on-remove=&quot;handleRemove&quot;&gt;</span><br><span class="line">    &lt;i class=&quot;el-icon-plus&quot;&gt;&lt;/i&gt;</span><br><span class="line">&lt;/el-upload&gt;</span><br><span class="line">&lt;el-dialog :visible.sync=&quot;dialogVisible&quot;&gt;</span><br><span class="line">    &lt;img width=&quot;100%&quot; :src=&quot;dialogImageUrl&quot; alt=&quot;&quot;&gt;</span><br><span class="line">&lt;/el-dialog&gt;</span><br></pre></td></tr></table></figure>
<p>我们其实要修改的是 action中，我们传递的服务器地址接口 post请求。</p>
<p>我们这里的服务器是 express 构建的，所以我们在 sever 中定义了</p>
<h6 id="我们需要在-server-下创建一个-upload文件夹，用于我们的文件上传"><a href="#我们需要在-server-下创建一个-upload文件夹，用于我们的文件上传" class="headerlink" title="我们需要在 server 下创建一个 upload文件夹，用于我们的文件上传"></a><strong>我们需要在 server 下创建一个 upload文件夹，用于我们的文件上传</strong></h6><p>然后再 src 的 api/base.js 文件中对应的接口为：</p>
<p><code>uploadUrl:&quot;/api/upload&quot;,</code></p>
<p><em>`//导出图片 上传</em>`</p>
<p><code>export const uploadUrl=&#39;/api/upload&#39;</code></p>
<p>随后再 我们的 <code>upLoadImg.vue</code> 中进行引入</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;uploadUrl&#125; <span class="keyword">from</span> <span class="string">&quot;../../../api/base&quot;</span></span><br><span class="line"><span class="comment">// 并在 data 中进行注册</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">    <span class="attr">name</span>:<span class="string">&quot;upLoadImgVue&quot;</span>,</span><br><span class="line">    <span class="function"><span class="title">data</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            uploadUrl,</span><br><span class="line">            <span class="attr">dialogImageUrl</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">            <span class="attr">dialogVisible</span>: <span class="literal">false</span></span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>将原来控件中的 action 修改为 双向绑定  <code>:action=&quot;uploadUrl&quot;</code></p>
<font color="blue">**我这里碰到了一个 bug，就是我上传的图片如果有中文 会乱码**</font>



<p><strong>现在上传成功了，现在需要将 这个上传图片的地址，存到我 form 表单的 image 属性中</strong></p>
<p>在控件中引入 <code>:on-success=&quot;handleSuccess&quot;</code></p>
<p>然后就在 handleSuccess中执行需要的内容即可，我们这边需要将 图片url 传递给 父组件表单vue。</p>
<p>这里肯定需要一个  <strong>子传父的 自定义事件</strong>  这肯定会的啦，就不详细说了</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 上传成功回调处理</span></span><br><span class="line"><span class="function"><span class="title">handleSuccess</span>(<span class="params">response, file, fileList</span>)</span>&#123;</span><br><span class="line">    <span class="comment">// url: &quot;upload\\1677749642735-614.png&quot;</span></span><br><span class="line">    <span class="keyword">const</span> fileName = host + <span class="string">&quot;/&quot;</span> + response.url.split(<span class="string">&quot;\\&quot;</span>).pop();</span><br><span class="line">    <span class="built_in">console</span>.log(fileName)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">console</span>.log(response,file,fileList)</span><br><span class="line">    <span class="built_in">this</span>.$emit(<span class="string">&quot;sendImage&quot;</span>, fileName)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后修改 表单中的 image 属性</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">sendImage</span>(<span class="params">imgUrl</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.ruleForm.image.push(imgUrl)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="实现表单-Form-中的富文本组件-上传"><a href="#实现表单-Form-中的富文本组件-上传" class="headerlink" title="实现表单 Form 中的富文本组件 上传"></a>实现表单 Form 中的富文本组件 上传</h6><p>富文本编译器，需要用到第三方的插件，这里使用的是 <strong>wangEditor 富文本编译器</strong></p>
<p>所以我们也需要创建 wangEditor 这个Vue文件，<strong>然后我们这里也同样采用 自定义事件，进行父传子</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;wangEditor @sendWangEditor=&quot;sendWangEditor&quot;&gt;&lt;/wangEditor&gt;</span><br></pre></td></tr></table></figure>
<h6 id="最后实现商品的添加"><a href="#最后实现商品的添加" class="headerlink" title="最后实现商品的添加"></a>最后实现商品的添加</h6><p>点击保存应该 可以提交此时的填写的商品信息，并且添加到数据库。</p>
<p>在表单Vue中，对按钮绑定事件：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">submitForm</span>(<span class="params">formName</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.$refs[formName].validate(<span class="function">(<span class="params">valid</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (valid) &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&quot;添加商品&quot;</span>, <span class="built_in">this</span>.ruleForm);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;error submit!!&#x27;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p>router （express） 定义的 接口为：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">router.get(<span class="string">&quot;/goods/item/insertTbItem&quot;</span>, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;...&#125;</span><br></pre></td></tr></table></figure>
<p>对应 src api 下的 base.js 中的  <code>addGoods:&quot;/api/goods/item/insertTbItem&quot;,*//商品添加地址*</code></p>
<p>然后对应的  src api 下的 index.js</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">addGoods</span>(<span class="params">params</span>)</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> axios.get(base.addGoods, &#123; params &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="然后就是撰写-Form-表单的方法："><a href="#然后就是撰写-Form-表单的方法：" class="headerlink" title="然后就是撰写 Form 表单的方法："></a><strong>然后就是撰写 Form 表单的方法：</strong></h6><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 提交事件  --------</span></span><br><span class="line"><span class="function"><span class="title">submitForm</span>(<span class="params">formName</span>)</span> &#123;</span><br><span class="line">  <span class="built_in">this</span>.$refs[formName].validate(<span class="function">(<span class="params">valid</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (valid) &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&#x27;获取表单的输入信息：----&#x27;</span>, <span class="built_in">this</span>.ruleForm);</span><br><span class="line">        <span class="comment">//添加商品----参数： title cid  category sellPoint price num descs paramsInfo image</span></span><br><span class="line">        <span class="keyword">let</span> &#123; title, cid, category, sellPoint, price, num, descs, image &#125; = <span class="built_in">this</span>.ruleForm;</span><br><span class="line">          <span class="built_in">this</span>.insertTbItem(&#123;</span><br><span class="line">              title, cid, category, sellPoint, price, num, descs,</span><br><span class="line">              <span class="attr">image</span>: <span class="built_in">JSON</span>.stringify(image)</span><br><span class="line">          &#125;)</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&#x27;error submit!!&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;,</span><br><span class="line"><span class="comment">// 添加商品的接口 -----------------</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="title">insertTbItem</span>(<span class="params">params</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">let</span> res = <span class="keyword">await</span> <span class="built_in">this</span>.$api.addGoods(params)</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;+++++++++++++++++++++++++++++++++&quot;</span>, res)</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;添加商品&quot;</span>, res.data);</span><br><span class="line">  <span class="keyword">if</span> (res.data.status === <span class="number">200</span>) &#123;<span class="comment">//添加成功--</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">//信息提示</span></span><br><span class="line">      <span class="built_in">this</span>.$message(&#123;</span><br><span class="line">          <span class="attr">message</span>: <span class="string">&#x27;恭喜你，添加商品成功&#x27;</span>,</span><br><span class="line">          <span class="attr">type</span>: <span class="string">&#x27;success&#x27;</span></span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="comment">//跳转到产品列表界面--- </span></span><br><span class="line">      <span class="built_in">this</span>.$router.push(<span class="string">&#x27;/goodsManage/goodsList&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">//错误信息提示</span></span><br><span class="line">      <span class="built_in">this</span>.$message.error(<span class="string">&#x27;错了哦，添加商品失败&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p><code>INSERT INTO project(title, image, sellPoint, price, cid, category, num,  descs, paramsInfo) VALUES (&#39;214&#39;,&#39;[&quot;http://localhost:9898/1677766470520-618.png&quot;]&#39;,&#39;13134&#39;,&#39;142&#39;,&#39;1001&#39;,&#39;新鲜水果&#39;,&#39;13124&#39;,&#39;&lt;p&gt;hello&lt;/p&gt;&#39;,&#39;&#39;)</code></p>
<p>这个源代码里 sql 语句是正确的，但是数据库有一个字段  upgrated </p>
<h5 id="实现点击重置功能"><a href="#实现点击重置功能" class="headerlink" title="实现点击重置功能"></a>实现点击重置功能</h5><font color="blue">**重置功能，但是 上传图片区域 **</font>

<p><strong>首先对于 上传图片 的 upLoadImage Vue 文件</strong>，需要先定义一个 ref 用于找到这个控件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  &lt;div&gt;</span><br><span class="line">      &lt;el-upload</span><br><span class="line">...</span><br><span class="line">      ref=&quot;upload&quot;</span><br><span class="line">      multiple</span><br><span class="line">      &gt;</span><br><span class="line">...</span><br><span class="line">  &lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>并在 methods 中定义 方法 clear</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">clear</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 自带 api clearFiles</span></span><br><span class="line">    <span class="built_in">this</span>.$refs.upload.clearFiles()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>然后在 Form 组件中，</strong>对 upLoad 标签，给定一个 ref</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;upLoadImgVue  @sendImage=&quot;sendImage&quot; ref=&quot;uploadImage&quot;&gt;&lt;/upLoadImgVue&gt;</span><br></pre></td></tr></table></figure>
<p>然后重置按钮，添加对应的 找到 ref 执行器 clear 方法</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">resetForm</span>(<span class="params">formName</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.$refs[formName].resetFields();</span><br><span class="line">    <span class="comment">// 清空图片列表  这个办法是 组件自己的方法</span></span><br><span class="line">    <span class="built_in">this</span>.$refs.uploadImage.clear()</span><br><span class="line">    <span class="comment">// WangEidtor</span></span><br><span class="line"></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<font color="blue">**重置功能， 富文本区域并没有 清空**</font>

<p><strong>同样在 Form 组件中定义一个  ref</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;wangEditor @sendWangEditor=&quot;sendWangEditor&quot; ref=&quot;wangEdit&quot;&gt;&lt;/wangEditor&gt;</span><br></pre></td></tr></table></figure>
<p>然后在重置按钮中，写方法</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">resetForm</span>(<span class="params">formName</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.$refs[formName].resetFields();</span><br><span class="line">    <span class="comment">// 清空图片列表  这个办法是 组件自己的方法</span></span><br><span class="line">    <span class="built_in">this</span>.$refs.uploadImage.clear()</span><br><span class="line">    <span class="comment">// WangEidtor</span></span><br><span class="line">    <span class="comment">// this.$refs.wangEdit.html = &quot;&quot;</span></span><br><span class="line">    <span class="comment">// 或者 用其 api 方法</span></span><br><span class="line">    <span class="built_in">this</span>.$refs.wangEdit.editor.clear()  </span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<h4 id="实现List-页面的-选中某几项-然后批量删除"><a href="#实现List-页面的-选中某几项-然后批量删除" class="headerlink" title="实现List 页面的 选中某几项 然后批量删除"></a>实现List 页面的 选中某几项 然后批量删除</h4><p>首先 table 在 Element UI 中对于选择哪几个，是有专门的触发函数的 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- event: </span><br><span class="line">  select:当用户手动勾选数据行的 Checkbox 时触发的事件  selection row </span><br><span class="line">  select-all	当用户手动勾选全选 Checkbox 时触发的事件	selection</span><br><span class="line"></span><br><span class="line">--&gt;</span><br><span class="line">&lt;!-- 部分二 ：表格部分 --&gt;</span><br><span class="line">&lt;div class=&quot;list-table&quot;&gt;</span><br><span class="line">    &lt;el-table</span><br><span class="line">    :data=&quot;tableData&quot;</span><br><span class="line">    header-cell-class-name=&quot;textCenter&quot;</span><br><span class="line">    border</span><br><span class="line">    style=&quot;width: 100%&quot;</span><br><span class="line">    @select=&quot;selectHandle&quot;</span><br><span class="line">    @select-all=&quot;selectHandle&quot;</span><br><span class="line">    &gt;</span><br><span class="line">    ....</span><br></pre></td></tr></table></figure>
<p>触发的事件回调函数 是一致的 都是我们自己定义的 <strong>selectHandle</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 点击勾选选择框 ————————————</span></span><br><span class="line"><span class="function"><span class="title">selectHandle</span>(<span class="params">selection</span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 可以获取所有选中的 行</span></span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;selection&quot;</span>, selection)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p>点击按钮批量删除，触发对应方法</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 批量删除</span></span><br><span class="line"><span class="function"><span class="title">partDelete</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;批量删除 --ids--&quot;</span>, <span class="built_in">this</span>.ids);</span><br><span class="line">    <span class="comment">// 需要拼接是因为 我们的接口输入的是个 字符串</span></span><br><span class="line">    <span class="keyword">let</span> idsStr = <span class="built_in">this</span>.ids.join(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    <span class="built_in">this</span>.$confirm(<span class="string">&#x27;确定删除选中的商品数据?&#x27;</span>, <span class="string">&#x27;提示&#x27;</span>, &#123;</span><br><span class="line">        <span class="attr">confirmButtonText</span>: <span class="string">&#x27;确定&#x27;</span>,</span><br><span class="line">        <span class="attr">cancelButtonText</span>: <span class="string">&#x27;取消&#x27;</span>,</span><br><span class="line">        <span class="attr">type</span>: <span class="string">&#x27;warning&#x27;</span></span><br><span class="line">    &#125;).then(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.$api.batchDelete(&#123;<span class="attr">ids</span>:idsStr&#125;).then(</span><br><span class="line">            <span class="function">(<span class="params">res</span>)=&gt;</span>&#123;</span><br><span class="line">                <span class="comment">// 删除成功需要重新渲染列表</span></span><br><span class="line">                <span class="keyword">if</span>(res.data.status == <span class="number">200</span>)&#123;</span><br><span class="line">                    <span class="built_in">this</span>.$message(&#123;</span><br><span class="line">                        <span class="attr">type</span>: <span class="string">&#x27;success&#x27;</span>,</span><br><span class="line">                        <span class="attr">message</span>: <span class="string">&#x27;删除成功!&#x27;</span></span><br><span class="line">                    &#125;);</span><br><span class="line">                    <span class="built_in">this</span>.getGoodsList(<span class="number">1</span>)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p><strong><font color="orange">然后需要解决的bug问题是，我将这页选择的都删了，这页没有了，怎么显示回上一页</font></strong></p>
<h2 id="将整个项目推送到-gitee中"><a href="#将整个项目推送到-gitee中" class="headerlink" title="将整个项目推送到 gitee中"></a>将整个项目推送到 gitee中</h2><p><strong>Step1：首先初始你需要新建一个项目</strong></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/新建仓库.png" alt=""></p>
<p><strong>Step2：在项目文件中打开 git bash</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git init</span><br><span class="line">git add .</span><br><span class="line">//在这之前，首次需要 注册邮箱和姓名</span><br><span class="line">git config --global user.email &quot;963561243@qq.com&quot;</span><br><span class="line">git config --global user.name &quot;JiangKaisheng&quot;</span><br><span class="line">//然后再</span><br><span class="line">git commit -m &quot;搭建项目&quot;</span><br><span class="line"> </span><br><span class="line">// 初始第一次  远程一下</span><br><span class="line">git remote add origin https://gitee.com/kaikai-superman/vue2_-purchase-ego.git</span><br><span class="line"></span><br><span class="line">// push 到 master 分支上</span><br><span class="line">git push -u origin &quot;master&quot;</span><br></pre></td></tr></table></figure>
<p>而后每一次提交</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 先要 pull 一下保持更新</span><br><span class="line">git pull</span><br></pre></td></tr></table></figure>
<p>在实际的开发中 肯定不会在 master 分支上的</p>
<p>所以我们可能需要自己建立分支 </p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/建立分支.png" alt=""></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/实际创建.png" alt=""></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 可查看 本地和远端 分别由什么分支</span><br><span class="line">// 注意查看之前最好先 更新 git pull 一下</span><br><span class="line">git branch -a</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>ResNet迁移学习 之 花图像分类</title>
    <url>/2021/11/23/ResNet%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%20%E4%B9%8B%20%E8%8A%B1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>@<a href="ResNet迁移学习 之 花图像分类">TOC</a><br>迁移学习 (Transfer Learning) 是把已学训练好的模型参数用作新训练模型的起始参数. 迁移学习是深度学习中非常重要和常用的一个策略.</p>
<h1 id="为什么使用迁移学习"><a href="#为什么使用迁移学习" class="headerlink" title="为什么使用迁移学习"></a>为什么使用迁移学习</h1><p>迁移学习 (Transfer Learning) 可以帮助我们得到更好的结果.</p>
<ol>
<li>当我们手上的数据比较少的时候,<br>训练非常容易造成过拟合的现象。使用迁移学习可以帮助我们通过更少的训练数据达到更好的效果。使得模型的泛化能力更强, 训练过程更稳定。</li>
<li>迁移学习 (Transfer Learning) 可以帮助我们节省时间。通过迁移学习，利用前人花大量时间训练好的参数，能帮助我们在模型的训练上节省大把的时间。</li>
</ol>
<h2 id="常见的迁移学习-backbone"><a href="#常见的迁移学习-backbone" class="headerlink" title="常见的迁移学习 backbone"></a>常见的迁移学习 backbone</h2><p><a href="https://pytorch.org/vision/stable/models.html">Pytorch 迁移学习官网 API</a></p>
<ul>
<li>VGG   </li>
<li>ResNet </li>
<li>SqueezeNet </li>
<li>DenseNet </li>
<li>Inception  <a href="https://jks88995656.github.io/2021/09/21/Pytorch%20GoogleNet%E4%B8%AD%E7%9A%84Inception/">GoogleNet 中的 Inception结构</a></li>
<li>GoogLeNet </li>
<li>ShuffleNet</li>
<li>MobileNet</li>
</ul>
<h1 id="冻层实现"><a href="#冻层实现" class="headerlink" title="冻层实现"></a>冻层实现</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_parameter_requires_grad</span>(<span class="params">model, feature_extracting</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    是否保留梯度, 实现冻层  保留梯度也就是冻结层</span></span><br><span class="line"><span class="string">    :param model:模型</span></span><br><span class="line"><span class="string">    :param feature_extracting:是否冻层</span></span><br><span class="line"><span class="string">    :return:无返回值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> feature_extracting:  <span class="comment"># 如果冻层</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():  <span class="comment"># 遍历每个权重参数</span></span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line">            <span class="comment"># param.requires_grad = False的作用是:</span></span><br><span class="line">            <span class="comment"># 屏蔽预训练模型的权重。</span></span><br></pre></td></tr></table></figure>
<h1 id="模型初始化"><a href="#模型初始化" class="headerlink" title="模型初始化"></a>模型初始化</h1><p>ResNet模型的初始化，是冻结全连接层之前所有的层参数，并将全连接层重写为符合自己数据集的输出。例如：花图像数据集一共有102个类，所以最后的输出为102个。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_model</span>(<span class="params">model_name, num_classes, feature_extract, use_pretrained_state=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    初始化模型</span></span><br><span class="line"><span class="string">    :param model_name: 模型名字</span></span><br><span class="line"><span class="string">    :param num_classes:  类别数</span></span><br><span class="line"><span class="string">    :param feature_extract: 是否部冻层</span></span><br><span class="line"><span class="string">    :param use_pretrained_state: 是否下载模型  为True的话为自动下载加载到模型内 为False的话就自己加载模型</span></span><br><span class="line"><span class="string">    :return: 返回模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model_ft = <span class="literal">None</span></span><br><span class="line">    input_size = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> model_name == <span class="string">&quot;resnet&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">            原来Resnet152模型结构中最后两层为：</span></span><br><span class="line"><span class="string">                (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span></span><br><span class="line"><span class="string">                (fc): Linear(in_features=2048, out_features=1000, bias=True)  </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        model_ft = models.resnet152(pretrained=use_pretrained_state)  <span class="comment"># 下载参数 False就不下载 需要下面手动加</span></span><br><span class="line">        model_ft.load_state_dict(torch.load(<span class="string">&#x27;./dataset/pth/resnet152-b121ed2d.pth&#x27;</span>))  <span class="comment"># 手动加 模型参数</span></span><br><span class="line">        set_parameter_requires_grad(model_ft, feature_extract)  <span class="comment"># 冻层</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 修改全连接层</span></span><br><span class="line">        num_ftrs = model_ft.fc.in_features  <span class="comment"># 获取resnet最后全连接层输入的维度 2048，默认解冻</span></span><br><span class="line">        model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes),</span><br><span class="line">                                    nn.LogSoftmax(dim=<span class="number">1</span>))</span><br><span class="line">        <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">            经过修改线性层输出的维度之后变为：</span></span><br><span class="line"><span class="string">                (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span></span><br><span class="line"><span class="string">                (fc): Sequential(</span></span><br><span class="line"><span class="string">                    (0): Linear(in_features=2048, out_features=102, bias=True)</span></span><br><span class="line"><span class="string">                    (1): LogSoftmax()</span></span><br><span class="line"><span class="string">                )</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        input_size = <span class="number">224</span></span><br><span class="line">        <span class="built_in">print</span>(model_ft)</span><br><span class="line">    <span class="keyword">return</span> model_ft, input_size</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h1 id="获取需更新参数"><a href="#获取需更新参数" class="headerlink" title="获取需更新参数"></a>获取需更新参数</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parameter_to_update</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    获取需要更新的参数</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :return: 需要更新的参数列表</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 是否训练所有层</span></span><br><span class="line">    params_to_update = model.parameters()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Params to learn:&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> feature_extract:</span><br><span class="line">        params_to_update = []</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                params_to_update.append(param)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;\t&quot;</span>, name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;\t&quot;</span>, name)</span><br><span class="line">    <span class="keyword">return</span> params_to_update</span><br></pre></td></tr></table></figure>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>里面有一些API 不明白</p>
<ul>
<li><a href="https://www.jianshu.com/p/3ed11362b54f">torch.max(outputs, 1)</a> </li>
<li><a href="https://www.cnblogs.com/liujianing/p/13428387.html">optimizer.state_dict()</a></li>
<li><a href="https://www.jianshu.com/p/60fc57e19615">model.load_state_dict(best_model_wts)</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">model, dataloaders, criterion, optimizer, filename, num_epochs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    训练模型</span></span><br><span class="line"><span class="string">    :param model: 引入的权重模型</span></span><br><span class="line"><span class="string">    :param dataloaders: 导入数据 格式为dataloaders</span></span><br><span class="line"><span class="string">    :param criterion: 损失函数</span></span><br><span class="line"><span class="string">    :param optimizer: 优化器</span></span><br><span class="line"><span class="string">    :param filename: 模型名称（地址）</span></span><br><span class="line"><span class="string">    :param num_epochs: epoch数</span></span><br><span class="line"><span class="string">    :return:model, val_acc_history, train_acc_history, valid_losses, train_losses, LRs</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 获取起始时间</span></span><br><span class="line">    start = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于GPU</span></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line">    val_acc_history = []</span><br><span class="line">    train_acc_history = []</span><br><span class="line">    train_loss = []</span><br><span class="line">    valid_loss = []</span><br><span class="line">    LRs = [optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]]  <span class="comment">## ？？？</span></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())  <span class="comment"># 保存最好的模型权重参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(num_epochs)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练和验证</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># 训练</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()  <span class="comment"># 验证</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历数据</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)  <span class="comment"># inputs shape : torch.Size([16, 3, 224, 224])</span></span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 梯度清零</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 只有训练的时候计算和更新梯度</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)  <span class="comment"># torch.Size([16, 102])</span></span><br><span class="line">                    <span class="comment"># https://www.jianshu.com/p/3ed11362b54f</span></span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)  <span class="comment"># dim是max函数索引的维度0/1，0是每列的最大值，1是每行的最大值</span></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;preds&quot;</span>, preds)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 计算损失</span></span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 训练阶段更新权重</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 计算损失</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)  <span class="comment"># size 表示 inputs 的形状的 第一个也就是 batch 16</span></span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)  <span class="comment"># 预测和实际标签一样就算上</span></span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / <span class="built_in">len</span>(dataloaders[phase].dataset)  <span class="comment"># 这个loss的定义 ？？？</span></span><br><span class="line">            epoch_acc = running_corrects.double() / <span class="built_in">len</span>(</span><br><span class="line">                dataloaders[phase].dataset)  <span class="comment"># ???  dataloaders[phase].dataset  为什么有dataset属性 是啥呢</span></span><br><span class="line"></span><br><span class="line">            time_spend = time.time() - start  <span class="comment"># 所花费的时间 start是初始开始时间</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Time spend &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(time_spend // <span class="number">60</span>, time_spend % <span class="number">60</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 得到最好那次的模型</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;valid&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())  <span class="comment"># copy当前最好模型的所有权重</span></span><br><span class="line">                state = &#123;</span><br><span class="line">                    <span class="string">&#x27;state_dict&#x27;</span>: model.state_dict(),  <span class="comment"># 当前最好模型的所有权重</span></span><br><span class="line">                    <span class="string">&#x27;best_acc&#x27;</span>: best_acc,  <span class="comment"># 最好的准确率 （测试集上）</span></span><br><span class="line">                    <span class="string">&#x27;optimizer&#x27;</span>: optimizer.state_dict(),  <span class="comment"># https://www.cnblogs.com/liujianing/p/13428387.html</span></span><br><span class="line">                &#125;</span><br><span class="line">                torch.save(state, filename)  <span class="comment"># filename 保存的模型名（其实是地址）</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;valid&#x27;</span>:</span><br><span class="line">                val_acc_history.append(epoch_acc)</span><br><span class="line">                valid_loss.append(epoch_loss)</span><br><span class="line">                scheduler.step(epoch_loss)  <span class="comment"># ??? 更新权重参数</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                train_acc_history.append(epoch_acc)</span><br><span class="line">                train_loss.append(epoch_loss)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Optimizer learning rate : &#123;:.7f&#125;&#x27;</span>.<span class="built_in">format</span>(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]))</span><br><span class="line">        LRs.append(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>])  <span class="comment"># 添加此时的学习率</span></span><br><span class="line"></span><br><span class="line">    time_spend_all = time.time() - start  <span class="comment"># 所花费的时间 start是初始开始时间</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(time_spend_all // <span class="number">60</span>, time_spend_all % <span class="number">60</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best val Acc: &#123;:4f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练完后用最好的一次当做模型最终的结果</span></span><br><span class="line">    model.load_state_dict(best_model_wts)  <span class="comment"># model加载 可以查看 https://www.jianshu.com/p/60fc57e19615</span></span><br><span class="line">    <span class="comment"># 返回</span></span><br><span class="line">    <span class="keyword">return</span> model, val_acc_history, train_acc_history, valid_loss, train_loss, LRs</span><br></pre></td></tr></table></figure>
<h2 id="如果是仅仅微调所有参数的话"><a href="#如果是仅仅微调所有参数的话" class="headerlink" title="如果是仅仅微调所有参数的话"></a>如果是仅仅微调所有参数的话</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 有全体参数的情况下  微调训练全部层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_all_layers</span>(<span class="params">num_epochs</span>):</span></span><br><span class="line">    <span class="comment"># 保存文件的名字</span></span><br><span class="line">    file_path = <span class="string">&#x27;./dataset/pth/resnet152_fc.pth&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载模型</span></span><br><span class="line">    checkpoint = torch.load(file_path)</span><br><span class="line">    best_acc = checkpoint[<span class="string">&#x27;best_acc&#x27;</span>]</span><br><span class="line">    model_ft = models.resnet152(pretrained=<span class="literal">False</span>)</span><br><span class="line">    model_ft.load_state_dict(checkpoint[<span class="string">&#x27;state_dict&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将所有参数的requires_grad 设为True 微调 训练所有层</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> model_ft.parameters():</span><br><span class="line">        param.requires_grad = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.Adam(model_ft.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line">    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">6</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    criterion = nn.NLLLoss()</span><br><span class="line"></span><br><span class="line">    optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(model_ft, dataloaders,</span><br><span class="line">                                                                                                criterion, optimizer,</span><br><span class="line">                                                                                                num_epoch=num_epochs,</span><br><span class="line">                                                                                                filename=<span class="string">&#x27;resnet152_all_layers.pth&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="用于最后模型测试"><a href="#用于最后模型测试" class="headerlink" title="用于最后模型测试"></a>用于最后模型测试</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fortest</span>():</span></span><br><span class="line">    <span class="comment"># 保存文件的名字</span></span><br><span class="line">    file_path = <span class="string">&#x27;./dataset/pth/resnet152_fc.pth&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载模型</span></span><br><span class="line">    model_ft = torch.load(file_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># GPU模式</span></span><br><span class="line">    model_ft = model_ft.to(device)</span><br><span class="line">    <span class="comment"># 得到一个batch的测试数据</span></span><br><span class="line">    dataiter = <span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;valid&#x27;</span>])</span><br><span class="line">    images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line">    model_ft.<span class="built_in">eval</span>()</span><br><span class="line">    train_on_gpu = torch.cuda.is_available()</span><br><span class="line">    <span class="keyword">if</span> train_on_gpu:</span><br><span class="line">        output = model_ft(images.cuda())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = model_ft(images)</span><br><span class="line"></span><br><span class="line">    _, preds_tensor = torch.<span class="built_in">max</span>(output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    preds = np.squeeze(preds_tensor.numpy()) <span class="keyword">if</span> <span class="keyword">not</span> train_on_gpu <span class="keyword">else</span> np.squeeze(preds_tensor.cpu().numpy())</span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 结果展示</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">20</span>))</span><br><span class="line">    columns = <span class="number">4</span></span><br><span class="line">    rows = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(columns * rows):</span><br><span class="line">        ax = fig.add_subplot(rows, columns, idx + <span class="number">1</span>, xticks=[], yticks=[])</span><br><span class="line">        plt.imshow(im_convert(images[idx]))</span><br><span class="line">        ax.set_title(<span class="string">&quot;&#123;&#125; (&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(cat_to_name[<span class="built_in">str</span>(preds[idx])], cat_to_name[<span class="built_in">str</span>(labels[idx].item())]),</span><br><span class="line">                     color=(<span class="string">&quot;green&quot;</span> <span class="keyword">if</span> cat_to_name[<span class="built_in">str</span>(preds[idx])] == cat_to_name[<span class="built_in">str</span>(labels[idx].item())] <span class="keyword">else</span> <span class="string">&quot;red&quot;</span>))</span><br><span class="line">    plt.savefig(<span class="string">&#x27;./img_show.png&#x27;</span>)</span><br><span class="line">    plt.close(fig)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h1><p>一般这个部分 不同数据集是不一样的。<br>但我们需要的 数据一定是 一个 dataloader （同时其一般为 字典格式）例如： <strong>data_loader = {“train”: train_loader, “valid”: test_loader}</strong></p>
<p>如上面所示，所以我们一般数据集是划分为 训练集、验证集、测试集的。（但训练一般前两者即可）。</p>
<p>在花朵任务内：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">image_datasets, dataloaders, dataset_sizes, class_names = create_dataset(batch_size=batch_size)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>定义数据预处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 图片路径</span></span><br><span class="line">data_dir = <span class="string">&#x27;./dataset/flower_data/&#x27;</span></span><br><span class="line">train_dir = data_dir + <span class="string">&#x27;/train&#x27;</span></span><br><span class="line">valid_dir = data_dir + <span class="string">&#x27;/valid&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取标签对应的实际名字</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./dataset/flower_data/cat_to_name.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    cat_to_name = json.load(f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([transforms.RandomRotation(<span class="number">45</span>),  <span class="comment"># 随机旋转，-45到45度之间随机选</span></span><br><span class="line">                                 transforms.CenterCrop(<span class="number">224</span>),  <span class="comment"># 从中心开始裁剪</span></span><br><span class="line">                                 transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 随机水平翻转 选择一个概率概率</span></span><br><span class="line">                                 transforms.RandomVerticalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 随机垂直翻转</span></span><br><span class="line">                                 transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.1</span>, saturation=<span class="number">0.1</span>, hue=<span class="number">0.1</span>),</span><br><span class="line">                                 <span class="comment"># 参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相</span></span><br><span class="line">                                 transforms.RandomGrayscale(p=<span class="number">0.025</span>),  <span class="comment"># 概率转换成灰度率，3通道就是R=G=B</span></span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])  <span class="comment"># 均值，标准差</span></span><br><span class="line">                                 ]),</span><br><span class="line">    <span class="string">&#x27;valid&#x27;</span>: transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                 transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">                                 ]),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>create_dataset方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># # 数据集创建初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span>(<span class="params">batch_size</span>):</span></span><br><span class="line">    <span class="comment"># 数据创建初始化</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这就类似于一个字典  &#123;&#x27;train&#x27;:./dataset/flower_data/train....,&#x27;valid&#x27;:......&#125;</span></span><br><span class="line">    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) <span class="keyword">for</span> x <span class="keyword">in</span></span><br><span class="line">                      [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看一下 image_datasets 的内容</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;image_datasets&quot;</span>, image_datasets)</span><br><span class="line">    <span class="comment"># torch.utils.data.DataLoader使用方法</span></span><br><span class="line">    <span class="comment"># 数据加载器，结合了数据集和取样器，并且可以提供多个线程处理数据集。</span></span><br><span class="line">    <span class="comment"># 在训练模型时使用到此函数，用来把训练数据分成多个小组，此函数每次抛出一组数据。直至把所有的数据都抛出。就是做一个数据的初始化。</span></span><br><span class="line">    <span class="comment"># 这里同样是生成一个字典格式</span></span><br><span class="line">    dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=<span class="literal">True</span>) <span class="keyword">for</span> x <span class="keyword">in</span></span><br><span class="line">                   [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看一下dataloaders 的内容</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dataloaders&quot;</span>, dataloaders)</span><br><span class="line">    <span class="comment"># 字典形式</span></span><br><span class="line">    dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;</span><br><span class="line">    <span class="comment"># 查看一下 dataset_sizes 的内容</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dataset_sizes&quot;</span>, dataset_sizes)</span><br><span class="line">    <span class="comment"># 返回一个list类型</span></span><br><span class="line">    class_names = image_datasets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line">    <span class="keyword">return</span> image_datasets, dataloaders, dataset_sizes, class_names</span><br></pre></td></tr></table></figure>
<h1 id="最终Main调用顺序"><a href="#最终Main调用顺序" class="headerlink" title="最终Main调用顺序"></a>最终Main调用顺序</h1><h2 id="配置图片路径"><a href="#配置图片路径" class="headerlink" title="配置图片路径"></a>配置图片路径</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 图片路径</span></span><br><span class="line">data_dir = <span class="string">&#x27;./dataset/flower_data/&#x27;</span></span><br><span class="line">train_dir = data_dir + <span class="string">&#x27;/train&#x27;</span></span><br><span class="line">valid_dir = data_dir + <span class="string">&#x27;/valid&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取标签对应的实际名字</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./dataset/flower_data/cat_to_name.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    cat_to_name = json.load(f)</span><br></pre></td></tr></table></figure>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>划分训练集、验证集、测试集等。并做图像增强。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([transforms.RandomRotation(<span class="number">45</span>),  <span class="comment"># 随机旋转，-45到45度之间随机选</span></span><br><span class="line">                                 transforms.CenterCrop(<span class="number">224</span>),  <span class="comment"># 从中心开始裁剪</span></span><br><span class="line">                                 transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 随机水平翻转 选择一个概率概率</span></span><br><span class="line">                                 transforms.RandomVerticalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 随机垂直翻转</span></span><br><span class="line">                                 transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.1</span>, saturation=<span class="number">0.1</span>, hue=<span class="number">0.1</span>),</span><br><span class="line">                                 <span class="comment"># 参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相</span></span><br><span class="line">                                 transforms.RandomGrayscale(p=<span class="number">0.025</span>),  <span class="comment"># 概率转换成灰度率，3通道就是R=G=B</span></span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])  <span class="comment"># 均值，标准差</span></span><br><span class="line">                                 ]),</span><br><span class="line">    <span class="string">&#x27;valid&#x27;</span>: transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                 transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">                                 ]),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="配置超参数"><a href="#配置超参数" class="headerlink" title="配置超参数"></a>配置超参数</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 超参数配置</span></span><br><span class="line"><span class="comment"># 是否用人家训练好的特征来做,True 为 不改变权重参数也就是冻层，False 为自己重新训练所有层的权重参数</span></span><br><span class="line">feature_extract = <span class="literal">True</span>  <span class="comment"># 冻层</span></span><br><span class="line">num_classes = <span class="number">102</span>  <span class="comment"># 输出的类别数</span></span><br><span class="line">batch_size = <span class="number">16</span>  <span class="comment"># 一次训练的样本数目</span></span><br><span class="line">num_epochs = <span class="number">20</span></span><br></pre></td></tr></table></figure>
<h2 id="创建数据-DataLoader"><a href="#创建数据-DataLoader" class="headerlink" title="创建数据 DataLoader"></a>创建数据 DataLoader</h2><p>一般这都是一个整体方法。这里 分来开写了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">image_datasets, dataloaders, dataset_sizes, class_names = create_dataset(batch_size=batch_size)</span><br></pre></td></tr></table></figure>
<h2 id="获取初始化ResNet模型"><a href="#获取初始化ResNet模型" class="headerlink" title="获取初始化ResNet模型"></a>获取初始化ResNet模型</h2><p>冻结了最后一层全连接层外的所有层参数，并对最后一层线性层修改为自己的数据集样本个数输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 获取模型  模型冻结了部分层，最后一层线性层修改</span></span><br><span class="line">resnet152 = initialize_model(</span><br><span class="line">    model_name=<span class="string">&#x27;resnet&#x27;</span>,</span><br><span class="line">    num_classes=num_classes,</span><br><span class="line">    feature_extract=feature_extract,</span><br><span class="line">    use_pretrained=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="是否使用GPU训练"><a href="#是否使用GPU训练" class="headerlink" title="是否使用GPU训练"></a>是否使用GPU训练</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 是否使用GPU训练</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> torch.cuda.is_available():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CUDA is not available.  Training on CPU ...&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CUDA is available!  Training on GPU ...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="模型训练属性配置"><a href="#模型训练属性配置" class="headerlink" title="模型训练属性配置"></a>模型训练属性配置</h2><h3 id="哪些参数需要被训练"><a href="#哪些参数需要被训练" class="headerlink" title="哪些参数需要被训练"></a>哪些参数需要被训练</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练参数</span></span><br><span class="line">params_to_update = parameter_to_update(resnet152)</span><br></pre></td></tr></table></figure>
<h3 id="优化器、衰减器、损失函数"><a href="#优化器、衰减器、损失函数" class="headerlink" title="优化器、衰减器、损失函数"></a>优化器、衰减器、损失函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 优化器设置</span></span><br><span class="line">optimizer = torch.optim.Adam(params_to_update, lr=<span class="number">0.01</span>)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">6</span>, gamma=<span class="number">0.1</span>)  <span class="comment"># 学习率每7个epoch衰减成原来的1/10</span></span><br><span class="line"><span class="comment"># 最后一层已经LogSoftmax()了，所以不能nn.CrossEntropyLoss()来计算了，nn.CrossEntropyLoss()相当于logSoftmax()和nn.NLLLoss()整合</span></span><br><span class="line">criterion = nn.NLLLoss()</span><br></pre></td></tr></table></figure>
<h2 id="开始ResNet预训练（最后一层线性训练）"><a href="#开始ResNet预训练（最后一层线性训练）" class="headerlink" title="开始ResNet预训练（最后一层线性训练）"></a>开始ResNet预训练（最后一层线性训练）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># # 开始训练</span></span><br><span class="line">model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(resnet152, dataloaders,</span><br><span class="line">                                                                                            criterion, optimizer,</span><br><span class="line">                                                                                            num_epoch=num_epochs,</span><br><span class="line">                                                                                            filename=<span class="string">&quot;resnet152_fc.pth&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="微调所有ResNet参数训练"><a href="#微调所有ResNet参数训练" class="headerlink" title="微调所有ResNet参数训练"></a>微调所有ResNet参数训练</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_all_layers(num_epochs)</span><br></pre></td></tr></table></figure>
<h2 id="评估模型结果"><a href="#评估模型结果" class="headerlink" title="评估模型结果"></a>评估模型结果</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fortest()</span><br></pre></td></tr></table></figure>
<h1 id="整体代码"><a href="#整体代码" class="headerlink" title="整体代码"></a>整体代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorboard <span class="keyword">import</span> summary</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, models, datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">im_convert</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    <span class="comment"># 展示数据</span></span><br><span class="line">    image = tensor.to(<span class="string">&quot;cpu&quot;</span>).clone().detach()  <span class="comment"># 方法解读 https://zhuanlan.zhihu.com/p/148061684</span></span><br><span class="line">    <span class="comment"># 结论：根据上述例1~3可知，np.squeeze（）函数可以删除数组形状中的单维度条目，</span></span><br><span class="line">    <span class="comment"># 即把shape中为1的维度去掉，但是对非单维的维度不起作用。</span></span><br><span class="line">    image = image.numpy().squeeze()  <span class="comment"># 方法解读 https://blog.csdn.net/qq_38675570/article/details/80048650</span></span><br><span class="line">    <span class="comment"># 这里用np.transpose（img，(1,2,0)）</span></span><br><span class="line">    <span class="comment"># 将图片的格式由（channels,imagesize,imagesize）转化为（imagesize,imagesize,channels）,这样plt.show()就可以显示图片了。</span></span><br><span class="line">    <span class="comment"># pytorch中 最开始的应该是 维度</span></span><br><span class="line">    image = image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 乘以标准差 加上 均值 就是 原来的图片样本值</span></span><br><span class="line">    image = image * np.array((<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)) + np.array((<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>))</span><br><span class="line">    <span class="comment"># ？？？</span></span><br><span class="line">    image = image.clip(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示图片效果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_image</span>():</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">12</span>))</span><br><span class="line">    columns = <span class="number">4</span></span><br><span class="line">    rows = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为什么加了一个迭代器就这样了</span></span><br><span class="line">    dataiter = <span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;valid&#x27;</span>])</span><br><span class="line">    inputs, classes = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(columns * rows):</span><br><span class="line">        ax = fig.add_subplot(rows, columns, idx + <span class="number">1</span>, xticks=[], yticks=[])</span><br><span class="line">        ax.set_title(cat_to_name[<span class="built_in">str</span>(<span class="built_in">int</span>(class_names[classes[idx]]))])  <span class="comment"># 为什么还要 先转int类型？？？</span></span><br><span class="line">        plt.imshow(im_convert(inputs[idx]))  <span class="comment"># 图片转换显示</span></span><br><span class="line">    plt.show()  <span class="comment"># 显示整个图</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 原版的数据获取 mnt</span></span><br><span class="line"><span class="comment"># def get_data():</span></span><br><span class="line"><span class="comment">#     &quot;&quot;&quot;获取数据&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     # 获取测试集</span></span><br><span class="line"><span class="comment">#     train = torchvision.datasets.CIFAR100(root=&quot;./mnt&quot;, train=True, download=True,</span></span><br><span class="line"><span class="comment">#                                           transform=torchvision.transforms.Compose([</span></span><br><span class="line"><span class="comment">#                                               torchvision.transforms.ToTensor(),  # 转换成张量</span></span><br><span class="line"><span class="comment">#                                               torchvision.transforms.Normalize((0.1307,), (0.3081,))  # 标准化</span></span><br><span class="line"><span class="comment">#                                           ]))</span></span><br><span class="line"><span class="comment">#     train_loader = DataLoader(train, batch_size=batch_size)  # 分割测试集</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     # 获取测试集</span></span><br><span class="line"><span class="comment">#     test = torchvision.datasets.CIFAR100(root=&quot;./mnt&quot;, train=False, download=True,</span></span><br><span class="line"><span class="comment">#                                          transform=torchvision.transforms.Compose([</span></span><br><span class="line"><span class="comment">#                                              torchvision.transforms.ToTensor(),  # 转换成张量</span></span><br><span class="line"><span class="comment">#                                              torchvision.transforms.Normalize((0.1307,), (0.3081,))  # 标准化</span></span><br><span class="line"><span class="comment">#                                          ]))</span></span><br><span class="line"><span class="comment">#     test_loader = DataLoader(test, batch_size=batch_size)  # 分割训练</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     data_loader = &#123;&quot;train&quot;: train_loader, &quot;valid&quot;: test_loader&#125;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     # 返回分割好的训练集和测试集</span></span><br><span class="line"><span class="comment">#     return data_loader</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 数据集创建初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span>(<span class="params">batch_size</span>):</span></span><br><span class="line">    <span class="comment"># 数据创建初始化</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这就类似于一个字典  &#123;&#x27;train&#x27;:./dataset/flower_data/train....,&#x27;valid&#x27;:......&#125;</span></span><br><span class="line">    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) <span class="keyword">for</span> x <span class="keyword">in</span></span><br><span class="line">                      [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看一下 image_datasets 的内容</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;image_datasets&quot;</span>, image_datasets)</span><br><span class="line">    <span class="comment"># torch.utils.data.DataLoader使用方法</span></span><br><span class="line">    <span class="comment"># 数据加载器，结合了数据集和取样器，并且可以提供多个线程处理数据集。</span></span><br><span class="line">    <span class="comment"># 在训练模型时使用到此函数，用来把训练数据分成多个小组，此函数每次抛出一组数据。直至把所有的数据都抛出。就是做一个数据的初始化。</span></span><br><span class="line">    <span class="comment"># 这里同样是生成一个字典格式</span></span><br><span class="line">    dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=<span class="literal">True</span>) <span class="keyword">for</span> x <span class="keyword">in</span></span><br><span class="line">                   [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看一下dataloaders 的内容</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dataloaders&quot;</span>, dataloaders)</span><br><span class="line">    <span class="comment"># 字典形式</span></span><br><span class="line">    dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]&#125;</span><br><span class="line">    <span class="comment"># 查看一下 dataset_sizes 的内容</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dataset_sizes&quot;</span>, dataset_sizes)</span><br><span class="line">    <span class="comment"># 返回一个list类型</span></span><br><span class="line">    class_names = image_datasets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line">    <span class="keyword">return</span> image_datasets, dataloaders, dataset_sizes, class_names</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_parameter_requires_grad</span>(<span class="params">model, feature_extracting</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    是否保留梯度, 实现冻层  保留梯度也就是冻结层</span></span><br><span class="line"><span class="string">    :param model:模型</span></span><br><span class="line"><span class="string">    :param feature_extracting:是否冻层</span></span><br><span class="line"><span class="string">    :return:无返回值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> feature_extracting:  <span class="comment"># 如果冻层</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():  <span class="comment"># 遍历每个权重参数</span></span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line">            <span class="comment"># param.requires_grad = False的作用是:</span></span><br><span class="line">            <span class="comment"># 屏蔽预训练模型的权重。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_model</span>(<span class="params">model_name, num_classes, feature_extract, use_pretrained_state=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    初始化模型</span></span><br><span class="line"><span class="string">    :param model_name: 模型名字</span></span><br><span class="line"><span class="string">    :param num_classes:  类别数</span></span><br><span class="line"><span class="string">    :param feature_extract: 是否部冻层</span></span><br><span class="line"><span class="string">    :param use_pretrained_state: 是否下载模型  为True的话为自动下载加载到模型内 为False的话就自己加载模型</span></span><br><span class="line"><span class="string">    :return: 返回模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model_ft = <span class="literal">None</span></span><br><span class="line">    input_size = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> model_name == <span class="string">&quot;resnet&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">            原来Resnet152模型结构中最后两层为：</span></span><br><span class="line"><span class="string">                (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span></span><br><span class="line"><span class="string">                (fc): Linear(in_features=2048, out_features=1000, bias=True)  </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        model_ft = models.resnet152(pretrained=use_pretrained_state)  <span class="comment"># 下载参数 False就不下载 需要下面手动加</span></span><br><span class="line">        model_ft.load_state_dict(torch.load(<span class="string">&#x27;./dataset/pth/resnet152-b121ed2d.pth&#x27;</span>))  <span class="comment"># 手动加 模型参数</span></span><br><span class="line">        set_parameter_requires_grad(model_ft, feature_extract)  <span class="comment"># 冻层</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 修改全连接层</span></span><br><span class="line">        num_ftrs = model_ft.fc.in_features  <span class="comment"># 获取resnet最后全连接层输入的维度 2048</span></span><br><span class="line">        model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes),</span><br><span class="line">                                    nn.LogSoftmax(dim=<span class="number">1</span>))</span><br><span class="line">        <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">            经过修改线性层输出的维度之后变为：</span></span><br><span class="line"><span class="string">                (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span></span><br><span class="line"><span class="string">                (fc): Sequential(</span></span><br><span class="line"><span class="string">                    (0): Linear(in_features=2048, out_features=102, bias=True)</span></span><br><span class="line"><span class="string">                    (1): LogSoftmax()</span></span><br><span class="line"><span class="string">                )</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        input_size = <span class="number">224</span></span><br><span class="line">        <span class="built_in">print</span>(model_ft)</span><br><span class="line">    <span class="keyword">return</span> model_ft, input_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parameter_to_update</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    获取需要更新的参数</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :return: 需要更新的参数列表</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 是否训练所有层</span></span><br><span class="line">    params_to_update = model.parameters()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Params to learn:&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> feature_extract:</span><br><span class="line">        params_to_update = []</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                params_to_update.append(param)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;\t&quot;</span>, name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;\t&quot;</span>, name)</span><br><span class="line">    <span class="keyword">return</span> params_to_update</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">model, dataloaders, criterion, optimizer, filename, num_epochs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    训练模型</span></span><br><span class="line"><span class="string">    :param model: 引入的权重模型</span></span><br><span class="line"><span class="string">    :param dataloaders: 导入数据 格式为dataloaders</span></span><br><span class="line"><span class="string">    :param criterion: 损失函数</span></span><br><span class="line"><span class="string">    :param optimizer: 优化器</span></span><br><span class="line"><span class="string">    :param filename: 模型名称（地址）</span></span><br><span class="line"><span class="string">    :param num_epochs: epoch数</span></span><br><span class="line"><span class="string">    :return:model, val_acc_history, train_acc_history, valid_losses, train_losses, LRs</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 获取起始时间</span></span><br><span class="line">    start = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于GPU</span></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line">    val_acc_history = []</span><br><span class="line">    train_acc_history = []</span><br><span class="line">    train_loss = []</span><br><span class="line">    valid_loss = []</span><br><span class="line">    LRs = [optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]]  <span class="comment">## ？？？</span></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())  <span class="comment"># 保存最好的模型权重参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(num_epochs)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练和验证</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># 训练</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()  <span class="comment"># 验证</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历数据</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)  <span class="comment"># inputs shape : torch.Size([16, 3, 224, 224])</span></span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 梯度清零</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 只有训练的时候计算和更新梯度</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)  <span class="comment"># torch.Size([16, 102])</span></span><br><span class="line">                    <span class="comment"># https://www.jianshu.com/p/3ed11362b54f</span></span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)  <span class="comment"># dim是max函数索引的维度0/1，0是每列的最大值，1是每行的最大值</span></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;preds&quot;</span>, preds)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 计算损失</span></span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 训练阶段更新权重</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 计算损失</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)  <span class="comment"># size 表示 inputs 的形状的 第一个也就是 batch 16</span></span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)  <span class="comment"># 预测和实际标签一样就算上</span></span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / <span class="built_in">len</span>(dataloaders[phase].dataset)  <span class="comment"># 这个loss的定义 ？？？</span></span><br><span class="line">            epoch_acc = running_corrects.double() / <span class="built_in">len</span>(</span><br><span class="line">                dataloaders[phase].dataset)  <span class="comment"># ???  dataloaders[phase].dataset  为什么有dataset属性 是啥呢</span></span><br><span class="line"></span><br><span class="line">            time_spend = time.time() - start  <span class="comment"># 所花费的时间 start是初始开始时间</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Time spend &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(time_spend // <span class="number">60</span>, time_spend % <span class="number">60</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 得到最好那次的模型</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;valid&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())  <span class="comment"># copy当前最好模型的所有权重</span></span><br><span class="line">                state = &#123;</span><br><span class="line">                    <span class="string">&#x27;state_dict&#x27;</span>: model.state_dict(),  <span class="comment"># 当前最好模型的所有权重</span></span><br><span class="line">                    <span class="string">&#x27;best_acc&#x27;</span>: best_acc,  <span class="comment"># 最好的准确率 （测试集上）</span></span><br><span class="line">                    <span class="string">&#x27;optimizer&#x27;</span>: optimizer.state_dict(),  <span class="comment"># https://www.cnblogs.com/liujianing/p/13428387.html</span></span><br><span class="line">                &#125;</span><br><span class="line">                torch.save(state, filename)  <span class="comment"># filename 保存的模型名（其实是地址）</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;valid&#x27;</span>:</span><br><span class="line">                val_acc_history.append(epoch_acc)</span><br><span class="line">                valid_loss.append(epoch_loss)</span><br><span class="line">                scheduler.step(epoch_loss)  <span class="comment"># ??? 更新权重参数</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                train_acc_history.append(epoch_acc)</span><br><span class="line">                train_loss.append(epoch_loss)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Optimizer learning rate : &#123;:.7f&#125;&#x27;</span>.<span class="built_in">format</span>(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]))</span><br><span class="line">        LRs.append(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>])  <span class="comment"># 添加此时的学习率</span></span><br><span class="line"></span><br><span class="line">    time_spend_all = time.time() - start  <span class="comment"># 所花费的时间 start是初始开始时间</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(time_spend_all // <span class="number">60</span>, time_spend_all % <span class="number">60</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best val Acc: &#123;:4f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练完后用最好的一次当做模型最终的结果</span></span><br><span class="line">    model.load_state_dict(best_model_wts)  <span class="comment"># model加载 可以查看 https://www.jianshu.com/p/60fc57e19615</span></span><br><span class="line">    <span class="comment"># 返回</span></span><br><span class="line">    <span class="keyword">return</span> model, val_acc_history, train_acc_history, valid_loss, train_loss, LRs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有全体参数的情况下  微调训练全部层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_all_layers</span>(<span class="params">num_epochs</span>):</span></span><br><span class="line">    <span class="comment"># 保存文件的名字</span></span><br><span class="line">    file_path = <span class="string">&#x27;./dataset/pth/resnet152_fc.pth&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载模型</span></span><br><span class="line">    checkpoint = torch.load(file_path)</span><br><span class="line">    best_acc = checkpoint[<span class="string">&#x27;best_acc&#x27;</span>]</span><br><span class="line">    model_ft = models.resnet152(pretrained=<span class="literal">False</span>)</span><br><span class="line">    model_ft.load_state_dict(checkpoint[<span class="string">&#x27;state_dict&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将所有参数的requires_grad 设为True 微调 训练所有层</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> model_ft.parameters():</span><br><span class="line">        param.requires_grad = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.Adam(model_ft.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line">    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">6</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    criterion = nn.NLLLoss()</span><br><span class="line"></span><br><span class="line">    optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(model_ft, dataloaders,</span><br><span class="line">                                                                                                criterion, optimizer,</span><br><span class="line">                                                                                                num_epoch=num_epochs,</span><br><span class="line">                                                                                                filename=<span class="string">&#x27;resnet152_all_layers.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fortest</span>():</span></span><br><span class="line">    <span class="comment"># 保存文件的名字</span></span><br><span class="line">    file_path = <span class="string">&#x27;./dataset/pth/resnet152_fc.pth&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载模型</span></span><br><span class="line">    model_ft = torch.load(file_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># GPU模式</span></span><br><span class="line">    model_ft = model_ft.to(device)</span><br><span class="line">    <span class="comment"># 得到一个batch的测试数据</span></span><br><span class="line">    dataiter = <span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;valid&#x27;</span>])</span><br><span class="line">    images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line">    model_ft.<span class="built_in">eval</span>()</span><br><span class="line">    train_on_gpu = torch.cuda.is_available()</span><br><span class="line">    <span class="keyword">if</span> train_on_gpu:</span><br><span class="line">        output = model_ft(images.cuda())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = model_ft(images)</span><br><span class="line"></span><br><span class="line">    _, preds_tensor = torch.<span class="built_in">max</span>(output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    preds = np.squeeze(preds_tensor.numpy()) <span class="keyword">if</span> <span class="keyword">not</span> train_on_gpu <span class="keyword">else</span> np.squeeze(preds_tensor.cpu().numpy())</span><br><span class="line">    <span class="built_in">print</span>(preds)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 结果展示</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">20</span>))</span><br><span class="line">    columns = <span class="number">4</span></span><br><span class="line">    rows = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(columns * rows):</span><br><span class="line">        ax = fig.add_subplot(rows, columns, idx + <span class="number">1</span>, xticks=[], yticks=[])</span><br><span class="line">        plt.imshow(im_convert(images[idx]))</span><br><span class="line">        ax.set_title(<span class="string">&quot;&#123;&#125; (&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(cat_to_name[<span class="built_in">str</span>(preds[idx])], cat_to_name[<span class="built_in">str</span>(labels[idx].item())]),</span><br><span class="line">                     color=(<span class="string">&quot;green&quot;</span> <span class="keyword">if</span> cat_to_name[<span class="built_in">str</span>(preds[idx])] == cat_to_name[<span class="built_in">str</span>(labels[idx].item())] <span class="keyword">else</span> <span class="string">&quot;red&quot;</span>))</span><br><span class="line">    plt.savefig(<span class="string">&#x27;./img_show.png&#x27;</span>)</span><br><span class="line">    plt.close(fig)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    plt.switch_backend(<span class="string">&#x27;agg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    配置图片路径以及数据预处理</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 图片路径</span></span><br><span class="line">    data_dir = <span class="string">&#x27;./dataset/flower_data/&#x27;</span></span><br><span class="line">    train_dir = data_dir + <span class="string">&#x27;/train&#x27;</span></span><br><span class="line">    valid_dir = data_dir + <span class="string">&#x27;/valid&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取标签对应的实际名字</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./dataset/flower_data/cat_to_name.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        cat_to_name = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据预处理</span></span><br><span class="line">    data_transforms = &#123;</span><br><span class="line">        <span class="string">&#x27;train&#x27;</span>: transforms.Compose([transforms.RandomRotation(<span class="number">45</span>),  <span class="comment"># 随机旋转，-45到45度之间随机选</span></span><br><span class="line">                                     transforms.CenterCrop(<span class="number">224</span>),  <span class="comment"># 从中心开始裁剪</span></span><br><span class="line">                                     transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 随机水平翻转 选择一个概率概率</span></span><br><span class="line">                                     transforms.RandomVerticalFlip(p=<span class="number">0.5</span>),  <span class="comment"># 随机垂直翻转</span></span><br><span class="line">                                     transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.1</span>, saturation=<span class="number">0.1</span>, hue=<span class="number">0.1</span>),</span><br><span class="line">                                     <span class="comment"># 参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相</span></span><br><span class="line">                                     transforms.RandomGrayscale(p=<span class="number">0.025</span>),  <span class="comment"># 概率转换成灰度率，3通道就是R=G=B</span></span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])  <span class="comment"># 均值，标准差</span></span><br><span class="line">                                     ]),</span><br><span class="line">        <span class="string">&#x27;valid&#x27;</span>: transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                     transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">                                     ]),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 超参数配置</span></span><br><span class="line">    <span class="comment"># 是否用人家训练好的特征来做,True 为 不改变权重参数也就是冻层，False 为自己重新训练所有层的权重参数</span></span><br><span class="line">    feature_extract = <span class="literal">True</span>  <span class="comment"># 冻层</span></span><br><span class="line">    num_classes = <span class="number">102</span>  <span class="comment"># 输出的类别数</span></span><br><span class="line">    batch_size = <span class="number">16</span>  <span class="comment"># 一次训练的样本数目</span></span><br><span class="line">    num_epochs = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建数据</span></span><br><span class="line">    image_datasets, dataloaders, dataset_sizes, class_names = create_dataset(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## 获取模型  模型冻结了部分层，最后一层线性层修改</span></span><br><span class="line">    resnet152 = initialize_model(</span><br><span class="line">        model_name=<span class="string">&#x27;resnet&#x27;</span>,</span><br><span class="line">        num_classes=num_classes,</span><br><span class="line">        feature_extract=feature_extract,</span><br><span class="line">        use_pretrained=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否使用GPU训练</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> torch.cuda.is_available():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;CUDA is not available.  Training on CPU ...&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;CUDA is available!  Training on GPU ...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出网络结构</span></span><br><span class="line">    <span class="built_in">print</span>(summary(resnet152, (<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练参数</span></span><br><span class="line">    params_to_update = parameter_to_update(resnet152)</span><br><span class="line">    <span class="comment"># model_ft = model_ft.to(device)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 优化器设置</span></span><br><span class="line">    optimizer = torch.optim.Adam(params_to_update, lr=<span class="number">0.01</span>)</span><br><span class="line">    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">6</span>, gamma=<span class="number">0.1</span>)  <span class="comment"># 学习率每7个epoch衰减成原来的1/10</span></span><br><span class="line">    <span class="comment"># 最后一层已经LogSoftmax()了，所以不能nn.CrossEntropyLoss()来计算了，nn.CrossEntropyLoss()相当于logSoftmax()和nn.NLLLoss()整合</span></span><br><span class="line">    criterion = nn.NLLLoss()</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># # 开始训练</span></span><br><span class="line">    model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs = train_model(resnet152, dataloaders,</span><br><span class="line">                                                                                                criterion, optimizer,</span><br><span class="line">                                                                                                num_epoch=num_epochs,</span><br><span class="line">                                                                                                filename=<span class="string">&quot;resnet152_fc.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_all_layers(num_epochs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 评估模型结果</span></span><br><span class="line">    fortest()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="博客参考"><a href="#博客参考" class="headerlink" title="博客参考"></a>博客参考</h1><p><a href="https://www.jb51.net/article/222221.htm">PyTorch一小时掌握之ResNet迁移学习篇</a></p>
]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>ResNet</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%20%20%EF%BC%88%E9%A2%98%E7%9B%AE%20%E4%B8%8E%20%E7%B1%BB%E5%9E%8B%E5%BD%92%E7%BA%B3%EF%BC%89/</url>
    <content><![CDATA[<h2 id="代码随想录-（题目-与-类型归纳）"><a href="#代码随想录-（题目-与-类型归纳）" class="headerlink" title="代码随想录  （题目 与 类型归纳）"></a>代码随想录  （题目 与 类型归纳）</h2><h3 id="一些值的记忆的JAVA代码点"><a href="#一些值的记忆的JAVA代码点" class="headerlink" title="一些值的记忆的JAVA代码点"></a>一些值的记忆的JAVA代码点</h3><h4 id="数组与List"><a href="#数组与List" class="headerlink" title="数组与List"></a>数组与List</h4><h5 id="数组和-List-的相互转换-Arrays-asList"><a href="#数组和-List-的相互转换-Arrays-asList" class="headerlink" title="数组和 List 的相互转换      Arrays.asList"></a>数组和 List 的相互转换      <code>Arrays.asList</code></h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 数组转 List    </span></span><br><span class="line">List&lt;String&gt; wordList = Arrays.asList(String数组);</span><br><span class="line"><span class="comment">// list 转 int[]</span></span><br><span class="line"><span class="keyword">int</span>[] res = result.stream().mapToInt(Integer::intValue).toArray();</span><br></pre></td></tr></table></figure>
<h5 id="二维数组-按行初始化-Arrays-fill"><a href="#二维数组-按行初始化-Arrays-fill" class="headerlink" title="二维数组 按行初始化  Arrays.fill"></a>二维数组 按行初始化  <code>Arrays.fill</code></h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">chessboard = <span class="keyword">new</span> <span class="keyword">char</span>[n][n];</span><br><span class="line"><span class="comment">// 使用 Arrays方法</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">char</span>[] c : chessboard) &#123;</span><br><span class="line">	<span class="comment">// 填充棋盘</span></span><br><span class="line">	Arrays.fill(c, <span class="string">&#x27;.&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="二维数组转list"><a href="#二维数组转list" class="headerlink" title="二维数组转list"></a>二维数组转list</h5><p>将一个二维数组，变成一个一维度的 List</p>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">char</span>[] c : chessboard) &#123;</span><br><span class="line">	<span class="comment">// String.valueOf() 返回char数组参数的字符串表示形式</span></span><br><span class="line">    <span class="comment">// 那对于不同类型肯定不一样啦</span></span><br><span class="line">	list.add(String.valueOf(c));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><h5 id="比较字符串两者字母是否数量一致-Arrays-equals"><a href="#比较字符串两者字母是否数量一致-Arrays-equals" class="headerlink" title="比较字符串两者字母是否数量一致   Arrays.equals"></a>比较字符串两者字母是否数量一致   <code>Arrays.equals</code></h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span>[] str1 = s.toCharArray();</span><br><span class="line"><span class="keyword">char</span>[] str2 = t.toCharArray();</span><br><span class="line">Arrays.sort(str1);</span><br><span class="line">Arrays.sort(str2);</span><br><span class="line"><span class="comment">// 使用 equals 方法看看是不是一直 </span></span><br><span class="line"><span class="keyword">return</span> Arrays.equals(str1, str2);</span><br></pre></td></tr></table></figure>
<h5 id="字符串和-char-互相转换-toCharArray-new-String"><a href="#字符串和-char-互相转换-toCharArray-new-String" class="headerlink" title="字符串和 char[ ] 互相转换  toCharArray()  new String( )"></a>字符串和 char[ ] 互相转换  <code>toCharArray()</code>  <code>new String( )</code></h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span>[] sentence = s.toCharArray();</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="keyword">new</span> String(sentence);</span><br><span class="line"><span class="comment">// 如果创建一个新的</span></span><br><span class="line">String s = <span class="keyword">new</span> String(<span class="keyword">new</span> <span class="keyword">char</span>[]&#123;<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>&#125;);</span><br><span class="line"><span class="comment">// 截取</span></span><br><span class="line">String.valueOf(s, <span class="number">0</span>, 取不到的索引位置);</span><br></pre></td></tr></table></figure>
<h5 id="字符串（数字）宇整型-Int-互相转换"><a href="#字符串（数字）宇整型-Int-互相转换" class="headerlink" title="字符串（数字）宇整型 Int 互相转换"></a>字符串（数字）宇整型 Int 互相转换</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 字符串转数字</span></span><br><span class="line"><span class="keyword">int</span> num = Integer.parseInt(str);  <span class="comment">//比较耗费时间</span></span><br><span class="line"><span class="comment">// 数字转字符串</span></span><br><span class="line">String str = String.valueof(num);</span><br></pre></td></tr></table></figure>
<h5 id="替换字符的方法-replace"><a href="#替换字符的方法-replace" class="headerlink" title="替换字符的方法 replace"></a>替换字符的方法 <code>replace</code></h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String result = s.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;%20&quot;</span>);</span><br></pre></td></tr></table></figure>
<h5 id="字符串拼接-List内容-String-join"><a href="#字符串拼接-List内容-String-join" class="headerlink" title="字符串拼接 List内容   String.join"></a>字符串拼接 List内容   <code>String.join</code></h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String.join(<span class="string">&quot; &quot;</span>, wordList);</span><br></pre></td></tr></table></figure>
<h4 id="Collection-相关方法（针对-List）"><a href="#Collection-相关方法（针对-List）" class="headerlink" title="Collection 相关方法（针对  List）"></a>Collection 相关方法（针对  List）</h4><h5 id="将List-的内容全部逆序-Collections-reverse"><a href="#将List-的内容全部逆序-Collections-reverse" class="headerlink" title="将List 的内容全部逆序   Collections.reverse"></a>将List 的内容全部逆序   <code>Collections.reverse</code></h5><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">Collections.reverse(wordList);</span><br></pre></td></tr></table></figure>
<h4 id="Compare-用法"><a href="#Compare-用法" class="headerlink" title="Compare 用法"></a>Compare 用法</h4><p>其实涉及这块，我还是觉得 用 js 写起来简单一些</p>
<p><strong>用于sort</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">       Arrays.sort(people, <span class="keyword">new</span> Comparator&lt;<span class="keyword">int</span>[]&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(<span class="keyword">int</span>[] person1, <span class="keyword">int</span>[] person2)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">if</span> (person1[<span class="number">0</span>] != person2[<span class="number">0</span>]) &#123;</span><br><span class="line">                    <span class="keyword">return</span> person2[<span class="number">0</span>] - person1[<span class="number">0</span>];</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> person1[<span class="number">1</span>] - person2[<span class="number">1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">有时候甚至不需要这个库</span><br><span class="line">    我们后面其实 这个<span class="keyword">return</span> 返回的应该是一个正数或者负数 注意因为简写所以不需要 <span class="keyword">return</span></span><br><span class="line">    最好别用这种，碰到数据超了 或者值超了 = = 就不行了</span><br><span class="line">    Arrays.sort(points, (p1, p2) -&gt; p1[<span class="number">1</span>] &lt; p2[<span class="number">1</span>] ? -<span class="number">1</span> : <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<h4 id="优先队列（顶堆）"><a href="#优先队列（顶堆）" class="headerlink" title="优先队列（顶堆）"></a>优先队列（顶堆）</h4><h5 id="实现小（大）顶堆，并按规则排序-PriorityQueue"><a href="#实现小（大）顶堆，并按规则排序-PriorityQueue" class="headerlink" title="实现小（大）顶堆，并按规则排序    PriorityQueue"></a>实现小（大）顶堆，并按规则排序    <code>PriorityQueue</code></h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 例如 小(大)顶堆内存储的节点为 key ，按照存储key对应的value 大小排序为 小顶堆</span></span><br><span class="line">PriorityQueue&lt;Integer&gt; minHeap = <span class="keyword">new</span> PriorityQueue&lt;&gt;(<span class="keyword">new</span> Comparator&lt;Integer&gt;()&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer a,Integer b)</span></span>&#123;</span><br><span class="line">		<span class="keyword">return</span> HashMap.get(a) - HashMap.get(b);</span><br><span class="line">        <span class="comment">//return HashMap.get(a) - HashMap.get(b);</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="优先队列的函数-API"><a href="#优先队列的函数-API" class="headerlink" title="优先队列的函数 API"></a>优先队列的函数 API</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 其插入会自动进行堆排序的（自行调整堆）</span></span><br><span class="line">minHeap.add(key);</span><br><span class="line"><span class="comment">// 弹出堆顶  返回结果 </span></span><br><span class="line">minHeap.poll();</span><br><span class="line"><span class="comment">// 查看堆顶  返回结果</span></span><br><span class="line">minHeap.peek()；</span><br><span class="line"><span class="comment">// 查看堆是否为空  返回 布尔值</span></span><br><span class="line">minHeap.isEmpty()</span><br></pre></td></tr></table></figure>
<h4 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h4><h5 id="求一个二叉树的最大高度（递归）"><a href="#求一个二叉树的最大高度（递归）" class="headerlink" title="求一个二叉树的最大高度（递归）"></a>求一个二叉树的最大高度（递归）</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> depth = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxDepth</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 还是宏观来看 </span></span><br><span class="line">    <span class="comment">// 根节点为空 肯定没深度</span></span><br><span class="line">    <span class="keyword">if</span>(root == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 有根节点的话  </span></span><br><span class="line">    <span class="comment">// 我们就去看左右子树的深度</span></span><br><span class="line">    <span class="comment">// 左右 深度大的那个 肯定是根节点的深度 -1</span></span><br><span class="line">    <span class="comment">// 最后加上 根节点就是答案</span></span><br><span class="line">    <span class="keyword">int</span> left = maxDepth(root.left);</span><br><span class="line">    <span class="keyword">int</span> right = maxDepth(root.right);</span><br><span class="line">    depth = Math.max(left,right);</span><br><span class="line">    <span class="keyword">return</span> depth + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="求是不是一颗二叉排序树（递归）"><a href="#求是不是一颗二叉排序树（递归）" class="headerlink" title="求是不是一颗二叉排序树（递归）"></a>求是不是一颗二叉排序树（递归）</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> pre = Long.MIN_VALUE;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValidBST</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">boolean</span> left = isValidBST(root.left);</span><br><span class="line">        <span class="keyword">if</span> (root.val &lt;= pre) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        pre = root.val;</span><br><span class="line">        <span class="keyword">boolean</span> right = isValidBST(root.right);</span><br><span class="line">        <span class="keyword">return</span> left &amp;&amp; right;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="题目分类"><a href="#题目分类" class="headerlink" title="题目分类"></a>题目分类</h3><ul>
<li>打钩的表示 肯定会做；</li>
<li><font color="green">绿色</font> 表示我能写出来，但是不一定 不熟，有时候就想不到</li>
<li><font color="blue">蓝色</font> 表示有想法做出来但是过不了或者 不是考的想法，时间复杂度太高</li>
<li><font color="orange">橙色</font>的意思是，大概率还是写不出来，但是我看得懂； </li>
<li><font color="red">红色</font>的意思是，我估计写不出来，只能靠默写，原理不是很明白</li>
</ul>
<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><ul>
<li>[x] 二分查找                                                                      方法：二分查找</li>
<li>[ ] <font color="blue">移除元素</font>                                                                      方法：双指针（可用覆盖隐式双指针）</li>
<li>[ ] <font color="blue">序数组的平方</font>                                                              方法：双指针</li>
<li>[ ] <font color="orange">长度最小的子数组</font>                                                      方法：滑动窗口（双指针实现）</li>
<li>[ ] <font color="orange">螺旋矩阵Ⅱ</font>                                                                  方法：模拟  找到合适判断条件转方向</li>
</ul>
<h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><ul>
<li>[x] 移除链表元素                                                                     方法：头结点</li>
<li>[x] 设计链表                                                                             方法：头结点，index超过 需要先判断null</li>
<li>[ ] <font color="orange">反转链表</font>                                                                             方法：递归</li>
<li>[x] 两两交换链表中的节点                                                      方法：<font color="red">递归</font>   或  头结点+双指针</li>
<li>[x] 删除链表的倒数第 N 个结点                                             方法：头结点+栈</li>
<li>[ ] <font color="green">链表相交</font>                                                                             方法：双指针</li>
<li>[ ] 环形链表 II                                                                          方法：<font color="orange">头结点+快慢指针+数学</font>  或  哈希Set</li>
</ul>
<h3 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h3><ul>
<li>[x] 有效的字母异位词                                                              方法：<font color="green">equals函数</font>  或  哈希表</li>
<li>[ ] <font color="orange">查找常用字符</font>                                                                      方法：哈希表  （但逻辑比较复杂）</li>
<li>[x] 两个数组的交集                                                                  方法：哈希Set</li>
<li>[ ] <font color="orange">快乐数                                                                                  </font>                                                                                方法：数学+哈希Set+ 获取一个数所有位数操作</li>
<li>[x] 两数之和                                                                              方法：哈希表</li>
<li>[ ] <font color="orange">四数相加Ⅱ</font>                                                                          方法：分两段暴力 + 哈希表</li>
<li>[ ] 赎金信                                                                                  方法：哈希表（<font color="green">用数组哈希更快一些</font>）</li>
<li>[ ] <font color="orange">三数之和</font>                                                                              方法：循环内双指针（去重考虑难度大）</li>
<li>[ ] <font color="orange">四数之和</font>                                                                              方法：双循环内双指针（去重考虑难度大）</li>
</ul>
<h3 id="字符串-1"><a href="#字符串-1" class="headerlink" title="字符串"></a>字符串</h3><ul>
<li>[x] 反转字符串                                                                           方法：双指针</li>
<li>[ ] <font color="blue">反转字符串Ⅱ</font>                                                                       方法：双指针</li>
<li>[ ] <font color="blue">替换空格</font>                                                                                方法：字符串API <code>replace</code> 或 StringBuilder遍历</li>
<li>[x] 反转字符串里的单词       方法：API trim + 正则表达 + 双指针+ StringBuilder   或者 <font color="red">正则+list+collection+join</font></li>
<li>[x] 左旋转字符串                                                                        方法：StringBuilder</li>
<li>[ ] <font color="red">重复的子字符串</font>                                                                     方法：数学</li>
</ul>
<h3 id="栈与队列"><a href="#栈与队列" class="headerlink" title="栈与队列"></a>栈与队列</h3><ul>
<li>[x] 用栈实现队列                                                                         方法：Java 类定义写法  注意：什么时候将第一个队列全部放到第二个中</li>
<li>[x] 用队列实现栈                                                                         方法：使用Deque   里面有 removeFirst removeLast方法 更快</li>
<li>[x] 有效的括号                                                                             方法：使用Deque  正着写就行（就是麻烦点），反着写比较难写</li>
<li>[x] 删除字符串中的所有相邻重复项                                          方法：使用Deque  正着写，利用 Deque双端 简单一些</li>
<li>[ ] 逆波兰表达式                                                                         方法：使用Deque栈，使用<strong>正则表达式</strong>判断是否会数字</li>
<li>[ ] <font color="red">滑动窗口最大值</font>                                                                     方法：使用Deque 编写单调栈，要前后两头都考虑</li>
<li>[ ] <font color="orange">前K个高频元素</font>                                                                       方法：哈希表 + 优先队列（小顶堆）</li>
</ul>
<h3 id="二叉树-1"><a href="#二叉树-1" class="headerlink" title="二叉树"></a>二叉树</h3><p><img src="C:\Users\96356\Desktop\上传图片\20210219190809451.png" alt="20210219190809451" style="zoom:50%;" /></p>
<h4 id="二叉树的遍历方式"><a href="#二叉树的遍历方式" class="headerlink" title="二叉树的遍历方式"></a>二叉树的遍历方式</h4><ul>
<li>[x] 二叉树的前序遍历                                                                     方法：递归</li>
<li>[x] 二叉树的后序遍历                                                                     方法：递归</li>
<li>[x] 二叉树的中序遍历                                                                     方法：递归</li>
<li>[x] 二叉树的层次遍历                                                                     方法：Queue队列 </li>
</ul>
<h4 id="二叉树的属性"><a href="#二叉树的属性" class="headerlink" title="二叉树的属性"></a>二叉树的属性</h4><ul>
<li>[ ] <font color="green">对称二叉树</font>                                                                                 方法：递归</li>
<li>[x] 二叉树的最大深度                                                                     方法：<font color="orange">递归  </font>或  层次</li>
<li>[ ] <font color="red">二叉树的最小深度</font>                                                                     方法：<font color="red">递归  </font></li>
<li>[ ] <font color="blue">完全二叉树的节点个数</font>                                                             方法：<font color="red">递归</font> 或  层次</li>
<li>[ ] <font color="green">平衡二叉树</font>                                                                                方法：递归</li>
<li>[ ] <font color="red">二叉树的所有路径</font>                                                                     方法：递归</li>
<li>[ ] <font color="orange">左叶子之和</font>                                                                                方法：递归   <font color="orange">（如何判断是左叶子！）</font></li>
<li>[ ] <font color="blue">找树左下角的值</font>                                              方法：<font color="orange">递归（如何判断是最后一层最左侧） 或 特殊的 BFS 方法</font></li>
<li>[ ] <font color="green">路经总和</font>                                                                                   方法：递归</li>
</ul>
<h4 id="二叉树的修改和改造"><a href="#二叉树的修改和改造" class="headerlink" title="二叉树的修改和改造"></a>二叉树的修改和改造</h4><ul>
<li>[ ] <font color="green">翻转二叉树</font>                                                                                   方法：递归</li>
<li>[ ] <font color="red">从中序与后序遍历序列构造二叉树</font>                                             方法：<font color="red">哈希表 + 递归</font></li>
<li>[ ] <font color="green">最大二叉树 </font>                                                                                  方法：递归 （用左右控制截取nums）</li>
<li>[ ] <font color="orange">合并二叉树</font>                                                                                   方法：递归（都有的创建新节点来做简单）</li>
</ul>
<h4 id="搜索二叉树的属性"><a href="#搜索二叉树的属性" class="headerlink" title="搜索二叉树的属性"></a>搜索二叉树的属性</h4><p>注意搜索二叉树其实就是  排序二叉树，可以利用到 左边小，右边大的性质，这样更快</p>
<font color="red">**其中序排序是 有序序列**</font>

<ul>
<li><p>[x] 700. 二叉搜索树中的搜索                                                            方法：递归，利用性质更快</p>
</li>
<li><p>[ ] <font color="orange">98.验证二叉搜索树</font>                                                                     方法：递归，用改良中序</p>
</li>
<li>[ ] <font color="orange">530.二叉搜索树的最小绝对差</font>                                                   方法：递归，同上改良 </li>
<li>[ ] <font color="orange">501.二叉搜索树中的众数</font>                                                           方法：<font color="orange">中序递归按情况计数，需要记录前节点</font></li>
<li>[ ] <font color="green">538.把二叉搜索树转换为累加树</font>                                               方法：右根左 递归，<font color="green">记录前节点累加，类似于上题</font></li>
</ul>
<h4 id="二叉树公共祖先问题"><a href="#二叉树公共祖先问题" class="headerlink" title="二叉树公共祖先问题"></a>二叉树公共祖先问题</h4><ul>
<li>[ ] <font color="red">236.二叉树的最近公共祖先</font> <strong>（最近经常出 字节啥的）</strong>          方法：递归 </li>
<li>[ ] <font color="orange">235.二叉搜索树的最近公共祖先</font>                                              方法：<font color="orange">循环判断（利用二叉搜索树的性质）</font> 或者 同上题</li>
</ul>
<h4 id="二叉搜索树的修改和改造"><a href="#二叉搜索树的修改和改造" class="headerlink" title="二叉搜索树的修改和改造"></a>二叉搜索树的修改和改造</h4><ul>
<li>[x] 701.二叉搜索树中的插入操作                                                         方法：循环判断 （利用二叉搜素树的性质）                                                                                                           注意：我考虑的插入的一定是 叶子节点               或者 递归</li>
<li>[ ] <font color="red">450.删除二叉搜索树中的节点 </font>                                                         方法：循环判断  或者 递归   <font color="red"><strong>都比较难没咋看懂</strong></font> </li>
<li>[ ] <font color="red">669.修剪二叉搜索树</font>                                                                        方法：递归  <font color="red"><strong>难想</strong></font> </li>
<li>[ ] <font color="orange">108.将有序数组转换为二叉搜索树</font>                                                 方法：递归  <font color="orange">要注意右侧落点（否则- -会<strong>死循环</strong>）</font></li>
</ul>
<h3 id="回溯算法"><a href="#回溯算法" class="headerlink" title="回溯算法"></a>回溯算法</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/20210219192050666.png" alt=""></p>
<h4 id="组合问题"><a href="#组合问题" class="headerlink" title="组合问题"></a>组合问题</h4><ul>
<li><p>[ ] <font color="orange">77.组合</font>                                                                               方法：回溯  剪枝优化 <code>large - (k - path.size()) + 1</code></p>
</li>
<li><p>[ ] <font color="orange">17.电话号码的字母组合</font>                                                    方法：哈希（转换为数组更快）+ 回溯。 树的高度应该是 电话号码的个数</p>
</li>
<li><p>[ ] <font color="blue">39.组合总和</font>                                                                       方法：利用begin的回溯法，<font color="orange">需关于值的 剪枝 break 降低复杂度</font></p>
</li>
<li><p>[ ] 40.组合总和Ⅱ                                                                   方法：利用begin的回溯法，<strong>需要额外的重复剪枝 continue</strong>，不然答案会重复</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(begin &lt; i &amp;&amp; candidate[i-<span class="number">1</span>] == candidate[i] )</span><br><span class="line">    <span class="keyword">continue</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>[ ] <font color="green">216.组合总和Ⅲ</font>                                                                 方法：类似于 组合总数，只是要在 return 的时候注意 只有长度为k的才可以</p>
</li>
</ul>
<h4 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h4><ul>
<li>[ ] <font color="orange">131.分割回文串</font>                                                                               方法：回溯  begin ，需要截取字符串 (begin, i+1)</li>
<li>[ ] <font color="orange">93.复原IP地址</font>     <strong>2021.3.24虾皮笔试</strong>                                           方法：回溯 begin 和上题很像 但是要注意细节处理 使用path记录，最后拼接答案（我用的 get() 和 sub  Integer.parseInt 是比较慢 = =的 ）</li>
</ul>
<h4 id="子集"><a href="#子集" class="headerlink" title="子集"></a>子集</h4><ul>
<li>[ ] <font color="orange">78.子集</font>                                                                               方法：回溯  begin  递归出口直接写就好</li>
<li>[ ] <font color="orange">90.子集Ⅱ</font>                                                                               方法：回溯  begin  同上 只是要剪枝。 要先sort一下，不然剪枝无效的。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(begin &lt; i &amp;&amp; candidate[i-<span class="number">1</span>] == candidate[i] )</span><br><span class="line">    <span class="keyword">continue</span>;</span><br></pre></td></tr></table></figure>
<h4 id="排列"><a href="#排列" class="headerlink" title="排列"></a>排列</h4><ul>
<li><p>[ ] <font color="orange">46.全排列</font>                                                                               方法：回溯  begin=0  + visited数组</p>
</li>
<li><p>[ ] <font color="orange">47.全排列Ⅱ</font>                                                                           方法：回溯  begin=0  + visited数组 + 剪枝</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>( i &gt; <span class="number">0</span> &amp;&amp; numbers[i-<span class="number">1</span>] == numbers[i]  &amp;&amp; visited[i-<span class="number">1</span>] == <span class="keyword">true</span>)</span><br><span class="line">    <span class="keyword">continue</span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="棋盘问题"><a href="#棋盘问题" class="headerlink" title="棋盘问题"></a>棋盘问题</h4><ul>
<li><p>[ ] <font color="red">51.N皇后</font>                                                                               方法：回溯  begin 变成 row 行， 每次找到当前行哪一列位置好使进行递归。 答案用的是一个  二位数组记录并判断是否合适</p>
</li>
<li><p>[ ] <font color="red">37.解数独</font>                                                                              方法：回溯中有 3层for  ，backtrack有返回值 boolean 因为只要获取一个</p>
</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">https://mp.weixin.qq.com/s/VCirGskFGPln-S2LGFTgKg</span><br></pre></td></tr></table></figure>
<h4 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h4><ul>
<li><p>[ ] <font color="red">491.递增子序列（和子集问题很像）</font>                                                                               方法：回溯  begin  哈希去重（如果用 path判断的 话 有个样例有bug， 不能盲目i的用之前的去重办法）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (path.size() != <span class="number">0</span> &amp;&amp; path.get(path.size() - <span class="number">1</span>) &gt; numbers[i] ) </span><br><span class="line">    <span class="keyword">continue</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>[ ] <font color="red">332.重新安排行程</font>                                                                              方法：begin = 0， 类似于全排列的做法。 backtrack有返回值 boolean 因为只要获取一个。 在判断的时候，需要判断</p>
</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">// 刚开始就字典序排序</span><br><span class="line">Collections.sort(tickets,(a,b) -&gt; a.get(1).compareTo(b.get(1))); // 字典序排序</span><br><span class="line">//</span><br></pre></td></tr></table></figure>
<h3 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/20210917104315.png" alt=""></p>
<p><strong>贪心的本质是选择每一阶段的局部最优，从而达到全局最优</strong>。</p>
<h4 id="简单题目"><a href="#简单题目" class="headerlink" title="简单题目"></a>简单题目</h4><ul>
<li>[x] 455.分发饼干                                                                             方法：贪心 双循环</li>
<li>[ ] <font color="orange">1005.K次取反后最大化的数组和</font>                                             方法：贪心思路比较难想</li>
<li>[ ] <font color="orange">860.柠檬水找零</font>                                                                方法：模拟，但是有两种情况，用方法去考虑规避</li>
</ul>
<h4 id="中等题目"><a href="#中等题目" class="headerlink" title="中等题目"></a>中等题目</h4><h5 id="排序问题"><a href="#排序问题" class="headerlink" title="排序问题"></a>排序问题</h5><ul>
<li>[ ] 376. <font color="red">摆动序列</font>                                                                    方法：非常优化的动态规划 其他方法太复杂</li>
<li>[ ] <font color="orange">738.单调递增的数字</font>                                                        方法：从右往左改数字</li>
</ul>
<h5 id="贪心解决股票问题"><a href="#贪心解决股票问题" class="headerlink" title="贪心解决股票问题"></a>贪心解决股票问题</h5><ul>
<li>[ ] <font color="orange">122.买卖股票的最佳时期Ⅱ</font>                                                  方法：动态规划 或 贪心</li>
<li>[ ] <font color="orange">714.买卖股票的最佳时期含手续费 </font>                                      方法：动态规划和上题基本一模一样，这里的贪心策略比较难想</li>
</ul>
<h5 id="两个维度权衡问题"><a href="#两个维度权衡问题" class="headerlink" title="两个维度权衡问题"></a>两个维度权衡问题</h5><ul>
<li>[ ] <font color="orange">135.分发糖果</font>                                                                 方法：贪心算法，从左和从右考虑两次</li>
<li>[ ] <font color="orange">406.根据身高重建队列</font>                                                  方法：贪心算法，分两步</li>
</ul>
<h4 id="有点难度"><a href="#有点难度" class="headerlink" title="有点难度"></a>有点难度</h4><h5 id="区间问题"><a href="#区间问题" class="headerlink" title="区间问题"></a>区间问题</h5><ul>
<li>[ ] <font color="red">55.跳跃游戏</font>                                                                 方法：贪心算法 和 动态规划 我觉得对我来说都不好想 = =</li>
<li>[ ] <font color="red">45.跳跃游戏Ⅱ</font>                                                             方法：贪心算法，从左和从右考虑两次</li>
</ul>
<p>重叠区域</p>
<ul>
<li>[ ] <font color="orange">452.用最少数量的箭引爆气球</font>                                    方法：贪心算法 这道题用 java sort 的时候需要注意  普通 a[1] -b[1]是不行的  得用三目表达式 return 正负回去</li>
<li>[ ] <font color="orange">435.无重叠区间</font>                                                           方法：贪心算法 和上题一样只是  需要添加判断等于的时候  最后用减法即可， length - 穿过的箭就是答案</li>
<li>[ ] <font color="red">763.划分字母区间</font>   <strong>2022美团测试开发题</strong>                 方法：其规则比较难想，转换为上面两题的做法答案思路是不一样的，所以这里他其实巧妙的保存了最后一个元素的索引，然后特殊遍历去做</li>
<li>[ ] <font color="blue">56.合并区间</font>                                                                 方法：JS使用来回两次 用splice方法增加删除 就是速度慢，java想实现同样的想来太慢了。这个想法是按右侧先排，然后再左右合并。   <strong>代码最简单的想法是，先按左侧排序，然后在将合适的填入（更快）</strong>。</li>
</ul>
<ul>
<li>[ ] <font color="blue">53.最大子序和</font>                                                             方法：用动态规划 最简单</li>
<li>[ ] <font color="orange">134.加油站</font>                                                                  方法： 在用模拟方法的时候，需要 i+count+1 才可以  他的意思是说  例如 x到 k 就不行，那 x到k中，所有的点到Z肯定也是不行的。</li>
<li>[ ] <font color="orange">968.监控二叉树</font>   困难题 <strong>天堂硅谷竞赛题</strong>                方法：后续遍历 ，子节点告诉父节点干嘛 摄像头尽可能的装在父节点上，0，1，2表示3种状态，被监视到，放摄像头，没监视到</li>
</ul>
<h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/动态规划上半部分.png" alt=""></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/动态规划下部分.png" alt=""></p>
<ul>
<li>[x] 509.斐波那契函数                                                方法：基础 一维 动态规划</li>
<li>[x] 70.爬楼梯                                                              方法：和上面一题  动态转移方程一模一样</li>
<li>[x] 746.使用最小花费爬楼梯                                     方法：上一题的 在加上 cost[i]，也很简单</li>
<li>[x] 62.不同路径                                                           方法：简单的二维动态</li>
<li>[x] 63.不同路径 II                                                      方法：上题 加个判断 </li>
<li>[ ] <font color="orange">343.整数拆分</font>                                                       方法：动态规划（比较难想，属于背包问题），用数学方法最佳，根据数学推断 分成3一堆一堆，最大</li>
<li>[ ] <font color="red">96.不同的二叉搜索树</font>                                          方法：动态规划很难想 记不住  建议背下来</li>
</ul>
<h4 id="背包问题"><a href="#背包问题" class="headerlink" title="背包问题"></a>背包问题</h4><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/背包问题的分类.png" alt=""></p>
<h5 id="0-1背包问题"><a href="#0-1背包问题" class="headerlink" title="0-1背包问题"></a>0-1背包问题</h5><p>也就是每个东西只能拿一次</p>
<font color="red">**滚动数组的内循环，从后往前**</font>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">    <span class="comment">// 内循环 从后往前</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">let</span> j = amount; j &gt;= nums[i]; j--)&#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>[x] <font color="red">416.分割等和子集</font>                                             方法：就是最基本的 0-1背包问题 只是 weight[i] 变成 nums[i] ，二维一维都可写。  这道题的暴力做法，为回溯。  </p>
</li>
<li><p>[x] <font color="red">1049.最后一块石头的重量 II</font>                            方法：转换思想后 完全就是 0-1背包  只是最后 return 你要想清楚返回的是啥</p>
</li>
<li><p>[x] <font color="red">494.目标和</font>                                                        方法：转换思想后 是个 0-1背包的 <strong>组合问题</strong>，其动态转移方程 有变化 为  <code>dp[j] += dp[j - nums[i]];</code>  并且初始化 dp[0] 要考虑清楚。</p>
<p>二维写不出来，= =            回溯看了别人的可以过哎，就是很慢。</p>
</li>
<li><p>[x] <font color="red">474.一零和</font>                                                       方法：0-1背包问题，这里的滚动数组 内层变成了二维双循环，所以 滚动数组为二维    滚动数组定义为 <strong>最多有i个0和j个1的strs的最大子集的大小</strong> 其状态转移方程为</p>
<p><code>dp[i][j] = max(dp[i][j], dp[i - zeroNum][j - oneNum] + 1);</code>  zeroNum 与 oneNum 表示为当前</p>
</li>
</ul>
<h5 id="完全背包问题"><a href="#完全背包问题" class="headerlink" title="完全背包问题"></a>完全背包问题</h5><font color="red">**其实就是 滚动数组的内循环，不再从后往前，为从前往后**</font>  **这个适用于组合问题**

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">    <span class="comment">// 内循环 从前往后</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">let</span> j = nums[i]; j &lt;= amount; j++)&#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

遍历顺序问题：

**组合问题** （求组合个数）

对于组合问题或者背包问题    **都采用 先遍历物品，再遍历背包**

对于组合问题（问排序数）  **都采用 先遍历背包，再遍历物品**

**dp的定义为  dp[i] 为当前 i 下 有几个的组合数**

采用的 动态转移方程为

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">dp[j] += dp[j - nums[i]];</span><br></pre></td></tr></table></figure>

  初始化要注意：  `dp[0] = 1`



**求组合问题中的 最佳**

**dp的定义为  dp[i] 为当前 i 下 可以的数字组合中，长度的最小值**

采用的 动态转移方程为

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">dp[j] = <span class="built_in">Math</span>.min(dp[j], dp[j- coins[i]] + <span class="number">1</span>) </span><br></pre></td></tr></table></figure>

  初始化要注意 一般：  `dp[0] = 0`， 其他都为 `Infinity`  无穷大



对于排序问题，其遍历顺序是有区别的

我应该先遍历容积，再遍历背包

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> j = <span class="number">0</span>; j &lt;= n; j++)&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt;= nums.length; i++)&#123;</span><br><span class="line">    	<span class="keyword">if</span>(j &gt;= nums[i])&#123;</span><br><span class="line">    		dp[j] += dp[j - nums[i]]</span><br><span class="line">    	&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



- [x] <font color="orange">518.零钱兑换 Ⅱ</font>                                             方法：完全背包的**组合问题 ** 其动态转移方程 有变化 为  `dp[j] += dp[j - nums[i]];`  并且初始化 dp[0] 要考虑清楚。应该初始为 1

- [x] <font color="orange">377.组合总数Ⅳ</font>                                              方法：**组合数** 就是目标和 那道题的 完全背包 （数字可以重复用） `dp[j] += dp[j - nums[i]];`  并且初始化 dp[0] 要考虑清楚。应该初始为 1

  **不过这道题求的是排序数  不是 组合数  所以 内外循环 遍历顺序需要变换**。  **昨天刚做个这个 所以我第一次做出来了**

- [x] <font color="blue">70.爬楼梯（完全背包解法)</font>                         方法：同样这道题 也可以理解为 **排序数** 和上题做法一模一样。 就是 nums[] 物品数组 变成步数而已 {1,2}

- [x] <font color="red">322.零钱兑换</font>                                       方法：**求组合问题中的 最佳**

- [x] <font color="blue">279.完全平方数</font>                                   方法：**求组合问题中的 最佳**， 和上题一样，就是这题需要自己先构建处 一个 物品[ ] 出来

  这题用 java 比较麻烦，因为构造这个 物品[ ]  只能用list 还要转 = -= 自讨苦吃，所以我不写。

- [x] <font color="red">139.单词拆分</font>                                      方法：属于**排序问题**   但是这个递推公式比较难想

> 如果确定dp[j] 是true，且 [j, i] 这个区间的子串出现在字典里，那么dp[i]一定是true。（j < i ）。
>
> 所以递推公式是 if([j, i] 这个区间的子串出现在字典里 && dp[j]是true) 那么 dp[i] = true。



#### 打家劫舍

这个类型的题其实不算 0-1背包问题， **因为 背包问题没有限制取包的规则**

- [ ] <font color="orange">198.打家劫舍（线性）</font>                                              方法： `dp[i] = Math.max(dp[i-2] + nums[i] ,dp[i-1])` 没写出来，太蠢了，白写题目了，以前这个题做的出来的啊

- [ ] <font color="blue">213.打家劫舍Ⅱ  （环状）</font>                                        方法：由于是环状，其实最后的落点一定在 倒数第一家或者倒数第二家。所以我们可以把数组拆成  0- n-2  和 1- n-1 来取其中最大值，每一段的取值和上一题线性一致。

- [ ] <font color="red">337.打家劫舍Ⅲ  （树形dp）</font>                                        方法：**必须后续遍历递归做**，**因为通过递归函数的返回值来做下一步计算**。dp为2维度 为 【不偷，偷】的分别最大值。

  递归逻辑为 如果抢了当前节点，两个孩子就不能动，如果没抢当前节点，就可以考虑抢左右孩子（**注意这里说的是“考虑”**）递归出口为 碰到 null 返回 [0,0]



#### 股票问题

- [ ] <font color="red">121.买卖股票的最佳时机 （只能买卖一次）</font>                方法：这题一定要是1维度的，因为他只买卖一次，不能用下面的二维来做。

- [ ] <font color="red">122.买卖股票的最佳时机Ⅱ （可以买卖多次）</font>            方法： 定义dp 的理解上， `dp[i][0]表示第i天不持有股票, dp[i][1]表示第i天持有股票`。 所以首先要合理初始化， 然后遍历讨论 `dp[i][0]` 和 `dp[i][1]` 的可能性，分别各自有两种。

- [ ] <font color="red">123.买卖股票的最佳时机Ⅲ （最多买卖两次）</font> 方法：

  <font color="red">**这道题的 dp定义为  `dp[i][j]`  描绘的是当天整体处于的状态，不是当天的操作**</font>

<pre><code> `dp[i][0]` 第 i 天没有操作， 那前面也不可能操作
</code></pre><p>  ​                    <code>dp[i][0] = dp[i - 1][0];</code></p>
<pre><code> `dp[i][1]` 第 i 天第一次买入，这个意思是 

 之前是的状态是第一次买入，但今天可以不卖 
</code></pre><p>  ​    或者是 前面一直是静默状态，今天买入了</p>
<p>  ​                    <code>dp[i][1] = Math.max(dp[i - 1][1], dp[i - 1][0] - prices[i])</code></p>
<pre><code> `dp[i][2]` 第 i 天第一次卖出，这个意思是 之前的状态已经是卖出第一次了，我今天静默；或者是今天确实是第一次卖出
</code></pre><p>  ​                    <code>dp[i][2] = Math.max(dp[i - 1][2], dp[i - 1][1] + prices[i]);</code></p>
<pre><code> `dp[i][3]` 第 i 天第二次买入 ，这个意思就是 之前已经卖出过第一次了，此刻已经是买入的状态。有可能为之前已经买入第二次，今天是静默 或者  是今天买的第二次，之前一直是第一次卖出的状态
</code></pre><p>  ​                    <code>dp[i][3] = Math.max(dp[i - 1][3], dp[i - 1][2] - prices[i]</code>        </p>
<pre><code> `dp[i][4]` 第 i 天第二次卖出，这个意思是  此时整体是第二次卖出的状态，有两种可能：第一之前已经卖出了第二次了，我今天是静默；第二我就是今天卖的
</code></pre><p>  ​                <code>dp[i][4] = Math.max(dp[i - 1][4], dp[i - 1][3] + prices[i]);</code></p>
  <font color="blue">**初始化中** </font> `dp[i][1]  = -prices[0]`

  第二次买入依赖于第一次卖出的状态，其实相当于第0天第一次买入了，第一次卖出了，然后在买入一次（第二次买入）

  ​    `dp[i][3]  = -prices[0]`

  <font color="blue">**最后的 return 可定是** `dp[prices.length - 1][4]`</font>，因为我要满足两次都卖出的时候状态并且是最后一天的时候。

- [ ] <font color="red">188.买卖股票的最佳时机Ⅳ （最多买卖k次）</font>  方法：这题就是上一题 2 => k **变成循环就完了**

- [ ] **309.买卖股票多次  但是买入之后需要一天的冷冻期    方法：**

- [ ] <font color="blue">714.买卖多次 但是每次有手续费</font>                    方法：这题就是 122.买卖股票的最佳时机Ⅱ （可以买卖多次） 卖了多个费用而已



#### 子序列问题

##### 子序列（不连续）问题

**全部是正常遍历顺序** 

- [ ] <font color="red">300.最长递增子序列</font>                                方法：`dp[i] = max(dp[i], dp[j] + 1);`  初始化全为1  两层for 循环

- [x] <font color="red">1143.最长公共子序列</font>                               方法：`dp[i][j]` 的含义是 `text1[0:i-1]` 和 `text2[0:j-1]` 的最长公共子序列。

  如果`text1[i - 1] 与 text2[j - 1]`不相同，那就看看`text1[0, i - 2]与text2[0, j - 1]的最长公共子序列 和 text1[0, i - 1]与text2[0, j - 2]的最长公共子序列，取最大的。`

  ![](http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/QQ截图20220915200451.png)

- [ ] <font color="blue">1035.不相交的线</font>                                      方法：**和上面一题一模一样，代码都是一样的**，就是换个场景。 语法糖啊。



##### 子序列（连续）问题

**全部是正常遍历顺序** 

- [ ] <font color="blue">674.最长连续递增子序列</font>          方法：这道题 和 <font color="red">300.最长递增子序列</font> 想法是一样的，只是 j 的变化范围的区别，在这里必须是连续的 所以 j 的取值只有 i 的前一个，但是 不连续的情况下， j 的取值是 [0, i-1]。  所以只需要在 300的基础上，需改 j 的初始值wei  i - 1 即可。

- [ ] <font color="red">718.最长公共子数组</font>                  方法：这道题<font color="red">1143.最长公共子序列</font>  一模一样，就是这里是连续，连续和不连续的区别在于，动态转移方程不同

  对于  非连续 

  <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(text1[i-<span class="number">1</span>] == text2[j-<span class="number">1</span>])</span><br><span class="line">    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    dp[i][j] = <span class="built_in">Math</span>.max(dp[i-<span class="number">1</span>][j],dp[i][j-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

  对于 连续  只有   并且最大的并不是 dp最后，所以需要一个 result 去维护

  <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(text1[i-<span class="number">1</span>] == text2[j-<span class="number">1</span>])</span><br><span class="line">    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">1</span></span><br></pre></td></tr></table></figure>



- [ ] 53.最大子数和                     方法：正常的一维动态规划



##### 编辑距离

**全部是正常遍历顺序** 

- [ ] <font color="orange">392.判断子序列</font>                    方法：用最大公共子序列，然后判断最后结果必须和 s序列长度一样。这个方法是可行的.

  <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这位 t 对比上了 所以去掉这位 继续</span></span><br><span class="line">dp[i][j] = dp[i][j-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

- [ ] <font color="red">115.不同的子序列</font>             方法：这道题其实就是编辑距离，只是仅仅考虑删除，不包括修改和增加。**并且只考虑左侧字符串。** 并且这道题是考虑 匹配的数量，所以动态规划表达式有所区别。

- [ ] <font color="blue">583.两个字符串的删除操作</font>    方法：这道题是上一题的变成了 2个字符串都删除，求删到一样的最小步数。其实最佳的结束点就是最大公共子序列，步数就是 长度- 最大公共子序列啊。。

- [ ] <font color="red">72.编辑距离</font>                     方法：这道题是最经典的编辑距离的问题，也就是上面 <font color="red">115.不同的子序列</font>的完全版，需要同时考虑 删除、修改和增加，这道题dp考虑的是操作数。

  `dp[i][j] 表示以下标i-1为结尾的字符串word1，和以下标j-1为结尾的字符串word2，最近编辑距离为dp[i][j]。`

​        其中删除和增加的 动态规划表达式是一样的

​        `if (word1[i - 1] != word2[j - 1])`，此时就需要编辑了，如何编辑呢？

​        **操作一：word1删除一个元素，那么就是以下标i - 2为结尾的word1 与 j-1为结尾的                   word2的最近编辑距离 再加上一个操作。**

​        即 `dp[i][j] = dp[i - 1][j] + 1;`

​        **操作二：word2删除一个元素，那么就是以下标i - 1为结尾的word1 与 j-2为结尾的                   word2的最近编辑距离 再加上一个操作。**

​         即 `dp[i][j] = dp[i][j - 1] + 1;`

​        对于修改

​        就是该 word1[i-1] 为 word2[j-1] ，也就是 `dp[i][j] = dp[i-1][j-1] + 1` 

​        // 初始化

​        `dp[i][0] 和 dp[0][j]`   肯定是分别删除它的全部啦

​        

#### 回文

**这里的题 dp 全部不用 + 1**

**遍历顺序全部为 i 从下到上  j 从左（i/i+1 开始自己分析情况）到右**

- [ ] <font color="red">647.回文子串</font>                               方法：动态规划法 （需要注意遍历顺序）， 另外还有中心扩散法，这个方法比较巧妙并且空间复杂度低

- [ ] 5.最长回文子串

- [ ] 516.最长回文子序列          方法：动态规划法

  <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">    dp[i][i] = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i = length - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">let</span> j = i + <span class="number">1</span>; j &lt; length; j++) &#123;</span><br><span class="line">        <span class="keyword">if</span>(s[i] === s[j]) &#123;</span><br><span class="line">            dp[i][j] = dp[i+<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">2</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            dp[i][j] = <span class="built_in">Math</span>.max(dp[i+<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

  **另一种新奇的思路试， 将s.reverse()， s 和 s.reverse() 的最大公共子序列就是最长回文子序列**





### 单调栈

什么时候用单调栈呢？

**通常是一维数组，要寻找任一个元素的右边或者左边第一个比自己大或者小的元素的位置，此时我们就要想到可以用单调栈了**。时间复杂度为O(n)。

**单调栈的本质是空间换时间**，因为在遍历的过程中需要用一个栈来记录右边第一个比当前元素高的元素，优点是整个数组只需要遍历一次。

**注意点：**

<font color="blue">单调栈里只需要存放元素的下标i就可以了，如果需要使用对应的元素，直接T[i]就可以获取。</font>

<p><strong>单调递增递减怎么看？</strong></p>
<font color="red">**指的是栈头到栈底应该保持一种单调的状态**</font>

<ul>
<li>如果求一个元素右边第一个更大元素，单调栈就是递增的</li>
<li>如果求一个元素右边第一个更小元素，单调栈就是递减的。</li>
</ul>
<p><strong>使用单调栈在 遍历一次数组中  一般来说有3种情况</strong></p>
<ul>
<li>当前遍历的元素T[i]小于栈顶元素T[st.top()]的情况</li>
<li>当前遍历的元素T[i]等于栈顶元素T[st.top()]的情况</li>
<li>当前遍历的元素T[i]大于栈顶元素T[st.top()]的情况</li>
</ul>
<p>难点主要在对三种情况应该具体怎么分析入栈和出栈的</p>
<ul>
<li><p>[ ] 739.每日温度                                      方法：求右侧第一个最大的，单调栈从栈顶到栈底，单调递增。</p>
</li>
<li><p>[ ] 496.下一个最大的元素Ⅰ（不循环）                   方法： 这道题利用 <code>indexOf</code> 再双循环非常的简单。 使用单调栈的话，其实他非常依赖于 <code>nums2</code> 的长度，因为他把每一个 后面第一个值大于之前某一值的 键值对存入，然后在用数组一的 值作为key去找，其实速度并不快，但是思路也清晰的。（我自己写可能还是不行）</p>
</li>
<li><p>[ ] 503.下一个最大的元素Ⅱ（循环）   方法：和上一题一样，就是 nums 需要扩张一倍，然后  index 需要mode一下</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> nextGreaterElements = <span class="function"><span class="keyword">function</span>(<span class="params">nums</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> numsTemp = [...nums,...nums]</span><br><span class="line">    <span class="keyword">let</span> stack = []</span><br><span class="line">    <span class="keyword">let</span> result = <span class="keyword">new</span> <span class="built_in">Array</span>(nums.length).fill(-<span class="number">1</span>)</span><br><span class="line">    stack.push(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; numsTemp.length; i++)&#123;</span><br><span class="line">        <span class="keyword">while</span>(stack.length &amp;&amp; numsTemp[stack[stack.length - <span class="number">1</span>]] &lt; numsTemp[i])&#123;</span><br><span class="line">            <span class="keyword">let</span> index = stack.pop() % nums.length</span><br><span class="line">            result[index] = numsTemp[i]</span><br><span class="line">        &#125;</span><br><span class="line">        stack.push(i)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>[ ] <font color="red">47.接雨水</font>                       方法：暴力双指针，带数组双指针（推荐），单调栈（一样是 从小到大的顺序）</p>
</li>
</ul>
<h1 id="额外需要注意的题目"><a href="#额外需要注意的题目" class="headerlink" title="额外需要注意的题目"></a>额外需要注意的题目</h1>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/Vue%20%E7%9A%84%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="Vue-的前端面试题"><a href="#Vue-的前端面试题" class="headerlink" title="Vue 的前端面试题"></a>Vue 的前端面试题</h1><h2 id="考点1：理解Vue"><a href="#考点1：理解Vue" class="headerlink" title="考点1：理解Vue"></a>考点1：理解Vue</h2><h3 id="面试题：v-model的作用和实现原理是什么？"><a href="#面试题：v-model的作用和实现原理是什么？" class="headerlink" title="面试题：v-model的作用和实现原理是什么？"></a>面试题：v-model的作用和实现原理是什么？</h3><p>v-binde 是数据只能从data流向页面的  单向数据绑定</p>
<p>语法：<code>v-bind:href =&quot;xxx&quot;</code> 或简写为 <code>:href</code></p>
<p>v-model本质上不过是语法糖，可以用 v-model 指令在<strong>表单</strong>及<strong>元素</strong>上创建<strong>双向数据绑定</strong>。</p>
<p>语法：<code>v-mode:value=&quot;xxx&quot;</code> 或简写为 <code>v-model=&quot;xxx&quot;</code> </p>
<p>其实现的原理为：</p>
<ol>
<li>v-bind:绑定响应式数据</li>
<li>触发oninput 事件并传递数据</li>
</ol>
<blockquote>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">v-model</span>=<span class="string">&quot;sth&quot;</span> /&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 等同于--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">:value</span>=<span class="string">&quot;sth&quot;</span> @<span class="attr">input</span>=<span class="string">&quot;sth = $event.target.value&quot;</span> /&gt;</span></span><br><span class="line"><span class="comment">&lt;!--自html5开始,input每次输入都会触发oninput事件，所以输入时input的内容会绑定到sth中，于是sth的值就被改变--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--$event 指代当前触发的事件对象;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--$event.target 指代当前触发的事件对象的dom;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--$event.target.value 就是当前dom的value值;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--在@input方法中，value =&gt; sth;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--在:value中,sth =&gt; value;--&gt;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="面试题：如何理解-Vue的-MVVM-机制"><a href="#面试题：如何理解-Vue的-MVVM-机制" class="headerlink" title="面试题：如何理解 Vue的  MVVM 机制"></a>面试题：如何理解 Vue的  MVVM 机制</h3><p>MVVM 是 Model-View-ViewModel 的缩写， </p>
<ul>
<li>Model 代表数据模型， 定义数据操作的业务逻辑， 对应Vue中 data中的数据</li>
<li>View 代表 UI 组件， 它负责将数据模型转化成 UI 展现出来， 也就是页面的 dom</li>
<li>ViewModel 通过双向绑定把 View 和Model 进行同步交互，不需要手动操作 DOM 的一种设计思想。<strong>Vue实例对象，其中包含数据绑定和Dom监听两部分。</strong></li>
</ul>
<p><img src="http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/QQ截图20221218001832.png" style="zoom: 80%;" /></p>
<p>在 html 代码中，可以形象的概括为如下图所示：</p>
<p><img src="http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/QQ截图20221218002608.png" style="zoom:80%;" /></p>
<h3 id="面试题：Vue-2中-双向绑定（响应式）实现的原理"><a href="#面试题：Vue-2中-双向绑定（响应式）实现的原理" class="headerlink" title="面试题：Vue 2中 双向绑定（响应式）实现的原理"></a>面试题：Vue 2中 双向绑定（响应式）实现的原理</h3><p>采用<strong>数据劫持结合发布者- 订阅者模式</strong>的方式， 通过 <code>Object.defineProperty</code>来劫持各个属性的setter，getter，在数据变动时发布消息给订阅者，触发相应监听回调。当把一个普通 <code>Javascript</code> 对象传给 Vue 实例来作为它的 data 选项时， Vue 将遍历它的属性， 用 Object.defineProperty 将它们转为 getter/setter。用户看不到 getter/setter，但是在内部它们让 Vue 追踪依赖， 在属性被访问和修改时通知变化。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Object</span>.defineProperty(data, <span class="string">&#x27;count&#x27;</span>, &#123;</span><br><span class="line">    <span class="comment">// 用于响应获取</span></span><br><span class="line">    get () &#123;&#125;,</span><br><span class="line">    <span class="comment">// 用于响应修改</span></span><br><span class="line">    set () &#123;&#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>实现原理：</p>
<ul>
<li><p>对象类型：通过<code>Object.defineProperty()</code>对属性的读取、修改进行拦截（数据劫持）。</p>
</li>
<li><p>数组类型：通过重写更新数组的一系列方法（7个）来实现拦截。（对数组的变更方法进行了包裹）。其实质是 通过重写数组的Array.prototype对应的方法，具体来说就是重新指定要操作数组的prototype，并重写该prototype中对应上面的7个数组方法。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> methods = [<span class="string">&#x27;pop&#x27;</span>,<span class="string">&#x27;shift&#x27;</span>,<span class="string">&#x27;unshift&#x27;</span>,<span class="string">&#x27;sort&#x27;</span>,<span class="string">&#x27;reverse&#x27;</span>,<span class="string">&#x27;splice&#x27;</span>, <span class="string">&#x27;push&#x27;</span>];</span><br><span class="line"><span class="comment">// 复制Array.prototype，并将其prototype指向Array.prototype</span></span><br><span class="line"><span class="keyword">let</span> proto = <span class="built_in">Object</span>.create(<span class="built_in">Array</span>.prototype);</span><br><span class="line">methods.forEach(<span class="function"><span class="params">method</span> =&gt;</span> &#123;</span><br><span class="line">    proto[method] = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123; <span class="comment">// 重写proto中的数组方法</span></span><br><span class="line">        <span class="built_in">Array</span>.prototype[method].call(<span class="built_in">this</span>, ...arguments);</span><br><span class="line">        viewRender() <span class="comment">// 视图更新</span></span><br><span class="line">        <span class="function"><span class="keyword">function</span> <span class="title">observe</span>(<span class="params">obj</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">Array</span>.isArray(obj)) &#123; <span class="comment">// 数组实现响应式</span></span><br><span class="line">                obj.__proto__ = proto; <span class="comment">// 改变传入数组的prototype</span></span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">typeof</span> obj === <span class="string">&#x27;object&#x27;</span>) &#123;</span><br><span class="line">                ... <span class="comment">// 对象的响应式实现</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<font color="red"><Strong>没有用于响应 添加和删除的方法</Strong></font>
</li>
<li><p><strong>存在问题：</strong></p>
<ul>
<li><p>对象新增属性、删除属性, 界面不会更新，因为 Vue2 监测不到。</p>
<font color="blue">**这是因为在 Vue实例创建时，person.sex并未声明，所以就没有Vue转换为响应式的属性，自然就不会触发视图的更新。**</font>

<p><strong>新增属性</strong></p>
<p>例如现在有一个 对象person，</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">this</span>.person.sex = <span class="string">&quot;女&quot;</span>   <span class="comment">// 无效，因为Vue2 监测不到</span></span><br></pre></td></tr></table></figure>
<p>解决办法，使用 <code>$set</code></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">this</span>.$set(<span class="built_in">this</span>.person,<span class="string">&quot;sex&quot;</span>,<span class="string">&quot;女&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>删除属性</strong></p>
<p>例如现在有一个 对象person，里面有一个 name 属性</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="built_in">this</span>.person.name   <span class="comment">// 无效，因为Vue2 监测不到</span></span><br></pre></td></tr></table></figure>
<p>解决办法，使用 <code>$delete</code></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">this</span>.$delete(<span class="built_in">this</span>.person, <span class="string">&quot;name&quot;</span>) </span><br></pre></td></tr></table></figure>
<blockquote>
<p>delte会删除数组的值，但是它依然会在内存中占位置<br>而vue.delete会删除数组在内存中的占位</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> arr1 = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="keyword">let</span> arr2 = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="keyword">delete</span> arr1[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">this</span>.$delete(arr2,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">console</span>.log(arr1)    <span class="comment">//【1, empty, 3】</span></span><br><span class="line"><span class="built_in">console</span>.log(arr2)    <span class="comment">//【1,2】</span></span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>直接通过下标修改数组, 界面不会自动更新。</p>
<p>例如 现在有一个 hobby 数组，我想修改第一个元素的内容</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">this</span>.hobby[<span class="number">0</span>] = <span class="string">&quot;逛街&quot;</span>  <span class="comment">// 无效</span></span><br></pre></td></tr></table></figure>
<p>解决办法 两种办法</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 使用 $set</span></span><br><span class="line"><span class="built_in">this</span>.$set(<span class="built_in">this</span>.hobby, <span class="number">0</span>, <span class="string">&quot;逛街&quot;</span>)</span><br><span class="line"><span class="comment">// 使用 数组 API</span></span><br><span class="line"><span class="built_in">this</span>.hobby.splice(<span class="number">0</span>, <span class="number">1</span>, <span class="string">&quot;逛街&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="面试题：Vue-3中-双向绑定（响应式）实现的原理？-并说明为啥Vue-2-的不太好"><a href="#面试题：Vue-3中-双向绑定（响应式）实现的原理？-并说明为啥Vue-2-的不太好" class="headerlink" title="面试题：Vue 3中 双向绑定（响应式）实现的原理？ 并说明为啥Vue 2 的不太好"></a>面试题：Vue 3中 双向绑定（响应式）实现的原理？ 并说明为啥Vue 2 的不太好</h3><p>实现原理: </p>
<ul>
<li>通过<strong>Proxy（代理）</strong>:  Proxy 可以理解成，在目标对象之前架设一层“拦截”，外界对该对象的访问，都必须先通过这层拦截，因此提供了一种机制，可以对外界的访问进行过滤和改写。</li>
<li>通过<strong>Reflect（反射）</strong>:  对源对象的属性进行操作。其用于替换 Object.defineProperty，更加的工程化，因为其可以返回 true or false。</li>
</ul>
<p>Vue 3中 读取和修改对象数据的一个例子：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> person = &#123;name：<span class="string">&quot;凯凯&quot;</span>, <span class="attr">age</span>: <span class="number">25</span>&#125;</span><br><span class="line"><span class="comment">// p 相当于 数据代理了 person</span></span><br><span class="line"><span class="keyword">const</span> p = <span class="keyword">new</span> <span class="built_in">Proxy</span>(person,&#123;</span><br><span class="line">    <span class="comment">//有人读取p的某个属性时调用  target 为源数据也就是 person  propName是操作的属性</span></span><br><span class="line">    <span class="function"><span class="title">get</span>(<span class="params">target,propName</span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`有人读取了p身上的<span class="subst">$&#123;propName&#125;</span>属性`</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">Reflect</span>.get(target,propName)</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment">//有人修改p的某个属性、或给p追加某个属性时调用    value为需要修改的值</span></span><br><span class="line">    <span class="function"><span class="title">set</span>(<span class="params">target,propName,value</span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`有人修改了p身上的<span class="subst">$&#123;propName&#125;</span>属性，我要去更新界面了！`</span>)</span><br><span class="line">        <span class="built_in">Reflect</span>.set(target,propName,value)</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment">//有人删除p的某个属性时调用</span></span><br><span class="line">    <span class="function"><span class="title">deleteProperty</span>(<span class="params">target,propName</span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`有人删除了p身上的<span class="subst">$&#123;propName&#125;</span>属性，我要去更新界面了！`</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">Reflect</span>.deleteProperty(target,propName)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">p.name              <span class="comment">// 获取方法，调用 get 方法</span></span><br><span class="line">p.name = <span class="string">&quot;凯凯超人&quot;</span>  <span class="comment">// 修改方法，调用 set 方法  【p 和 person 全改】</span></span><br><span class="line">p.sex = <span class="string">&quot;男&quot;</span>        <span class="comment">// 添加方法，调用 set 方法  【p 和 person 全改】</span></span><br><span class="line"><span class="keyword">delete</span> p.sex        <span class="comment">// 删除方法，调用 deleteProperty  【p 和 person 全改】</span></span><br></pre></td></tr></table></figure>
<p>与 Vue2 比的优势在于：</p>
<ul>
<li><p><strong>对于 对象的响应式：</strong></p>
<p>Vue2 中实现的原理 Object.defineProperty 只能遍历对象属性进行劫持，无法检测到 直接对于对象属性中的添加和删除。想要实现添加和删除，不要分别使用 $set 和 $delete 这两个 vm 的实例方法</p>
<p>Vue 3中的 Proxy 可以劫持整个对象，并返回一个新对象，通过操作新对象来达到响应式的目的。所以我可以直接修改对象里面的内容。</p>
</li>
<li><p><strong>对于 数组的响应式：</strong></p>
<p>Vue 2中 <code>Object.defineProperty</code> 无法监控到数组下标及数组长度的变化，其通过 <font color="orange"><strong>包裹数组</strong></font> 更新元素的方法实现，本质就是做了两件事：</p>
<ul>
<li>调用原生对应的方法对数组进行更新。也就是原生 JS 对数组进行改变的方法 。</li>
<li>重新解析模板，进而更新页面。</li>
</ul>
<p>​    或者使用 <code>Vue.set()</code> 和 <code>vm.$set()</code></p>
<p>Proxy可以直接监控数组的变化（push、shift、splice 等原生数组API即可）,</p>
</li>
<li><font color="blue">Vue 3中 Proxy 有多达13种拦截方法，不限于 apply、ownkeys、deleteProperty、has等等，这是 Vue 2中`Object.defineProperty` 不具备的。</font>
</li>
<li><p>Vue 2中 data 如果数据较多 且深的时候 <code>Object.defineProperty</code> 要深度遍历data中的每个属性，将其设置为响应式（即配置 getter/setter），性能较差。</p>
<p><strong>Vue 3中 Proxy只在 getter 时才对对象的下一层进行劫持（优化了性能），真正访问到的内部对象才会变成响应式。</strong> </p>
<p><strong>数据劫持也就是 给数据绑定上 setter 和 getter 方法。</strong></p>
</li>
</ul>
<h3 id="面试题：Vue-data-中某一个属性比那花，视图会立即同步执行重新渲染么？"><a href="#面试题：Vue-data-中某一个属性比那花，视图会立即同步执行重新渲染么？" class="headerlink" title="面试题：Vue data 中某一个属性比那花，视图会立即同步执行重新渲染么？"></a>面试题：Vue data 中某一个属性比那花，视图会立即同步执行重新渲染么？</h3><p>不会。</p>
<p>Vue实现响应式并不是在监听到数据发生变化后，DOM立即变化。而是按照一定的策略进行DOM的更新。Vue在更新DOM时 是异步执行的，只要监听到数据的变化，Vue就会开启一个队列，并缓冲在同一事件循环中发生的所有数据变更。</p>
<p>如果同一个 watcher 被多次触发，只会被推入到这个队列中一次。然后再缓冲中去除重复数据对于避免不必要的计算和DOM操作时非常重要的。</p>
<p>然后，在下一个的事件循环tick中，Vue刷新队列并执行实际（已经去过重的）工作。</p>
<h3 id="面试题：什么是虚拟-DOM？"><a href="#面试题：什么是虚拟-DOM？" class="headerlink" title="面试题：什么是虚拟 DOM？"></a>面试题：什么是虚拟 DOM？</h3><ul>
<li>虚拟DOM 是描述真实DOM 结构及其属性信息的 JS 对象。</li>
<li>使用 虚拟DOM 能够有效减少直接操作 DOM 的次数，改为查找 JS 对象的属性变化，从而提高程序的性能。 （我的理解是，这里表达的是 diff算法的意思，diff算法会比对前后两份 DOM 的属性变化，如果属性发生变化之后，才会重新创建对应的虚拟DOM结点，否则就用原来的）</li>
<li>使用 虚拟DOM 可以实现跨平台，根据虚拟DOM 可以渲染成不同平台上对应的内容，如原生APP（Android、ios），小程序、浏览器等。</li>
<li>虚拟 DOM 通过 diff 算法，将前后两次的虚拟 DOM 树进行对比，定位出具体需要更新的部分，最终在真实 DOM中局部渲染。</li>
</ul>
<h3 id="面试题：Vue的-解释虚拟化DOM-diff-算法？-理解循环中的-key-机制？"><a href="#面试题：Vue的-解释虚拟化DOM-diff-算法？-理解循环中的-key-机制？" class="headerlink" title="面试题：Vue的 解释虚拟化DOM + diff 算法？ 理解循环中的 key 机制？"></a>面试题：Vue的 解释虚拟化DOM + diff 算法？ 理解循环中的 key 机制？</h3><p>为什么 key 最好不要使用 索引值，而最好是数据里的唯一 id 呢？ 因为会造成模板的渲染错误，其原理与 虚拟DOM的形成和 diff算法有关。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">li</span> <span class="attr">v-for</span>=<span class="string">&quot;(p,index) of persons&quot;</span> <span class="attr">:key</span>=<span class="string">&quot;key&quot;</span>&gt;</span></span><br><span class="line">		&#123;&#123;p.name&#125;&#125;-&#123;&#123;p.age&#125;&#125;</span><br><span class="line">		<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/QQ图片20221221181526.png" alt=""></p>
<p>其具体的解释步骤可以概括为如下：</p>
<ol>
<li>Vue会针对data中的persons数组，初始化虚拟DOM结点，其顺序是根据 我们 <strong>v-for指定的 :key 这里也就是索引来排序的</strong></li>
<li>然后会将虚拟DOM转化为真实DOM结点，进行页面渲染</li>
<li>此时，我们填好对应的input数据，再我们点击了 button 在 persons数组 前面添加了一条数据</li>
<li>然后 Vue 对新的数据再次生成虚拟DOM，还是按照 :key 也就是索引来排序，此时他发现之前已经有一份对应的虚拟DOM了，这个时候执行diff对比算法，再进行渲染。<ul>
<li>对比原则为，<strong>首先对比右侧第一行，key = 0， 再去左边找key = 0 的发现</strong> 原先是张山-18  新的是老刘-30，那我不对啊<strong>我要生成一个新的真实DOM结点</strong>，之前的不能用了，而后面的 input 框发现两者是一致的（这里不会考虑用户输入的 value的），那Vue表示，那我不需要再生成一个新的DOM了啊，我拿旧的就可以了（然而旧的里面）。此时生成第一条混乱数据   老刘-30  input(张三-18)  就是这么来的。</li>
</ul>
</li>
<li>那之后两条都是，到最后一条 key =3 ，那左边没有3的奥，那我两个部分真实DOM全部需要生成。</li>
</ol>
<h3 id="面试题：简单聊聊-new-Vue-以后发生的事情"><a href="#面试题：简单聊聊-new-Vue-以后发生的事情" class="headerlink" title="面试题：简单聊聊 new Vue 以后发生的事情"></a>面试题：简单聊聊 new Vue 以后发生的事情</h3><ol>
<li><p>new Vue会调用 Vue 原型链上的_init方法对 Vue 实例进行初始化；</p>
</li>
<li><p>首先是initLifecycle初始化生命周期，对 Vue 实例内部的一些属性（如 children、parent、isMounted）进行初始化；</p>
</li>
<li><p>initEvents，初始化当前实例上的一些自定义事件（Vue.$on）；</p>
</li>
<li><p>initRender，解析slots绑定在 Vue 实例上，绑定createElement方法在实例上；</p>
</li>
<li><p>完成对生命周期、自定义事件等一系列属性的初始化后，触发生命周期钩子beforeCreate；</p>
</li>
<li><p>initInjections，在初始化data和props之前完成依赖注入（类似于 React.Context）；</p>
</li>
<li><p>initState，完成对data和props的初始化，同时对属性完成数据劫持内部，启用监听者对数据进行监听（更改）；</p>
</li>
<li><p>initProvide，对依赖注入进行解析；</p>
</li>
<li><p>完成对数据（state 状态）的初始化后，触发生命周期钩子created；</p>
</li>
<li><p>进入挂载阶段，将 vue 模板语法通过vue-loader解析成虚拟 DOM 树，虚拟 DOM 树与数据完成双向绑定，触发生命周期钩子beforeMount；</p>
</li>
<li><p>将解析好的虚拟 DOM 树通过 vue 渲染成真实 DOM，触发生命周期钩子mounted；</p>
</li>
</ol>
<h3 id="面试题：Vue模板编译的原理"><a href="#面试题：Vue模板编译的原理" class="headerlink" title="面试题：Vue模板编译的原理"></a>面试题：Vue模板编译的原理</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/QQ截图20230306022826.png" alt=""></p>
<h2 id="考点2：Vue的属性内容考点"><a href="#考点2：Vue的属性内容考点" class="headerlink" title="考点2：Vue的属性内容考点"></a>考点2：Vue的属性内容考点</h2><h3 id="面试题：Vue-中-watch-和-computed-使用差异是什么？"><a href="#面试题：Vue-中-watch-和-computed-使用差异是什么？" class="headerlink" title="面试题：Vue 中 watch 和 computed 使用差异是什么？"></a>面试题：Vue 中 watch 和 computed 使用差异是什么？</h3><p><strong>计算属性：</strong></p>
<ul>
<li>计算属性会自动追踪响应式依赖，当响应式数据改变的时候，会重新计算并缓存计算结果。  （实际表现看起来和 data 很类似）<strong>computed 和 methods 的差异是它具有缓存性，方法调用总是会在重渲染发生时再次执行函数。</strong></li>
<li>计算属性默认时只读的，当需要用到 “可写”的属性，可以通过同时提供 getter 和 setter来创建。</li>
<li><font color="red">计算属性 getter 时无法做异步请求或者更改 DOM的，只能用于计算。</font>



</li>
</ul>
<p><strong>监视属性：</strong></p>
<p><strong>无缓存性</strong></p>
<ul>
<li><p>使用监视属性 在每次响应式状态发生变化时，触发回调函数，可以在回调中执行异步操作等复杂逻辑。</p>
</li>
<li><p>通过设置 <code>immediate:true</code> 可以在监视测创建时立即触发回调函数， 可以设置 <code>deep:true</code>来进行深度监视。</p>
<p>监视属性的回调函数默认发生在DOM更新之前，指明 <code>flush:&quot;post&quot;</code>，可以让监视器 回调中能访问被 Vue 更新之后的DOM（这是目的，说<strong>白了就是 可以异步执行回调函数，相当于我DOM已经更新完成了，我再调用这个方法</strong>） </p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//监视多级结构中所有属性的变化</span></span><br><span class="line"><span class="attr">numbers</span>:&#123;</span><br><span class="line">    <span class="attr">immediate</span>:<span class="literal">true</span>, <span class="comment">//初始化时让先handler调用一下</span></span><br><span class="line">    <span class="attr">deep</span>:<span class="literal">true</span>,</span><br><span class="line">    <span class="comment">// 回调函数</span></span><br><span class="line">    <span class="function"><span class="title">handler</span>(<span class="params">newInfo,oldInfo</span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&#x27;numbers改变了&#x27;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>总结应用场景：</strong></p>
<ul>
<li><p>当数值需要进行计算，并且依赖于其他数据。应该使用 computed，因为可以利用 computed 的缓存特性。</p>
</li>
<li><p>当需要在数据变化时，执行异步或开销较大的操作时。使用watch。</p>
</li>
</ul>
<h3 id="面试题：v-if-和-v-show-的区别"><a href="#面试题：v-if-和-v-show-的区别" class="headerlink" title="面试题：v-if 和 v-show 的区别"></a>面试题：v-if 和 v-show 的区别</h3><p><strong>v-show</strong></p>
<p>v-show不管条件是真还是假，第一次渲染的时候都会编译出来，也就是标签都会添加到DOM中。之后切换的时候，通过display: none;样式来显示隐藏元素。可以说只是改变css的样式，几乎不会影响什么性能。</p>
<p><strong>v-if</strong></p>
<p><strong>在首次</strong>渲染的时候，如果条件为假，什么也不操作，页面当作没有这些元素。当条件为真的时候，开始局部编译，动态的向DOM元素里面添加元素。当条件从真变为假的时候，开始局部编译，卸载这些元素，也就是删除。</p>
<p><strong>所以 v-if  适合运营条件不大可能改变的情况， v-show 适合频繁切换</strong></p>
<h2 id="考点3：-Vue的生命周期函数"><a href="#考点3：-Vue的生命周期函数" class="headerlink" title="考点3： Vue的生命周期函数"></a>考点3： Vue的生命周期函数</h2><h3 id="面试题：vue生命周期中异步加载在mouted还是create里实现"><a href="#面试题：vue生命周期中异步加载在mouted还是create里实现" class="headerlink" title="面试题：vue生命周期中异步加载在mouted还是create里实现"></a>面试题：vue生命周期中异步加载在mouted还是create里实现</h3><p>一般来说，可以在，<strong>created，mounted中都可以发送数据请求，但是，大部分时候，会在created发送请求。</strong><br>Created的使用场景：如果页面首次渲染的就来自后端数据。因为，此时data已经挂载到vue实例了。<br>在 created（如果希望首次选的数据来自于后端，就在此处发请求）（只发了异步请求，渲染是在后端响应之后才进行的）、beforeMount、mounted（在mounted中发请求会进行二次渲染） 这三个钩子函数中进行调用。<br>因为在这三个钩子函数中，data 已经创建，可以将服务端端返回的数据进行赋值。但是<strong>最常用的是在 created 钩子函数中调用异步请求</strong>，因为在 created 钩子函数中调用异步请求有两个优点：</p>
<ul>
<li>第一点：能更快获取到服务端数据，减少页面 loading 时间；</li>
<li>第二点：放在 created 中有助于一致性，因为ssr 不支持 beforeMount 、mounted 钩子函数。</li>
</ul>
<blockquote>
<p>在 Vue.js 中，SSR 是指将 Vue 应用程序渲染为 HTML 字符串，并在服务器上进行初始渲染，然后将其发送到客户端进行交互。</p>
<p>SSR（Server-Side Rendering）在服务器端渲染 Vue.js 应用程序时，使用的是 Node.js 环境而不是浏览器环境。由于 Node.js 没有浏览器中提供的 DOM 和浏览器 API，因此在 SSR 期间无法执行与 DOM 相关的操作，例如在 beforeMount 和 mounted 钩子函数中更新 DOM。</p>
<p>在 SSR 期间，Vue.js 会在服务器上渲染组件并返回 HTML 字符串，然后在浏览器端重新挂载和激活组件。因此，beforeMount 和 mounted 钩子函数只会在浏览器中执行，而不会在服务器上执行。</p>
<p>为了在 SSR 和客户端应用程序中保持一致性，Vue.js 提供了其他生命周期钩子函数，例如 created 和 mounted 钩子函数，可以在服务器和客户端上都执行。在这些钩子函数中，您可以执行与 DOM 无关的操作，例如在 created 钩子函数中进行数据预取，以便在组件挂载时使用。</p>
</blockquote>
<h3 id="面试题：讲一讲Vue的生命钩子有哪几个，每个阶段在干什么？"><a href="#面试题：讲一讲Vue的生命钩子有哪几个，每个阶段在干什么？" class="headerlink" title="面试题：讲一讲Vue的生命钩子有哪几个，每个阶段在干什么？"></a>面试题：讲一讲Vue的生命钩子有哪几个，每个阶段在干什么？</h3><p><strong>红圈mounted 之前属于挂载流程， 红圈mounted 属于更新流程，红圈mounted 之后属于 销毁流程</strong> </p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/生命周期.png" alt=""></p>
<p>详细的说，分为 开始创建、初始化数据、编译模板、挂载Dom、渲染→更新→渲染、销毁等一系列过程</p>
<p><strong>关于销毁Vue实例</strong> （destroyed）</p>
<ol>
<li>.销毁后借助Vue开发者工具看不到任何信息。</li>
<li><strong>销毁后自定义事件会失效，但原生DOM事件依然有效（<font color="red">现在高版本的Vue2.0，也无效</font>）。</strong></li>
<li>一般不会在 beforeDestroy 操作数据，因为即便操作数据，也不会再触发更新流程了。(因为更新流程已经被杀死了，没有办法再调准到之前的步骤)</li>
</ol>
<h3 id="面试题：如何理解-nextTick？"><a href="#面试题：如何理解-nextTick？" class="headerlink" title="面试题：如何理解 $nextTick？"></a>面试题：如何理解 $nextTick？</h3><ul>
<li><code>this.$nextTick(回调函数)</code> <strong>在下一次 DOM 更新结束后执行其指定的回调。可以传递一个回调函数作为参数，或者await 返回的 Promise。</strong></li>
<li>Vue中如果数据变化，Vue不会立刻更新DOM，而是开启一个队列，把组件更新函数保存在队列中，<strong>等同一事件循环中发生的所有数据变更完成后，再统一对视图进行更新</strong>。此时如果想要获取更新后的DOM状态，就可以使用 <code>$nextTick</code></li>
<li>使用场景：在 created 或 setup 中想要获取 DOM 时，在响应式数据变化后获取 DOM更新后的状态时。</li>
</ul>
<h3 id="面试题：既然函数是引用类型，为什么-vue-的-data-还是可以用函数"><a href="#面试题：既然函数是引用类型，为什么-vue-的-data-还是可以用函数" class="headerlink" title="面试题：既然函数是引用类型，为什么 vue 的 data 还是可以用函数"></a>面试题：既然函数是引用类型，为什么 vue 的 data 还是可以用函数</h3><p>JavaScript只有函数构成作用域(注意理解作用域，<strong>只有函数{}构成作用域</strong>,对象的{}以及if(){}都不构成作用域),data是一个函数时，每个组件实例都有自己的作用域，每个实例相互独立，不会相互影响。</p>
<p>换句话说就是，Vue组件可能会存在多个实例，如果使用对象形式定义data的话，会导致她们共用一个data对象的情况，那么状态变更将会影响所有组件实例。</p>
<p>这非常的不合理，但是如果采用函数形式的话，在initData的时候其将会作为工厂函数返回全新的data对象，有效避免了多实例之间状态污染的问题。</p>
<h2 id="考点4：-Vue-的组件通信"><a href="#考点4：-Vue-的组件通信" class="headerlink" title="考点4： Vue 的组件通信"></a>考点4： Vue 的组件通信</h2><p><img src="https://uploadfiles.nowcoder.com/images/20220301/4107856_1646128629803/500809B9BD071EA8067678D9EC046261" alt="img"></p>
<p>有props和$emit、<img src="https://www.nowcoder.com/equation?tex=attrs%E5%92%8C&amp;preview=true" alt="img">listeners、v-model、provide和inject、全局事件总线、parent和children、boradcast和dispatch（这种是 vue1.0使用的 ，现在不常用) 和 vuex处理组件之间的数据交互</p>
<h3 id="面试题：父子组件之间时如何通信的？"><a href="#面试题：父子组件之间时如何通信的？" class="headerlink" title="面试题：父子组件之间时如何通信的？"></a>面试题：父子组件之间时如何通信的？</h3><p><strong>父组件将数据传递给子组件</strong></p>
<font color="blue">使用 props 方法， 父组件通过注册标签传递，子组件 props属性进行接受。</font>

<p>所有的 props 都遵循单项绑定原则，即单向数据流，props 因父组件的更新而变化，自然地将新的状态向下流往子组件，而不会逆向传递。这避免了子组件意外修改父组件的属性状态的情况。</p>
<p><strong>子组件将数据传递给父组件</strong></p>
<p>主要有两种主流方法：</p>
<ul>
<li><p>方法一：在父组件标签中绑定一个自定义事件，然后子组件使用 $emit 方法去触发自定义事件，顺便带上自己的数据参数传递过去</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">// 父组件绑定自定义事件</span><br><span class="line"><span class="tag">&lt;<span class="name">Student</span> <span class="attr">v-on:sendName</span>=<span class="string">&quot;printStudentName&quot;</span> <span class="attr">:parm</span>=<span class="string">&quot;2&quot;</span>  /&gt;</span></span><br><span class="line"></span><br><span class="line">// 子组件中 methods函数 去$emit触发自定义事件</span><br><span class="line">sendStudentName2()&#123;</span><br><span class="line">	//触发Student组件实例身上的 sendName 事件</span><br><span class="line">	this.$emit(&#x27;sendName&#x27;, this.studentName,this.parm);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>方法二：通过父组件的 ref 属性来绑定自定义事件（这个绑定实际需要在 生命函数 mounted中进行绑定），然后子组件同样使用 $emit 方法去触发自定义事件，顺便带上自己的数据参数传递过去。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">// 父组件 ref 声明自定义事件</span><br><span class="line"><span class="tag">&lt;<span class="name">Student</span> <span class="attr">ref</span>=<span class="string">&quot;stu&quot;</span> <span class="attr">:parm</span>=<span class="string">&quot;3&quot;</span>  /&gt;</span></span><br><span class="line"></span><br><span class="line">// 父组件 mounted 生命周期函数</span><br><span class="line">mounted() &#123;</span><br><span class="line">	// 两个参数分别为 自定义事件名  和  自定义绑定的接受参数的回调函数</span><br><span class="line">	this.$refs.stu.$on(&quot;sendName&quot;,this.printStudentName) </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 子组件中 methods函数 去$emit触发自定义事件</span><br><span class="line">sendStudentName2()&#123;</span><br><span class="line">	//触发Student组件实例身上的 sendName 事件 </span><br><span class="line">	this.$emit(&#x27;sendName&#x27;, this.studentName,this.parm);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>两种方法的 解绑自定义均为：</p>
<ul>
<li>全部解绑  <code>this.$off(事件名)</code></li>
<li>解绑一个  <code>this.$off(&quot;sendName&quot;)</code></li>
<li>解绑多个  <code>this.$off([&quot;sendName&quot;,&quot;test&quot;])</code></li>
</ul>
<h3 id="面试题：父传子-ref-refs"><a href="#面试题：父传子-ref-refs" class="headerlink" title="面试题：父传子   ref/refs"></a>面试题：父传子   ref/refs</h3><p><code>ref</code> 这个属性用在子组件上，它的引用就指向了子组件的实例。可以通过实例来访问组件的数据和方法。</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/ref_refs.png" style="zoom: 80%;" /></p>
<h3 id="面试题：父子之间互传-parent-children"><a href="#面试题：父子之间互传-parent-children" class="headerlink" title="面试题：父子之间互传 $parent/$children"></a>面试题：父子之间互传 $parent/$children</h3><p>使用 <code>$parent</code> 可以让组件访问父组件的实例（<strong>访问的是上一级 父组件的属性和方法</strong>）</p>
<p>使用 <code>$children</code> 可以让组件访问子组件的实例，<strong>但是 $children 并不能保证顺序，并且访问的数据也不是响应的</strong>。</p>
<p> <img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/parent_children.png" alt=""></p>
<h3 id="面试题：隔代-祖传子-传递-attrs-和-listeners"><a href="#面试题：隔代-祖传子-传递-attrs-和-listeners" class="headerlink" title="面试题：隔代  祖传子 传递 $attrs 和 $listeners"></a>面试题：隔代  祖传子 传递 $attrs 和 $listeners</h3><ul>
<li>$attrs: 继承所有的父组件属性（除了 prop 传递的属性 class 和 style），一般用在子组件的子元素上</li>
<li>$listeners:该属性是一个对象，里面包含了作用在这个组件上的所有监听器，可以配合 v-on=”$listeners” 将所有的事件监听器指向这个组件的某个特定的子元素。（相当于子组件继承分组件的事情）</li>
</ul>
<h3 id="面试题：Vue3-0-中祖传孙-provide-inject？"><a href="#面试题：Vue3-0-中祖传孙-provide-inject？" class="headerlink" title="面试题：Vue3.0 中祖传孙  provide/inject？"></a>面试题：Vue3.0 中祖传孙  provide/inject？</h3><p>provide 与 inject  <strong>祖先组件 传递数据给 孙子组件</strong></p>
<p>如果祖先和孙子中间隔了好几代，就不适合使用 props，需要中间传好几层</p>
<p>父组件有一个 <code>provide</code> 选项来提供数据，后代组件有一个 <code>inject</code> 选项来开始使用这些数据</p>
<ul>
<li><ol>
<li><p>祖组件中：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">setup</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">	......</span><br><span class="line">    <span class="keyword">let</span> car = reactive(&#123;<span class="attr">name</span>:<span class="string">&#x27;奔驰&#x27;</span>,<span class="attr">price</span>:<span class="string">&#x27;40万&#x27;</span>&#125;)</span><br><span class="line">    provide(<span class="string">&#x27;car&#x27;</span>,car)</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>后代组件中：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">setup</span>(<span class="params">props,context</span>)</span>&#123;</span><br><span class="line">	......</span><br><span class="line">    <span class="keyword">const</span> car = inject(<span class="string">&#x27;car&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;car&#125;</span><br><span class="line">	......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h3 id="面试题：任意组件通信-全局事件总线通信-bus-on？"><a href="#面试题：任意组件通信-全局事件总线通信-bus-on？" class="headerlink" title="面试题：任意组件通信 全局事件总线通信  $bus $on？"></a>面试题：任意组件通信 全局事件总线通信  $bus $on？</h3><p>一种组件间通信的方式，适用于<span style="color:red">任意组件间通信</span>。</p>
<p><strong>安装全局事件总线：</strong></p>
<p>使用 vm 作为中间商对象，因为其含有需要的属性，并且任意的组件都可以访问到这个实例。（原型的原因）</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> Vue(&#123;</span><br><span class="line">   ......</span><br><span class="line">   <span class="function"><span class="title">beforeCreate</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">      Vue.prototype.$bus = <span class="built_in">this</span> <span class="comment">//安装全局事件总线，$bus就是当前应用的vm</span></span><br><span class="line">   &#125;,</span><br><span class="line">    ......</span><br><span class="line">&#125;) </span><br></pre></td></tr></table></figure>
<p><strong>如何使用：</strong></p>
<p>接收数据：A组件想接收数据，则在A组件中给$bus绑定自定义事件，事件的<span style="color:red">回调留在A组件自身。</span></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">methods:&#123;</span><br><span class="line">  <span class="function"><span class="title">demo</span>(<span class="params">data</span>)</span>&#123;......&#125;</span><br><span class="line">&#125;</span><br><span class="line">......</span><br><span class="line"><span class="function"><span class="title">mounted</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">  <span class="built_in">this</span>.$bus.$on(<span class="string">&#x27;xxxx&#x27;</span>,<span class="built_in">this</span>.demo)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>提供数据：提供数据的组件 触发事件传递数据：<code>this.$bus.$emit(&#39;xxxx&#39;,数据)</code></p>
<p><strong>如何解绑</strong></p>
<p>最好在beforeDestroy钩子中，用$off去解绑 <strong>接受数据端的 自定义事件</strong>。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">beforeDestroy</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">	<span class="built_in">this</span>.$off(<span class="string">&quot;xxxx&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>缺点：</strong></p>
<p>全局事件总线，可以让任何两个组件之间互相传递数据，但是吧，如果对于同一个数据，所有的组件之间的通信，就要写很多全局事件挂在 vm上，非常的冗余。</p>
<p>所以引入了数据管理器  VueX。</p>
<h2 id="考点5：如何理解-VueX？"><a href="#考点5：如何理解-VueX？" class="headerlink" title="考点5：如何理解 VueX？"></a>考点5：如何理解 VueX？</h2><h3 id="面试题：如何理解VueX？其使用场景是什么？"><a href="#面试题：如何理解VueX？其使用场景是什么？" class="headerlink" title="面试题：如何理解VueX？其使用场景是什么？"></a>面试题：如何理解VueX？其使用场景是什么？</h3><p><strong>是一种特殊的组件通信方式</strong>，<font color="blue">说白了就是 要实现 对共享数据（状态）的 方便读写，因为事件总线对 不同组件之间读写共享数据，是读写分离的，代码写起来比较麻烦，特别是对应一个共享数据（状态），很多组件都要使用的情况。</font></p>
<p>如下两个情况下，适合使用 Vuex</p>
<ul>
<li><p>多个组件依赖于同一状态 </p>
</li>
<li><p>来自不同组件的行为需要变更同一状态</p>
</li>
</ul>
<p>vuex是一种状态管理机制，将全局组件的共享状态抽取出来为一个store，以一个单例模式存在，<strong>应用任何一个组件中都可以使用</strong>，vuex更改state的唯一途径是通过mutation，mutation需要commit触发, action实际触发是mutation，<strong>其中mutation处理同步任务，action处理异步任务。</strong></p>
<h3 id="面试题：VueX-有哪几个部分组成，是干什么的？以及如何使用VueX"><a href="#面试题：VueX-有哪几个部分组成，是干什么的？以及如何使用VueX" class="headerlink" title="面试题：VueX 有哪几个部分组成，是干什么的？以及如何使用VueX"></a>面试题：VueX 有哪几个部分组成，是干什么的？以及如何使用VueX</h3><p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/vuex.png" alt=""></p>
<p>Vuex的属性包含以下6个：</p>
<p>1）state</p>
<p>state是存储的单一状态，是存储的基本数据。</p>
<p>2）Getters</p>
<p>其类似于  在组件中的 计算属性 computed，但是计算属性只能作用于自己一个vue。没有共享的效果，因为针对的是共享数据，所以使用 <code>getters</code> 可是实现共享读。</p>
<p>3）Mutations</p>
<p>mutations提交更改数据，使用store.commit方法更改state存储的状态。（mutations同步函数）</p>
<p>4）Actions</p>
<p>actions像一个装饰器，提交mutation，而不是直接变更状态。（actions可以包含任何异步操作）</p>
<p>5）Module</p>
<p>Module是store分割的模块，每个模块拥有自己的state、getters、mutations、actions。</p>
<p><strong>如何使用 VueX</strong></p>
<p>在src 内创建文件夹 store 创建文件：<code>src/store/index.js</code>   （官方推荐写法）</p>
<ul>
<li><p>初始化数据、配置<code>actions</code>、配置<code>mutations</code>，操作文件<code>store.js</code> <strong>（如下为 实际需要使用模块化+ 命名空间）</strong></p>
<font color="blue">**一般配置为 actions中的方法为 小写字母， mutations 中的方法为 大写字母 以示区别。**</font>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> countAbout = &#123;</span><br><span class="line">  <span class="attr">namespaced</span>:<span class="literal">true</span>,<span class="comment">//开启命名空间,不设置没法用map读</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">const</span> actions = &#123;</span><br><span class="line">        <span class="comment">//响应组件中加的动作 context是个miniStore</span></span><br><span class="line">       <span class="function"><span class="title">jia</span>(<span class="params">context,value</span>)</span>&#123;</span><br><span class="line">          context.commit(<span class="string">&#x27;JIA&#x27;</span>,value)</span><br><span class="line">       &#125;,</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> mutations = &#123;</span><br><span class="line">        <span class="comment">//执行加</span></span><br><span class="line">       <span class="function"><span class="title">JIA</span>(<span class="params">state,value</span>)</span>&#123;</span><br><span class="line">          state.sum += value</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="attr">state</span>:&#123;<span class="attr">x</span>:<span class="number">1</span>&#125;,</span><br><span class="line">  <span class="attr">getters</span>: &#123;</span><br><span class="line">    <span class="function"><span class="title">bigSum</span>(<span class="params">state</span>)</span>&#123;</span><br><span class="line">       <span class="keyword">return</span> state.sum * <span class="number">10</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> personAbout = &#123;</span><br><span class="line">  <span class="attr">namespaced</span>:<span class="literal">true</span>,<span class="comment">//开启命名空间</span></span><br><span class="line">  <span class="attr">actions</span>: &#123; ... &#125;,</span><br><span class="line">  <span class="attr">mutations</span>: &#123; ... &#125;,</span><br><span class="line">  <span class="attr">state</span>:&#123; ... &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> store = <span class="keyword">new</span> Vuex.Store(&#123;</span><br><span class="line">  <span class="attr">modules</span>: &#123;</span><br><span class="line">    countAbout,</span><br><span class="line">    personAbout</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>在<code>main.js</code>中创建 vm 时传入<code>store</code>配置项</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">......</span><br><span class="line"><span class="comment">//引入store</span></span><br><span class="line"><span class="keyword">import</span> store <span class="keyword">from</span> <span class="string">&#x27;./store&#x27;</span></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建vm</span></span><br><span class="line"><span class="keyword">new</span> Vue(&#123;</span><br><span class="line">   <span class="attr">el</span>:<span class="string">&#x27;#app&#x27;</span>,</span><br><span class="line">   <span class="attr">render</span>: <span class="function"><span class="params">h</span> =&gt;</span> h(App),</span><br><span class="line">   store</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>组件中读取vuex中的数据（state 或者 getters）：例如<code>$store.state.sum</code></p>
<p>组件中修改vuex中的数据：<code>$store.dispatch(&#39;action中的方法名&#39;,数据)</code>  或者 <code>$store.commit(&#39;mutations中的方法名&#39;,数据)</code>。</p>
<p>后一种是跳过了 actions  直接使用 mutations</p>
<p><strong>图中的后两步都是自动执行的 真正数据修改和 模板render</strong></p>
<blockquote>
<p> 备注：若没有网络请求或其他业务逻辑，组件中也可以越过actions，即不写<code>dispatch</code>，直接编写<code>commit</code>，也就是<code>$store.commit(&#39;mutations中的方法名&#39;,数据)</code></p>
</blockquote>
<h3 id="面试题：了解-Vuex-的辅助函数么？讲讲你的理解。"><a href="#面试题：了解-Vuex-的辅助函数么？讲讲你的理解。" class="headerlink" title="面试题：了解 Vuex 的辅助函数么？讲讲你的理解。"></a>面试题：了解 Vuex 的辅助函数么？讲讲你的理解。</h3><p>有4个辅助函数，她们的主要目的是简化我们读取 Vuex state 和 getters 中数据，和简化我们使用 actions 和 mutations 的方法。</p>
<p>因为我每次template需要显示 state里的某个 XXX  都要  $store.state.XXX 非常的麻烦。所以其有对应的 mapState 和 mapGetters 函数来简化我们的写法，将state 和 getters 数据映射到 计算属性中。</p>
<ol>
<li><p><strong>mapState方法：</strong>用于帮助我们映射<code>state</code>中的数据为计算属性</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">computed: &#123;</span><br><span class="line">    <span class="comment">//借助mapState生成计算属性：sum、school、subject（对象写法）</span></span><br><span class="line">     ...mapState(&#123;<span class="attr">sum</span>:<span class="string">&#x27;sum&#x27;</span>,<span class="attr">school</span>:<span class="string">&#x27;school&#x27;</span>,<span class="attr">subject</span>:<span class="string">&#x27;subject&#x27;</span>&#125;),</span><br><span class="line">         </span><br><span class="line">    <span class="comment">//借助mapState生成计算属性：sum、school、subject（数组写法）推荐这样</span></span><br><span class="line">    ...mapState([<span class="string">&#x27;sum&#x27;</span>,<span class="string">&#x27;school&#x27;</span>,<span class="string">&#x27;subject&#x27;</span>]),</span><br><span class="line">    <span class="comment">// 如果使用了模块化 和命名空间 前面的参数指定你是来自哪个vuex 的store模块</span></span><br><span class="line">    ...mapState(<span class="string">&#x27;countAbout&#x27;</span>,[<span class="string">&#x27;sum&#x27;</span>,<span class="string">&#x27;school&#x27;</span>,<span class="string">&#x27;subject&#x27;</span>]),</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>mapGetters方法：</strong>用于帮助我们映射<code>getters</code>中的数据为计算属性</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">computed: &#123;</span><br><span class="line">    <span class="comment">//借助mapGetters生成计算属性：bigSum（对象写法）</span></span><br><span class="line">    ...mapGetters(&#123;<span class="attr">bigSum</span>:<span class="string">&#x27;bigSum&#x27;</span>&#125;),</span><br><span class="line"></span><br><span class="line">    <span class="comment">//借助mapGetters生成计算属性：bigSum（数组写法）推荐这样</span></span><br><span class="line">    ...mapGetters([<span class="string">&#x27;bigSum&#x27;</span>])</span><br><span class="line">    <span class="comment">//如果使用了模块化 和命名空间 前面的参数指定你是来自哪个vuex 的store模块</span></span><br><span class="line">    ...mapGetters(<span class="string">&#x27;countAbout&#x27;</span>,[<span class="string">&#x27;bigSum&#x27;</span>])</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>同理如果我们想要修改state中的数据，使用 $store.dispatch(‘action中的方法名’,数据) 或者 <code>$store.commit(&#39;mutations中的方法名&#39;,数据)</code>，也是非常的麻烦的。</p>
<p>所以 Vuex 提供了 mapActions 和 mapMutations ，可以将 触发actions 和 直接触发 mutations 对应的方法，直接映射到 methods 的某一简写方法中</p>
<ol>
<li><p><strong>mapActions方法：</strong>用于帮助我们生成与<code>actions</code>对话的方法，即：包含<code>$store.dispatch(xxx)</code>的函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">methods:&#123;</span><br><span class="line">    <span class="comment">//靠mapActions生成：incrementOdd、incrementWait（对象形式）</span></span><br><span class="line">    ...mapActions(&#123;<span class="attr">incrementOdd</span>:<span class="string">&#x27;jiaOdd&#x27;</span>,<span class="attr">incrementWait</span>:<span class="string">&#x27;jiaWait&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//靠mapActions生成：jiaOdd、jiaWait（数组形式）</span></span><br><span class="line">    ...mapActions([<span class="string">&#x27;jiaOdd&#x27;</span>,<span class="string">&#x27;jiaWait&#x27;</span>])</span><br><span class="line">    <span class="comment">//前面的参数指定你是来自哪个vuex 的store模块  当然使用对象形式也可以</span></span><br><span class="line">    ...mapActions(<span class="string">&#x27;countAbout&#x27;</span>,[<span class="string">&#x27;jiaOdd&#x27;</span>,<span class="string">&#x27;jiaWait&#x27;</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>mapMutations方法：</strong>用于帮助我们生成与<code>mutations</code>对话的方法，即：包含<code>$store.commit(xxx)</code>的函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">methods:&#123;</span><br><span class="line">    <span class="comment">//靠mapActions生成：increment、decrement（对象形式）</span></span><br><span class="line">    ...mapMutations(&#123;<span class="attr">increment</span>:<span class="string">&#x27;JIA&#x27;</span>,<span class="attr">decrement</span>:<span class="string">&#x27;JIAN&#x27;</span>&#125;),</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//靠mapMutations生成：JIA、JIAN（对象形式）</span></span><br><span class="line">    ...mapMutations([<span class="string">&#x27;JIA&#x27;</span>,<span class="string">&#x27;JIAN&#x27;</span>]),</span><br><span class="line">    <span class="comment">//前面的参数指定你是来自哪个vuex 的store模块  当然使用对象形式也可以</span></span><br><span class="line">    ...mapMutations(<span class="string">&#x27;countAbout&#x27;</span>,[<span class="string">&#x27;JIA&#x27;</span>,<span class="string">&#x27;JIAN&#x27;</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>备注：mapActions与mapMutations使用时，若需要传递参数需要：<strong>在模板中绑定事件时传递好参数，否则参数是事件对象。</strong></p>
</blockquote>
<h3 id="面试题：Vuex实现原理"><a href="#面试题：Vuex实现原理" class="headerlink" title="面试题：Vuex实现原理"></a>面试题：Vuex实现原理</h3><p><strong>store是怎么注册的?</strong></p>
<p>我们看到Vuex在vue 的生命周期中的初始化钩子前插入一段 Vuex 初始化代码。给 Vue 的实例注入一个 $store的属性，这也就是为什么我们在 Vue 的组件中可以通过this.$store.xxx, 访问到 Vuex 的各种数据和状态。 说的就是 main.js 中的</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> Vue(&#123;</span><br><span class="line">   <span class="attr">el</span>:<span class="string">&#x27;#app&#x27;</span>,</span><br><span class="line">   <span class="attr">render</span>: <span class="function"><span class="params">h</span> =&gt;</span> h(App),</span><br><span class="line">   <span class="comment">// 这里啦</span></span><br><span class="line">   store</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>mutations，commit 是怎么实现的</strong></p>
<ol>
<li>说明 “mutations” 的实现原理，即它是一个纯函数，接收当前状态和负载作为参数，并返回一个新的状态对象，而不会直接修改原状态。</li>
<li>说明 “commit” 的实现原理，即它是一个方法，用于触发指定的 mutation 的执行，从而修改状态。在执行 mutation 前，Vuex 会检查该 mutation 是否存在，以确保应用程序的状态不被意外修改。</li>
</ol>
<p>现实可以举的例子：</p>
<blockquote>
<p>假设你正在开发一个电子商务网站，你需要在多个组件中共享用户购物车中的商品列表。如果使用Vuex，你可以将购物车商品列表存储在Vuex的状态树中。通过在组件中使用getter来获取购物车商品列表，使用mutation来修改购物车商品列表，使用action来发起异步请求更新购物车商品列表，使用commit来触发mutation的执行。</p>
<p>例如，当用户在商品详情页中点击“加入购物车”按钮时，你可以触发一个名为“ADD_TO_CART”的mutation来将商品添加到购物车商品列表中。该mutation将接收当前状态和商品负载作为参数，并返回一个新的状态对象。接着，你可以在购物车页面中使用getter来获取购物车商品列表，并显示出来。</p>
<p>这样，当购物车商品列表的状态发生变化时，所有相关的组件都会自动更新。同时，你可以在Vuex的状态树中添加其他属性，如用户登录状态、支付状态等，以实现更复杂的应用程序状态管理需求。</p>
</blockquote>
<p><strong>辅助函数的实现都差不太多，在这里了解一下mapState</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义辅助函数 mapState</span></span><br><span class="line"><span class="keyword">const</span> mapState = <span class="function">(<span class="params">stateKeys</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> stateObj = &#123;&#125;</span><br><span class="line">  stateKeys.forEach(<span class="function"><span class="params">key</span> =&gt;</span> &#123;</span><br><span class="line">    stateObj[key] = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>.$store.state[key]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="keyword">return</span> stateObj</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：mutation和action有什么区别？"><a href="#面试题：mutation和action有什么区别？" class="headerlink" title="面试题：mutation和action有什么区别？"></a>面试题：mutation和action有什么区别？</h3><p>Mutation是更改 Vuex 的 store 中的状态的唯一方法。在action中调用<code>$store.commit</code>来触发Mutation。</p>
<p>Action 类似于 mutation，不同在于：<strong>Action 提交的是 mutation，而不是直接变更状态</strong>。Action 可以包含任意异步操作。通过 <code>$store.dispatch</code>来触发Action。</p>
<h3 id="面试题：为什么-mutation是同步的，而action是异步的？"><a href="#面试题：为什么-mutation是同步的，而action是异步的？" class="headerlink" title="面试题：为什么 mutation是同步的，而action是异步的？"></a>面试题：为什么 mutation是同步的，而action是异步的？</h3><p>在Vuex中，mutation是同步的，而action是异步的。这是因为mutation用于更改state，而state是一个同步的状态。当我们在mutation中更改state时，这种更改必须是同步的，以便我们能够准确地知道state的值是什么，并且能够在我们的应用程序中正确地使用它。</p>
<p>另一方面，action可以用于异步任务，例如发出网络请求或执行定时任务。这些任务可能需要等待一段时间才能完成，因此将它们放在mutation中会阻塞我们的应用程序，导致UI不响应或无响应的情况。因此，我们可以使用action来处理这些异步任务，并在任务完成后调用相应的mutation来更改state。</p>
<p>总之，mutation和action的不同在于它们被设计用于不同的任务。mutation用于同步的状态更改，而action用于异步任务的处理，以便我们的应用程序可以在执行这些任务时保持响应性。</p>
<h3 id="面试题：Vuex-和-localStorage-的区别是什么？"><a href="#面试题：Vuex-和-localStorage-的区别是什么？" class="headerlink" title="面试题：Vuex 和 localStorage 的区别是什么？"></a>面试题：Vuex 和 localStorage 的区别是什么？</h3><ul>
<li>数据持久性：Vuex 存储的数据是在内存中维护的，只在当前会话中有效。而 localStorage 是浏览器提供的本地存储机制，可以将数据永久地存储在用户的浏览器中，即使用户关闭了浏览器或重新打开了一个新的标签页，存储的数据也不会消失。</li>
<li>数据可见性：Vuex 存储的数据只能在当前应用程序中共享和使用，不能被其他应用程序或其他网站访问到。而 localStorage 存储的数据是全局可见的，可以被任何网站或应用程序访问和使用。</li>
<li>存储容量：Vuex 存储的数据量通常较小，因为它主要用于在组件之间共享状态和数据。而 localStorage 可以存储更多的数据，但也有存储容量的限制，通常为 5-10 MB 左右。</li>
<li>数据格式：Vuex 存储的数据通常是 JavaScript 对象或数组，可以轻松地进行读取、更新和删除操作。而 localStorage 存储的数据必须是字符串格式，需要进行序列化和反序列化才能读取、更新和删除。</li>
</ul>
<p>总之，Vuex 和 localStorage 是两个不同的概念，它们在数据的持久性、可见性、存储容量和数据格式等方面存在较大差异。在实际开发中，应根据实际需求选择合适的存储方案。如果需要在应用程序中共享状态和数据，可以使用 Vuex；如果需要将数据永久保存在用户的本地浏览器中，可以使用 localStorage。</p>
<h2 id="考点6：-Vue-router-路由"><a href="#考点6：-Vue-router-路由" class="headerlink" title="考点6： Vue-router 路由"></a>考点6： Vue-router 路由</h2><h3 id="面试题：路由跳转和location-href的区别？"><a href="#面试题：路由跳转和location-href的区别？" class="headerlink" title="面试题：路由跳转和location.href的区别？"></a>面试题：路由跳转和location.href的区别？</h3><p>使用location.href=’/url’来跳转，简单方便，但是刷新了页面；<br>使用路由方式跳转，无刷新页面，静态跳转；</p>
<h3 id="面试题：如何理解-Vue-router-缓存路由组件-keep-alive-生命周期函数？"><a href="#面试题：如何理解-Vue-router-缓存路由组件-keep-alive-生命周期函数？" class="headerlink" title="面试题：如何理解 Vue-router 缓存路由组件   keep-alive 生命周期函数？"></a>面试题：如何理解 Vue-router 缓存路由组件   <code>keep-alive</code> 生命周期函数？</h3><p>有时候客户想要保存之前输入的数据，例如当前input 框的输入，那就不能再切换到其他组件的时候，因为切换到其他组件 当前组件会被销毁，原来dom结点中的值也被销毁了。Vue的 keep-alive标签 就可以解决这个问题。</p>
<p>Vue 的keep-alive 是一个Vue.js的一个内置组件，其实现组件缓存，它的功能是在多个组件间动态切换时缓存被移除的组件实例。</p>
<p>keep-alive 的实质原理为，<strong>Vue 的缓存机制</strong>并不是直接存储 DOM 结构，而是将 DOM 节点抽象成了一个个 VNode节点，所以，keep- alive的缓存也是基于VNode节点的而不是直接存储DOM结构。</p>
<p>其实就是将需要缓存的VNode节点保存在this.cache中／在render时,如果VNode的name符合在缓存条件（可以用include以及exclude控制），则会从this.cache中取出之前缓存的VNode实例进行渲染。</p>
<p>其有两个属性 <code>include</code> 和 <code>exclude</code></p>
<p><strong>include属性</strong>：字符串或正则表达式。只有名称匹配的组件会被缓存。</p>
<p><strong>exclude属性</strong>： 字符串或正则表达式。任何名称匹配的组件都不会被缓存。</p>
<font color="red">注意 里面的字符串，对应的是 Vue 组件中的 **name 属性**！！</font>

<ul>
<li>设置<code>keep-alive</code>的可缓存组件最大数, <code>prop</code>属性名为<code>max</code>，通过设置<code>max</code>，可以控制可缓存组件的最大数。这是一个 基于 LRU 算法的缓存，如果缓存的实例对象即将超过指定那个最大数量，则最久没有被访问的缓存实例将被销毁，以便为新的实例腾出空间。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;keep-alive :max=&quot;max&quot;&gt;</span><br><span class="line">	&lt;router-view&gt;&lt;/router-view&gt;</span><br><span class="line">&lt;/keep-alive&gt;</span><br></pre></td></tr></table></figure>
<p>当一个组件在 keep-alive 中被切换时，会触发改组件实例对象的 activated 和 deactivated 生命周期函数，用来替代 mounted 和 unmounted。每次进入这个页面组件，都会触发<code>activated</code>生命周期，而且每次退出的时候会触发<code>deactivated</code>生命周期。</p>
<h3 id="面试题：Vue-router-两个新的生命周期钩子-active-和-deactive-的使用理解？"><a href="#面试题：Vue-router-两个新的生命周期钩子-active-和-deactive-的使用理解？" class="headerlink" title="面试题：Vue-router 两个新的生命周期钩子  active 和 deactive 的使用理解？"></a>面试题：Vue-router 两个新的生命周期钩子  <code>active</code> 和 <code>deactive</code> 的使用理解？</h3><font color="red">路由组件所独有的两个钩子，用于捕获路由组件的激活状态。</font>

<p><strong>其解决的问题在于：</strong></p>
<p>之前使用了 <code>keep-alive</code> 标签来缓存路由组件，使得客户在切换其他组件的时候，不销毁当前组件，以保证原有填写数据的缓存。</p>
<p><strong>但是，由于没有销毁组件，一些定时器等会一直执行（因为 <code>beforeDestoryed</code>生命周期函数根本无法执行），非常占用内存。</strong></p>
<p>在路由中，其专门有两种生命周期函数来解决这个问题。</p>
<ul>
<li><code>activated</code>路由组件被激活时触发。</li>
<li><code>deactivated</code>路由组件失活时触发，也就是切换到别的组件去展示了。</li>
</ul>
<p>举个例子，例如在 activated的时候我们创建了一个 <code>setTimeOut</code>，则需要在 deactivated 的时候清除这个定时器。</p>
<ul>
<li></li>
</ul>
<h3 id="面试题：什么是路由守卫？"><a href="#面试题：什么是路由守卫？" class="headerlink" title="面试题：什么是路由守卫？"></a>面试题：什么是路由守卫？</h3><p>作用：对路由进行权限控制</p>
<p>解决问题：也就是根据用户缓存的信息，判断是否可以显示等操作，其实就是所谓的守卫  就是 <strong>验证权限</strong></p>
<p>分为三种：<font color="blue">全局守卫、独享守卫、组件内守卫</font></p>
<h4 id="前置-后置-全局守卫"><a href="#前置-后置-全局守卫" class="headerlink" title="前置/后置 全局守卫"></a>前置/后置 全局守卫</h4><p>全局守卫分为 前置和后置守卫两种</p>
<ul>
<li>前置守卫一般用于校验用户信息，是否可以执行到下一vue页面。写的时候注意一定要写<code>next()</code> 进行放行。 </li>
<li>后置守卫一般用于改变浏览器标题等，用的比较少。<strong>因为是在每次路由切换完毕再执行</strong>，所以肯定是已经切换完的，因此没有 <code>next</code> 这个参数方法。</li>
</ul>
<p>将 src 目录下的 route 目录中的 index.js 文件，创建路由进行赋值，再进行全局守卫配置。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> VueRouter(&#123;</span><br><span class="line">	...</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 全局前置路由守卫   初始化的时候被调用、每次路由切换之前被调用</span></span><br><span class="line">router.beforeEach(<span class="function">(<span class="params">to, <span class="keyword">from</span>, next</span>) =&gt;</span> &#123;</span><br><span class="line">	<span class="comment">/* must call `next` */</span></span><br><span class="line">	<span class="built_in">console</span>.log(<span class="string">&quot;前置路由&quot;</span>, to, <span class="keyword">from</span>)</span><br><span class="line">	<span class="keyword">if</span>(to.meta.isAuth)&#123;</span><br><span class="line">		<span class="keyword">if</span>(<span class="built_in">localStorage</span>.getItem(<span class="string">&quot;school&quot;</span>) === <span class="string">&quot;hangzhou Dianzi University&quot;</span>)&#123;</span><br><span class="line">			next()</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			alert(<span class="string">&quot;当前学校名不对,无权限查看&quot;</span>)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		next()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局后置路由守卫   初始化的时候被调用、每次路由切换之后被调用</span></span><br><span class="line">router.afterEach(<span class="function">(<span class="params">to, <span class="keyword">from</span></span>) =&gt;</span>&#123;</span><br><span class="line">	<span class="built_in">document</span>.title = to.meta.title || <span class="string">&quot;案例系统&quot;</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h4 id="独享守卫"><a href="#独享守卫" class="headerlink" title="独享守卫"></a>独享守卫</h4><p>独享守卫，也就是针对某一个单独的路由组件，设置权限。</p>
<p>使用 <code>beforeEnter</code> 方法，定义在路由内部。<font color="blue">注意：独享守卫没有后置方法。</font></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> VueRouter(&#123;</span><br><span class="line">	<span class="attr">routes</span>:[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">name</span>:<span class="string">&quot;newsVue&quot;</span>,</span><br><span class="line">            <span class="attr">path</span>:<span class="string">&#x27;news&#x27;</span>, <span class="comment">//此处一定不要写：/news</span></span><br><span class="line">            <span class="attr">component</span>:News,</span><br><span class="line">            <span class="attr">meta</span>:&#123;<span class="attr">title</span>:<span class="string">&quot;新闻&quot;</span>&#125;,</span><br><span class="line">            <span class="function"><span class="title">beforeEnter</span>(<span class="params">to, <span class="keyword">from</span>, next</span>)</span>&#123;</span><br><span class="line">                <span class="comment">/* must call `next` */</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="built_in">localStorage</span>.getItem(<span class="string">&quot;school&quot;</span>) === <span class="string">&quot;hangzhou Dianzi University&quot;</span>)&#123;</span><br><span class="line">                    next()</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    alert(<span class="string">&quot;当前学校名不对&quot;</span>)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>
<h4 id="组件内守卫"><a href="#组件内守卫" class="headerlink" title="组件内守卫"></a>组件内守卫</h4><p>组件内守卫是 针对于 使用路由规则，进入和离开的  回调函数（类似于生命周期函数）</p>
<p>分为两种，分为：</p>
<ul>
<li><p>beforeRouteEnter：通过路由规则，进入该组件时被调用</p>
<p>其基本和 之前的前置全局守卫 和 独享守卫一模一样</p>
</li>
<li><p>beforeRouteLeave：离开守卫：通过路由规则，离开该组件时被调用</p>
<font color="red">**这个注意不是 后置守卫，其指的是路由离开这个组件后调用，不是指的切换之后。**</font>

</li>
</ul>
<p>其配置在需要守卫的  vue 文件中，例如：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">  <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">      <span class="attr">name</span>:<span class="string">&quot;NewsVue&quot;</span>,</span><br><span class="line">...</span><br><span class="line">      <span class="comment">//进入守卫：通过路由规则，进入该组件时被调用</span></span><br><span class="line">      <span class="function"><span class="title">beforeRouteEnter</span>(<span class="params">to, <span class="keyword">from</span>, next</span>)</span>&#123;</span><br><span class="line">          <span class="comment">/* must call `next` */</span></span><br><span class="line">          <span class="built_in">console</span>.log(<span class="string">&quot;我进入了 news组件&quot;</span>)</span><br><span class="line">          <span class="keyword">if</span>(<span class="built_in">localStorage</span>.getItem(<span class="string">&quot;school&quot;</span>) === <span class="string">&quot;hangzhou Dianzi University&quot;</span>)&#123;</span><br><span class="line">              next()</span><br><span class="line">          &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">              alert(<span class="string">&quot;当前 school 没有权限&quot;</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          </span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="comment">//离开守卫：通过路由规则，离开该组件时被调用</span></span><br><span class="line">      <span class="function"><span class="title">beforeRouteLeave</span>(<span class="params">to, <span class="keyword">from</span>, next</span>)</span>&#123;</span><br><span class="line">          <span class="comment">/* must call `next` */</span></span><br><span class="line">          <span class="built_in">console</span>.log(<span class="string">&quot;我离开news组件了去了&quot;</span>,to.name)</span><br><span class="line">          next()</span><br><span class="line">      &#125;,</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：-Vue-路由模式有哪几种？"><a href="#面试题：-Vue-路由模式有哪几种？" class="headerlink" title="面试题： Vue 路由模式有哪几种？"></a>面试题： Vue 路由模式有哪几种？</h3><p>实际有三种模式，hash模式、history模式 和 memory模式</p>
<ul>
<li>url的hash，就是通常所说的锚点#，javascript通过hashChange事件来监听url的变化，IE7以下需要轮询。比如这个 URL：<a href="http://www.abc.com/#/hello，hash">http://www.abc.com/#/hello，hash</a> 的值为#/hello。它的特点在于：hash 虽然出现在 URL 中，但不会被包括在 HTTP 请求中，对后端完全没有影响，因此<strong>改变 hash 不会重新加载页面</strong>。</li>
<li>HTML5的History模式，它使url看起来像普通网站那样，以“/”分割，没有#，单页面并没有跳转。不过使用这种模式需要服务端支持，服务端在接收到所有请求后，都只想同一个html文件，不然会出现404。因此单页面应用只有一个html，整个网站的内容都在这一个html里，通过js来处理。</li>
<li>在实现上不管时哪种模式，<strong>最终都是通过监听 propstate 事件来触发路由跳转处理</strong>，url显示不同只是在显示效果上的差异。</li>
</ul>
<h3 id="面试题：HashRouter-和-HistoryRouter的区别和原理"><a href="#面试题：HashRouter-和-HistoryRouter的区别和原理" class="headerlink" title="面试题：HashRouter 和 HistoryRouter的区别和原理"></a>面试题：HashRouter 和 HistoryRouter的区别和原理</h3><p><strong>vue-router</strong>是Vue官方的路由管理器。它和 Vue.js 的核心深度集成，让构建单页面应用变得易如反掌。vue-router默认 hash 模式，还有一种是history模式。</p>
<p>原理：</p>
<ol>
<li><p>hash路由：</p>
<p><strong>hash模式的工作原理是hashchange事件</strong>，<strong>可以在window监听hash的变化</strong>。</p>
<p>我们在url后面随便添加一个#xx触发这个事件。vue-router默认的是hash模式—使用URL的hash来模拟一个完整的URL,于是当URL改变的时候,页面不会重新加载,也就是单页应用了,当#后面的hash发生变化,不会导致浏览器向服务器发出请求,浏览器不发出请求就不会刷新页面,并且会触发hasChange这个事件,通过监听hash值的变化来实现更新页面部分内容的操作</p>
<p>对于hash模式会创建hashHistory对象,在访问不同的路由的时候,会发生两件事:<br><strong>HashHistory.push()将新的路由添加到浏览器访问的历史的栈顶,和HasHistory.replace()替换到当前栈顶的路由</strong></p>
<p>两种模式可以用如下图所示：</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/QQ截图20230125202753.png" style="zoom: 50%;" /></p>
</li>
<li><p>history路由：</p>
<p>主要使用HTML5的pushState()和replaceState()这两个api结合window.popstate事件（监听浏览器前进后退）来实现的pushState() 可以改变url地址且不会发送请求, replaceState()可以读取历史记录栈,还可以对浏览器记录进行修改</p>
</li>
</ol>
<h3 id="面试题：js是如何监听HistoryRouter的变化的"><a href="#面试题：js是如何监听HistoryRouter的变化的" class="headerlink" title="面试题：js是如何监听HistoryRouter的变化的"></a>面试题：js是如何监听HistoryRouter的变化的</h3><p>通过浏览器的地址栏来改变切换页面，前端实现主要有两种方式：</p>
<ul>
<li>通过hash改变，利用window.onhashchange 监听。</li>
<li>在</li>
</ul>
<p>在JavaScript中，可以使用<code>window.addEventListener</code>方法监听浏览器的<code>popstate</code>事件来监听<code>HistoryRouter</code>的变化。当用户点击浏览器的前进或后退按钮时，或者通过JavaScript代码调用<code>history.pushState()</code>或<code>history.replaceState()</code>方法来修改浏览器的历史记录时，<code>popstate</code>事件会被触发。</p>
<p>下面是一个简单的示例代码，展示如何使用<code>window.addEventListener</code>方法监听<code>popstate</code>事件：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">window</span>.addEventListener(<span class="string">&#x27;popstate&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">event</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;History state changed&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>当用户点击浏览器的前进或后退按钮时，或者通过JavaScript代码调用<code>history.pushState()</code>或<code>history.replaceState()</code>方法来修改浏览器的历史记录时，控制台会输出<code>History state changed</code>这条信息。</p>
<p>在事件处理函数中，可以通过<code>event.state</code>属性来获取当前历史记录的状态对象。这个状态对象可以是任何JavaScript对象，它可以在调用<code>history.pushState()</code>或<code>history.replaceState()</code>方法时传递进去。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">window</span>.addEventListener(<span class="string">&#x27;popstate&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">event</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;History state changed:&#x27;</span>, event.state);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>在这个示例中，控制台会输出<code>History state changed:</code>以及当前历史记录的状态对象。</p>
<h3 id="面试题：vue-router-实现懒加载"><a href="#面试题：vue-router-实现懒加载" class="headerlink" title="面试题：vue-router 实现懒加载"></a>面试题：vue-router 实现懒加载</h3><p><strong>懒加载</strong>：当打包构建应用时，JavaScript 包会变得非常大，影响页面加载。如果我们能把不同路由对应的组件分割成不同的代码块，然后当路由被访问的时候才加载对应组件，这样就更加高效了。</p>
<p>要实现 Vue Router 的懒加载，可以使用 Webpack 的代码分割功能和异步组件。在实际开发中也推荐使用异步组件（这个方法来自于 chatGPT）</p>
<ol>
<li><p>安装 <code>@babel/plugin-syntax-dynamic-import</code> 和 <code>@vue/cli-plugin-babel</code> 依赖：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install --save-dev @babel/plugin-syntax-dynamic-import @vue/cli-plugin-babel</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新 <code>babel.config.js</code> 文件以启用 <code>@babel/plugin-syntax-dynamic-import</code>：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">  <span class="attr">plugins</span>: [<span class="string">&#x27;@babel/plugin-syntax-dynamic-import&#x27;</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在路由配置中，将路由组件更改为异步组件。例如，将以下代码：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> Foo <span class="keyword">from</span> <span class="string">&#x27;./components/Foo.vue&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> routes = [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">path</span>: <span class="string">&#x27;/foo&#x27;</span>,</span><br><span class="line">    <span class="attr">component</span>: Foo</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>更改为：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> routes = [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">path</span>: <span class="string">&#x27;/foo&#x27;</span>,</span><br><span class="line">    <span class="attr">component</span>: <span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;./components/Foo.vue&#x27;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>此更改告诉 Webpack 在需要时异步加载 <code>./components/Foo.vue</code> 文件，而不是在应用程序初始化时立即加载它。</p>
<p>通过这种方式，Vue.js 应用程序可以更快地加载，并且只在需要时加载组件代码，而不是一次性加载所有代码。</p>
<h2 id="考点7：修改ElementUI-样式的几种方式"><a href="#考点7：修改ElementUI-样式的几种方式" class="headerlink" title="考点7：修改ElementUI 样式的几种方式"></a>考点7：修改ElementUI 样式的几种方式</h2><ol>
<li><p>新建全局样式表</p>
<p>新建 global.css 文件，并在 main.js 中引入。 </p>
<p>global.css 文件一般都放在 src-&gt;assets 静态资源文件夹下的 style 文件夹下，在 main.js 的引用写法如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&quot;./assets/style/global.css&quot;</span></span><br></pre></td></tr></table></figure>
<p>在 global.css 文件中写的样式，无论在哪一个 vue 单页面都会覆盖 ElementUI 默认的样式。</p>
<font color="blue">第一种全局引入css文件的方式，适合于对elementUI整体的修改，比如整体配色的修改；</font>
</li>
<li><p>在当前-vue-单页面中添加一个新的style标签  </p>
<p>在当前的vue单页面的style标签后，添加一对新的style标签，新的style标签中不要添加scoped属性。在有写scoped的style标签中书写的样式不会覆盖 ElementUI 默认的样式。</p>
<font color="blue">第二种添加一个style标签的形式，也能够实现修改默认样式的效果，但实际上因为是修改了全局的样式，因此 在不同的vue组件中修改同一个样式有可能会有冲突。</font>
</li>
<li><font color="red">**使用/deep/深度修改标签样式**  极力推荐</font>

<p>找到需要修改的 ElementUI 标签的类名，然后在类名前加上<strong>/deep/</strong>，可以强制修改默认样式。这种方式可以直接用到有scoped属性的 style 标签中。</p>
<font color="blue">第三种方式通过 **/deep/** 的方式可以很方便的在vue组件中修改默认样式，也不会于其他页面有冲突。</font>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 修改级联选择框的默认宽度</span></span><br><span class="line">/deep/ .el-cascader &#123;</span><br><span class="line">  <span class="attr">width</span>: <span class="number">100</span>%;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过内联样式 或者 绑定类样式覆盖默认样式 <strong>不推荐</strong></p>
<font color="blue">第四种方式局限性比较大，可以使用，但不推荐使用。</font>









</li>
</ol>
<h2 id="考点8：Vue的优势"><a href="#考点8：Vue的优势" class="headerlink" title="考点8：Vue的优势"></a>考点8：Vue的优势</h2><h3 id="面试题：jquery-和-vue相比"><a href="#面试题：jquery-和-vue相比" class="headerlink" title="面试题：jquery 和 vue相比"></a>面试题：jquery 和 vue相比</h3><p>通俗的来说 jquery 就是对 dom 操作进行了封装，实际还是 dom操作。</p>
<p>而 Vue 其利用了 MVVM的架构，完美了分离了数据和视图，通过声明式渲染和响应式数据绑定的方式来帮助我们完全避免了对 DOM 的操作。</p>
<h3 id="面试题：Vue-通过数据劫持可以精准探测数据在具体dom上的变化-为什么还需要虚拟-DOM-diff-呢"><a href="#面试题：Vue-通过数据劫持可以精准探测数据在具体dom上的变化-为什么还需要虚拟-DOM-diff-呢" class="headerlink" title="面试题：Vue 通过数据劫持可以精准探测数据在具体dom上的变化,为什么还需要虚拟 DOM diff 呢?"></a>面试题：Vue 通过数据劫持可以精准探测数据在具体dom上的变化,为什么还需要虚拟 DOM diff 呢?</h3><p>现代前端框架有两种方式侦测变化，一种是 <strong>pull</strong> ，一种是 <strong>push</strong></p>
<p><strong>pull:</strong> 其代表为React，我们可以回忆一下React是如何侦测到变化的,我们通常会用setStateAPI显式更新，然后React会进行一层层的Virtual Dom Diff操作找出差异，然后Patch到DOM上，React从一开始就不知道到底是哪发生了变化，只是知道「有变化了」，然后再进行比较暴力的Diff操作查找「哪发生变化了」，另外一个代表就是Angular的脏检查操作。</p>
<p><strong>push:</strong> Vue的响应式系统则是push的代表，当Vue程序初始化的时候就会对数据data进行依赖的收集，一但数据发生变化,响应式系统就会立刻得知。因此Vue是一开始就知道是「在哪发生变化了」，但是这又会产生一个问题，如果你熟悉Vue的响应式系统就知道，通常一个绑定一个数据就需要一个Watcher</p>
<p>一但我们的绑定细粒度过高就会产生大量的Watcher，这会带来内存以及依赖追踪的开销，而细粒度过低会无法精准侦测变化,因此Vue的设计是选择中等细粒度的方案,在组件级别进行push侦测的方式,也就是那套响应式系统,通常我们会第一时间侦测到发生变化的组件,然后在组件内部进行Virtual Dom Diff获取更加具体的差异，而Virtual Dom Diff则是pull操作，Vue是push+pull结合的方式进行变化侦测的。</p>
<h3 id="面试题：vue单页面和传统的多页面区别？"><a href="#面试题：vue单页面和传统的多页面区别？" class="headerlink" title="面试题：vue单页面和传统的多页面区别？"></a>面试题：vue单页面和传统的多页面区别？</h3><p>单页面应用（SPA）</p>
<p><strong>通俗一点说就是指只有一个主页面的应用</strong>，浏览器一开始要加载所有必须的 html, js, css。所有的页面内容都包含在这个所谓的主页面中。但在写的时候，还是会分开写（页面片段），然后在交互的时候由路由程序动态载入，单页面的页面跳转，仅刷新局部资源。多应用于pc端。</p>
<p>多页面（MPA）</p>
<p>指一个应用中有多个页面，页面跳转时是整页刷新</p>
<p><strong>单页面的优点：</strong></p>
<p>用户体验好，快，内容的改变不需要重新加载整个页面，基于这一点spa对服务器压力较小；前后端分离；页面效果会比较炫酷（比如切换页面内容时的专场动画）。</p>
<p><strong>单页面缺点：</strong></p>
<p><strong>不利于seo</strong>；导航不可用，如果一定要导航需要自行实现前进、后退。<strong>（由于是单页面不能用浏览器的前进后退功能，所以需要自己建立堆栈管理）</strong>；初次加载时耗时多；页面复杂度提高很多。</p>
<h2 id="面试题：-Vue的响应式指的是什么？"><a href="#面试题：-Vue的响应式指的是什么？" class="headerlink" title="面试题： Vue的响应式指的是什么？"></a>面试题： Vue的响应式指的是什么？</h2><p>底层是通过 <code>Object.definePropery</code> 实现，然后再中间去做了一些这些监听的机制，订阅发布者模式等，结合他的一个deep（深拷贝）更新的一个机制去实现响应式的。</p>
<h2 id="面试题：如何理解-Vue-的MVVM机制"><a href="#面试题：如何理解-Vue-的MVVM机制" class="headerlink" title="面试题：如何理解 Vue 的MVVM机制"></a>面试题：如何理解 Vue 的MVVM机制</h2><p>MVVM就是一种框架的设计架构，view-model model view 。</p>
<p>主要的优势在于<strong>Vue和model 之间双向数据绑定的</strong>，视图改变数据会改变，数据改变了视图也会改变。</p>
<h2 id="面试题-响应式数据在哪里定义？"><a href="#面试题-响应式数据在哪里定义？" class="headerlink" title="面试题 : 响应式数据在哪里定义？"></a>面试题 : 响应式数据在哪里定义？</h2><p>肯定是在 data里进行定义的。</p>
<p>不在 data 中定义的数据，是非响应式的。</p>
<p>可以利用 Vue 的语法糖 $set, 将这个数据强制变成响应式。</p>
<p>或者给这个属性数据，自己手写一个 get  set 方法。</p>
<p><strong>面试题：手写get方法怎么实现呢？</strong></p>
<p>利用 js 原生的 Object.defineProper同样，去对这个属性的变量修改以及变量的获取去做监听，监听到了之后去给他绑定现成的事件就可以了。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/NodeJS%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>[toc]</p>
<h3 id="Node-js-（最全）基础-全栈项目"><a href="#Node-js-（最全）基础-全栈项目" class="headerlink" title="Node.js （最全）基础+全栈项目"></a>Node.js （最全）基础+全栈项目</h3><p>​            作者：kerwin</p>
<p>​            版本：QF1.0</p>
<p>​            版权：千锋HTML5大前端教研院</p>
<p>​            公众号: 大前端私房菜</p>
<h4 id="一、Node-js基础"><a href="#一、Node-js基础" class="headerlink" title="一、Node.js基础"></a>一、Node.js基础</h4><h5 id="1-认识Node-js"><a href="#1-认识Node-js" class="headerlink" title="1.  认识Node.js"></a>1.  认识Node.js</h5><blockquote>
<p>Node.js是一个javascript运行环境。它让javascript可以开发后端程序，实现几乎其他后端语言实现的所有功能，可以与PHP、Java、Python、.NET、Ruby等后端语言平起平坐。</p>
<p>Nodejs是基于V8引擎，V8是Google发布的开源JavaScript引擎，本身就是用于Chrome浏览器的js解释部分，但是Ryan Dahl 这哥们，鬼才般的，把这个V8搬到了服务器上，用于做服务器的软件。</p>
</blockquote>
<h6 id="01-nodejs的特性"><a href="#01-nodejs的特性" class="headerlink" title="01 nodejs的特性"></a>01 nodejs的特性</h6><ul>
<li>Nodejs语法完全是js语法，只要你懂js基础就可以学会Nodejs后端开发</li>
<li>NodeJs超强的高并发能力,实现高性能服务器</li>
<li>开发周期短、开发成本低、学习成本低</li>
</ul>
<h6 id="02-使用-Node-js-需要了解多少-JavaScript"><a href="#02-使用-Node-js-需要了解多少-JavaScript" class="headerlink" title="02 使用 Node.js 需要了解多少 JavaScript"></a>02 使用 Node.js 需要了解多少 JavaScript</h6><blockquote>
<p><a href="http://nodejs.cn/learn/how-much-javascript-do-you-need-to-know-to-use-nodejs">http://nodejs.cn/learn/how-much-javascript-do-you-need-to-know-to-use-nodejs</a></p>
</blockquote>
<h6 id="03-浏览器环境vs-node环境"><a href="#03-浏览器环境vs-node环境" class="headerlink" title="03 浏览器环境vs node环境"></a>03 浏览器环境vs node环境</h6><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220209152247426.png" alt="image-20220209152247426"></p>
<p>Node.js 可以解析JS代码（没有浏览器安全级别的限制）提供很多系统级别的API，如：</p>
<ul>
<li><p>文件的读写 (File System)</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fs.readFile(<span class="string">&#x27;./ajax.png&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>, <span class="function">(<span class="params">err, content</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(content)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>进程的管理 (Process)</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span>(<span class="params">argv</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(argv)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main(process.argv.slice(<span class="number">2</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>网络通信 (HTTP/HTTPS)</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> http = <span class="built_in">require</span>(<span class="string">&quot;http&quot;</span>)</span><br><span class="line"></span><br><span class="line">http.createServer(<span class="function">(<span class="params">req,res</span>) =&gt;</span> &#123;</span><br><span class="line">  res.writeHead(<span class="number">200</span>, &#123;</span><br><span class="line">    <span class="string">&quot;content-type&quot;</span>: <span class="string">&quot;text/plain&quot;</span></span><br><span class="line">  &#125;)</span><br><span class="line">  res.write(<span class="string">&quot;hello nodejs&quot;</span>)</span><br><span class="line">  res.end()</span><br><span class="line">&#125;).listen(<span class="number">3000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="2-开发环境搭建"><a href="#2-开发环境搭建" class="headerlink" title="2.  开发环境搭建"></a>2.  开发环境搭建</h5><blockquote>
<p><a href="http://nodejs.cn/download/">http://nodejs.cn/download/</a></p>
</blockquote>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220210095903409.png" alt="image-20220210095903409"></p>
<h5 id="3-模块、包、commonJS"><a href="#3-模块、包、commonJS" class="headerlink" title="3.  模块、包、commonJS"></a>3.  模块、包、commonJS</h5><p>​            <img src="%E7%AC%94%E8%AE%B0.assets/image-20220210100015768.png" alt="image-20220210100015768"></p>
<h6 id="02-CommonJS规范"><a href="#02-CommonJS规范" class="headerlink" title="02 CommonJS规范"></a>02 CommonJS规范</h6><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220210101652166.png" alt="image-20220210101652166" style="zoom: 67%; float: left;" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220210101720533.png" alt="image-20220210101720533" style="zoom: 67%; float: left;" /></p>
<h6 id="03-modules模块化规范写法"><a href="#03-modules模块化规范写法" class="headerlink" title="03 modules模块化规范写法"></a>03 modules模块化规范写法</h6><p>我们可以把公共的功能 抽离成为一个单独的 js 文件 作为一个模块，默认情况下面这个模块里面的方法或者属性，外面是没法访问的。如果要让外部可以访问模块里面的方法或者属性，就必须在模块里面通过 exports 或者 module.exports 暴露属性或者方法。</p>
<p>m1.js：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> name = <span class="string">&#x27;gp19&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> sayName = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;module 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接口暴露方法一：</span></span><br><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">  <span class="attr">say</span>: sayName</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接口暴露方法二：</span></span><br><span class="line"><span class="built_in">exports</span>.say = sayName</span><br><span class="line"></span><br><span class="line"><span class="comment">// 错误！</span></span><br><span class="line"><span class="built_in">exports</span> = &#123;</span><br><span class="line">  <span class="attr">say</span>: sayName</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>main.js：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> m1 = <span class="built_in">require</span>(<span class="string">&#x27;./m1&#x27;</span>)</span><br><span class="line">m1.say()</span><br></pre></td></tr></table></figure>
<h5 id="4-Npm-amp-Yarn"><a href="#4-Npm-amp-Yarn" class="headerlink" title="4.  Npm&amp;Yarn"></a>4.  Npm&amp;Yarn</h5><h6 id="01-npm的使用"><a href="#01-npm的使用" class="headerlink" title="01 npm的使用"></a>01 npm的使用</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">npm init</span><br><span class="line">npm install 包名 –g  （uninstall,update）</span><br><span class="line">npm install 包名 --save-dev (uninstall,update)</span><br><span class="line">npm list -g (不加-g，列举当前目录下的安装包)</span><br><span class="line">npm info 包名（详细信息） npm info 包名 version(获取最新版本)</span><br><span class="line">npm install md5@<span class="number">1</span>（安装指定版本）</span><br><span class="line">npm outdated(  检查包是否已经过时)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="string">&quot;dependencies&quot;</span>: &#123;    <span class="string">&quot;md5&quot;</span>: <span class="string">&quot;^2.1.0&quot;</span>  &#125;  ^ 表示 如果 直接npm install 将会 安md5</span><br><span class="line">    <span class="number">2.</span>*.*  	最新版本</span><br><span class="line"></span><br><span class="line">	<span class="string">&quot;dependencies&quot;</span>: &#123;    <span class="string">&quot;md5&quot;</span>: <span class="string">&quot;~2.1.0&quot;</span>  &#125;  ~ 表示 如果 直接npm install 将会 安装md5 <span class="number">2.1</span>.*  最新版本</span><br><span class="line"></span><br><span class="line">	<span class="string">&quot;dependencies&quot;</span>: &#123;    <span class="string">&quot;md5&quot;</span>: <span class="string">&quot;*&quot;</span>  &#125;  * 表示 如果 直接npm install 将会 安装 md5  最新版本</span><br></pre></td></tr></table></figure>
<h6 id="02-全局安装-nrm"><a href="#02-全局安装-nrm" class="headerlink" title="02 全局安装 nrm"></a>02 全局安装 nrm</h6><blockquote>
<p>NRM (npm registry manager)是npm的镜像源管理工具，有时候国外资源太慢，使用这个就可以快速地在 npm 源间切换。</p>
</blockquote>
<p><code>手动切换方法： npm config set registry https://registry.npm.taobao.org</code></p>
<p><strong>安装 nrm</strong></p>
<p>在命令行执行命令，npm install -g nrm，全局安装nrm。</p>
<p><strong>使用 nrm</strong></p>
<p>执行命令 nrm ls 查看可选的源。 其中，带*的是当前使用的源，上面的输出表明当前源是官方源。</p>
<p><strong>切换 nrm</strong></p>
<p>如果要切换到taobao源，执行命令nrm use taobao。</p>
<p><strong>测试速度</strong></p>
<p>你还可以通过 nrm test 测试相应源的响应时间。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nrm test</span><br></pre></td></tr></table></figure>
<blockquote>
<p> 扩展：</p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220210114017616.png" alt="image-20220210114017616"></p>
</blockquote>
 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g cnpm --registry=https://registry.npmmirror.com</span><br></pre></td></tr></table></figure>
<h6 id="03-yarn使用"><a href="#03-yarn使用" class="headerlink" title="03 yarn使用"></a>03 yarn使用</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install -g yarn</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">对比npm:</span><br><span class="line">	速度超快: Yarn 缓存了每个下载过的包，所以再次使用时无需重复下载。 同时利用并行下载以最大化资源利用率，因此安装速度更快。</span><br><span class="line">    超级安全: 在执行代码之前，Yarn 会通过算法校验每个安装包的完整性。</span><br><span class="line"></span><br><span class="line">开始新项目</span><br><span class="line">	yarn init </span><br><span class="line">添加依赖包</span><br><span class="line">	yarn add [package] </span><br><span class="line">	yarn add [package]@[version] </span><br><span class="line">	yarn add [package] --dev </span><br><span class="line">升级依赖包</span><br><span class="line">	 yarn upgrade [package]@[version] </span><br><span class="line">移除依赖包</span><br><span class="line">	 yarn remove [package]</span><br><span class="line">	 </span><br><span class="line">安装项目的全部依赖</span><br><span class="line">	 yarn install </span><br></pre></td></tr></table></figure>
<h5 id="5-内置模块"><a href="#5-内置模块" class="headerlink" title="5.  内置模块"></a>5.  内置模块</h5><h6 id="01-http模块"><a href="#01-http模块" class="headerlink" title="01  http模块"></a>01  http模块</h6><blockquote>
<p>要使用 HTTP 服务器和客户端，则必须 <code>require(&#39;http&#39;)</code>。</p>
</blockquote>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建本地服务器来从其接收数据</span></span><br><span class="line"><span class="keyword">const</span> server = http.createServer(<span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  res.writeHead(<span class="number">200</span>, &#123; <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span> &#125;);</span><br><span class="line">  res.end(<span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">    <span class="attr">data</span>: <span class="string">&#x27;Hello World!&#x27;</span></span><br><span class="line">  &#125;));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">server.listen(<span class="number">8000</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建本地服务器来从其接收数据</span></span><br><span class="line"><span class="keyword">const</span> server = http.createServer();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 监听请求事件</span></span><br><span class="line">server.on(<span class="string">&#x27;request&#x27;</span>, <span class="function">(<span class="params">request, res</span>) =&gt;</span> &#123;</span><br><span class="line">  res.writeHead(<span class="number">200</span>, &#123; <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span> &#125;);</span><br><span class="line">  res.end(<span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">    <span class="attr">data</span>: <span class="string">&#x27;Hello World!&#x27;</span></span><br><span class="line">  &#125;));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">server.listen(<span class="number">8000</span>);</span><br></pre></td></tr></table></figure>
<h6 id="02-url模块"><a href="#02-url模块" class="headerlink" title="02   url模块"></a>02   url模块</h6><p><strong>02.1 parse</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">&#x27;url&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> urlString = <span class="string">&#x27;https://www.baidu.com:443/ad/index.html?id=8&amp;name=mouse#tag=110&#x27;</span></span><br><span class="line"><span class="keyword">const</span> parsedStr = url.parse(urlString)</span><br><span class="line"><span class="built_in">console</span>.log(parsedStr)</span><br></pre></td></tr></table></figure>
<p><strong>02.2 format</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">&#x27;url&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> urlObject = &#123;</span><br><span class="line">  <span class="attr">protocol</span>: <span class="string">&#x27;https:&#x27;</span>,</span><br><span class="line">  <span class="attr">slashes</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">auth</span>: <span class="literal">null</span>,</span><br><span class="line">  <span class="attr">host</span>: <span class="string">&#x27;www.baidu.com:443&#x27;</span>,</span><br><span class="line">  <span class="attr">port</span>: <span class="string">&#x27;443&#x27;</span>,</span><br><span class="line">  <span class="attr">hostname</span>: <span class="string">&#x27;www.baidu.com&#x27;</span>,</span><br><span class="line">  <span class="attr">hash</span>: <span class="string">&#x27;#tag=110&#x27;</span>,</span><br><span class="line">  <span class="attr">search</span>: <span class="string">&#x27;?id=8&amp;name=mouse&#x27;</span>,</span><br><span class="line">  <span class="attr">query</span>: &#123; <span class="attr">id</span>: <span class="string">&#x27;8&#x27;</span>, <span class="attr">name</span>: <span class="string">&#x27;mouse&#x27;</span> &#125;,</span><br><span class="line">  <span class="attr">pathname</span>: <span class="string">&#x27;/ad/index.html&#x27;</span>,</span><br><span class="line">  <span class="attr">path</span>: <span class="string">&#x27;/ad/index.html?id=8&amp;name=mouse&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">const</span> parsedObj = url.format(urlObject)</span><br><span class="line"><span class="built_in">console</span>.log(parsedObj)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>02.3 resolve</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">&#x27;url&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> a = url.resolve(<span class="string">&#x27;/one/two/three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>)  ( 注意最后加/ ，不加/的区别 )</span><br><span class="line"><span class="keyword">var</span> b = url.resolve(<span class="string">&#x27;http://example.com/&#x27;</span>, <span class="string">&#x27;/one&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> c = url.resolve(<span class="string">&#x27;http://example.com/one&#x27;</span>, <span class="string">&#x27;/two&#x27;</span>)</span><br><span class="line"><span class="built_in">console</span>.log(a + <span class="string">&quot;,&quot;</span> + b + <span class="string">&quot;,&quot;</span> + c)</span><br></pre></td></tr></table></figure>
<h6 id="03-querystring模块"><a href="#03-querystring模块" class="headerlink" title="03  querystring模块"></a>03  querystring模块</h6><p><strong>03.1 parse</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> querystring = <span class="built_in">require</span>(<span class="string">&#x27;querystring&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> qs = <span class="string">&#x27;x=3&amp;y=4&#x27;</span></span><br><span class="line"><span class="keyword">var</span> parsed = querystring.parse(qs)</span><br><span class="line"><span class="built_in">console</span>.log(parsed)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>03.2 stringify</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> querystring = <span class="built_in">require</span>(<span class="string">&#x27;querystring&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> qo = &#123;</span><br><span class="line">  <span class="attr">x</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="attr">y</span>: <span class="number">4</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> parsed = querystring.stringify(qo)</span><br><span class="line"><span class="built_in">console</span>.log(parsed)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>03.3 escape/unescape</strong></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220213211406894.png" alt="image-20220213211406894" style="zoom:67%;" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220213211423142.png" alt="image-20220213211423142" style="zoom:67%;" /></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> querystring = <span class="built_in">require</span>(<span class="string">&#x27;querystring&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> str = <span class="string">&#x27;id=3&amp;city=北京&amp;url=https://www.baidu.com&#x27;</span></span><br><span class="line"><span class="keyword">var</span> escaped = querystring.escape(str)</span><br><span class="line"><span class="built_in">console</span>.log(escaped)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> querystring = <span class="built_in">require</span>(<span class="string">&#x27;querystring&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> str = <span class="string">&#x27;id%3D3%26city%3D%E5%8C%97%E4%BA%AC%26url%3Dhttps%3A%2F%2Fwww.baidu.com&#x27;</span></span><br><span class="line"><span class="keyword">var</span> unescaped = querystring.unescape(str)</span><br><span class="line"><span class="built_in">console</span>.log(unescaped)</span><br></pre></td></tr></table></figure>
<h6 id="04-http模块补充"><a href="#04-http模块补充" class="headerlink" title="04  http模块补充"></a>04  http模块补充</h6><p><strong>04.1 接口：jsonp</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">&#x27;url&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> app = http.createServer(<span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> urlObj = url.parse(req.url, <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (urlObj.pathname) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;/api/user&#x27;</span>:</span><br><span class="line">      res.end(<span class="string">`<span class="subst">$&#123;urlObj.query.cb&#125;</span>(&#123;&quot;name&quot;: &quot;gp145&quot;&#125;)`</span>)</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">    <span class="attr">default</span>:</span><br><span class="line">      res.end(<span class="string">&#x27;404.&#x27;</span>)</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">8080</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;localhost:8080&#x27;</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>04.2 跨域：CORS</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">&#x27;url&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> querystring = <span class="built_in">require</span>(<span class="string">&#x27;querystring&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> app = http.createServer(<span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> data = <span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="keyword">let</span> urlObj = url.parse(req.url, <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">  res.writeHead(<span class="number">200</span>, &#123;</span><br><span class="line">    <span class="string">&#x27;content-type&#x27;</span>: <span class="string">&#x27;application/json;charset=utf-8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Access-Control-Allow-Origin&#x27;</span>: <span class="string">&#x27;*&#x27;</span></span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  req.on(<span class="string">&#x27;data&#x27;</span>, <span class="function">(<span class="params">chunk</span>) =&gt;</span> &#123;</span><br><span class="line">    data += chunk</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  req.on(<span class="string">&#x27;end&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    responseResult(querystring.parse(data))</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">responseResult</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (urlObj.pathname) &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;/api/login&#x27;</span>:</span><br><span class="line">        res.end(<span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">          <span class="attr">message</span>: data</span><br><span class="line">        &#125;))</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      <span class="attr">default</span>:</span><br><span class="line">        res.end(<span class="string">&#x27;404.&#x27;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">8080</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;localhost:8080&#x27;</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>04.3 模拟get</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> https = <span class="built_in">require</span>(<span class="string">&#x27;https&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1、接口 2、跨域</span></span><br><span class="line"><span class="keyword">const</span> server = http.createServer(<span class="function">(<span class="params">request, response</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">var</span> url = request.url.substr(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> data = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  response.writeHeader(<span class="number">200</span>, &#123;</span><br><span class="line">    <span class="string">&#x27;content-type&#x27;</span>: <span class="string">&#x27;application/json;charset=utf-8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Access-Control-Allow-Origin&#x27;</span>: <span class="string">&#x27;*&#x27;</span></span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  https.get(<span class="string">`https://m.lagou.com/listmore.json<span class="subst">$&#123;url&#125;</span>`</span>, <span class="function">(<span class="params">res</span>) =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">    res.on(<span class="string">&#x27;data&#x27;</span>, <span class="function">(<span class="params">chunk</span>) =&gt;</span> &#123;</span><br><span class="line">      data += chunk</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    res.on(<span class="string">&#x27;end&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">      response.end(<span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">        <span class="attr">ret</span>: <span class="literal">true</span>,</span><br><span class="line">        data</span><br><span class="line">      &#125;))</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">server.listen(<span class="number">8080</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;localhost:8080&#x27;</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>04.4 模拟post：服务器提交（攻击）</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> https = <span class="built_in">require</span>(<span class="string">&#x27;https&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> querystring = <span class="built_in">require</span>(<span class="string">&#x27;querystring&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> postData = querystring.stringify(&#123;</span><br><span class="line">  <span class="attr">province</span>: <span class="string">&#x27;上海&#x27;</span>,</span><br><span class="line">  <span class="attr">city</span>: <span class="string">&#x27;上海&#x27;</span>,</span><br><span class="line">  <span class="attr">district</span>: <span class="string">&#x27;宝山区&#x27;</span>,</span><br><span class="line">  <span class="attr">address</span>: <span class="string">&#x27;同济支路199号智慧七立方3号楼2-4层&#x27;</span>,</span><br><span class="line">  <span class="attr">latitude</span>: <span class="number">43.0</span>,</span><br><span class="line">  <span class="attr">longitude</span>: <span class="number">160.0</span>,</span><br><span class="line">  <span class="attr">message</span>: <span class="string">&#x27;求购一条小鱼&#x27;</span>,</span><br><span class="line">  <span class="attr">contact</span>: <span class="string">&#x27;13666666&#x27;</span>,</span><br><span class="line">  <span class="attr">type</span>: <span class="string">&#x27;sell&#x27;</span>,</span><br><span class="line">  <span class="attr">time</span>: <span class="number">1571217561</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> options = &#123;</span><br><span class="line">  <span class="attr">protocol</span>: <span class="string">&#x27;https:&#x27;</span>,</span><br><span class="line">  <span class="attr">hostname</span>: <span class="string">&#x27;ik9hkddr.qcloud.la&#x27;</span>,</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>,</span><br><span class="line">  <span class="attr">port</span>: <span class="number">443</span>,</span><br><span class="line">  <span class="attr">path</span>: <span class="string">&#x27;/index.php/trade/add_item&#x27;</span>,</span><br><span class="line">  <span class="attr">headers</span>: &#123;</span><br><span class="line">    <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/x-www-form-urlencoded&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Content-Length&#x27;</span>: Buffer.byteLength(postData)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">doPost</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> data</span><br><span class="line"></span><br><span class="line">  <span class="keyword">let</span> req = https.request(options, <span class="function">(<span class="params">res</span>) =&gt;</span> &#123;</span><br><span class="line">    res.on(<span class="string">&#x27;data&#x27;</span>, <span class="function"><span class="params">chunk</span> =&gt;</span> data += chunk)</span><br><span class="line">    res.on(<span class="string">&#x27;end&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="built_in">console</span>.log(data)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  req.write(postData)</span><br><span class="line">  req.end()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// setInterval(() =&gt; &#123;</span></span><br><span class="line"><span class="comment">//   doPost()</span></span><br><span class="line"><span class="comment">// &#125;, 1000)</span></span><br></pre></td></tr></table></figure>
<p><strong>04.5 爬虫</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> https = <span class="built_in">require</span>(<span class="string">&#x27;https&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> cheerio = <span class="built_in">require</span>(<span class="string">&#x27;cheerio&#x27;</span>)</span><br><span class="line"></span><br><span class="line">http.createServer(<span class="function">(<span class="params">request, response</span>) =&gt;</span> &#123;</span><br><span class="line">  response.writeHead(<span class="number">200</span>, &#123;</span><br><span class="line">    <span class="string">&#x27;content-type&#x27;</span>: <span class="string">&#x27;application/json;charset=utf-8&#x27;</span></span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> options = &#123;</span><br><span class="line">    <span class="comment">// protocol: &#x27;https:&#x27;,</span></span><br><span class="line">    <span class="attr">hostname</span>: <span class="string">&#x27;i.maoyan.com&#x27;</span>,</span><br><span class="line">    <span class="attr">port</span>: <span class="number">443</span>,</span><br><span class="line">    <span class="attr">path</span>: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">    <span class="attr">method</span>: <span class="string">&#x27;GET&#x27;</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> req = https.request(options, <span class="function">(<span class="params">res</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> data = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    res.on(<span class="string">&#x27;data&#x27;</span>, <span class="function">(<span class="params">chunk</span>) =&gt;</span> &#123;</span><br><span class="line">      data += chunk</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    res.on(<span class="string">&#x27;end&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">      filterData(data)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">filterData</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">    <span class="comment">//   console.log(data)</span></span><br><span class="line">    <span class="keyword">let</span> $ = cheerio.load(data)</span><br><span class="line">    <span class="keyword">let</span> $movieList = $(<span class="string">&#x27;.column.content&#x27;</span>)</span><br><span class="line">    <span class="built_in">console</span>.log($movieList)</span><br><span class="line">    <span class="keyword">let</span> movies = []</span><br><span class="line">    $movieList.each(<span class="function">(<span class="params">index, value</span>) =&gt;</span> &#123;</span><br><span class="line">      movies.push(&#123;</span><br><span class="line">        <span class="attr">title</span>: $(value).find(<span class="string">&#x27;.movie-title .title&#x27;</span>).text(),</span><br><span class="line">        <span class="attr">detail</span>: $(value).find(<span class="string">&#x27;.detail .actor&#x27;</span>).text(),</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    response.end(<span class="built_in">JSON</span>.stringify(movies))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  req.end()</span><br><span class="line">&#125;).listen(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure>
<h6 id="05-event模块"><a href="#05-event模块" class="headerlink" title="05  event模块"></a>05  event模块</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> EventEmitter = <span class="built_in">require</span>(<span class="string">&#x27;events&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyEventEmitter</span> <span class="keyword">extends</span> <span class="title">EventEmitter</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> event = <span class="keyword">new</span> MyEventEmitter()</span><br><span class="line"></span><br><span class="line">event.on(<span class="string">&#x27;play&#x27;</span>, <span class="function">(<span class="params">movie</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(movie)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">event.emit(<span class="string">&#x27;play&#x27;</span>, <span class="string">&#x27;我和我的祖国&#x27;</span>)</span><br><span class="line">event.emit(<span class="string">&#x27;play&#x27;</span>, <span class="string">&#x27;中国机长&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h6 id="06-fs文件操作模块"><a href="#06-fs文件操作模块" class="headerlink" title="06  fs文件操作模块"></a>06  fs文件操作模块</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建文件夹</span></span><br><span class="line">fs.mkdir(<span class="string">&#x27;./logs&#x27;</span>, <span class="function">(<span class="params">err</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;done.&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 文件夹改名</span></span><br><span class="line">fs.rename(<span class="string">&#x27;./logs&#x27;</span>, <span class="string">&#x27;./log&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;done&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除文件夹</span></span><br><span class="line">fs.rmdir(<span class="string">&#x27;./log&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;done.&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写内容到文件里</span></span><br><span class="line">fs.writeFile(</span><br><span class="line">  <span class="string">&#x27;./logs/log1.txt&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hello&#x27;</span>,</span><br><span class="line">  <span class="comment">// 错误优先的回调函数</span></span><br><span class="line">  <span class="function">(<span class="params">err</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (err) &#123;</span><br><span class="line">      <span class="built_in">console</span>.log(err.message)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">&#x27;文件创建成功&#x27;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 给文件追加内容</span></span><br><span class="line">fs.appendFile(<span class="string">&#x27;./logs/log1.txt&#x27;</span>, <span class="string">&#x27;\nworld&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;done.&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取文件内容</span></span><br><span class="line">fs.readFile(<span class="string">&#x27;./logs/log1.txt&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>, <span class="function">(<span class="params">err, data</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(data)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除文件</span></span><br><span class="line">fs.unlink(<span class="string">&#x27;./logs/log1.txt&#x27;</span>, <span class="function">(<span class="params">err</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;done.&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 批量写文件</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">  fs.writeFile(<span class="string">`./logs/log-<span class="subst">$&#123;i&#125;</span>.txt`</span>, <span class="string">`log-<span class="subst">$&#123;i&#125;</span>`</span>, <span class="function">(<span class="params">err</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;done.&#x27;</span>)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取文件/目录信息</span></span><br><span class="line">fs.readdir(<span class="string">&#x27;./&#x27;</span>, <span class="function">(<span class="params">err, data</span>) =&gt;</span> &#123;</span><br><span class="line">  data.forEach(<span class="function">(<span class="params">value, index</span>) =&gt;</span> &#123;</span><br><span class="line">    fs.stat(<span class="string">`./<span class="subst">$&#123;value&#125;</span>`</span>, <span class="function">(<span class="params">err, stats</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="comment">// console.log(value + &#x27;:&#x27; + stats.size)</span></span><br><span class="line">      <span class="built_in">console</span>.log(value + <span class="string">&#x27; is &#x27;</span> + (stats.isDirectory() ? <span class="string">&#x27;directory&#x27;</span> : <span class="string">&#x27;file&#x27;</span>))</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同步读取文件</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> content = fs.readFileSync(<span class="string">&#x27;./logs/log-1.txt&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">  <span class="built_in">console</span>.log(content)</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="number">0</span>)</span><br><span class="line">&#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(e.message)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 异步读取文件：方法一</span></span><br><span class="line">fs.readFile(<span class="string">&#x27;./logs/log-0.txt&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>, <span class="function">(<span class="params">err, content</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(content)</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="number">0</span>)</span><br><span class="line">&#125;)</span><br><span class="line"><span class="built_in">console</span>.log(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 异步读取文件：方法二</span></span><br><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&quot;fs&quot;</span>).promises</span><br><span class="line">fs.readFile(<span class="string">&#x27;./logs/log-0.txt&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>).then(<span class="function"><span class="params">result</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(result)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在<code>fs</code>模块中，提供同步方法是为了方便使用。那我们到底是应该用异步方法还是同步方法呢？</p>
<p>由于Node环境执行的JavaScript代码是服务器端代码，所以，绝大部分需要在服务器运行期反复执行业务逻辑的代码，<em>必须使用异步代码</em>，否则，同步代码在执行时期，服务器将停止响应，因为JavaScript只有一个执行线程。</p>
<p>服务器启动时如果需要读取配置文件，或者结束时需要写入到状态文件时，可以使用同步代码，因为这些代码只在启动和结束时执行一次，不影响服务器正常运行时的异步执行。</p>
<h6 id="07-stream流模块"><a href="#07-stream流模块" class="headerlink" title="07  stream流模块"></a>07  stream流模块</h6><p><code>stream</code>是Node.js提供的又一个仅在服务区端可用的模块，目的是支持“流”这种数据结构。</p>
<p>什么是流？流是一种抽象的数据结构。想象水流，当在水管中流动时，就可以从某个地方（例如自来水厂）源源不断地到达另一个地方（比如你家的洗手池）。我们也可以把数据看成是数据流，比如你敲键盘的时候，就可以把每个字符依次连起来，看成字符流。这个流是从键盘输入到应用程序，实际上它还对应着一个名字：标准输入流（stdin）。</p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220407085931744.png" alt="image-20220407085931744"></p>
<p>如果应用程序把字符一个一个输出到显示器上，这也可以看成是一个流，这个流也有名字：标准输出流（stdout）。流的特点是数据是有序的，而且必须依次读取，或者依次写入，不能像Array那样随机定位。</p>
<p>有些流用来读取数据，比如从文件读取数据时，可以打开一个文件流，然后从文件流中不断地读取数据。有些流用来写入数据，比如向文件写入数据时，只需要把数据不断地往文件流中写进去就可以了。</p>
<p>在Node.js中，流也是一个对象，我们只需要响应流的事件就可以了：<code>data</code>事件表示流的数据已经可以读取了，<code>end</code>事件表示这个流已经到末尾了，没有数据可以读取了，<code>error</code>事件表示出错了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打开一个流:</span></span><br><span class="line"><span class="keyword">var</span> rs = fs.createReadStream(<span class="string">&#x27;sample.txt&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>);</span><br><span class="line"></span><br><span class="line">rs.on(<span class="string">&#x27;data&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">chunk</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;DATA:&#x27;</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(chunk);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">rs.on(<span class="string">&#x27;end&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;END&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">rs.on(<span class="string">&#x27;error&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;ERROR: &#x27;</span> + err);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>要注意，<code>data</code>事件可能会有多次，每次传递的<code>chunk</code>是流的一部分数据。</p>
<p>要以流的形式写入文件，只需要不断调用<code>write()</code>方法，最后以<code>end()</code>结束：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> ws1 = fs.createWriteStream(<span class="string">&#x27;output1.txt&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>);</span><br><span class="line">ws1.write(<span class="string">&#x27;使用Stream写入文本数据...\n&#x27;</span>);</span><br><span class="line">ws1.write(<span class="string">&#x27;END.&#x27;</span>);</span><br><span class="line">ws1.end();</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>pipe</code> 就像可以把两个水管串成一个更长的水管一样，两个流也可以串起来。一个<code>Readable</code>流和一个<code>Writable</code>流串起来后，所有的数据自动从<code>Readable</code>流进入<code>Writable</code>流，这种操作叫<code>pipe</code>。</p>
<p>在Node.js中，<code>Readable</code>流有一个<code>pipe()</code>方法，就是用来干这件事的。</p>
<p>让我们用<code>pipe()</code>把一个文件流和另一个文件流串起来，这样源文件的所有数据就自动写入到目标文件里了，所以，这实际上是一个复制文件的程序：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> readstream = fs.createReadStream(<span class="string">&#x27;./1.txt&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> writestream = fs.createWriteStream(<span class="string">&#x27;./2.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">readstream.pipe(writestream)</span><br></pre></td></tr></table></figure>
<h6 id="08-zlib"><a href="#08-zlib" class="headerlink" title="08 zlib"></a>08 zlib</h6><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220407105916114.png" alt="image-20220407105916114" style="zoom:50%;" /></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> zlib = <span class="built_in">require</span>(<span class="string">&#x27;zlib&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> gzip = zlib.createGzip()</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> readstream = fs.createReadStream(<span class="string">&#x27;./note.txt&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> writestream = fs.createWriteStream(<span class="string">&#x27;./note2.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">readstream</span><br><span class="line">  .pipe(gzip)</span><br><span class="line">  .pipe(writestream)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="09-crypto"><a href="#09-crypto" class="headerlink" title="09 crypto"></a>09 crypto</h6><p>crypto模块的目的是为了提供通用的加密和哈希算法。用纯JavaScript代码实现这些功能不是不可能，但速度会非常慢。Nodejs用C/C++实现这些算法后，通过cypto这个模块暴露为JavaScript接口，这样用起来方便，运行速度也快。</p>
<p>MD5是一种常用的哈希算法，用于给任意数据一个“签名”。这个签名通常用一个十六进制的字符串表示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> crypto = <span class="built_in">require</span>(<span class="string">&#x27;crypto&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> hash = crypto.createHash(<span class="string">&#x27;md5&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可任意多次调用update():</span></span><br><span class="line">hash.update(<span class="string">&#x27;Hello, world!&#x27;</span>);</span><br><span class="line">hash.update(<span class="string">&#x27;Hello, nodejs!&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(hash.digest(<span class="string">&#x27;hex&#x27;</span>)); </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>update()</code>方法默认字符串编码为<code>UTF-8</code>，也可以传入Buffer。</p>
<p>如果要计算SHA1，只需要把<code>&#39;md5&#39;</code>改成<code>&#39;sha1&#39;</code>，就可以得到SHA1的结果<code>1f32b9c9932c02227819a4151feed43e131aca40</code>。</p>
<p>Hmac算法也是一种哈希算法，它可以利用MD5或SHA1等哈希算法。不同的是，Hmac还需要一个密钥：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const crypto = require(&#x27;crypto&#x27;);</span><br><span class="line"></span><br><span class="line">const hmac = crypto.createHmac(&#x27;sha256&#x27;, &#x27;secret-key&#x27;);</span><br><span class="line"></span><br><span class="line">hmac.update(&#x27;Hello, world!&#x27;);</span><br><span class="line">hmac.update(&#x27;Hello, nodejs!&#x27;);</span><br><span class="line"></span><br><span class="line">console.log(hmac.digest(&#x27;hex&#x27;)); // 80f7e22570...</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>只要密钥发生了变化，那么同样的输入数据也会得到不同的签名，因此，可以把Hmac理解为用随机数“增强”的哈希算法。</p>
<p>AES是一种常用的对称加密算法，加解密都用同一个密钥。crypto模块提供了AES支持，但是需要自己封装好函数，便于使用：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> crypto = <span class="built_in">require</span>(<span class="string">&quot;crypto&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">encrypt</span> (<span class="params">key, iv, data</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> decipher = crypto.createCipheriv(<span class="string">&#x27;aes-128-cbc&#x27;</span>, key, iv);</span><br><span class="line">    <span class="comment">// decipher.setAutoPadding(true);</span></span><br><span class="line">    <span class="keyword">return</span> decipher.update(data, <span class="string">&#x27;binary&#x27;</span>, <span class="string">&#x27;hex&#x27;</span>) + decipher.final(<span class="string">&#x27;hex&#x27;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">decrypt</span> (<span class="params">key, iv, crypted</span>) </span>&#123;</span><br><span class="line">     crypted = Buffer.from(crypted, <span class="string">&#x27;hex&#x27;</span>).toString(<span class="string">&#x27;binary&#x27;</span>);</span><br><span class="line">     <span class="keyword">let</span> decipher = crypto.createDecipheriv(<span class="string">&#x27;aes-128-cbc&#x27;</span>, key, iv);</span><br><span class="line">     <span class="keyword">return</span> decipher.update(crypted, <span class="string">&#x27;binary&#x27;</span>, <span class="string">&#x27;utf8&#x27;</span>) + decipher.final(<span class="string">&#x27;utf8&#x27;</span>);</span><br><span class="line">&#125;</span><br><span class="line">key,iv必须是<span class="number">16</span>个字节</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以看出，加密后的字符串通过解密又得到了原始内容。</p>
<h5 id="6-路由"><a href="#6-路由" class="headerlink" title="6.   路由"></a>6.   路由</h5><h6 id="01-基础"><a href="#01-基础" class="headerlink" title="01   基础"></a>01   基础</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * @作者: kerwin</span></span><br><span class="line"><span class="comment"> * @公众号: 大前端私房菜</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">&quot;fs&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> path = <span class="built_in">require</span>(<span class="string">&quot;path&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">render</span>(<span class="params">res, path</span>) </span>&#123;</span><br><span class="line">    res.writeHead(<span class="number">200</span>, &#123; <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;text/html;charset=utf8&quot;</span> &#125;)</span><br><span class="line">    res.write(fs.readFileSync(path, <span class="string">&quot;utf8&quot;</span>))</span><br><span class="line">    res.end()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> route = &#123;</span><br><span class="line">    <span class="string">&quot;/login&quot;</span>: <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">        render(res, <span class="string">&quot;./static/login.html&quot;</span>)</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;/home&quot;</span>: <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">        render(res, <span class="string">&quot;./static/home.html&quot;</span>)</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;/404&quot;</span>: <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">        res.writeHead(<span class="number">404</span>, &#123; <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;text/html;charset=utf8&quot;</span> &#125;)</span><br><span class="line">        res.write(fs.readFileSync(<span class="string">&quot;./static/404.html&quot;</span>, <span class="string">&quot;utf8&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="02-获取参数"><a href="#02-获取参数" class="headerlink" title="02   获取参数"></a>02   获取参数</h6><p>get请求</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;/api/login&quot;</span>:<span class="function">(<span class="params">req,res</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">const</span> myURL = <span class="keyword">new</span> URL(req.url, <span class="string">&#x27;http://127.0.0.1:3000&#x27;</span>);</span><br><span class="line">    <span class="built_in">console</span>.log(myURL.searchParams.get(<span class="string">&quot;username&quot;</span>))   </span><br><span class="line">    render(res,<span class="string">`&#123;ok:1&#125;`</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>post请求</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;/api/login&quot;</span>: <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> post = <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">        <span class="comment">// 通过req的data事件监听函数，每当接受到请求体的数据，就累加到post变量中</span></span><br><span class="line">        req.on(<span class="string">&#x27;data&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">chunk</span>) </span>&#123;</span><br><span class="line">            post += chunk;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 在end事件触发后，通过querystring.parse将post解析为真正的POST请求格式，然后向客户端返回。</span></span><br><span class="line">        req.on(<span class="string">&#x27;end&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            post = <span class="built_in">JSON</span>.parse(post);</span><br><span class="line">            render(res, <span class="string">`&#123;ok:1&#125;`</span>)</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h6 id="03-静态资源处理"><a href="#03-静态资源处理" class="headerlink" title="03   静态资源处理"></a>03   静态资源处理</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">readStaticFile</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> myURL = <span class="keyword">new</span> URL(req.url, <span class="string">&#x27;http://127.0.0.1:3000&#x27;</span>)</span><br><span class="line">    <span class="keyword">var</span> filePathname = path.join(__dirname, <span class="string">&quot;/static&quot;</span>, myURL.pathname);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (fs.existsSync(filePathname)) &#123;</span><br><span class="line">        <span class="comment">// console.log(1111)</span></span><br><span class="line">        res.writeHead(<span class="number">200</span>, &#123; <span class="string">&quot;Content-Type&quot;</span>: <span class="string">`<span class="subst">$&#123;mime.getType(myURL.pathname.split(<span class="string">&quot;.&quot;</span>)[<span class="number">1</span>])&#125;</span>;charset=utf8`</span> &#125;)</span><br><span class="line">        res.write(fs.readFileSync(filePathname, <span class="string">&quot;utf8&quot;</span>))</span><br><span class="line">        res.end()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="二、Express"><a href="#二、Express" class="headerlink" title="二、Express"></a>二、Express</h4><blockquote>
<p><a href="https://www.expressjs.com.cn/">https://www.expressjs.com.cn/</a></p>
</blockquote>
<p>基于 Node.js 平台，快速、开放、极简的 web 开发框架。</p>
<h5 id="1-特色"><a href="#1-特色" class="headerlink" title="1.特色"></a>1.特色</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220411103139587.png" alt="image-20220411103139587" style="zoom: 50%;float:left;" /></p>
<h5 id="2-安装"><a href="#2-安装" class="headerlink" title="2.安装"></a>2.安装</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ npm install express --save</span><br></pre></td></tr></table></figure>
<h5 id="3-路由"><a href="#3-路由" class="headerlink" title="3.路由"></a>3.路由</h5><p>路由是指如何定义应用的端点（URIs）以及如何响应客户端的请求。</p>
<p>路由是由一个 URI、HTTP 请求（GET、POST等）和若干个句柄组成，它的结构如下： app.METHOD(path, [callback…], callback)， app 是 express 对象的一个实例， METHOD 是一个 HTTP 请求方法， path 是服务器上的路径， callback 是当路由匹配时要执行的函数。</p>
<p>下面是一个基本的路由示例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> app = express();</span><br><span class="line"></span><br><span class="line"><span class="comment">// respond with &quot;hello world&quot; when a GET request is made to the homepage</span></span><br><span class="line">app.get(<span class="string">&#x27;/&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;hello world&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>路由路径和请求方法一起定义了请求的端点，它可以是字符串、字符串模式或者正则表达式。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 匹配根路径的请求</span></span><br><span class="line">app.get(<span class="string">&#x27;/&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;root&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配 /about 路径的请求</span></span><br><span class="line">app.get(<span class="string">&#x27;/about&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;about&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配 /random.text 路径的请求</span></span><br><span class="line">app.get(<span class="string">&#x27;/random.text&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;random.text&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>使用<strong>字符串模式的路由路径</strong>  <strong>（注意这个 不是 正则表达式）</strong>示例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 匹配 acd 和 abcd</span></span><br><span class="line">app.get(<span class="string">&#x27;/ab?cd&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;ab?cd&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配 /ab/******</span></span><br><span class="line">app.get(<span class="string">&#x27;/ab/:id&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;aaaaaaa&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配 abcd、abbcd、abbbcd等</span></span><br><span class="line">app.get(<span class="string">&#x27;/ab+cd&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;ab+cd&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配 abcd、abxcd、abRABDOMcd、ab123cd等</span></span><br><span class="line">app.get(<span class="string">&#x27;/ab*cd&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;ab*cd&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配 /abe 和 /abcde</span></span><br><span class="line">app.get(<span class="string">&#x27;/ab(cd)?e&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line"> res.send(<span class="string">&#x27;ab(cd)?e&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>使用<strong>正则表达式</strong>的路由路径示例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 匹配任何路径中含有 a 的路径：</span></span><br><span class="line">app.get(<span class="regexp">/a/</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;/a/&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 匹配 butterfly、dragonfly，不匹配 butterflyman、dragonfly man等</span></span><br><span class="line">app.get(<span class="regexp">/.*fly$/</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;/.*fly$/&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p><strong>可以为请求处理提供多个回调函数，其行为类似 中间件。</strong>唯一的区别是这些回调函数有可能调用 next(‘route’) 方法而略过其他路由回调函数。可以利用该机制为路由定义前提条件，如果在现有路径上继续执行没有意义，则可将控制权交给剩下的路径。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.get(<span class="string">&#x27;/example/a&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;Hello from A!&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>使用多个回调函数处理路由（记得指定 next 对象）：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.get(<span class="string">&#x27;/example/b&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;response will be sent by the next function ...&#x27;</span>);</span><br><span class="line">  next();</span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;Hello from B!&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>使用回调函数数组处理路由：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> cb0 = <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;CB0&#x27;</span>)</span><br><span class="line">  next()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> cb1 = <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;CB1&#x27;</span>)</span><br><span class="line">  next()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> cb2 = <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;Hello from C!&#x27;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用数组形式 更加的优雅</span></span><br><span class="line">app.get(<span class="string">&#x27;/example/c&#x27;</span>, [cb0, cb1, cb2])</span><br></pre></td></tr></table></figure>
<p><strong>混合使用函数和函数数组处理路由</strong>：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> cb0 = <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;CB0&#x27;</span>)</span><br><span class="line">  next()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> cb1 = <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;CB1&#x27;</span>)</span><br><span class="line">  next()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">&#x27;/example/d&#x27;</span>, [cb0, cb1], <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;response will be sent by the next function ...&#x27;</span>)</span><br><span class="line">  next()</span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;Hello from D!&#x27;</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="4-中间件"><a href="#4-中间件" class="headerlink" title="4.中间件"></a>4.中间件</h5><p>Express 是一个自身功能极简，完全是<strong>由路由和中间件构成一个的 web 开发框架</strong>：从本质上来说，<strong>一个 Express 应用就是在调用各种中间件。</strong></p>
<p>中间件（Middleware） 是一个函数，它可以访问请求对象（request object (req)）, 响应对象（response object (res)）, 和 web 应用中处于请求-响应循环流程中的中间件，一般被命名为 next 的变量。</p>
<p>中间件的功能包括：</p>
<ul>
<li>执行任何代码。</li>
<li>修改请求和响应对象。</li>
<li>终结请求-响应循环。</li>
<li>调用堆栈中的下一个中间件。</li>
</ul>
<p>如果当前中间件没有终结请求-响应循环，则必须调用 next() 方法将控制权交给下一个中间件，否则请求就会挂起。</p>
<p>Express 应用可使用如下几种中间件：</p>
<ul>
<li>应用级中间件</li>
<li>路由级中间件</li>
<li>错误处理中间件</li>
<li>内置中间件</li>
<li>第三方中间件</li>
</ul>
<p>使用可选则挂载路径，可在应用级别或路由级别装载中间件。另外，你还可以同时装在一系列中间件函数，从而在一个挂载点上创建一个子中间件栈。</p>
<h6 id="（1）应用级中间件"><a href="#（1）应用级中间件" class="headerlink" title="（1）应用级中间件"></a>（1）应用级中间件</h6><p>应用级中间件绑定到 app 对象 使用 app.use() 和 app.METHOD()， 其中， METHOD 是需要处理的 HTTP 请求的方法，例如 GET, PUT, POST 等等，全部小写。例如：</p>
<font color="red">**不过他要注意 app.use 挂载的顺序，你不能一进来就 验证token吧，肯定要调用login 或者其他请求的时候，才开始 app.use挂载。**</font>

<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> app = express()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 没有挂载路径的中间件，应用的每个请求都会执行该中间件</span></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;Time:&#x27;</span>, <span class="built_in">Date</span>.now())</span><br><span class="line">  next()</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="（2）路由级中间件"><a href="#（2）路由级中间件" class="headerlink" title="（2）路由级中间件"></a>（2）路由级中间件</h6><p>路由级中间件和应用级中间件一样，只是它绑定的对象为 express.Router()。</p>
<p>这个就是对需要挂载的路由，进行一定的拦截与验证。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> router = express.Router()</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> app = express()</span><br><span class="line"><span class="keyword">var</span> router = express.Router()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 没有挂载路径的中间件，通过该路由的每个请求都会执行该中间件</span></span><br><span class="line">router.use(<span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;Time:&#x27;</span>, <span class="built_in">Date</span>.now())</span><br><span class="line">  next()</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个中间件栈，显示任何指向 /user/:id 的 HTTP 请求的信息</span></span><br><span class="line">router.use(<span class="string">&#x27;/user/:id&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;Request URL:&#x27;</span>, req.originalUrl)</span><br><span class="line">  next()</span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;Request Type:&#x27;</span>, req.method)</span><br><span class="line">  next()</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个中间件栈，处理指向 /user/:id 的 GET 请求</span></span><br><span class="line">router.get(<span class="string">&#x27;/user/:id&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 如果 user id 为 0, 跳到下一个路由</span></span><br><span class="line">  <span class="keyword">if</span> (req.params.id == <span class="number">0</span>) next(<span class="string">&#x27;route&#x27;</span>)</span><br><span class="line">  <span class="comment">// 负责将控制权交给栈中下一个中间件</span></span><br><span class="line">  <span class="keyword">else</span> next() <span class="comment">//</span></span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 渲染常规页面</span></span><br><span class="line">  res.render(<span class="string">&#x27;regular&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 处理 /user/:id， 渲染一个特殊页面</span></span><br><span class="line">router.get(<span class="string">&#x27;/user/:id&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(req.params.id)</span><br><span class="line">  res.render(<span class="string">&#x27;special&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将路由挂载至应用</span></span><br><span class="line">app.use(<span class="string">&#x27;/&#x27;</span>, router)</span><br></pre></td></tr></table></figure>
<h6 id="（3）错误处理中间件"><a href="#（3）错误处理中间件" class="headerlink" title="（3）错误处理中间件"></a>（3）错误处理中间件</h6><p>错误处理中间件和其他中间件定义类似，只是要使用 4 个参数，而不是 3 个，其签名如下： (err, req, res, next)。</p>
<p><strong>其肯定是放在最后的，理论上算应用级中间件的后置。</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">err, req, res, next</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.error(err.stack)</span><br><span class="line">  res.status(<span class="number">500</span>).send(<span class="string">&#x27;Something broke!&#x27;</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h6 id="（4）内置的中间件"><a href="#（4）内置的中间件" class="headerlink" title="（4）内置的中间件"></a>（4）内置的中间件</h6><p>express.static 是 Express 唯一内置的中间件。它基于 serve-static，负责在 Express 应用中提托管静态资源。每个应用可有多个静态目录。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.use(express.static(<span class="string">&#x27;public&#x27;</span>))</span><br><span class="line">app.use(express.static(<span class="string">&#x27;uploads&#x27;</span>))</span><br><span class="line">app.use(express.static(<span class="string">&#x27;files&#x27;</span>))</span><br></pre></td></tr></table></figure>
<h6 id="（5）第三方中间件"><a href="#（5）第三方中间件" class="headerlink" title="（5）第三方中间件"></a>（5）第三方中间件</h6><p>安装所需功能的 node 模块，并在应用中加载，可以在应用级加载，也可以在路由级加载。</p>
<p>下面的例子安装并加载了一个解析 cookie 的中间件： cookie-parser</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ npm install cookie-parser</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> app = express()</span><br><span class="line"><span class="keyword">var</span> cookieParser = <span class="built_in">require</span>(<span class="string">&#x27;cookie-parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加载用于解析 cookie 的中间件</span></span><br><span class="line">app.use(cookieParser())</span><br></pre></td></tr></table></figure>
<h5 id="5-获取请求参数"><a href="#5-获取请求参数" class="headerlink" title="5. 获取请求参数"></a>5. 获取请求参数</h5><p>get</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">req.query</span><br></pre></td></tr></table></figure>
<p>post</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.use(express.urlencoded(&#123;<span class="attr">extended</span>:<span class="literal">false</span>&#125;))</span><br><span class="line">app.use(express.json())</span><br><span class="line">req.body</span><br></pre></td></tr></table></figure>
<h5 id="6-利用-Express-托管静态文件"><a href="#6-利用-Express-托管静态文件" class="headerlink" title="6.利用 Express 托管静态文件"></a>6.利用 Express 托管静态文件</h5><p>通过 Express 内置的 express.static 可以方便地托管静态文件，例如图片、CSS、JavaScript 文件等。</p>
<p>将静态资源文件所在的目录作为参数传递给 express.static 中间件就可以提供静态资源文件的访问了。例如，假设在 public 目录放置了图片、CSS 和 JavaScript 文件，你就可以：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.use(express.static(<span class="string">&#x27;public&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>现在，public 目录下面的文件就可以访问了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">http:<span class="comment">//localhost:3000/images/kitten.jpg</span></span><br><span class="line">http:<span class="comment">//localhost:3000/css/style.css</span></span><br><span class="line">http:<span class="comment">//localhost:3000/js/app.js</span></span><br><span class="line">http:<span class="comment">//localhost:3000/images/bg.png</span></span><br><span class="line">http:<span class="comment">//localhost:3000/hello.html</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>所有文件的路径都是相对于存放目录的，因此，存放静态文件的目录名不会出现在 URL 中。</p>
</blockquote>
<p>如果你的静态资源存放在多个目录下面，你可以多次调用 express.static 中间件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.use(express.static(<span class="string">&#x27;public&#x27;</span>))</span><br><span class="line">app.use(express.static(<span class="string">&#x27;files&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>访问静态资源文件时，express.static 中间件会根据目录添加的顺序查找所需的文件。</p>
<p>如果你希望所有通过 express.static 访问的文件都存放在一个“虚拟（virtual）”目录（即目录根本不存在）下面，可以通过为静态资源目录指定一个挂载路径的方式来实现，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">app.use(&#x27;/static&#x27;, express.static(&#x27;public&#x27;))</span><br></pre></td></tr></table></figure>
<p>现在，你就可以通过带有 “/static” 前缀的地址来访问 public 目录下面的文件了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">http:<span class="comment">//localhost:3000/static/images/kitten.jpg</span></span><br><span class="line">http:<span class="comment">//localhost:3000/static/css/style.css</span></span><br><span class="line">http:<span class="comment">//localhost:3000/static/js/app.js</span></span><br><span class="line">http:<span class="comment">//localhost:3000/static/images/bg.png</span></span><br><span class="line">http:<span class="comment">//localhost:3000/static/hello.html</span></span><br></pre></td></tr></table></figure>
<h5 id="7-服务端渲染（模板引擎）"><a href="#7-服务端渲染（模板引擎）" class="headerlink" title="7.服务端渲染（模板引擎）"></a>7.服务端渲染（模板引擎）</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220411104609389.png" alt="image-20220411104609389" style="zoom:50%;float:left" /></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">npm i ejs</span><br></pre></td></tr></table></figure>
<p>需要在应用中进行如下设置才能让 Express 渲染模板文件：</p>
<ul>
<li>views, 放模板文件的目录，比如： app.set(‘views’, ‘./views’)</li>
<li>view engine, 模板引擎，比如： app.set(‘view engine’, ‘ejs’)</li>
</ul>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220411104652068.png" alt="image-20220411104652068" style="zoom:50%;float:left" /></p>
<h4 id="三、MongoDB"><a href="#三、MongoDB" class="headerlink" title="三、MongoDB"></a>三、MongoDB</h4><h5 id="1-关系型与非关系型数据库"><a href="#1-关系型与非关系型数据库" class="headerlink" title="1.关系型与非关系型数据库"></a>1.关系型与非关系型数据库</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413085332378.png" alt="image-20220413085332378" style="zoom:67%;float:left" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090707891.png" alt="image-20220413090707891" style="zoom: 67%;float:left;" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090406721.png" alt="image-20220413090406721"></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090614205.png" alt="image-20220413090614205"></p>
<h5 id="2-安装数据库"><a href="#2-安装数据库" class="headerlink" title="2.安装数据库"></a>2.安装数据库</h5><p><a href="https://docs.mongodb.com/manual/administration/install-community/">https://docs.mongodb.com/manual/administration/install-community/</a></p>
<h5 id="3-启动数据库"><a href="#3-启动数据库" class="headerlink" title="3.启动数据库"></a>3.启动数据库</h5><h6 id="（1）windows"><a href="#（1）windows" class="headerlink" title="（1）windows"></a>（1）windows</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mongod --dbpath d:/data/db</span><br><span class="line">mongo</span><br></pre></td></tr></table></figure>
<h6 id="（2）mac"><a href="#（2）mac" class="headerlink" title="（2）mac"></a>（2）mac</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mongod --config /usr/local/etc/mongod.conf</span><br><span class="line">mongo</span><br></pre></td></tr></table></figure>
<h5 id="4-在命令行中操作数据库"><a href="#4-在命令行中操作数据库" class="headerlink" title="4.在命令行中操作数据库"></a>4.在命令行中操作数据库</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090814836.png" alt="image-20220413090814836" style="zoom:50%;float:left;" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090825381.png" alt="image-20220413090825381" style="zoom:50%;float:left" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090837613.png" alt="image-20220413090837613" style="zoom:50%;float:left" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090858199.png" alt="image-20220413090858199" style="zoom:50%;float:left" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090907539.png" alt="image-20220413090907539" style="zoom:50%;float:left" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413090916971.png" alt="image-20220413090916971" style="zoom:50%;float:left" /></p>
<h5 id="5-可视化工具进行增删改查"><a href="#5-可视化工具进行增删改查" class="headerlink" title="5.可视化工具进行增删改查"></a>5.可视化工具进行增删改查</h5><p>Robomongo Robo3T adminMongo</p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220413091031852.png" alt="image-20220413091031852"></p>
<h5 id="6-nodejs连接操作数据库"><a href="#6-nodejs连接操作数据库" class="headerlink" title="6.nodejs连接操作数据库"></a>6.nodejs连接操作数据库</h5><p>连接数据库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> mongoose = <span class="built_in">require</span>(<span class="string">&quot;mongoose&quot;</span>)</span><br><span class="line"></span><br><span class="line">mongoose.connect(<span class="string">&quot;mongodb://127.0.0.1:27017/company-system&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>创建模型</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> mongoose = <span class="built_in">require</span>(<span class="string">&quot;mongoose&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> Schema = mongoose.Schema</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> UserType = &#123;</span><br><span class="line">    <span class="attr">username</span>:<span class="built_in">String</span>,</span><br><span class="line">    <span class="attr">password</span>:<span class="built_in">String</span>,</span><br><span class="line">    <span class="attr">gender</span>:<span class="built_in">Number</span>,</span><br><span class="line">    <span class="attr">introduction</span>:<span class="built_in">String</span>,</span><br><span class="line">    <span class="attr">avatar</span>:<span class="built_in">String</span>,</span><br><span class="line">    <span class="attr">role</span>:<span class="built_in">Number</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">const</span> UserModel = mongoose.model(<span class="string">&quot;user&quot;</span>,<span class="keyword">new</span> Schema(UserType))</span><br><span class="line"><span class="built_in">module</span>.exports  = UserModel </span><br></pre></td></tr></table></figure>
<p>增加数据</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">UserModel.create(&#123;</span><br><span class="line">    introduction,username,gender,avatar,password,role</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>查询数据</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">UserModel.find(&#123;<span class="attr">username</span>:<span class="string">&quot;kerwin&quot;</span>&#125;,[<span class="string">&quot;username&quot;</span>,<span class="string">&quot;role&quot;</span>,<span class="string">&quot;introduction&quot;</span>,<span class="string">&quot;password&quot;</span>]).sort(&#123;<span class="attr">createTime</span>:-<span class="number">1</span>&#125;).skip(<span class="number">10</span>).limit(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>更新数据</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">UserModel.updateOne(&#123;</span><br><span class="line">    _id</span><br><span class="line">&#125;,&#123;</span><br><span class="line">    introduction,username,gender,avatar</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>删除数据</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">UserModel.deleteOne(&#123;_id&#125;)</span><br></pre></td></tr></table></figure>
<h4 id="四、接口规范与业务分层"><a href="#四、接口规范与业务分层" class="headerlink" title="四、接口规范与业务分层"></a>四、接口规范与业务分层</h4><h5 id="1-接口规范"><a href="#1-接口规范" class="headerlink" title="1.接口规范"></a>1.接口规范</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220414094020921.png" alt="image-20220414094020921" style="zoom: 67%; float: left;" /></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220414094043782.png" alt="image-20220414094043782" style="zoom: 67%;float:left" /></p>
<h5 id="2-业务分层"><a href="#2-业务分层" class="headerlink" title="2.业务分层"></a>2.业务分层</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220414094653807.png" alt="image-20220414094653807"></p>
<h4 id="五、登录鉴权"><a href="#五、登录鉴权" class="headerlink" title="五、登录鉴权"></a>五、登录鉴权</h4><h5 id="1-Cookie-amp-Session"><a href="#1-Cookie-amp-Session" class="headerlink" title="1. Cookie&amp;Session"></a>1. Cookie&amp;Session</h5><p>「HTTP 无状态」<strong>我们知道，HTTP 是无状态的。也就是说，HTTP 请求方和响应方间无法维护状态，都是一次性的，它不知道前后的请求都发生了什么。但有的场景下，我们需要维护状态。最典型的，一个用户登陆微博，发布、关注、评论，都应是在登录后的用户状态下的。</strong>「标记」那解决办法是什么呢？<img src="%E7%AC%94%E8%AE%B0.assets/image-20220414095345868.png" alt="image-20220414095345868"></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> express = <span class="built_in">require</span>(<span class="string">&quot;express&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> session = <span class="built_in">require</span>(<span class="string">&quot;express-session&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> MongoStore = <span class="built_in">require</span>(<span class="string">&quot;connect-mongo&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> app = express();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.use(</span><br><span class="line">  session(&#123;</span><br><span class="line">    <span class="attr">secret</span>: <span class="string">&quot;this is session&quot;</span>, <span class="comment">// 服务器生成 session 的签名</span></span><br><span class="line">    <span class="attr">resave</span>: <span class="literal">true</span>, </span><br><span class="line">    <span class="attr">saveUninitialized</span>: <span class="literal">true</span>, <span class="comment">//强制将为初始化的 session 存储</span></span><br><span class="line">    <span class="attr">cookie</span>: &#123;</span><br><span class="line">      <span class="attr">maxAge</span>: <span class="number">1000</span> * <span class="number">60</span> * <span class="number">10</span>,<span class="comment">// 过期时间</span></span><br><span class="line">      <span class="attr">secure</span>: <span class="literal">false</span>, <span class="comment">// 为 true 时候表示只有 https 协议才能访问cookie</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">rolling</span>: <span class="literal">true</span>, <span class="comment">//为 true 表示 超时前刷新，cookie 会重新计时； 为 false 表示在超时前刷新多少次，都是按照第一次刷新开始计时。</span></span><br><span class="line">    <span class="attr">store</span>: MongoStore.create(&#123;</span><br><span class="line">      <span class="attr">mongoUrl</span>: <span class="string">&#x27;mongodb://127.0.0.1:27017/kerwin_session&#x27;</span>,</span><br><span class="line">      <span class="attr">ttl</span>: <span class="number">1000</span> * <span class="number">60</span> * <span class="number">10</span> <span class="comment">// 过期时间</span></span><br><span class="line">  &#125;),</span><br><span class="line"></span><br><span class="line">  &#125;)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">app.use(<span class="function">(<span class="params">req,res,next</span>)=&gt;</span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(req.url===<span class="string">&quot;/login&quot;</span>)&#123;</span><br><span class="line">    next()</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(req.session.user)&#123;</span><br><span class="line">      req.session.garbage = <span class="built_in">Date</span>();</span><br><span class="line">      next();</span><br><span class="line">  &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">   	  res.redirect(<span class="string">&quot;/login&quot;</span>)   </span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="2-JSON-Web-Token-JWT"><a href="#2-JSON-Web-Token-JWT" class="headerlink" title="2. JSON Web Token (JWT)"></a>2. JSON Web Token (JWT)</h5><h6 id="（1）介绍"><a href="#（1）介绍" class="headerlink" title="（1）介绍"></a>（1）介绍</h6><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220415082822828.png" alt="image-20220415082822828"></p>
<p>我为什么要保存这可恶的session呢， 只让每个客户端去保存该多好？</p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220415083015066.png" alt="image-20220415083015066"></p>
<p>当然， 如果一个人的token 被别人偷走了， 那我也没办法， 我也会认为小偷就是合法用户， 这其实和一个人的session id 被别人偷走是一样的。</p>
<p>这样一来， 我就不保存session id 了， 我只是生成token , 然后验证token ， 我用我的CPU计算时间获取了我的session 存储空间 ！</p>
<p>解除了session id这个负担， 可以说是无事一身轻， 我的机器集群现在可以轻松地做水平扩展， 用户访问量增大， 直接加机器就行。 这种无状态的感觉实在是太好了！</p>
<p>缺点：</p>
<blockquote>
<ol>
<li>占带宽，正常情况下要比 session_id 更大，需要消耗更多流量，挤占更多带宽，假如你的网站每月有 10 万次的浏览器，就意味着要多开销几十兆的流量。听起来并不多，但日积月累也是不小一笔开销。实际上，许多人会在 JWT 中存储的信息会更多；</li>
<li>无法在服务端注销，那么久很难解决劫持问题；</li>
<li>性能问题，JWT 的卖点之一就是加密签名，由于这个特性，接收方得以验证 JWT 是否有效且被信任。对于有着严格性能要求的 Web 应用，这并不理想，尤其对于单线程环境。</li>
</ol>
</blockquote>
<p>注意：</p>
<blockquote>
<p>CSRF攻击的原因是浏览器会自动带上cookie，而不会带上token；</p>
<p>以CSRF攻击为例：</p>
<p>cookie：用户点击了链接，cookie未失效，导致发起请求后后端以为是用户正常操作，于是进行扣款操作；<br>token：用户点击链接，由于浏览器不会自动带上token，所以即使发了请求，后端的token验证不会通过，所以不会进行扣款操作；</p>
</blockquote>
<h6 id="（2）实现"><a href="#（2）实现" class="headerlink" title="（2）实现"></a>（2）实现</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//jsonwebtoken 封装</span></span><br><span class="line"><span class="keyword">const</span> jsonwebtoken = <span class="built_in">require</span>(<span class="string">&quot;jsonwebtoken&quot;</span>)</span><br><span class="line"><span class="keyword">const</span> secret = <span class="string">&quot;kerwin&quot;</span></span><br><span class="line"><span class="keyword">const</span> JWT = &#123;</span><br><span class="line">    <span class="function"><span class="title">generate</span>(<span class="params">value,exprires</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> jsonwebtoken.sign(value,secret,&#123;<span class="attr">expiresIn</span>:exprires&#125;)</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="title">verify</span>(<span class="params">token</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> jsonwebtoken.verify(token,secret)</span><br><span class="line">        &#125;<span class="keyword">catch</span>(e)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = JWT</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//node中间件校验</span></span><br><span class="line">app.use(<span class="function">(<span class="params">req,res,next</span>)=&gt;</span>&#123;</span><br><span class="line">  <span class="comment">// 如果token有效 ,next() </span></span><br><span class="line">  <span class="comment">// 如果token过期了, 返回401错误</span></span><br><span class="line">  <span class="keyword">if</span>(req.url===<span class="string">&quot;/login&quot;</span>)&#123;</span><br><span class="line">    next()</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> token = req.headers[<span class="string">&quot;authorization&quot;</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>]</span><br><span class="line">  <span class="keyword">if</span>(token)&#123;</span><br><span class="line">    <span class="keyword">var</span> payload = JWT.verify(token)</span><br><span class="line">    <span class="comment">// console.log(payload)</span></span><br><span class="line">    <span class="keyword">if</span>(payload)&#123;</span><br><span class="line">      <span class="keyword">const</span> newToken = JWT.generate(&#123;</span><br><span class="line">        <span class="attr">_id</span>:payload._id,</span><br><span class="line">        <span class="attr">username</span>:payload.username</span><br><span class="line">      &#125;,<span class="string">&quot;1d&quot;</span>)</span><br><span class="line">      res.header(<span class="string">&quot;Authorization&quot;</span>,newToken)</span><br><span class="line">      next()</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">      res.status(<span class="number">401</span>).send(&#123;<span class="attr">errCode</span>:<span class="string">&quot;-1&quot;</span>,<span class="attr">errorInfo</span>:<span class="string">&quot;token过期&quot;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"> <span class="comment">//生成token</span></span><br><span class="line"><span class="keyword">const</span> token = JWT.generate(&#123;</span><br><span class="line">    <span class="attr">_id</span>: result[<span class="number">0</span>]._id,</span><br><span class="line">    <span class="attr">username</span>: result[<span class="number">0</span>].username</span><br><span class="line">&#125;, <span class="string">&quot;1d&quot;</span>)</span><br><span class="line"></span><br><span class="line">res.header(<span class="string">&quot;Authorization&quot;</span>, token)</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//前端拦截</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * @作者: kerwin</span></span><br><span class="line"><span class="comment"> * @公众号: 大前端私房菜</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span></span><br><span class="line"><span class="comment">// Add a request interceptor</span></span><br><span class="line">axios.interceptors.request.use(<span class="function"><span class="keyword">function</span> (<span class="params">config</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> token = <span class="built_in">localStorage</span>.getItem(<span class="string">&quot;token&quot;</span>)</span><br><span class="line">    config.headers.Authorization = <span class="string">`Bearer <span class="subst">$&#123;token&#125;</span>`</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> config;</span><br><span class="line">  &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">error</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.reject(error);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add a response interceptor</span></span><br><span class="line">axios.interceptors.response.use(<span class="function"><span class="keyword">function</span> (<span class="params">response</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> &#123;authorization &#125; = response.headers</span><br><span class="line">    authorization &amp;&amp; <span class="built_in">localStorage</span>.setItem(<span class="string">&quot;token&quot;</span>,authorization)</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">  &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">error</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> &#123;status&#125; = error.response</span><br><span class="line">    <span class="keyword">if</span>(status===<span class="number">401</span>)&#123;</span><br><span class="line">        <span class="built_in">localStorage</span>.removeItem(<span class="string">&quot;token&quot;</span>)</span><br><span class="line">        <span class="built_in">window</span>.location.href=<span class="string">&quot;/login&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.reject(error);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="六、文件上传管理"><a href="#六、文件上传管理" class="headerlink" title="六、文件上传管理"></a>六、文件上传管理</h4><p>Multer 是一个 node.js 中间件，用于处理 <code>multipart/form-data</code> 类型的表单数据，它主要用于上传文件。</p>
<p><strong>注意</strong>: Multer 不会处理任何非 <code>multipart/form-data</code> 类型的表单数据。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install --save multer</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//前后端分离-前端</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> params = <span class="keyword">new</span> FormData()</span><br><span class="line">params.append(<span class="string">&#x27;kerwinfile&#x27;</span>, file.file)</span><br><span class="line">params.append(<span class="string">&#x27;username&#x27;</span>, <span class="built_in">this</span>.username)</span><br><span class="line"><span class="keyword">const</span> config = &#123;</span><br><span class="line">	<span class="attr">headers</span>: &#123;</span><br><span class="line">		<span class="string">&quot;Content-Type&quot;</span>:<span class="string">&quot;multipart/form-data&quot;</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">http.post(<span class="string">&#x27;/api/upload&#x27;</span>, params, config).then(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">	<span class="built_in">this</span>.imgpath = <span class="string">&#x27;http://localhost:3000&#x27;</span> + res.data</span><br><span class="line">&#125;)	</span><br></pre></td></tr></table></figure>
<p>Multer 会添加一个 <code>body</code> 对象 以及 <code>file</code> 或 <code>files</code> 对象 到 express 的 <code>request</code> 对象中。 <code>body</code> 对象包含表单的文本域信息，<code>file</code> 或 <code>files</code> 对象包含对象表单上传的文件信息。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">//前后端分离-后端</span></span><br><span class="line">router.post(<span class="string">&#x27;/upload&#x27;</span>, upload.single(<span class="string">&#x27;kerwinfile&#x27;</span>),<span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>) </span>&#123;</span><br><span class="line">	<span class="built_in">console</span>.log(req.file)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h4 id="七、APIDOC-API-文档生成工具"><a href="#七、APIDOC-API-文档生成工具" class="headerlink" title="七、APIDOC - API 文档生成工具"></a>七、APIDOC - API 文档生成工具</h4><p>apidoc 是一个简单的 RESTful API 文档生成工具，它从代码注释中提取特定格式的内容生成文档。支持诸如 Go、Java、C++、Rust 等大部分开发语言，具体可使用 <code>apidoc lang</code> 命令行查看所有的支持列表。</p>
<p>apidoc 拥有以下特点：</p>
<ol>
<li>跨平台，linux、windows、macOS 等都支持；</li>
<li>支持语言广泛，即使是不支持，也很方便扩展；</li>
<li>支持多个不同语言的多个项目生成一份文档；</li>
<li>输出模板可自定义；</li>
<li>根据文档生成 mock 数据；</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install -g apidoc</span><br></pre></td></tr></table></figure>
<h2 id=""><a href="#" class="headerlink" title=""></a><img src="%E7%AC%94%E8%AE%B0.assets/image-20220415085343339.png" alt="image-20220415085343339"></h2><p>注意：</p>
<p>(1) 在当前文件夹下 apidoc.json</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;name&quot;</span>: <span class="string">&quot;****接口文档&quot;</span>,</span><br><span class="line">	<span class="attr">&quot;version&quot;</span>: <span class="string">&quot;1.0.0&quot;</span>,</span><br><span class="line">	<span class="attr">&quot;description&quot;</span>: <span class="string">&quot;关于****的接口文档描述&quot;</span>,</span><br><span class="line">	<span class="attr">&quot;title&quot;</span>: <span class="string">&quot;****&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）可以利用vscode apidoc snippets 插件创建api</p>
<h4 id="八、Koa2"><a href="#八、Koa2" class="headerlink" title="八、Koa2"></a>八、Koa2</h4><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220417075653414.png" alt="image-20220417075653414" style="zoom:50%;" /></p>
<h5 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h5><p>koa 是由 Express 原班人马打造的，致力于成为一个更小、更富有表现力、更健壮的 Web 框架。使用 koa 编写 web 应用，通过组合不同的 generator，可以免除重复繁琐的回调函数嵌套，并极大地提升错误处理的效率。koa 不在内核方法中绑定任何中间件，它仅仅提供了一个轻量优雅的函数库，使得编写 Web 应用变得得心应手。</p>
<h5 id="2-快速开始"><a href="#2-快速开始" class="headerlink" title="2. 快速开始"></a>2. 快速开始</h5><h6 id="2-1-安装koa2"><a href="#2-1-安装koa2" class="headerlink" title="2.1 安装koa2"></a>2.1 安装koa2</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 初始化package.json</span><br><span class="line">npm init</span><br><span class="line"></span><br><span class="line"># 安装koa2 </span><br><span class="line">npm install koa</span><br></pre></td></tr></table></figure>
<h6 id="2-2-hello-world-代码"><a href="#2-2-hello-world-代码" class="headerlink" title="2.2 hello world 代码"></a>2.2 hello world 代码</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa()</span><br><span class="line"></span><br><span class="line">app.use( <span class="keyword">async</span> ( ctx ) =&gt; &#123;</span><br><span class="line">  ctx.body = <span class="string">&#x27;hello koa2&#x27;</span> <span class="comment">//json数据</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220417092053231.png" alt="image-20220417092053231"></p>
<h6 id="2-3-启动demo"><a href="#2-3-启动demo" class="headerlink" title="2.3 启动demo"></a>2.3 启动demo</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node index.js</span><br></pre></td></tr></table></figure>
<h5 id="3-koa-vs-express"><a href="#3-koa-vs-express" class="headerlink" title="3. koa vs express"></a>3. koa vs express</h5><p>通常都会说 Koa 是洋葱模型，这重点在于中间件的设计。但是按照上面的分析，会发现 Express 也是类似的，不同的是Express 中间件机制使用了 Callback 实现，这样如果出现异步则可能会使你在执行顺序上感到困惑，因此如果我们想做接口耗时统计、错误处理 Koa 的这种中间件模式处理起来更方便些。最后一点响应机制也很重要，Koa 不是立即响应，是整个中间件处理完成在最外层进行了响应，而 Express 则是立即响应。</p>
<h6 id="3-1更轻量"><a href="#3-1更轻量" class="headerlink" title="3.1更轻量"></a>3.1更轻量</h6><ul>
<li>koa 不提供内置的中间件；</li>
<li>koa 不提供路由，而是把路由这个库分离出来了（koa/router）</li>
</ul>
<h6 id="3-2-Context对象"><a href="#3-2-Context对象" class="headerlink" title="3.2 Context对象"></a>3.2 Context对象</h6><p>koa增加了一个Context的对象，作为这次请求的上下文对象（在koa2中作为中间件的第一个参数传入）。同时Context上也挂载了Request和Response两个对象。和Express类似，这两个对象都提供了大量的便捷方法辅助开发, 这样的话对于在保存一些公有的参数的话变得更加合情合理</p>
<h6 id="3-3-异步流程控制"><a href="#3-3-异步流程控制" class="headerlink" title="3.3 异步流程控制"></a>3.3 异步流程控制</h6><p>​    express采用callback来处理异步，    koa v1采用generator，koa v2 采用async/await。</p>
<p>​    generator和async/await使用同步的写法来处理异步，明显好于callback和promise，</p>
<h6 id="3-4-中间件模型"><a href="#3-4-中间件模型" class="headerlink" title="3.4 中间件模型"></a>3.4 中间件模型</h6><p>​    express基于connect中间件，线性模型；</p>
<p>​     koa中间件采用洋葱模型（对于每个中间件，在完成了一些事情后，可以非常优雅的将控制权传递给下一个中间件，并能够等待它完成，当后续的中间件完成处理后，控制权又回到了自己）</p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220417083817823.png" alt="image-20220417083817823" style="zoom:50%;float:left;" /></p>
<p>   <img src="%E7%AC%94%E8%AE%B0.assets/image-20220417085913567.png" alt="image-20220417085913567"></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//同步</span></span><br><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&quot;express&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> app = express()</span><br><span class="line"></span><br><span class="line">app.use(<span class="function">(<span class="params">req,res,next</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">1</span>)</span><br><span class="line">    next()</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">4</span>)</span><br><span class="line">    res.send(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">&#125;)</span><br><span class="line">app.use(<span class="function">()=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">3</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br><span class="line"><span class="comment">//异步</span></span><br><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&quot;express&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> app = express()</span><br><span class="line"></span><br><span class="line">app.use(<span class="keyword">async</span> (req,res,next)=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">await</span> next()</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">4</span>)</span><br><span class="line">    res.send(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">&#125;)</span><br><span class="line">app.use(<span class="keyword">async</span> ()=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">await</span> delay(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">3</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">delay</span>(<span class="params">time</span>)</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function">(<span class="params">resolve,reject</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">setTimeout</span>(resolve,<span class="number">1000</span>)</span><br><span class="line"> &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//同步</span></span><br><span class="line"><span class="keyword">var</span> koa = <span class="built_in">require</span>(<span class="string">&quot;koa&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> app = <span class="keyword">new</span> koa()</span><br><span class="line"></span><br><span class="line">app.use(<span class="function">(<span class="params">ctx,next</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">1</span>)</span><br><span class="line">    next()</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">4</span>)</span><br><span class="line">    ctx.body=<span class="string">&quot;hello&quot;</span></span><br><span class="line">&#125;)</span><br><span class="line">app.use(<span class="function">()=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">3</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//异步</span></span><br><span class="line"><span class="keyword">var</span> koa = <span class="built_in">require</span>(<span class="string">&quot;koa&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> app = <span class="keyword">new</span> koa()</span><br><span class="line"></span><br><span class="line">app.use(<span class="keyword">async</span> (ctx,next)=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">await</span> next()</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">4</span>)</span><br><span class="line">    ctx.body=<span class="string">&quot;hello&quot;</span></span><br><span class="line">&#125;) </span><br><span class="line">app.use(<span class="keyword">async</span> ()=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">await</span> delay(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">3</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">delay</span>(<span class="params">time</span>)</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function">(<span class="params">resolve,reject</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">setTimeout</span>(resolve,<span class="number">1000</span>)</span><br><span class="line"> &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure>
<h5 id="4-路由"><a href="#4-路由" class="headerlink" title="4. 路由"></a>4. 路由</h5><h6 id="4-1基本用发"><a href="#4-1基本用发" class="headerlink" title="4.1基本用发"></a>4.1基本用发</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Koa = <span class="built_in">require</span>(<span class="string">&quot;koa&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> Router = <span class="built_in">require</span>(<span class="string">&quot;koa-router&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> app = <span class="keyword">new</span> Koa()</span><br><span class="line"><span class="keyword">var</span> router = <span class="keyword">new</span> Router()</span><br><span class="line"></span><br><span class="line">router.post(<span class="string">&quot;/list&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=[<span class="string">&quot;111&quot;</span>,<span class="string">&quot;222&quot;</span>,<span class="string">&quot;333&quot;</span>]</span><br><span class="line">&#125;)</span><br><span class="line">app.use(router.routes()).use(router.allowedMethods())</span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure>
<h6 id="4-2-router-allowedMethods作用"><a href="#4-2-router-allowedMethods作用" class="headerlink" title="4.2 router.allowedMethods作用"></a>4.2 router.allowedMethods作用</h6><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220417102845079.png" alt="image-20220417102845079"></p>
<h6 id="4-3-请求方式"><a href="#4-3-请求方式" class="headerlink" title="4.3 请求方式"></a>4.3 请求方式</h6><p>Koa-router 请求方式： <code>get</code> 、 <code>put</code> 、 <code>post</code> 、 <code>patch</code> 、 <code>delete</code> 、 <code>del</code>  ，而使用方法就是 <code>router.方式()</code>  ，比如 <code>router.get()</code> 和 <code>router.post()</code> 。而 <code>router.all()</code> 会匹配所有的请求方法。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Koa = <span class="built_in">require</span>(<span class="string">&quot;koa&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> Router = <span class="built_in">require</span>(<span class="string">&quot;koa-router&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> app = <span class="keyword">new</span> Koa()</span><br><span class="line"><span class="keyword">var</span> router = <span class="keyword">new</span> Router()</span><br><span class="line"></span><br><span class="line">router.get(<span class="string">&quot;/user&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=[<span class="string">&quot;aaa&quot;</span>,<span class="string">&quot;bbb&quot;</span>,<span class="string">&quot;ccc&quot;</span>]</span><br><span class="line">&#125;)</span><br><span class="line">.put(<span class="string">&quot;/user/:id&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=&#123;<span class="attr">ok</span>:<span class="number">1</span>,<span class="attr">info</span>:<span class="string">&quot;user update&quot;</span>&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.post(<span class="string">&quot;/user&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=&#123;<span class="attr">ok</span>:<span class="number">1</span>,<span class="attr">info</span>:<span class="string">&quot;user post&quot;</span>&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.del(<span class="string">&quot;/user/:id&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=&#123;<span class="attr">ok</span>:<span class="number">1</span>,<span class="attr">info</span>:<span class="string">&quot;user del&quot;</span>&#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.use(router.routes()).use(router.allowedMethods())</span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure>
<h6 id="4-4-拆分路由"><a href="#4-4-拆分路由" class="headerlink" title="4.4 拆分路由"></a>4.4 拆分路由</h6><p>list.js</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Router = <span class="built_in">require</span>(<span class="string">&quot;koa-router&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> router = <span class="keyword">new</span> Router()</span><br><span class="line">router.get(<span class="string">&quot;/&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=[<span class="string">&quot;111&quot;</span>,<span class="string">&quot;222&quot;</span>,<span class="string">&quot;333&quot;</span>]</span><br><span class="line">&#125;)</span><br><span class="line">.put(<span class="string">&quot;/:id&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=&#123;<span class="attr">ok</span>:<span class="number">1</span>,<span class="attr">info</span>:<span class="string">&quot;list update&quot;</span>&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.post(<span class="string">&quot;/&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=&#123;<span class="attr">ok</span>:<span class="number">1</span>,<span class="attr">info</span>:<span class="string">&quot;list post&quot;</span>&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.del(<span class="string">&quot;/:id&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=&#123;<span class="attr">ok</span>:<span class="number">1</span>,<span class="attr">info</span>:<span class="string">&quot;list del&quot;</span>&#125;</span><br><span class="line">&#125;)</span><br><span class="line"><span class="built_in">module</span>.exports = router</span><br></pre></td></tr></table></figure>
<p>index.js</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Router = <span class="built_in">require</span>(<span class="string">&quot;koa-router&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> router = <span class="keyword">new</span> Router()</span><br><span class="line"><span class="keyword">var</span> user = <span class="built_in">require</span>(<span class="string">&quot;./user&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> list = <span class="built_in">require</span>(<span class="string">&quot;./list&quot;</span>)</span><br><span class="line">router.use(<span class="string">&#x27;/user&#x27;</span>, user.routes(), user.allowedMethods())</span><br><span class="line">router.use(<span class="string">&#x27;/list&#x27;</span>, list.routes(), list.allowedMethods())</span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = router</span><br></pre></td></tr></table></figure>
<p>entry入口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Koa = <span class="built_in">require</span>(<span class="string">&quot;koa&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> router = <span class="built_in">require</span>(<span class="string">&quot;./router/index&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> app = <span class="keyword">new</span> Koa()</span><br><span class="line">app.use(router.routes()).use(router.allowedMethods())</span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure>
<h6 id="4-5-路由前缀"><a href="#4-5-路由前缀" class="headerlink" title="4.5 路由前缀"></a>4.5 路由前缀</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">router.prefix(<span class="string">&#x27;/api&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h6 id="4-6-路由重定向"><a href="#4-6-路由重定向" class="headerlink" title="4.6 路由重定向"></a>4.6 路由重定向</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">router.get(<span class="string">&quot;/home&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.body=<span class="string">&quot;home页面&quot;</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment">//写法1 </span></span><br><span class="line">router.redirect(<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;/home&#x27;</span>);</span><br><span class="line"><span class="comment">//写法2</span></span><br><span class="line">router.get(<span class="string">&quot;/&quot;</span>,<span class="function">(<span class="params">ctx</span>)=&gt;</span>&#123;</span><br><span class="line">    ctx.redirect(<span class="string">&quot;/home&quot;</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="5-静态资源"><a href="#5-静态资源" class="headerlink" title="5.  静态资源"></a>5.  静态资源</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&#x27;path&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">static</span> = <span class="built_in">require</span>(<span class="string">&#x27;koa-static&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa()</span><br><span class="line"></span><br><span class="line">app.use(<span class="keyword">static</span>(</span><br><span class="line">  path.join( __dirname,  <span class="string">&quot;public&quot;</span>)</span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app.use( <span class="keyword">async</span> ( ctx ) =&gt; &#123;</span><br><span class="line">  ctx.body = <span class="string">&#x27;hello world&#x27;</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;[demo] static-use-middleware is starting at port 3000&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="6-获取请求参数"><a href="#6-获取请求参数" class="headerlink" title="6.  获取请求参数"></a>6.  获取请求参数</h5><h6 id="6-1get参数"><a href="#6-1get参数" class="headerlink" title="6.1get参数"></a>6.1get参数</h6><p>在koa中，获取GET请求数据源头是koa中request对象中的query方法或querystring方法，query返回是格式化好的参数对象，querystring返回的是请求字符串，由于ctx对request的API有直接引用的方式，所以获取GET请求数据有两个途径。</p>
<ul>
<li>是从上下文中直接获取 请求对象ctx.query，返回如 { a:1, b:2 } 请求字符串 ctx.querystring，返回如 a=1&amp;b=2</li>
<li>是从上下文的request对象中获取 请求对象ctx.request.query，返回如 { a:1, b:2 } 请求字符串 ctx.request.querystring，返回如 a=1&amp;b=2</li>
</ul>
<h6 id="6-2post参数"><a href="#6-2post参数" class="headerlink" title="6.2post参数"></a>6.2post参数</h6><p>对于POST请求的处理，koa-bodyparser中间件可以把koa2上下文的formData数据解析到ctx.request.body中</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> bodyParser = <span class="built_in">require</span>(<span class="string">&#x27;koa-bodyparser&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用ctx.body解析中间件</span></span><br><span class="line">app.use(bodyParser())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="7-ejs模板"><a href="#7-ejs模板" class="headerlink" title="7. ejs模板"></a>7. ejs模板</h5><h6 id="7-1-安装模块"><a href="#7-1-安装模块" class="headerlink" title="7.1 安装模块"></a>7.1 安装模块</h6><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># 安装koa模板使用中间件</span><br><span class="line">npm install --save koa-views</span><br><span class="line"></span><br><span class="line"># 安装ejs模板引擎</span><br><span class="line">npm install --save ejs</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="7-2-使用模板引擎"><a href="#7-2-使用模板引擎" class="headerlink" title="7.2 使用模板引擎"></a>7.2 使用模板引擎</h6><p><strong>文件目录</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── package.json</span><br><span class="line">├── index.js</span><br><span class="line">└── view</span><br><span class="line">    └── index.ejs</span><br></pre></td></tr></table></figure>
<p><strong>./index.js文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> views = <span class="built_in">require</span>(<span class="string">&#x27;koa-views&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&#x27;path&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加载模板引擎</span></span><br><span class="line">app.use(views(path.join(__dirname, <span class="string">&#x27;./view&#x27;</span>), &#123;</span><br><span class="line">  <span class="attr">extension</span>: <span class="string">&#x27;ejs&#x27;</span></span><br><span class="line">&#125;))</span><br><span class="line"></span><br><span class="line">app.use( <span class="keyword">async</span> ( ctx ) =&gt; &#123;</span><br><span class="line">  <span class="keyword">let</span> title = <span class="string">&#x27;hello koa2&#x27;</span></span><br><span class="line">  <span class="keyword">await</span> ctx.render(<span class="string">&#x27;index&#x27;</span>, &#123;</span><br><span class="line">    title,</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure>
<p><strong>./view/index.ejs 模板</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>&lt;%= title %&gt;<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>&lt;%= title %&gt;<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>EJS Welcome to &lt;%= title %&gt;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="8-cookie-amp-session"><a href="#8-cookie-amp-session" class="headerlink" title="8. cookie&amp;session"></a>8. cookie&amp;session</h5><h6 id="8-1-cookie"><a href="#8-1-cookie" class="headerlink" title="8.1 cookie"></a>8.1 cookie</h6><p>koa提供了从上下文直接读取、写入cookie的方法</p>
<ul>
<li>ctx.cookies.get(name, [options]) 读取上下文请求中的cookie</li>
<li>ctx.cookies.set(name, value, [options]) 在上下文中写入cookie</li>
</ul>
<h6 id="8-2-session"><a href="#8-2-session" class="headerlink" title="8.2 session"></a>8.2 session</h6><ul>
<li><p>koa-session-minimal 适用于koa2 的session中间件，提供存储介质的读写接口 。</p>
 <figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> session = <span class="built_in">require</span>(<span class="string">&#x27;koa-session-minimal&#x27;</span>)</span><br><span class="line">app.use(session(&#123;</span><br><span class="line">    <span class="attr">key</span>: <span class="string">&#x27;SESSION_ID&#x27;</span>,</span><br><span class="line">    <span class="attr">cookie</span>: &#123;</span><br><span class="line">        <span class="attr">maxAge</span>:<span class="number">1000</span>*<span class="number">60</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;))</span><br></pre></td></tr></table></figure>
</li>
</ul>
   <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.use(<span class="keyword">async</span> (ctx, next) =&gt; &#123;</span><br><span class="line">    <span class="comment">//排除login相关的路由和接口</span></span><br><span class="line">    <span class="keyword">if</span> (ctx.url.includes(<span class="string">&quot;login&quot;</span>)) &#123;</span><br><span class="line">        <span class="keyword">await</span> next()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ctx.session.user) &#123;</span><br><span class="line">        <span class="comment">//重新设置以下sesssion</span></span><br><span class="line">        ctx.session.mydate = <span class="built_in">Date</span>.now()</span><br><span class="line">        <span class="keyword">await</span> next()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">        ctx.redirect(<span class="string">&quot;/login&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="9-JWT"><a href="#9-JWT" class="headerlink" title="9. JWT"></a>9. JWT</h5>   <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">app.use(<span class="keyword">async</span>(ctx, next) =&gt; &#123;</span><br><span class="line">    <span class="comment">//排除login相关的路由和接口</span></span><br><span class="line">    <span class="keyword">if</span> (ctx.url.includes(<span class="string">&quot;login&quot;</span>)) &#123;</span><br><span class="line">        <span class="keyword">await</span> next()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> token = ctx.headers[<span class="string">&quot;authorization&quot;</span>]?.split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment">// console.log(req.headers[&quot;authorization&quot;])</span></span><br><span class="line">    <span class="keyword">if</span>(token)&#123;</span><br><span class="line">        <span class="keyword">const</span> payload=  JWT.verify(token)</span><br><span class="line">        <span class="keyword">if</span>(payload)&#123;</span><br><span class="line">            <span class="comment">//重新计算token过期时间</span></span><br><span class="line">            <span class="keyword">const</span> newToken = JWT.generate(&#123;</span><br><span class="line">                <span class="attr">_id</span>:payload._id,</span><br><span class="line">                <span class="attr">username</span>:payload.username</span><br><span class="line">            &#125;,<span class="string">&quot;10s&quot;</span>)</span><br><span class="line"></span><br><span class="line">            ctx.set(<span class="string">&quot;Authorization&quot;</span>,newToken)</span><br><span class="line">            <span class="keyword">await</span> next()</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            ctx.status = <span class="number">401</span></span><br><span class="line">            ctx.body = &#123;<span class="attr">errCode</span>:-<span class="number">1</span>,<span class="attr">errInfo</span>:<span class="string">&quot;token过期&quot;</span>&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">await</span> next()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h5><h5 id="10-上传文件"><a href="#10-上传文件" class="headerlink" title="10.上传文件"></a>10.上传文件</h5><blockquote>
<p><a href="https://www.npmjs.com/package/@koa/multer">https://www.npmjs.com/package/@koa/multer</a></p>
</blockquote>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">npm install --save @koa/multer multer</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> multer = <span class="built_in">require</span>(<span class="string">&#x27;@koa/multer&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> upload = multer(&#123; <span class="attr">dest</span>: <span class="string">&#x27;public/uploads/&#x27;</span> &#125;)</span><br><span class="line"></span><br><span class="line">router.post(<span class="string">&quot;/&quot;</span>,upload.single(<span class="string">&#x27;avatar&#x27;</span>),</span><br><span class="line"><span class="function">(<span class="params">ctx,next</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(ctx.request.body,ctx.file)</span><br><span class="line">    ctx.body=&#123;</span><br><span class="line">        <span class="attr">ok</span>:<span class="number">1</span>,</span><br><span class="line">        <span class="attr">info</span>:<span class="string">&quot;add user success&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="11-操作MongoDB"><a href="#11-操作MongoDB" class="headerlink" title="11.操作MongoDB"></a>11.操作MongoDB</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> mongoose = <span class="built_in">require</span>(<span class="string">&quot;mongoose&quot;</span>)</span><br><span class="line"></span><br><span class="line">mongoose.connect(<span class="string">&quot;mongodb://127.0.0.1:27017/kerwin_project&quot;</span>)</span><br><span class="line"><span class="comment">//插入集合和数据,数据库kerwin_project会自动创建</span></span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> mongoose = <span class="built_in">require</span>(<span class="string">&quot;mongoose&quot;</span>)</span><br><span class="line"><span class="keyword">const</span> Schema = mongoose.Schema</span><br><span class="line"><span class="keyword">const</span> UserType = &#123;</span><br><span class="line">    <span class="attr">username</span>:<span class="built_in">String</span>,</span><br><span class="line">    <span class="attr">password</span>:<span class="built_in">String</span>,</span><br><span class="line">    <span class="attr">age</span>:<span class="built_in">Number</span>,</span><br><span class="line">    <span class="attr">avatar</span>:<span class="built_in">String</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> UserModel = mongoose.model(<span class="string">&quot;user&quot;</span>,<span class="keyword">new</span> Schema(UserType))</span><br><span class="line"><span class="comment">// 模型user 将会对应 users 集合, </span></span><br><span class="line"><span class="built_in">module</span>.exports = UserModel</span><br></pre></td></tr></table></figure>
<h4 id="九、MySQL"><a href="#九、MySQL" class="headerlink" title="九、MySQL"></a>九、MySQL</h4><h5 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h5><p>付费的商用数据库：</p>
<ul>
<li>Oracle，典型的高富帅；</li>
<li>SQL Server，微软自家产品，Windows定制专款；</li>
<li>DB2，IBM的产品，听起来挺高端；</li>
<li>Sybase，曾经跟微软是好基友，后来关系破裂，现在家境惨淡。</li>
</ul>
<p>这些数据库都是不开源而且付费的，最大的好处是花了钱出了问题可以找厂家解决，不过在Web的世界里，常常需要部署成千上万的数据库服务器，当然不能把大把大把的银子扔给厂家，所以，无论是Google、Facebook，还是国内的BAT，无一例外都选择了免费的开源数据库：</p>
<ul>
<li>MySQL，大家都在用，一般错不了；</li>
<li>PostgreSQL，学术气息有点重，其实挺不错，但知名度没有MySQL高；</li>
<li>sqlite，嵌入式数据库，适合桌面和移动应用。</li>
</ul>
<p>作为一个JavaScript全栈工程师，选择哪个免费数据库呢？当然是MySQL。因为MySQL普及率最高，出了错，可以很容易找到解决方法。而且，围绕MySQL有一大堆监控和运维的工具，安装和使用很方便。</p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220420083146539.png" alt="image-20220420083146539"></p>
<h5 id="2-与非关系数据库区别"><a href="#2-与非关系数据库区别" class="headerlink" title="2.与非关系数据库区别"></a>2.与非关系数据库区别</h5><p>关系型和非关系型数据库的主要差异是数据存储的方式。关系型数据天然就是表格式的，因此存储在数据表的行和列中。数据表可以彼此关联协作存储，也很容易提取数据。</p>
<p>与其相反，非关系型数据不适合存储在数据表的行和列中，而是大块组合在一起。非关系型数据通常存储在数据集中，就像文档、键值对或者图结构。你的数据及其特性是选择数据存储和提取方式的首要影响因素。</p>
<p><strong>关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织</strong><br>优点：<br>1、易于维护：都是使用表结构，格式一致；<br>2、使用方便：SQL语言通用，可用于复杂查询；<br>3、复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。<br>缺点：<br>1、读写性能比较差，尤其是海量数据的高效率读写；<br>2、固定的表结构，灵活度稍欠；<br>3、高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。</p>
<p><strong>非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，可以是文档或者键值对等。</strong></p>
<p>优点：</p>
<p>1、格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。<br>2、速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘；<br>3、高扩展性；<br>4、成本低：nosql数据库部署简单，基本都是开源软件。</p>
<p>缺点：</p>
<p>1、不提供sql支持；<br>2、无事务处理；<br>3、数据结构相对复杂，复杂查询方面稍欠。</p>
<h5 id="3-sql语句"><a href="#3-sql语句" class="headerlink" title="3.sql语句"></a>3.sql语句</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220420092527846.png" alt="image-20220420092527846"></p>
<p>插入：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `students`(`id`, `name`, `score`, `gender`) <span class="keyword">VALUES</span> (<span class="keyword">null</span>,<span class="string">&#x27;kerwin&#x27;</span>,<span class="number">100</span>,<span class="number">1</span>)</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>可以不设置id,create_time</span><br></pre></td></tr></table></figure>
<p>更新：<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">UPDATE `students` <span class="keyword">SET</span> `name`<span class="operator">=</span><span class="string">&#x27;tiechui&#x27;</span>,`score`<span class="operator">=</span><span class="number">20</span>,`gender`<span class="operator">=</span><span class="number">0</span> <span class="keyword">WHERE</span> id<span class="operator">=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure><br>删除：<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> `students` <span class="keyword">WHERE</span> id<span class="operator">=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure><br>查询：<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">查所有的数据所有的字段</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `students` <span class="keyword">WHERE</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">查所有的数据某个字段</span><br><span class="line"><span class="keyword">SELECT</span> `id`, `name`, `score`, `gender` <span class="keyword">FROM</span> `students` <span class="keyword">WHERE</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">条件查询</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `students` <span class="keyword">WHERE</span> score<span class="operator">&gt;=</span><span class="number">80</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `students` <span class="keyword">where</span> score<span class="operator">&gt;=</span><span class="number">80</span> <span class="keyword">AND</span> gender<span class="operator">=</span><span class="number">1</span></span><br><span class="line"></span><br><span class="line">模糊查询</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `students` <span class="keyword">where</span> name <span class="keyword">like</span> <span class="string">&#x27;%k%&#x27;</span></span><br><span class="line"></span><br><span class="line">排序</span><br><span class="line"><span class="keyword">SELECT</span> id, name, gender, score <span class="keyword">FROM</span> students <span class="keyword">ORDER</span> <span class="keyword">BY</span> score;</span><br><span class="line"><span class="keyword">SELECT</span> id, name, gender, score <span class="keyword">FROM</span> students <span class="keyword">ORDER</span> <span class="keyword">BY</span> score <span class="keyword">DESC</span>;</span><br><span class="line"></span><br><span class="line">分页查询</span><br><span class="line"><span class="keyword">SELECT</span> id, name, gender, score <span class="keyword">FROM</span> students LIMIT <span class="number">50</span> <span class="keyword">OFFSET</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">记录条数</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> students;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) kerwinnum <span class="keyword">FROM</span> students;</span><br><span class="line"></span><br><span class="line">多表查询</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> students, classes;（这种多表查询又称笛卡尔查询，使用笛卡尔查询时要非常小心，由于结果集是目标表的行数乘积，对两个各自有<span class="number">100</span>行记录的表进行笛卡尔查询将返回<span class="number">1</span>万条记录，对两个各自有<span class="number">1</span>万行记录的表进行笛卡尔查询将返回<span class="number">1</span>亿条记录）</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    students.id sid,</span><br><span class="line">    students.name,</span><br><span class="line">    students.gender,</span><br><span class="line">    students.score,</span><br><span class="line">    classes.id cid,</span><br><span class="line">    classes.name cname</span><br><span class="line"><span class="keyword">FROM</span> students, classes; （要使用表名.列名这样的方式来引用列和设置别名，这样就避免了结果集的列名重复问题。）</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    s.id sid,</span><br><span class="line">    s.name,</span><br><span class="line">    s.gender,</span><br><span class="line">    s.score,</span><br><span class="line">    c.id cid,</span><br><span class="line">    c.name cname</span><br><span class="line"><span class="keyword">FROM</span> students s, classes c; （<span class="keyword">SQL</span>还允许给表设置一个别名）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">联表查询</span><br><span class="line"><span class="keyword">SELECT</span> s.id, s.name, s.class_id, c.name class_name, s.gender, s.score</span><br><span class="line"><span class="keyword">FROM</span> students s</span><br><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> classes c</span><br><span class="line"><span class="keyword">ON</span> s.class_id <span class="operator">=</span> c.id; （连接查询对多个表进行<span class="keyword">JOIN</span>运算，简单地说，就是先确定一个主表作为结果集，然后，把其他表的行有选择性地“连接”在主表结果集上。）</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220420090841742.png" alt="image-20220420090841742"></p>
<p>注意：</p>
<blockquote>
<ol>
<li>InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；</li>
<li>InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；</li>
</ol>
</blockquote>
<p><strong>外键约束</strong></p>
<p>CASCADE<br>在父表上update/delete记录时，同步update/delete掉子表的匹配记录 </p>
<p>SET NULL<br>在父表上update/delete记录时，将子表上匹配记录的列设为null (要注意子表的外键列不能为not null)  </p>
<p>NO ACTION<br>如果子表中有匹配的记录,则不允许对父表对应候选键进行update/delete操作 </p>
<p>RESTRICT<br>同no action, 都是立即检查外键约束</p>
<h5 id="4-nodejs-操作数据库"><a href="#4-nodejs-操作数据库" class="headerlink" title="4.nodejs 操作数据库"></a>4.nodejs 操作数据库</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> app = express()</span><br><span class="line"><span class="keyword">const</span> mysql2 = <span class="built_in">require</span>(<span class="string">&#x27;mysql2&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> port = <span class="number">9000</span></span><br><span class="line"></span><br><span class="line">app.get(<span class="string">&#x27;/&#x27;</span>,<span class="keyword">async</span> (req, res) =&gt; &#123;</span><br><span class="line">  <span class="keyword">const</span> config = getDBConfig()</span><br><span class="line">  <span class="keyword">const</span> promisePool = mysql2.createPool(config).promise();</span><br><span class="line">  <span class="comment">// console.log(promisePool)</span></span><br><span class="line">      <span class="keyword">let</span> user = <span class="keyword">await</span> promisePool.query(<span class="string">&#x27;select * from students&#x27;</span>);</span><br><span class="line"></span><br><span class="line">      <span class="built_in">console</span>.log(user)</span><br><span class="line">      <span class="keyword">if</span> (user[<span class="number">0</span>].length) &#123;</span><br><span class="line">          <span class="comment">//存在用户</span></span><br><span class="line">          res.send(user[<span class="number">0</span>])</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">//不存在</span></span><br><span class="line">          res.send( &#123;</span><br><span class="line">              <span class="attr">code</span>: -<span class="number">2</span>,</span><br><span class="line">              <span class="attr">msg</span>: <span class="string">&#x27;user not exsit&#x27;</span>,</span><br><span class="line">          &#125;)</span><br><span class="line">      &#125;      </span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.listen(port, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">`Example app listening at http://localhost:<span class="subst">$&#123;port&#125;</span>`</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getDBConfig</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">    <span class="attr">host</span>: <span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">    <span class="attr">user</span>: <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">    <span class="attr">port</span>: <span class="number">3306</span>,</span><br><span class="line">    <span class="attr">password</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="attr">database</span>: <span class="string">&#x27;kerwin_test&#x27;</span>,</span><br><span class="line">    <span class="attr">connectionLimit</span>: <span class="number">1</span> <span class="comment">//创建一个连接池</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">查询：</span><br><span class="line">promisePool.query(<span class="string">&#x27;select * from users&#x27;</span>);</span><br><span class="line"></span><br><span class="line">插入：</span><br><span class="line">promisePool.query(<span class="string">&#x27;INSERT INTO `users`(`id`,`name`,`age`, `password`) VALUES (?,?,?,?)&#x27;</span>,[<span class="literal">null</span>,<span class="string">&quot;kerwin&quot;</span>,<span class="number">100</span>,<span class="string">&quot;123456&quot;</span>]);</span><br><span class="line"></span><br><span class="line">更新：</span><br><span class="line">promisePool.query(<span class="string">`UPDATE users SET name = ? ,age=? WHERE id = ?`</span>,[<span class="string">&quot;xiaoming2&quot;</span>,<span class="number">20</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">删除：</span><br><span class="line">promisePool.query(<span class="string">`delete from users where id=?`</span>,[<span class="number">1</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="十、Socket编程"><a href="#十、Socket编程" class="headerlink" title="十、Socket编程"></a>十、Socket编程</h4><h5 id="1-websocket介绍"><a href="#1-websocket介绍" class="headerlink" title="1.websocket介绍"></a>1.websocket介绍</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220421084242097.png" alt="image-20220421084242097" style="zoom:50%;" /></p>
<p><strong>应用场景：</strong></p>
<ul>
<li><p>弹幕</p>
</li>
<li><p>媒体聊天</p>
</li>
<li><p>协同编辑</p>
</li>
<li><p>基于位置的应用</p>
</li>
<li><p>体育实况更新</p>
</li>
<li><p>股票基金报价实时更新</p>
</li>
</ul>
<p>WebSocket并不是全新的协议，而是利用了HTTP协议来建立连接。我们来看看WebSocket连接是如何创建的。</p>
<p>首先，WebSocket连接必须由浏览器发起，因为请求协议是一个标准的HTTP请求，格式如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">GET ws:<span class="comment">//localhost:3000/ws/chat HTTP/1.1</span></span><br><span class="line">Host: localhost</span><br><span class="line"><span class="attr">Upgrade</span>: websocket</span><br><span class="line"><span class="attr">Connection</span>: Upgrade</span><br><span class="line"><span class="attr">Origin</span>: http:<span class="comment">//localhost:3000</span></span><br><span class="line">Sec-WebSocket-Key: client-random-string</span><br><span class="line">Sec-WebSocket-Version: <span class="number">13</span></span><br></pre></td></tr></table></figure>
<p>该请求和普通的HTTP请求有几点不同：</p>
<ol>
<li>GET请求的地址不是类似<code>/path/</code>，而是以<code>ws://</code>开头的地址；</li>
<li>请求头<code>Upgrade: websocket</code>和<code>Connection: Upgrade</code>表示这个连接将要被转换为WebSocket连接；</li>
<li><code>Sec-WebSocket-Key</code>是用于标识这个连接，并非用于加密数据；</li>
<li><code>Sec-WebSocket-Version</code>指定了WebSocket的协议版本。</li>
</ol>
<p>随后，服务器如果接受该请求，就会返回如下响应：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HTTP/1.1 101 Switching Protocols</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Sec-WebSocket-Accept: server-random-string</span><br></pre></td></tr></table></figure>
<p>该响应代码<code>101</code>表示本次连接的HTTP协议即将被更改，更改后的协议就是<code>Upgrade: websocket</code>指定的WebSocket协议。</p>
<p>版本号和子协议规定了双方能理解的数据格式，以及是否支持压缩等等。如果仅使用WebSocket的API，就不需要关心这些。</p>
<p>现在，一个WebSocket连接就建立成功，浏览器和服务器就可以随时主动发送消息给对方。消息有两种，一种是文本，一种是二进制数据。通常，我们可以发送JSON格式的文本，这样，在浏览器处理起来就十分容易。</p>
<p>为什么WebSocket连接可以实现全双工通信而HTTP连接不行呢？实际上HTTP协议是建立在TCP协议之上的，TCP协议本身就实现了全双工通信，但是HTTP协议的请求－应答机制限制了全双工通信。WebSocket连接建立以后，其实只是简单规定了一下：接下来，咱们通信就不使用HTTP协议了，直接互相发数据吧。</p>
<p>安全的WebSocket连接机制和HTTPS类似。首先，浏览器用<code>wss://xxx</code>创建WebSocket连接时，会先通过HTTPS创建安全的连接，然后，该HTTPS连接升级为WebSocket连接，底层通信走的仍然是安全的SSL/TLS协议。</p>
<p><strong>浏览器支持</strong></p>
<p>很显然，要支持WebSocket通信，浏览器得支持这个协议，这样才能发出<code>ws://xxx</code>的请求。目前，支持WebSocket的主流浏览器如下：</p>
<ul>
<li>Chrome</li>
<li>Firefox</li>
<li>IE &gt;= 10</li>
<li>Sarafi &gt;= 6</li>
<li>Android &gt;= 4.4</li>
<li>iOS &gt;= 8</li>
</ul>
<p><strong>服务器支持</strong></p>
<p>由于WebSocket是一个协议，服务器具体怎么实现，取决于所用编程语言和框架本身。Node.js本身支持的协议包括TCP协议和HTTP协议，要支持WebSocket协议，需要对Node.js提供的HTTPServer做额外的开发。已经有若干基于Node.js的稳定可靠的WebSocket实现，我们直接用npm安装使用即可。</p>
<h5 id="2-ws模块"><a href="#2-ws模块" class="headerlink" title="2.ws模块"></a>2.ws模块</h5><p>服务器：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span>  WebSocket = <span class="built_in">require</span>(<span class="string">&quot;ws&quot;</span>)</span><br><span class="line">WebSocketServer = WebSocket.WebSocketServer</span><br><span class="line"><span class="keyword">const</span> wss = <span class="keyword">new</span> WebSocketServer(&#123; <span class="attr">port</span>: <span class="number">8080</span> &#125;);</span><br><span class="line">wss.on(<span class="string">&#x27;connection&#x27;</span>, <span class="function"><span class="keyword">function</span> <span class="title">connection</span>(<span class="params">ws</span>) </span>&#123;</span><br><span class="line">    ws.on(<span class="string">&#x27;message&#x27;</span>, <span class="function"><span class="keyword">function</span> <span class="title">message</span>(<span class="params">data, isBinary</span>) </span>&#123;</span><br><span class="line">        wss.clients.forEach(<span class="function"><span class="keyword">function</span> <span class="title">each</span>(<span class="params">client</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (client !== ws &amp;&amp; client.readyState === WebSocket.OPEN) &#123;</span><br><span class="line">                client.send(data, &#123; <span class="attr">binary</span>: isBinary &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    ws.send(<span class="string">&#x27;欢迎加入聊天室&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>客户端：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> ws = <span class="keyword">new</span> WebSocket(<span class="string">&quot;ws://localhost:8080&quot;</span>)</span><br><span class="line">ws.onopen = <span class="function">()=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;open&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">ws.onmessage = <span class="function">(<span class="params">evt</span>)=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(evt.data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>授权验证：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//前端</span></span><br><span class="line"><span class="keyword">var</span> ws = <span class="keyword">new</span> WebSocket(<span class="string">`ws://localhost:8080?token=<span class="subst">$&#123;<span class="built_in">localStorage</span>.getItem(<span class="string">&quot;token&quot;</span>)&#125;</span>`</span>)</span><br><span class="line">ws.onopen = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">&quot;open&quot;</span>)</span><br><span class="line">      ws.send(<span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">        <span class="attr">type</span>: WebSocketType.GroupList</span><br><span class="line">      &#125;))</span><br><span class="line">    &#125;</span><br><span class="line">ws.onmessage = <span class="function">(<span class="params">evt</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(evt.data)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//后端</span></span><br><span class="line"><span class="keyword">const</span> WebSocket = <span class="built_in">require</span>(<span class="string">&quot;ws&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> JWT = <span class="built_in">require</span>(<span class="string">&#x27;../util/JWT&#x27;</span>);</span><br><span class="line">WebSocketServer = WebSocket.WebSocketServer</span><br><span class="line"><span class="keyword">const</span> wss = <span class="keyword">new</span> WebSocketServer(&#123; <span class="attr">port</span>: <span class="number">8080</span> &#125;);</span><br><span class="line">wss.on(<span class="string">&#x27;connection&#x27;</span>, <span class="function"><span class="keyword">function</span> <span class="title">connection</span>(<span class="params">ws, req</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> myURL = <span class="keyword">new</span> URL(req.url, <span class="string">&#x27;http://127.0.0.1:3000&#x27;</span>);</span><br><span class="line">  <span class="keyword">const</span> payload = JWT.verify(myURL.searchParams.get(<span class="string">&quot;token&quot;</span>))</span><br><span class="line">  <span class="keyword">if</span> (payload) &#123;</span><br><span class="line">    ws.user = payload</span><br><span class="line">    ws.send(createMessage(WebSocketType.GroupChat, ws.user, <span class="string">&quot;欢迎来到聊天室&quot;</span>))</span><br><span class="line"></span><br><span class="line">    sendBroadList() <span class="comment">//发送好友列表</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ws.send(createMessage(WebSocketType.Error, <span class="literal">null</span>, <span class="string">&quot;token过期&quot;</span>))</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// console.log(3333,url)</span></span><br><span class="line">  ws.on(<span class="string">&#x27;message&#x27;</span>, <span class="function"><span class="keyword">function</span> <span class="title">message</span>(<span class="params">data, isBinary</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> messageObj = <span class="built_in">JSON</span>.parse(data)</span><br><span class="line">    <span class="keyword">switch</span> (messageObj.type) &#123;</span><br><span class="line">      <span class="keyword">case</span> WebSocketType.GroupList:</span><br><span class="line">        ws.send(createMessage(WebSocketType.GroupList, ws.user, <span class="built_in">JSON</span>.stringify(<span class="built_in">Array</span>.from(wss.clients).map(<span class="function"><span class="params">item</span> =&gt;</span> item.user))))</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> WebSocketType.GroupChat:</span><br><span class="line">        wss.clients.forEach(<span class="function"><span class="keyword">function</span> <span class="title">each</span>(<span class="params">client</span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (client !== ws &amp;&amp; client.readyState === WebSocket.OPEN) &#123;</span><br><span class="line">            client.send(createMessage(WebSocketType.GroupChat, ws.user, messageObj.data));</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> WebSocketType.SingleChat:</span><br><span class="line">        wss.clients.forEach(<span class="function"><span class="keyword">function</span> <span class="title">each</span>(<span class="params">client</span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (client.user.username === messageObj.to &amp;&amp; client.readyState === WebSocket.OPEN) &#123;</span><br><span class="line">            client.send(createMessage(WebSocketType.SingleChat, ws.user, messageObj.data));</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ws.on(<span class="string">&quot;close&quot;</span>,<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">      <span class="comment">//删除当前用户</span></span><br><span class="line">      wss.clients.delete(ws.user)</span><br><span class="line">      sendBroadList() <span class="comment">//发送好用列表</span></span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">const</span> WebSocketType = &#123;</span><br><span class="line">  <span class="attr">Error</span>: <span class="number">0</span>, <span class="comment">//错误</span></span><br><span class="line">  <span class="attr">GroupList</span>: <span class="number">1</span>,<span class="comment">//群列表</span></span><br><span class="line">  <span class="attr">GroupChat</span>: <span class="number">2</span>,<span class="comment">//群聊</span></span><br><span class="line">  <span class="attr">SingleChat</span>: <span class="number">3</span><span class="comment">//私聊</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">createMessage</span>(<span class="params">type, user, data</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">    <span class="attr">type</span>: type,</span><br><span class="line">    <span class="attr">user</span>: user,</span><br><span class="line">    <span class="attr">data</span>: data</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sendBroadList</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">  wss.clients.forEach(<span class="function"><span class="keyword">function</span> <span class="title">each</span>(<span class="params">client</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (client.readyState === WebSocket.OPEN) &#123;</span><br><span class="line">      client.send(createMessage(WebSocketType.GroupList, client.user, <span class="built_in">JSON</span>.stringify(<span class="built_in">Array</span>.from(wss.clients).map(<span class="function"><span class="params">item</span> =&gt;</span> item.user))))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="3-socket-io模块"><a href="#3-socket-io模块" class="headerlink" title="3.socket.io模块"></a>3.socket.io模块</h5><p>服务端：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> io = <span class="built_in">require</span>(<span class="string">&#x27;socket.io&#x27;</span>)(server);</span><br><span class="line">io.on(<span class="string">&#x27;connection&#x27;</span>, <span class="function">(<span class="params">socket</span>) =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> payload = JWT.verify(socket.handshake.query.token)</span><br><span class="line">  <span class="keyword">if</span> (payload) &#123;</span><br><span class="line">    socket.user = payload</span><br><span class="line">    socket.emit(WebSocketType.GroupChat, createMessage(socket.user, <span class="string">&quot;欢迎来到聊天室&quot;</span>))</span><br><span class="line">    sendBroadList() <span class="comment">//发送好友列表</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    socket.emit(WebSocketType.Error, createMessage(<span class="literal">null</span>, <span class="string">&quot;token过期&quot;</span>))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  socket.on(WebSocketType.GroupList, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    socket.emit(WebSocketType.GroupList, createMessage(<span class="literal">null</span>, <span class="built_in">Array</span>.from(io.sockets.sockets).map(<span class="function"><span class="params">item</span> =&gt;</span> item[<span class="number">1</span>].user).filter(<span class="function"><span class="params">item</span>=&gt;</span>item)));</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  socket.on(WebSocketType.GroupChat, <span class="function">(<span class="params">messageObj</span>) =&gt;</span> &#123;</span><br><span class="line">    socket.broadcast.emit(WebSocketType.GroupChat, createMessage(socket.user, messageObj.data));</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  socket.on(WebSocketType.SingleChat, <span class="function">(<span class="params">messageObj</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">Array</span>.from(io.sockets.sockets).forEach(<span class="function"><span class="keyword">function</span> (<span class="params">socket</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (socket[<span class="number">1</span>].user.username === messageObj.to) &#123;</span><br><span class="line">        socket[<span class="number">1</span>].emit(WebSocketType.SingleChat, createMessage(socket[<span class="number">1</span>].user, messageObj.data));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  socket.on(<span class="string">&#x27;disconnect&#x27;</span>, <span class="function"><span class="params">reason</span> =&gt;</span> &#123;</span><br><span class="line">     </span><br><span class="line">     sendBroadList() <span class="comment">//发送好用列表</span></span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sendBroadList</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  io.sockets.emit(WebSocketType.GroupList, createMessage(<span class="literal">null</span>, <span class="built_in">Array</span>.from(io.sockets.sockets).map(<span class="function"><span class="params">item</span> =&gt;</span> item[<span class="number">1</span>].user).filter(<span class="function"><span class="params">item</span>=&gt;</span>item)))</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//最后filter，是因为 有可能存在null的值</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>客户端：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> WebSocketType = &#123;</span><br><span class="line">    <span class="attr">Error</span>: <span class="number">0</span>, <span class="comment">//错误</span></span><br><span class="line">    <span class="attr">GroupList</span>: <span class="number">1</span>, <span class="comment">//群列表</span></span><br><span class="line">    <span class="attr">GroupChat</span>: <span class="number">2</span>, <span class="comment">//群聊</span></span><br><span class="line">    <span class="attr">SingleChat</span>: <span class="number">3</span> <span class="comment">//私聊</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> socket = io(<span class="string">`ws://localhost:3000?token=<span class="subst">$&#123;<span class="built_in">localStorage</span>.getItem(<span class="string">&quot;token&quot;</span>)&#125;</span>`</span>);</span><br><span class="line">socket.on(<span class="string">&quot;connect&quot;</span>,<span class="function">()=&gt;</span>&#123;</span><br><span class="line">	socket.emit(WebSocketType.GroupList)</span><br><span class="line">&#125;)</span><br><span class="line">socket.on(WebSocketType.GroupList, <span class="function">(<span class="params">messageObj</span>) =&gt;</span> &#123;</span><br><span class="line">    select.innerHTML = <span class="string">&quot;&quot;</span></span><br><span class="line">    select.innerHTML = <span class="string">`&lt;option value=&quot;all&quot;&gt;all&lt;/option&gt;`</span> + messageObj.data.map(<span class="function"><span class="params">item</span> =&gt;</span> <span class="string">`</span></span><br><span class="line"><span class="string">    &lt;option value=&quot;<span class="subst">$&#123;item.username&#125;</span>&quot;&gt;<span class="subst">$&#123;item.username&#125;</span>&lt;/option&gt;`</span>).join(<span class="string">&quot;&quot;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">socket.on(WebSocketType.GroupChat, <span class="function">(<span class="params">msg</span>) =&gt;</span> &#123;</span><br><span class="line">	<span class="built_in">console</span>.log(msg)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">socket.on(WebSocketType.SingleChat, <span class="function">(<span class="params">msg</span>) =&gt;</span> &#123;</span><br><span class="line">	<span class="built_in">console</span>.log(msg)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">socket.on(WebSocketType.Error, <span class="function">(<span class="params">msg</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">localStorage</span>.removeItem(<span class="string">&quot;token&quot;</span>)</span><br><span class="line">    location.href = <span class="string">&quot;/login&quot;</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">send.onclick = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (select.value === <span class="string">&quot;all&quot;</span>) &#123;</span><br><span class="line">        socket.emit(WebSocketType.GroupChat,&#123;</span><br><span class="line">            <span class="attr">data</span>: text.value</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        socket.emit(WebSocketType.SingleChat,&#123;</span><br><span class="line">            <span class="attr">data</span>: text.value,</span><br><span class="line">            <span class="attr">to</span>:select.value</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="十一、mocha"><a href="#十一、mocha" class="headerlink" title="十一、mocha"></a>十一、mocha</h4><p>单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。</p>
<p>比如对函数abs()，我们可以编写出以下几个测试用例：</p>
<p>输入正数，比如1、1.2、0.99，期待返回值与输入相同；</p>
<p>输入负数，比如-1、-1.2、-0.99，期待返回值与输入相反；</p>
<p>输入0，期待返回0；</p>
<p>输入非数值类型，比如null、[]、{}，期待抛出Error。</p>
<p>把上面的测试用例放到一个测试模块里，就是一个完整的单元测试。</p>
<p>如果单元测试通过，说明我们测试的这个函数能够正常工作。如果单元测试不通过，要么函数有bug，要么测试条件输入不正确，总之，需要修复使单元测试能够通过。</p>
<p>单元测试通过后有什么意义呢？如果我们对abs()函数代码做了修改，只需要再跑一遍单元测试，如果通过，说明我们的修改不会对abs()函数原有的行为造成影响，如果测试不通过，说明我们的修改与原有行为不一致，要么修改代码，要么修改测试。</p>
<p>这种以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例。在将来修改的时候，可以极大程度地保证该模块行为仍然是正确的。</p>
<p>mocha是JavaScript的一种单元测试框架，既可以在浏览器环境下运行，也可以在Node.js环境下运行。</p>
<p>使用mocha，我们就只需要专注于编写单元测试本身，然后，让mocha去自动运行所有的测试，并给出测试结果。</p>
<p>mocha的特点主要有：</p>
<ol>
<li>既可以测试简单的JavaScript函数，又可以测试异步代码，因为异步是JavaScript的特性之一；</li>
<li>可以自动运行所有测试，也可以只运行特定的测试；</li>
<li>可以支持before、after、beforeEach和afterEach来编写初始化代码。</li>
</ol>
<h5 id="1-编写测试"><a href="#1-编写测试" class="headerlink" title="1.编写测试"></a>1.编写测试</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> assert = <span class="built_in">require</span>(<span class="string">&#x27;assert&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> sum = <span class="built_in">require</span>(<span class="string">&#x27;../test&#x27;</span>);</span><br><span class="line">describe(<span class="string">&#x27;#hello.js&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line"></span><br><span class="line">    describe(<span class="string">&#x27;#sum()&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">        it(<span class="string">&#x27;sum() should return 0&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">            assert.strictEqual(sum(), <span class="number">0</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        it(<span class="string">&#x27;sum(1) should return 1&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">            assert.strictEqual(sum(<span class="number">1</span>), <span class="number">1</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        it(<span class="string">&#x27;sum(1, 2) should return 3&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">            assert.strictEqual(sum(<span class="number">1</span>, <span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        it(<span class="string">&#x27;sum(1, 2, 3) should return 6&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">            assert.strictEqual(sum(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), <span class="number">6</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="2-chai断言库"><a href="#2-chai断言库" class="headerlink" title="2.chai断言库"></a>2.chai断言库</h5><p><img src="%E7%AC%94%E8%AE%B0.assets/image-20220505113605440.png" alt="image-20220505113605440"></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> chai = <span class="built_in">require</span>(<span class="string">&#x27;chai&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> assert = chai.assert;</span><br><span class="line"></span><br><span class="line">describe(<span class="string">&#x27;assert Demo&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    it(<span class="string">&#x27;use assert lib&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> value = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        assert.typeOf(value, <span class="string">&#x27;string&#x27;</span>)</span><br><span class="line">        assert.equal(value, <span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">        assert.lengthOf(value, <span class="number">5</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> chai = <span class="built_in">require</span>(<span class="string">&#x27;chai&#x27;</span>);</span><br><span class="line">chai.should();</span><br><span class="line"></span><br><span class="line">describe(<span class="string">&#x27;should Demo&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    it(<span class="string">&#x27;use should lib&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> value = <span class="string">&#x27;hello&#x27;</span></span><br><span class="line">        value.should.exist.and.equal(<span class="string">&#x27;hello&#x27;</span>).and.have.length(<span class="number">5</span>).and.be.a(<span class="string">&#x27;string&#x27;</span>)</span><br><span class="line">        <span class="comment">// value.should.be.a(&#x27;string&#x27;)</span></span><br><span class="line">        <span class="comment">// value.should.equal(&#x27;hello&#x27;)</span></span><br><span class="line">        <span class="comment">// value.should.not.equal(&#x27;hello2&#x27;)</span></span><br><span class="line">        <span class="comment">// value.should.have.length(5);</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> chai = <span class="built_in">require</span>(<span class="string">&#x27;chai&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> expect = chai.expect;</span><br><span class="line"></span><br><span class="line">describe(<span class="string">&#x27;expect Demo&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    it(<span class="string">&#x27;use expect lib&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> value = <span class="string">&#x27;hello&#x27;</span></span><br><span class="line">        <span class="keyword">var</span> number = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">        expect(number).to.be.at.most(<span class="number">5</span>)</span><br><span class="line">        expect(number).to.be.at.least(<span class="number">3</span>)</span><br><span class="line">        expect(number).to.be.within(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        expect(value).to.exist</span><br><span class="line">        expect(value).to.be.a(<span class="string">&#x27;string&#x27;</span>)</span><br><span class="line">        expect(value).to.equal(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">        expect(value).to.not.equal(<span class="string">&#x27;您好&#x27;</span>)</span><br><span class="line">        expect(value).to.have.length(<span class="number">5</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="3-异步测试"><a href="#3-异步测试" class="headerlink" title="3.异步测试"></a>3.异步测试</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> fs =<span class="built_in">require</span>(<span class="string">&quot;fs&quot;</span>).promises</span><br><span class="line"><span class="keyword">var</span> chai = <span class="built_in">require</span>(<span class="string">&#x27;chai&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> expect = chai.expect;</span><br><span class="line">it(<span class="string">&#x27;test async function&#x27;</span>,<span class="keyword">async</span> <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> data =<span class="keyword">await</span> fs.readFile(<span class="string">&#x27;./1.txt&#x27;</span>,<span class="string">&quot;utf8&quot;</span>);</span><br><span class="line">    expect(data).to.equal(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="4-http测试"><a href="#4-http测试" class="headerlink" title="4.http测试"></a>4.http测试</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> request = <span class="built_in">require</span>(<span class="string">&#x27;supertest&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> app = <span class="built_in">require</span>(<span class="string">&#x27;../app&#x27;</span>);</span><br><span class="line"></span><br><span class="line">describe(<span class="string">&#x27;#test koa app&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> server = app.listen(<span class="number">3000</span>);</span><br><span class="line">    describe(<span class="string">&#x27;#test server&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">        it(<span class="string">&#x27;#test GET /&#x27;</span>, <span class="keyword">async</span> () =&gt; &#123;</span><br><span class="line">            <span class="keyword">await</span> request(server)</span><br><span class="line">                .get(<span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">                .expect(<span class="string">&#x27;Content-Type&#x27;</span>, <span class="regexp">/text\/html/</span>)</span><br><span class="line">                .expect(<span class="number">200</span>, <span class="string">&#x27;&lt;h1&gt;hello world&lt;/h1&gt;&#x27;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        after(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            server.close()</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="5-钩子函数"><a href="#5-钩子函数" class="headerlink" title="5.钩子函数"></a>5.钩子函数</h5><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">describe(<span class="string">&#x27;#hello.js&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    describe(<span class="string">&#x27;#sum()&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">        before(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;before:&#x27;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        after(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;after.&#x27;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        beforeEach(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;  beforeEach:&#x27;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        afterEach(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;  afterEach.&#x27;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/20/JavaScript%20%E7%AF%87%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="JavaScript-篇（包含ES6）面试题"><a href="#JavaScript-篇（包含ES6）面试题" class="headerlink" title="JavaScript 篇（包含ES6）面试题"></a>JavaScript 篇（包含ES6）面试题</h1><h2 id="考点-1：数据类型"><a href="#考点-1：数据类型" class="headerlink" title="考点 1：数据类型"></a>考点 1：数据类型</h2><h3 id="面试题：讲讲JS的数据类型？"><a href="#面试题：讲讲JS的数据类型？" class="headerlink" title="面试题：讲讲JS的数据类型？"></a>面试题：讲讲JS的数据类型？</h3><p>最新的 ECMAScript 标准定义了 8种数据类型:</p>
<p><strong>7种 基础数据类型</strong></p>
<ul>
<li><p>Boolean</p>
<p>​    永远只有<code>true</code>和<code>false</code>两个值。</p>
</li>
<li><p>Undefined：</p>
<p>​    一个没有被赋值的变量会有个默认值 undefined，<strong>是全局对象的一个属性</strong></p>
</li>
<li><p>Number</p>
<p>​    基于 IEEE 754 标准的双精度 64 位二进制格式的值（-(2^53 -1) 到 2^53 -1）</p>
<p>​    除了能够表示浮点数外，<font color="red"><strong>还有一些带符号的值：+Infinity，-Infinity 和 NaN (非数值，Not-a-    Number)。</strong></font></p>
</li>
<li><p>String</p>
<p>​    字符串一旦被创建，就不能被修改。</p>
</li>
<li><p>null   <font color="red">这是一个很奇怪的类型，下面的所有面试题都要注意他</font></p>
<p>​    可以理解为  null 作为尚未创建的对象，<strong>不是全局对象的一个属性</strong></p>
</li>
<li><p>BigInt（ES6 新增）</p>
<p>​    可以安全地存储和操作大整数. 常常通过在整数末尾附加 n 或调用构造函数来创建的。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> a = <span class="built_in">BigInt</span>(<span class="string">&#x27;43243242424242424242342432&#x27;</span>)</span><br><span class="line"><span class="comment">// 43243242424242424242342432n</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> b = <span class="number">43243242424242424242342432n</span></span><br><span class="line"><span class="comment">// 43243242424242424242342432n</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Symbol（ES6 新增）</p>
<p>​    可以通过调用内置函数 Symbol() 创建，这个函数会动态的生成一个匿名、全局唯一的值。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> a = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="keyword">const</span> b = <span class="built_in">Symbol</span>();</span><br><span class="line">a == b <span class="comment">// false</span></span><br><span class="line">a === b <span class="comment">// false</span></span><br></pre></td></tr></table></figure>
<p>Symbol 函数栈不能用 new 命令，因为 Symbol 是原始数据类型，不是对象。</p>
<p><strong>Symbol最大的用处就是：<code>避免对象的键被覆盖。</code></strong></p>
</li>
</ul>
<p>注意：基本类型全是<font color="blue">原始值</font>，也就是不可变。例如 js 对字符串的操作返回了一个新字符串，但是原始字符串并没有被改变），我们称这些类型的值为“原始值”。</p>
<p><strong>复杂数据类型</strong></p>
<ul>
<li>Object</li>
<li>Function  (本质也算Object)</li>
<li>Array （本质也算Object）</li>
</ul>
<h3 id="面试题：基本数据类型-和-引用数据类型的区别"><a href="#面试题：基本数据类型-和-引用数据类型的区别" class="headerlink" title="面试题：基本数据类型 和 引用数据类型的区别"></a>面试题：基本数据类型 和 引用数据类型的区别</h3><h5 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h5><ul>
<li>按值访问，可操作保存在变量中实际的值</li>
<li>值被保存在 <code>栈内存</code> 中，占据固定大小的空间</li>
</ul>
<h5 id="引用数据类型-复杂数据类型"><a href="#引用数据类型-复杂数据类型" class="headerlink" title="引用数据类型(复杂数据类型)"></a>引用数据类型(复杂数据类型)</h5><ul>
<li>引用类型的值是按引用访问的，<font color="red"><strong>访问的为存储地址</strong>，<strong>存储地址为存在 栈 中</strong></font></li>
<li>保存在<font color="red"><strong>堆内存中的对象</strong></font>，不能直接访问操作对象的内存空间</li>
</ul>
<p><img src="http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/微信图片_20221024195715.jpg" alt=""></p>
<h3 id="面试题：四种判断数据类型的方法"><a href="#面试题：四种判断数据类型的方法" class="headerlink" title="面试题：四种判断数据类型的方法"></a>面试题：四种判断数据类型的方法</h3><p>可参考链接 ： <a href="https://juejin.cn/post/6919805736734162952#heading-3">https://juejin.cn/post/6919805736734162952#heading-3</a></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>typeof 适合基本类型和function类型的检测，无法判断null与object</li>
<li>instanceof 适合自定义对象，也可以用来检测原生对象，在不同的iframe 和 window间检测时失效，还需要注意Object.create(null)对象的问题</li>
<li>constructor 基本能判断所有类型，除了null和undefined，但是constructor容易被修改，也不能跨iframe使用</li>
<li>tostring  （<code>Object.prototype.toString.call</code>）能判断所有类型，可将其封装为全能的DataType()判断所有数据类型</li>
</ul>
<h4 id="typeof"><a href="#typeof" class="headerlink" title="typeof"></a>typeof</h4><p><strong>总结</strong></p>
<ul>
<li><code>适用于判断（除null）基础类型,</code></li>
<li><code>判断引用类型，除了function 全返回object类型</code></li>
</ul>
<p><strong>对于基本数据类型来说，除了null返回的是object，其他都可返回正确的类型。</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typeof</span> <span class="string">&#x27;5&#x27;</span> <span class="comment">// string</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="number">5</span> <span class="comment">// number</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="literal">null</span> <span class="comment">// object</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="literal">undefined</span> <span class="comment">// undefined</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="literal">true</span> <span class="comment">// boolean</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="built_in">Symbol</span>(<span class="string">&#x27;5&#x27;</span>) <span class="comment">// symbol</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="number">5n</span> <span class="comment">// bigint</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="keyword">new</span> <span class="built_in">Object</span>(); <span class="comment">// object</span></span><br><span class="line"><span class="keyword">typeof</span> <span class="keyword">new</span> <span class="built_in">Function</span>(); <span class="comment">// function</span></span><br></pre></td></tr></table></figure>
<p>原因是因为：<font color="blue">null其实可以理解为一个还未创建的空对象</font>，所以转成了 object 类型。</p>
<blockquote>
<p>至于具体原因是因为，任何对象都会被转化为二进制，null转为二进制则表示全为0，如果前三个均为0，js就会把它当作是对象，这是js早期遗留下来的bug</p>
</blockquote>
<p><strong>对于复杂数据类型，除了function 全返回object类型</strong>   <font color="red">不过为什么呢？</font></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> a = <span class="keyword">new</span> <span class="built_in">Array</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>])</span><br><span class="line"><span class="keyword">let</span> b = <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;凯凯&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> c = <span class="keyword">new</span> <span class="built_in">Object</span>(<span class="string">&quot;kaikai&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="keyword">typeof</span> a)  <span class="comment">// object</span></span><br><span class="line"><span class="built_in">console</span>.log(<span class="keyword">typeof</span> b)  <span class="comment">// function</span></span><br><span class="line"><span class="built_in">console</span>.log(<span class="keyword">typeof</span> c)  <span class="comment">// object</span></span><br></pre></td></tr></table></figure>
<p>​    </p>
<h4 id="instanceof"><a href="#instanceof" class="headerlink" title="instanceof"></a>instanceof</h4><p><strong>总结</strong></p>
<ul>
<li>只能用来判断<code>变量的原型链上是否有构造函数的prototype属性（两个对象是否属于原型链的关系）</code>，不一定能获取对象的具体类型</li>
<li><font color="red">**Instanceof 不适用判断原始类型的值，只能用于判断对象是否从属关系**</font>

</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">[] <span class="keyword">instanceof</span> <span class="built_in">Array</span>; <span class="comment">// true</span></span><br><span class="line">[] <span class="keyword">instanceof</span> <span class="built_in">Object</span>; <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params"></span>) </span>&#123;&#125;;</span><br><span class="line"><span class="keyword">const</span> person = <span class="keyword">new</span> Person();</span><br><span class="line"></span><br><span class="line">person <span class="keyword">instanceof</span> Person; <span class="comment">// true</span></span><br><span class="line">person <span class="keyword">instanceof</span> <span class="built_in">Object</span>; <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
<p><strong><code>[] instanceof Array</code>为true 的解析</strong></p>
<ul>
<li>[].<strong>proto</strong> 的原型 是指向Array.prototype 的，说明两个对象是属于同一条原型链的，返回true。</li>
<li>也就是  <code>[].__proto__ === Array.prototype</code>   其实 []本身就是 Array 的对象，所以很好理解</li>
</ul>
<p><strong>从代码中可以得知<code>person instanceof Person</code>也是返回true的，那么为什么<code>person instanceof Object</code>也为true呢？</strong></p>
<p>是因为存在一条原型链，person这个实例对象的 .proto 也就是 Person 的原型prototype，然而 Person 本身也是一个 Object类的实例对象，所以 Person 的 .proto 也就是 Object的原型prototype。也就是存在：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">person.__proto__ === Person.prototype</span><br><span class="line">Person.__proto__ === <span class="built_in">Object</span>.prototype</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/原型链.png" alt=""></p>
<p><strong>注意：空对象 {} 的 instanceof  判断对于 null 有歧义</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> obj1 = &#123;&#125;</span><br><span class="line"><span class="built_in">console</span>.log(obj1 <span class="keyword">instanceof</span> <span class="built_in">Object</span>) <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> obj2 = <span class="built_in">Object</span>.create(<span class="literal">null</span>)</span><br><span class="line"><span class="built_in">console</span>.log(obj2 <span class="keyword">instanceof</span> <span class="built_in">Object</span>) <span class="comment">// false</span></span><br><span class="line"><span class="comment">// Object.create(null) 创建的对象不会继承任何属性或方法，也不会有 Object.prototype 对象上的方法，因此该对象的原型为 null。</span></span><br><span class="line"><span class="comment">// obj2.__proto__ === null</span></span><br><span class="line">obj2.__proto__ === <span class="built_in">Object</span>.prototype <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> obj3 = <span class="built_in">Object</span>.create(&#123;&#125;)</span><br><span class="line"><span class="built_in">console</span>.log(obj3 <span class="keyword">instanceof</span> <span class="built_in">Object</span>) <span class="comment">// true</span></span><br><span class="line"><span class="comment">// 这里有疑问因为</span></span><br><span class="line"><span class="built_in">console</span>.log(obj3.__proto__) <span class="comment">// &#123;&#125;</span></span><br><span class="line"><span class="built_in">console</span>.log(obj3.__proto__ === &#123;&#125;.prototype)  <span class="comment">// false</span></span><br><span class="line"><span class="built_in">console</span>.log(obj3.__proto__ === <span class="built_in">Object</span>.prototype)  <span class="comment">// false</span></span><br><span class="line"><span class="comment">//因为obj3.__proto__指向的是空对象&#123;&#125;，而不是Object.prototype。空对象的原型指向Object.prototype，所以obj3.__proto__.__proto__ === Object.prototype是成立的。</span></span><br></pre></td></tr></table></figure>
<h5 id="instanceof-的实现原理"><a href="#instanceof-的实现原理" class="headerlink" title="instanceof  的实现原理"></a>instanceof  的实现原理</h5><p>1.获取对象的原型</p>
<p>2.获取构造函数的 prototype 对象</p>
<p>3.判断构造函数的 prototype 对象是否在对象的原型链上</p>
<p>4.如果没有找到，就继续从其原型上找，Object.getPrototypeOf方法用来获取指定对象的原型</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">myInstanceof</span>(<span class="params">instanceObj,constructorFun</span>)</span>&#123;</span><br><span class="line">    <span class="comment">// Object.getPrototypeOf() 方法返回指定对象的原型（内部[[Prototype]]属性的值）。</span></span><br><span class="line">    <span class="comment">// 1.获取对象的原型</span></span><br><span class="line">    <span class="keyword">let</span> proto = <span class="built_in">Object</span>.getPrototypeOf(instanceObj)</span><br><span class="line">    <span class="comment">// 2.获取构造函数的 prototype 对象</span></span><br><span class="line">    <span class="keyword">let</span> prototype=<span class="title">constructorFun</span>.<span class="title">prototype</span></span><br><span class="line">    // 3.判断构造函数的 <span class="title">prototype</span> 对象是否在对象的原型链上</span><br><span class="line">    <span class="title">while</span>(<span class="params"><span class="literal">true</span></span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(!proto)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">        <span class="keyword">if</span>(proto === prototype)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">        <span class="comment">// 4.如果没有找到，就继续从其原型上找，Object.getPrototypeOf方法用来获取指定对象的原型</span></span><br><span class="line">        proto = <span class="built_in">Object</span>.getPrototypeOf(proto)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">        <span class="keyword">let</span> date = <span class="keyword">new</span> <span class="built_in">Date</span>()</span><br><span class="line">        <span class="comment">// myInstanceof(实例对象,构造函数)</span></span><br><span class="line">        <span class="keyword">let</span> res = myInstanceof(date,<span class="built_in">Date</span>)</span><br><span class="line">        <span class="keyword">let</span> res1 = myInstanceof(date,<span class="built_in">Object</span>)</span><br><span class="line">        <span class="keyword">let</span> res2 = myInstanceof(date,<span class="built_in">Array</span>)</span><br><span class="line">        <span class="built_in">console</span>.log(res)<span class="comment">//true</span></span><br><span class="line">        <span class="built_in">console</span>.log(res1)<span class="comment">//true</span></span><br><span class="line"><span class="comment">//具体来说，Array.prototype.__proto__指向Object.prototype，Date.prototype.__proto__指向Object.prototype。</span></span><br><span class="line">        <span class="built_in">console</span>.log(res2)<span class="comment">//false</span></span><br></pre></td></tr></table></figure>
<h4 id="constructor-NaN"><a href="#constructor-NaN" class="headerlink" title="constructor"></a>constructor</h4><p>原理：<code>每一个实例对象都可通过constructor来访问它的构造函数</code>,其实也是根据原型链的原理来的。</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/原型链.png" alt=""></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;5&#x27;</span>.__proto__.constructor === <span class="built_in">String</span> <span class="comment">// true</span></span><br><span class="line">[<span class="number">5</span>].__proto__.constructor === <span class="built_in">Array</span> <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 由于undefined和null是无效的对象，因此是没有constructor属性的,这两个值不能用这种方法判断.</span></span><br><span class="line"><span class="literal">undefined</span>.__proto__.constructor <span class="comment">// Cannot read property &#x27;__proto__&#x27; of undefined</span></span><br><span class="line"><span class="literal">null</span>.__proto__.constructor <span class="comment">// Cannot read property &#x27;__proto__&#x27; of undefined</span></span><br></pre></td></tr></table></figure>
<h4 id="toString-NaN"><a href="#toString-NaN" class="headerlink" title="toString"></a>toString</h4><ul>
<li>Object.prototype.toString方法返回对象的类型字符串，因此可用来判断一个值的类型。</li>
<li>因为实例对象有可能会自定义toString方法，会覆盖Object.prototype.toString，所以在使用时，最好加上call</li>
<li><strong>所有的数据类型都可以使用此方法进行检测，且非常精准</strong></li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 基础类型数据</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="string">&#x27;5&#x27;</span>) <span class="comment">// [object String]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="number">5</span>) <span class="comment">// [object Number]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call([<span class="number">5</span>]) <span class="comment">// [object Array]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="literal">true</span>) <span class="comment">// [object Boolean]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="literal">undefined</span>) <span class="comment">// [object Undefined]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="literal">null</span>) <span class="comment">// [object Null]</span></span><br><span class="line"><span class="comment">// 复杂类型数据</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="keyword">new</span> <span class="built_in">Function</span>()); <span class="comment">// [object Function]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="keyword">new</span> <span class="built_in">Date</span>()); <span class="comment">// [object Date]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="keyword">new</span> <span class="built_in">RegExp</span>()); <span class="comment">// [object RegExp]</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.toString.call(<span class="keyword">new</span> <span class="built_in">Error</span>()); <span class="comment">// [object Error]</span></span><br></pre></td></tr></table></figure>
<h3 id="面试题：强制类型转换和隐式类型转换是什么？举几个例子？"><a href="#面试题：强制类型转换和隐式类型转换是什么？举几个例子？" class="headerlink" title="面试题：强制类型转换和隐式类型转换是什么？举几个例子？"></a>面试题：强制类型转换和隐式类型转换是什么？举几个例子？</h3><p><strong>强制类型转换</strong>，也就是基本数据类型之间的强制转换，使用特定对应的 API进行操作。具体要看 JS 手册</p>
<p>这里举几个例子：</p>
<p>转成 Number类型：</p>
<ul>
<li><code>Number(变量)</code>   可以把一个变量强制转换成数值类型</li>
<li><code>parseInt(变量)</code>   例如   <code>parseInt(&quot;20.5&quot;)  =&gt; 20</code></li>
<li><code>parseFloat(变量)</code>  例如   <code>parseInt(&quot;20.5&quot;)  =&gt; 20.5</code></li>
</ul>
<p>转成 String 类型：</p>
<ul>
<li><code>String(变量)</code>   例如：<code>String(10) =&gt; &quot;10&quot;</code></li>
</ul>
<p>转成 Boolean 类型</p>
<ul>
<li><code>Boolean(变量)</code>  例如：<code>Boolean(1) =&gt; true</code></li>
</ul>
<p><strong>隐式类型转换</strong>，一般是 + 法引起的</p>
<p>例如：  <code>10 + &quot;11&quot;  =&gt; &quot;1011&quot;</code></p>
<p>例如：   <code>1 + true  =&gt; 2</code>   </p>
<font color="blue">隐式类型转换的高级考法：</font>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = ?;</span><br><span class="line"><span class="keyword">if</span>(a == <span class="number">1</span> &amp;&amp; a == <span class="number">2</span> &amp;&amp; a == <span class="number">3</span>)&#123;</span><br><span class="line"> 	<span class="built_in">console</span>.log(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>如果原始类型和对象比较，对象会转为原始类型的值在进行比较。</p>
</li>
<li><p>对象转换为原始类型的值，<strong>先调用对象的 valueOf 方法</strong>，如果返回的还是对象，<strong>再接着调用 toString 方法</strong></p>
<p>因此这里重写 valueOf 或者  toString 方法都是可行的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var a = &#123;</span><br><span class="line">    i:1,</span><br><span class="line">    toString: () =&gt; a.i++</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="面试题：js-中-和-的区别"><a href="#面试题：js-中-和-的区别" class="headerlink" title="面试题：js 中 == 和 === 的区别"></a>面试题：js 中 == 和 === 的区别</h3><ul>
<li>对于string、number等基础类型来讲，==和===有很大的区别：<ul>
<li><strong>不同类型：==比较是“转化为同一类型后的值”看“值”是否相同，===如果类型不同，它的结果就是不等。</strong></li>
<li>同类型比较：两者直接进行“值”比较，结果一样</li>
</ul>
</li>
<li>对于Array和Object等高级类型来讲，==和===没有区别，同为“指针地址”比较。</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">console</span>.log([]==[]);  <span class="comment">// false</span></span><br><span class="line"><span class="built_in">console</span>.log([]== <span class="number">0</span>);  <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log([]===[]);  <span class="comment">// false</span></span><br><span class="line"><span class="built_in">console</span>.log([]=== <span class="number">0</span>);  <span class="comment">// false  隐式转换</span></span><br><span class="line"></span><br><span class="line"><span class="literal">undefined</span> == <span class="literal">null</span>   <span class="comment">// true   隐式转换 </span></span><br><span class="line"><span class="literal">undefined</span> === <span class="literal">null</span>  <span class="comment">// false</span></span><br></pre></td></tr></table></figure>
<p><strong>原始值的比较是值的比较：</strong></p>
<ul>
<li>它们的值相等时它们就相等（==）</li>
<li>对象和原始值不同，<strong>对象的比较并非值的比较,而是引用的比较</strong>：</li>
<li>即使两个对象包含同样的属性及相同的值，它们也是不相等的</li>
<li>即使两个数组各个索引元素完全相等，它们也是不相等的,所以[]!=[]</li>
</ul>
<p>[]==0,是数组进行了隐式转换，空数组会转换成数字0，所以相等</p>
<h2 id="考点-2：传值-VS-传址"><a href="#考点-2：传值-VS-传址" class="headerlink" title="考点 2：传值 VS 传址"></a>考点 2：传值 VS 传址</h2><h3 id="传值"><a href="#传值" class="headerlink" title="传值"></a><strong>传值</strong></h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> a = <span class="number">1</span>; </span><br><span class="line"><span class="keyword">let</span> b = a; </span><br><span class="line">b = <span class="number">3</span>;</span><br><span class="line"><span class="comment">// 1 3</span></span><br><span class="line"><span class="built_in">console</span>.log(a, b);</span><br></pre></td></tr></table></figure>
<p><strong>解释</strong>：a 和 b 都是基础类型数据，所以其在栈中 分别有一个自己的独立空间。<strong>对于基础变量，访问直接访问到值（即内容）。</strong></p>
<p>对于 b 其实只是 b 空间内的值 变成了 a 地址中的值而已。</p>
<p>然后改变 b 地址里的值，这并不会影起 a 地址中 值的变化。</p>
<h3 id="传址"><a href="#传址" class="headerlink" title="传址"></a><strong>传址</strong></h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> c = &#123; <span class="attr">name</span>:<span class="string">&quot;hello&quot;</span> &#125;; </span><br><span class="line"><span class="keyword">let</span> d = c;</span><br><span class="line">c.name = <span class="string">&quot;hi&quot;</span>; </span><br><span class="line"><span class="comment">//&#123;name:&quot;hi&quot;&#125;	&#123;name:&quot;hi&quot;&#125;</span></span><br><span class="line"><span class="built_in">console</span>.log(c, d);</span><br></pre></td></tr></table></figure>
<p><strong>解释</strong>： c 和 d 都属于引用类型数据（复杂类型数据），其真实的数据内容是存在 堆中的，其在堆中的存储地址，并存储在栈中，即 c 和 d 在栈中 存储的是数据内容在堆中的存储地址。</p>
<p>所以 d = c 的时候，<strong>实际是一个引用地址的赋值</strong>，所以 d 和 c 此时存储的堆地址是一致的，那数据内容也是共享的啦。 </p>
<h2 id="考点-3：作用域"><a href="#考点-3：作用域" class="headerlink" title="考点 3：作用域"></a>考点 3：作用域</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">test</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">  <span class="built_in">console</span>.log(a);</span><br><span class="line">  <span class="built_in">console</span>.log(foo()); </span><br><span class="line">  <span class="keyword">var</span> a = <span class="number">1</span>; </span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">foo</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line"> 	<span class="keyword">return</span> a;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// undefined</span></span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line">test();</span><br></pre></td></tr></table></figure>
<p>解析：</p>
<p><code>console.log(a);</code>没有报错的原因是， js 中 var 变量有<strong>变量提升机制</strong>，会把定义都自动放到最前面。不过仅仅是声明变量，所以  输出的为 未定义的  <code>undefined</code>。</p>
<p>第二个输出 这个 a 其实是个闭包，的确是修改了 a 的值的。</p>
<h3 id="面试题：谈谈你对-作用域链-的理解"><a href="#面试题：谈谈你对-作用域链-的理解" class="headerlink" title="面试题：谈谈你对 作用域链 的理解"></a>面试题：谈谈你对 作用域链 的理解</h3><p>当所需要的变量，在所在的<strong>作用域中查找不到的时候，它会一层一层向上查找，直到找到全局作用域</strong>还没有找到的时候，就会放弃查找。这种一层一层的关系，就是作用域链。</p>
<p>举个例子：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>; </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">check</span>(<span class="params"></span>)</span>&#123; </span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(a); </span><br><span class="line">        <span class="built_in">console</span>.log(b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">var</span> func = check(); </span><br><span class="line"><span class="comment">// 1</span></span><br><span class="line"><span class="comment">// 报错</span></span><br><span class="line">func();</span><br></pre></td></tr></table></figure>
<p>作用域链是这么产生的：</p>
<ul>
<li><p>首先在  function 中 我没有定义a 和 b 啊</p>
</li>
<li><p>我回到 check 里找，还是没有定义 a 和 b 啊</p>
</li>
<li><p>我再跳出 check 函数，去最外面的全局变量中找，然后找到了 a 输出，b 还是没找到，所以表示为未定义，进而就报错了  <code>ReferenceError: b is not defined</code></p>
</li>
</ul>
<h2 id="考点-4：闭包"><a href="#考点-4：闭包" class="headerlink" title="考点 4：闭包"></a>考点 4：闭包</h2><h3 id="面试题：什么是闭包？如何理解闭包？"><a href="#面试题：什么是闭包？如何理解闭包？" class="headerlink" title="面试题：什么是闭包？如何理解闭包？"></a>面试题：什么是闭包？如何理解闭包？</h3><p><strong>闭包是：指有权访问另一个函数作用域中的变量的函数；</strong> </p>
<p>对于正常的 JS 函数：在 js 中变量的作用域属于函数作用域, 在函数执行完后，作用域就会被清理，内存也会随之被回收。</p>
<p><strong>但是由于闭包函数是建立在函数内部的子函数, 由于它可以访问上级作用域，即使上级函数执行完, 作用域也不会随之销毁,。</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">outer</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">var</span> name = <span class="string">&quot;kaikai&quot;</span>  <span class="comment">// 这个变量后续还要用，所以不会被释放</span></span><br><span class="line">    <span class="keyword">var</span> age = <span class="number">100</span>    <span class="comment">// 后续用不到，会释放</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;    <span class="comment">// 被return 并被变量接住，不会被释放</span></span><br><span class="line">        <span class="keyword">return</span> name + <span class="string">&quot;1111111111111&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> func = outer()</span><br><span class="line"><span class="built_in">console</span>.log(func())</span><br></pre></td></tr></table></figure>
<h3 id="面试题：闭包的优缺点"><a href="#面试题：闭包的优缺点" class="headerlink" title="面试题：闭包的优缺点"></a>面试题：闭包的优缺点</h3><p>优点为： 可以让临时变量常驻与内存</p>
<p>缺点为：由于临时变量没有及时的释放，堆在一起，导致内存爆炸而形成 内存泄露  </p>
<p>可以例如：  func = null  来清除</p>
<h3 id="闭包的应用：-函数柯里化-（要回写）"><a href="#闭包的应用：-函数柯里化-（要回写）" class="headerlink" title="闭包的应用： 函数柯里化 （要回写）"></a>闭包的应用： 函数柯里化 （要回写）</h3><p>函数柯里化：<strong>使用多个参数的函数</strong>转换成一系列<strong>使用一个参数的函数多次</strong>的技术。</p>
<p>举个例子：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">add</span>(<span class="params">a, b, c</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b + c</span><br><span class="line">&#125;</span><br><span class="line">add(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment">// curry 就是一个函数柯里化的过程</span></span><br><span class="line"><span class="keyword">let</span> addCurry = curry(add)</span><br><span class="line">addCurry(<span class="number">1</span>)(<span class="number">2</span>)(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>现在就是要实现 curry 这个函数，<font color="red"><strong>使函数从一次调用传入多个参数变成多次调用每次传一个参数。</strong></font></p>
<p>简单的说如果 入参 &gt;= 函数的 入参个数，就直接执行，否则就 返回一个  待接收 后续入参的 函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根哥版本的 函数柯里化</span></span><br><span class="line"><span class="comment">// ... args 是剩余参数一起接受的意思</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">curry</span>(<span class="params">fn, ...args</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// fn这个函数能取 length 表示这个函数参数的个数</span></span><br><span class="line">    <span class="comment">// 是 ES6 的语法</span></span><br><span class="line">    <span class="keyword">let</span> fnLen = fn.length</span><br><span class="line">    <span class="keyword">const</span> argsLen = args.length</span><br><span class="line">    <span class="comment">// argsLen 入参少于要求的 入参个数 就 接着接收 直到 达到 要求入参个数</span></span><br><span class="line">    <span class="keyword">if</span> (fnLen &gt; argsLen) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params">...args2</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> curry(fn, ...args, ...args2)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// this 指针指的是全局  然后就是 全局中调用 fn 也就是 add函数</span></span><br><span class="line">      <span class="keyword">return</span> fn.apply(<span class="built_in">this</span>, args)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>举一个现实的例子</strong></p>
<font color="blue">例如：我们有一个自定义的排序方法，然而我们每次对数组进行操作，都会把 这个自定义的函数方法给带上，这就导致了麻烦。</font>



<p>所以这个时候可以利用到函数柯里化，使得我们只需要传入 需要排序的数组即可，而我们自定义的排序方法其实就像 闭包一样存储在内存，无法释放。</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/根哥柯里化.png" alt=""></p>
<h2 id="考点-5：原型链和继承"><a href="#考点-5：原型链和继承" class="headerlink" title="考点 5：原型链和继承"></a>考点 5：原型链和继承</h2><h3 id="面试题：-new-操作符的实现原理"><a href="#面试题：-new-操作符的实现原理" class="headerlink" title="面试题： new 操作符的实现原理"></a>面试题： new 操作符的实现原理</h3><p><strong>new操作符的执行过程：</strong></p>
<ol>
<li>首先创建了一个新的空对象</li>
<li>设置原型，将对象的原型设置为函数的 prototype 对象。</li>
<li>让函数的 this 指向这个对象，执行构造函数的代码（为这个新对象添加属性）</li>
<li>判断函数的返回值类型，如果是值类型，返回创建的对象。如果是引用类型，就返回这个引用类型的对象。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fNew</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 1.创建新对象</span></span><br><span class="line">   <span class="keyword">let</span> obj = <span class="built_in">Object</span>.create(<span class="literal">null</span>)</span><br><span class="line">   <span class="keyword">let</span> <span class="title">constructor</span>=[].<span class="title">shift</span>.<span class="title">call</span>(<span class="params"><span class="built_in">arguments</span></span>)   // [ ]相当于 <span class="title">Array</span>.<span class="title">prototype</span></span><br><span class="line">    // 2.将对象的 <span class="title">__proto__</span> 赋值为构造函数的 <span class="title">prototype</span> 属性</span><br><span class="line">   <span class="title">obj</span>.<span class="title">__proto__</span>=<span class="title">constructor</span>.<span class="title">prototype</span></span><br><span class="line">   // 3.将构造函数内部的 <span class="title">this</span> 赋值为新对象，并且为新对象添加属性</span><br><span class="line">   <span class="title">let</span> <span class="title">ret</span> = <span class="title">constructor</span>.<span class="title">apply</span>(<span class="params">obj,<span class="built_in">arguments</span></span>)</span><br><span class="line">   // 4.返回新对象(<span class="params"><span class="built_in">this</span></span>)</span><br><span class="line">   <span class="title">return</span> <span class="title">typeof</span> <span class="title">ret</span> === &quot;<span class="title">object</span>&quot; &amp;&amp; <span class="title">ret</span> !== <span class="title">null</span>? <span class="title">ret</span> : <span class="title">obj</span></span><br><span class="line">&#125;</span><br><span class="line">// 构造函数</span><br><span class="line"><span class="title">function</span> <span class="title">Person</span>(<span class="params">name, member</span>) &#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">    <span class="built_in">this</span>.member = member;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 仿造new后的对象</span></span><br><span class="line"><span class="keyword">let</span> p = fNew(Person,<span class="string">&quot;张三&quot;</span>,<span class="number">18</span>)</span><br><span class="line"><span class="built_in">console</span>.log(p)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/D2B5CA33BD970F64A6301FA75AE2EB22.png" alt=""></p>
<h3 id="面试题：构造函数-和-实例的-原型关系"><a href="#面试题：构造函数-和-实例的-原型关系" class="headerlink" title="面试题：构造函数 和 实例的 原型关系"></a>面试题：构造函数 和 实例的 原型关系</h3><p><strong>原型链：</strong>当对象查找一个属性的时候，如果没有在自身找到，那么就会查找自身的原型，如果原型还没有找到，那么会继续查找原型的原型，直到找到 Object.prototype 的原型时，此时原型为 null，查找停止。<font color="blue"><strong>下图中蓝色的这条就是原型链</strong></font></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/构造函数与实例.png" alt=""></p>
<p>注意一些细节：</p>
<p><strong>constructor</strong></p>
<p>当获取 person.constructor 时，其实 person 中并没有 constructor 属性,当不能读取到constructor 属性时，会从 person 的原型也就是 Person.prototype 中读取，正好原型中有该属性，所以：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">person.constructor === Person.prototype.constructor</span><br></pre></td></tr></table></figure>
<p><code>__proto__</code> <strong>表示的原型的意思</strong></p>
<p>其次是 <code>__proto__</code> ，绝大部分浏览器都支持这个非标准的方法访问原型，然而它并不存在于 Person.prototype 中，</p>
<p>实际上，它是来自于 Object.prototype ，<strong>与其说是一个属性，不如说是一个 getter/setter</strong>，当使用 <code>obj.__proto__</code> 时，可以理解成返回了 Object.getPrototypeOf(obj) （ES5）。</p>
<p><strong>原型链继承：</strong>一个对象可以使用另外一个对象的属性或者方法，就称之为继承。</p>
<p>根据原型链的规则，如果查找一个对象属性且在自身不存在时，就会查找他对应的父类，相当于一个对象可以父类的属性和方法了。</p>
<p><strong>原型的定义 prototype</strong></p>
<ul>
<li><p><strong>每一个函数天生自带一个成员，叫做 prototype，是一个对象空间</strong>，所以你打印的时候显示 {}</p>
</li>
<li><p>即然每一个函数都有，构造函数也是函数，构造函数也有这个对象空间</p>
</li>
<li><p>这个 <code>prototype</code> 对象空间可以由函数名来访问，<font color="red"><strong>相当于我们的继承的东西是写在 原型对象空间中的</strong>。</font></p>
</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params"></span>) </span>&#123;&#125;</span><br><span class="line"><span class="built_in">console</span>.log(Person.prototype) <span class="comment">// 是一个对象</span></span><br><span class="line">Person.prototype.name = <span class="string">&#x27;prototype&#x27;</span></span><br><span class="line">Person.prototype.sayHi = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function Person()&#123;&#125;</span><br><span class="line"></span><br><span class="line">function Student()&#123;&#125;</span><br><span class="line"></span><br><span class="line">Student.prototype = new Person()</span><br></pre></td></tr></table></figure>
<h3 id="面试题：ES5的继承有哪几种"><a href="#面试题：ES5的继承有哪几种" class="headerlink" title="面试题：ES5的继承有哪几种"></a>面试题：ES5的继承有哪几种</h3><p><a href="https://www.jianshu.com/p/124ed22c4844">https://www.jianshu.com/p/124ed22c4844</a></p>
<p><strong>原型链继承、构造继承、组合继承、寄生组合式继承</strong></p>
<h4 id="原型链继承"><a href="#原型链继承" class="headerlink" title="原型链继承"></a>原型链继承</h4><p>  <strong>子类构造函数的原型对象指向父类构造函数的实例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params"></span>)</span>&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Student</span>(<span class="params"></span>)</span>&#123;&#125;</span><br><span class="line">Student.prototype = <span class="keyword">new</span> Person()</span><br></pre></td></tr></table></figure>
<p>让子类构造函数的原型对象，成为父类构造函数的实例，子类的实例通过原型链访问父类原型对象上的属性和方法。</p>
<font color="red">存在的问题：1实例上有引用（复杂）类型，所有实例都会共享这个引用类型。对于普通基础类型，各实例之间是独立的  2. .在创建子类型时，无法想父类的构造函数传递参数</font>

<h4 id="构造函数继承（经典继承）"><a href="#构造函数继承（经典继承）" class="headerlink" title="构造函数继承（经典继承）"></a>构造函数继承（经典继承）</h4><p>构造函数继承的本质：在子类构造函数内部调用父类构造函数。也就是 java 的 super</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params">name</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">this</span>.name = name</span><br><span class="line">  <span class="built_in">this</span>.color = [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Student</span> (<span class="params">name</span>) </span>&#123;</span><br><span class="line"><span class="comment">// 这个相当于改变 原本Person的this指针 现在指向Student</span></span><br><span class="line"><span class="comment">// 用apply也是可以的  </span></span><br><span class="line"><span class="comment">// 注意：构造函数继承只能 继承属性</span></span><br><span class="line">  Person.call(<span class="built_in">this</span>, name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> stu1 = <span class="keyword">new</span> Student(<span class="string">&#x27;guoguo&#x27;</span>)</span><br><span class="line">stu1.color.push(<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line"><span class="built_in">console</span>.log(stu1) </span><br><span class="line"><span class="comment">// &#123;name:&#x27;guoguoguo&#x27;, color: [&#x27;red&#x27;, &#x27;yellow&#x27;, &#x27;blue&#x27;, &#x27;green&#x27;]&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> stu2 = <span class="keyword">new</span> Student(<span class="string">&#x27;yuyuyu&#x27;</span>)</span><br><span class="line"><span class="built_in">console</span>.log(stu2)  </span><br><span class="line"><span class="comment">// &#123;name:&#x27;guoguoguo&#x27;, color: [&#x27;red&#x27;, &#x27;yellow&#x27;, &#x27;blue&#x27;]&#125;</span></span><br></pre></td></tr></table></figure>
<p>经典继承可以解决原型链继承不能向父类传参和实例共享引用类型值问题，但是它的<strong>缺点</strong>：</p>
<font color="red">实例无法共享父类原型对象上的方法和属性</font>



<h4 id="组合式继承"><a href="#组合式继承" class="headerlink" title="组合式继承"></a>组合式继承</h4><p>组合式继承的本质：<font color="blue">将原型链继承和构造函数继承组合到一起，借用构造函数来实现对实例属性的继承，借用原型链继承实现对原型对象的属性和方法的继承</font></p>
<font color="red">确定：组合继承调用了父类构造函数两次，造成了不必要的消耗</font>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Parent</span> (<span class="params">name</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name</span><br><span class="line">    <span class="built_in">this</span>.friend = [<span class="string">&#x27;lucky&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Parent.prototype.getFriend = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;找呀找呀找朋友&#x27;</span>, <span class="built_in">this</span>.friend)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Student</span> (<span class="params">name</span>) </span>&#123;</span><br><span class="line">    Parent.call(<span class="built_in">this</span>, name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Student.prototype = <span class="keyword">new</span> Parent(<span class="string">&#x27;tom&#x27;</span>)</span><br><span class="line"><span class="keyword">let</span> stu1 = <span class="keyword">new</span> Student(<span class="string">&#x27;lily&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(stu1)</span><br></pre></td></tr></table></figure>
<h4 id="原型式继承"><a href="#原型式继承" class="headerlink" title="原型式继承"></a>原型式继承</h4><p>原型式继承的原理：在create函数内部，先创建一个临时性的构造函数，将传入的对象作为这个构造函数的原型，然后返回这个临时构造函数的新实例。</p>
<p>本质上讲，<strong>Create对其传入的对象执行了一次浅复制</strong>。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Create</span> (<span class="params">obj</span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">Fun</span>(<span class="params"></span>) </span>&#123;&#125;</span><br><span class="line">  Fun.prototype = obj</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> Fun()</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> person = &#123; <span class="attr">name</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> another1 = Create(person)</span><br><span class="line"></span><br><span class="line">another1.name.push(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> another2 = Create(person)</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(another1.name) <span class="comment">// [1, 2, 3, 4]</span></span><br><span class="line"><span class="built_in">console</span>.log(another2.name) <span class="comment">// [1, 2, 3, 4]</span></span><br></pre></td></tr></table></figure>
<p>缺点：原型式继承,包含引用类型值的属性，<strong>始终都会共享相应的值</strong>，就像使用引用类型一样</p>
<h4 id="寄生式继承"><a href="#寄生式继承" class="headerlink" title="寄生式继承"></a>寄生式继承</h4><p>寄生式继承的核心：<strong>在原型式继承的基础上，增强对象，返回构造函数</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Create</span> (<span class="params">obj</span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">Fun</span> (<span class="params"></span>) </span>&#123;&#125;</span><br><span class="line">  Fun.prototype = obj</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> Fun()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">CreateAnother</span> (<span class="params">obj</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> clone = Create(obj)</span><br><span class="line">  clone.sayHi = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;&#125;</span><br><span class="line">  <span class="keyword">return</span> clone</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//函数的主要作用就是为构造函数新增属性和方法，以增强对象</span></span><br><span class="line"><span class="keyword">let</span> person1 = &#123;<span class="attr">name</span>: <span class="string">&#x27;guojing&#x27;</span>&#125;</span><br><span class="line"><span class="keyword">let</span> p1 = CreateAnother(person1)</span><br><span class="line"><span class="built_in">console</span>.log(p1) <span class="comment">// 普通类型  Fun &#123;sayHi: ƒ&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> person2 = &#123;<span class="attr">newArr</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125; <span class="comment">//引用类型</span></span><br><span class="line"><span class="keyword">let</span> p2 = CreateAnother(person2)</span><br><span class="line">p2.newArr.push(<span class="number">5</span>)  </span><br><span class="line"><span class="built_in">console</span>.log(person2)  <span class="comment">//&#123;newArr: [1, 2, 3, 4, 5]&#125;</span></span><br><span class="line"><span class="built_in">console</span>.log(p2)  <span class="comment">// Fun &#123;sayHi: ƒ&#125;</span></span><br></pre></td></tr></table></figure>
<p>缺点：</p>
<ul>
<li>原型式继承多个实例的引用类型属性指向相同，存在篡改的可能</li>
<li>无法传递参数</li>
</ul>
<h4 id="寄生组合式继承"><a href="#寄生组合式继承" class="headerlink" title="寄生组合式继承"></a>寄生组合式继承</h4><p>借用构造函数来继承属性，通过原型链的混合模式来继承方法，其背后的思路是：<br>不必为了执行子类型的原型而调用父类构造函数，使用寄生式继承来继承父类的原型，然后将结果指定给子类型的原型。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span> (<span class="params">name</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">this</span>.name = name</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Person.prototype.sayName = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="built_in">this</span>.name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Student</span> (<span class="params">name</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 在子类构造函数里调用父类的构造函数，继承构造函数属性的继承，并可以给父类构造函数传参</span></span><br><span class="line">  Person.call(<span class="built_in">this</span>, name)</span><br><span class="line">  <span class="built_in">this</span>.name = name</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 建立子类原型对象和父类原型对象的连接，通过Object.create方法对父类原型进行浅复制，再复制给子类原型</span></span><br><span class="line">Student.prototype = <span class="built_in">Object</span>.create(Person.prototype) </span><br><span class="line"><span class="comment">// 通过以上操作，Student.prototype.constructor指向的是Person,再进行增强原型，将constructor指向Student</span></span><br><span class="line">Student.prototype.constructor = Student </span><br></pre></td></tr></table></figure>
<h3 id="面试题：ES5-和-ES6-是如何是实现-类继承的"><a href="#面试题：ES5-和-ES6-是如何是实现-类继承的" class="headerlink" title="面试题：ES5 和 ES6 是如何是实现 类继承的"></a>面试题：ES5 和 ES6 是如何是实现 类继承的</h3><h4 id="ES5-的继承"><a href="#ES5-的继承" class="headerlink" title="ES5 的继承"></a>ES5 的继承</h4><p>只要记住存在类的原型对象中就可以了。</p>
<p>这里也就是 构造函数继承</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params">name,age</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name</span><br><span class="line">    <span class="built_in">this</span>.age = age</span><br><span class="line">&#125;</span><br><span class="line">Person.prototype.say = <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="built_in">this</span>.name, <span class="string">&quot;hello world&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Student</span>(<span class="params">name, age, grade</span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 这个相当于改变 原本Person的this指针 现在指向Student</span></span><br><span class="line">    <span class="comment">// 用apply也是可以的  </span></span><br><span class="line">    <span class="comment">// 注意：构造函数继承只能 继承属性</span></span><br><span class="line">    Person.call(<span class="built_in">this</span>, name, age)</span><br><span class="line">    <span class="comment">// Person.apply(this, [name, age])</span></span><br><span class="line">    <span class="built_in">this</span>.grade = grade</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> obj = <span class="keyword">new</span> Student(<span class="string">&quot;kaikai&quot;</span>,<span class="number">24</span>,<span class="number">100</span>)</span><br><span class="line"><span class="built_in">console</span>.log(obj)</span><br><span class="line"><span class="comment">// 不好使因为只能 继承属性，原型上的方法没法继承</span></span><br><span class="line">obj.say()</span><br></pre></td></tr></table></figure>
<h4 id="ES6-的继承与-Java基本一致（要会写）"><a href="#ES6-的继承与-Java基本一致（要会写）" class="headerlink" title="ES6 的继承与 Java基本一致（要会写）"></a>ES6 的继承与 Java基本一致（要会写）</h4><p>使用 <code>constructor</code> 作为构造函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">   <span class="comment">// 构造函数，实例化的时候将会被调用，如果不指定，那么会有一个不带参数的默认构造函数.</span></span><br><span class="line">   <span class="function"><span class="title">constructor</span>(<span class="params">name,color</span>)</span> &#123;</span><br><span class="line">     <span class="built_in">this</span>.name = name;</span><br><span class="line">     <span class="built_in">this</span>.color = color;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// toString 是原型对象上的属性 并且是重写的哦</span></span><br><span class="line">   <span class="function"><span class="title">toString</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">     <span class="built_in">console</span>.log(<span class="string">&#x27;name:&#x27;</span> + <span class="built_in">this</span>.name + <span class="string">&#x27;,color:&#x27;</span> + <span class="built_in">this</span>.color);</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> animal = <span class="keyword">new</span> Animal(<span class="string">&#x27;dog&#x27;</span>,<span class="string">&#x27;white&#x27;</span>);<span class="comment">//实例化Animal</span></span><br><span class="line">animal.toString();</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(animal.hasOwnProperty(<span class="string">&#x27;name&#x27;</span>)); <span class="comment">//true</span></span><br><span class="line"><span class="built_in">console</span>.log(animal.hasOwnProperty(<span class="string">&#x27;toString&#x27;</span>)); <span class="comment">// false</span></span><br><span class="line"><span class="built_in">console</span>.log(animal.__proto__.hasOwnProperty(<span class="string">&#x27;toString&#x27;</span>)); <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span> <span class="keyword">extends</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line"> <span class="function"><span class="title">constructor</span>(<span class="params">action</span>)</span> &#123;</span><br><span class="line">   <span class="comment">// 子类必须要在constructor中指定super 函数，否则在新建实例的时候会报错.</span></span><br><span class="line">   <span class="comment">// 如果没有置顶consructor,默认带super函数的constructor将会被添加、</span></span><br><span class="line">   <span class="built_in">super</span>(<span class="string">&#x27;cat&#x27;</span>,<span class="string">&#x27;white&#x27;</span>);</span><br><span class="line">   <span class="built_in">this</span>.action = action;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">// 重载父类原型对象 上的方法</span></span><br><span class="line"> <span class="function"><span class="title">toString</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="built_in">super</span>.toString());</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> cat = <span class="keyword">new</span> Cat(<span class="string">&#x27;catch&#x27;</span>)</span><br><span class="line"></span><br><span class="line">cat.toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实例cat 是 Cat 和 Animal 的实例，和Es5完全一致。</span></span><br><span class="line"><span class="built_in">console</span>.log(cat <span class="keyword">instanceof</span> Cat); <span class="comment">// true</span></span><br><span class="line"><span class="built_in">console</span>.log(cat <span class="keyword">instanceof</span> Animal); <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
<p><img src="C:\Users\96356\AppData\Roaming\Typora\typora-user-images\image-20230214175610951.png" alt="image-20230214175610951"></p>
<p>a 是  类A 的实例对象， b是 类B 的实例对象。B类是A类的子类。</p>
<p>所以 a 的 proto 是 A的原型，没问题。 b 的 proto 是B 的原型也没问题。</p>
<p><strong>B类的proto也就是 A 。</strong></p>
<p><strong>B的prototye 也就是 实例对象 b 的proto，</strong>实际是个对象空间但是属于A。</p>
<p>所以其 <strong>proto</strong> 就是 A 对应的 对象空间 { } </p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/原型与继承.png" alt=""></p>
<h2 id="考点6：Map-、-Set、weakSet-和-weakMap"><a href="#考点6：Map-、-Set、weakSet-和-weakMap" class="headerlink" title="考点6：Map 、 Set、weakSet 和 weakMap"></a>考点6：Map 、 Set、weakSet 和 weakMap</h2><h3 id="面试题：如何理解-Map-与-普通对象的区别"><a href="#面试题：如何理解-Map-与-普通对象的区别" class="headerlink" title="面试题：如何理解 Map 与 普通对象的区别"></a>面试题：如何理解 Map 与 普通对象的区别</h3><p>Map的key相比较普通对象来说更为灵活，</p>
<ul>
<li>普通对象的key只能以基础数据类型作为key值，并且所有传入的key值都会被转化成string类型</li>
<li>Map的key可以是各种数据类型格式。</li>
</ul>
<h3 id="面试题：weakMap-和-Map，weakSet-和-Set-的区别？"><a href="#面试题：weakMap-和-Map，weakSet-和-Set-的区别？" class="headerlink" title="面试题：weakMap 和 Map，weakSet 和 Set 的区别？"></a>面试题：weakMap 和 Map，weakSet 和 Set 的区别？</h3><p><a href="https://github.com/Advanced-Frontend/Daily-Interview-Question/issues/6">https://github.com/Advanced-Frontend/Daily-Interview-Question/issues/6</a></p>
<p><strong>Map</strong>  叫做字典</p>
<ul>
<li><p>本质上是健值对的集合，类似集合</p>
</li>
<li><p>Map 的键 key实际上是跟内存地址绑定的，只要内存地址不一样，就视为两个键。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> map = <span class="keyword">new</span> <span class="built_in">Map</span>();</span><br><span class="line"><span class="comment">// [&#x27;a&#x27;]是Array 也就是复杂数据类型，地址每次是不一样的</span></span><br><span class="line">map.set([<span class="string">&#x27;a&#x27;</span>], <span class="number">555</span>);</span><br><span class="line">map.get([<span class="string">&#x27;a&#x27;</span>]) <span class="comment">// undefined</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>可以遍历</strong>，方法API 很多，可以干跟各种数据格式转换。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建一个哈希表</span></span><br><span class="line"><span class="keyword">const</span> symbolValues = <span class="keyword">new</span> <span class="built_in">Map</span>()</span><br><span class="line"><span class="comment">// 添加</span></span><br><span class="line">symbolValues.set(<span class="string">&quot;I&quot;</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">// 读取</span></span><br><span class="line"><span class="keyword">const</span> value = symbolValues.get(<span class="string">&quot;I&quot;</span>)</span><br><span class="line"></span><br><span class="line">使用 <span class="keyword">for</span>...of遍历</span><br><span class="line"><span class="built_in">console</span>.log(map.entries())	<span class="comment">// 类似于 MapIterator &#123;&quot;name&quot; =&gt; &quot;An&quot;, &quot;des&quot; =&gt; &quot;JS&quot;&#125;</span></span><br><span class="line"><span class="built_in">console</span>.log(map.keys()) <span class="comment">// 类似于 MapIterator &#123;&quot;name&quot;, &quot;des&quot;&#125;</span></span><br><span class="line">size：返回字典中所包含的元素个数</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>weakMap</strong></p>
<ul>
<li>键key 必须是<strong>复杂数据类型</strong>（null 空对象是不行的），其他类型数据都不行 <strong>，而值可以是任意</strong></li>
<li>键key 所指向的对象，并且key值是<strong>弱引用</strong>，不计入垃圾回收机制</li>
<li>WeakMap 中，每个键对自己所引用对象的引用都是弱引用，在没有其他引用和该键引用同一对象，这个对象将会被垃圾回收（相应的key则变成无效的），所以，WeakMap 的 key 是不可枚举的。<font color="red"><strong>不能遍历</strong></font>，方法同  <code>get,set,has,delete</code></li>
</ul>
<p><strong>Set </strong> 叫做集合</p>
<ul>
<li><p>成员不能重复，放入任何数据类型都可以</p>
</li>
<li><p>只有健值，没有健名，有点类似数组。</p>
</li>
<li><p><strong>可以遍历</strong>，方法有add, delete,has，clear()</p>
<p>size：返回字典中所包含的元素个数</p>
</li>
</ul>
<p><strong>weakSet</strong></p>
<ul>
<li>WeakSet 只能储存对象引用，不能存放值</li>
<li><strong>成员都是弱引用，随时可以消失。</strong> 可以用来保存DOM节点，不容易造成内存泄漏</li>
<li><font color="red"><strong>不能遍历</strong></font>，方法同有add, delete,has， clear已废弃</li>
</ul>
<h2 id="考点7：JS-中的this"><a href="#考点7：JS-中的this" class="headerlink" title="考点7：JS 中的this"></a>考点7：JS 中的this</h2><p><a href="https://juejin.cn/post/6844903488304971789">https://juejin.cn/post/6844903488304971789</a></p>
<p>😎首先对this的下个定义：<strong>this是在执行上下文创建时确定的一个在执行过程中不可更改的变量。</strong></p>
<p><strong>JS 中 this 存在 严格模式和非严格模式 两种</strong>  一般使用  <code>&#39;use strict&#39;;</code> 进行声明表示 严格模式。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var a = 1;</span><br><span class="line">function fun() &#123;</span><br><span class="line">   &#x27;use strict&#x27;; </span><br><span class="line">    var a = 2;</span><br><span class="line">      return this.a;</span><br><span class="line">&#125;</span><br><span class="line">fun();//😨报错 Cannot read property &#x27;a&#x27; of undefined</span><br><span class="line">// 不使用 &#x27;use strict&#x27;;  1</span><br></pre></td></tr></table></figure>
<ul>
<li>严格模式下，<strong>this指向undefined;</strong></li>
<li>非严格模式下， <strong>this指向window;</strong></li>
</ul>
<ul>
<li>对于对象中的 this 指针，this 指向对象本身</li>
<li><strong>当obj在一个函数中声明的时候，</strong><ul>
<li><strong>严格模式下this会指向undefined，</strong></li>
<li><strong>非严格模式自动转为指向全局对象 window。 </strong></li>
</ul>
</li>
</ul>
<p>看🌰：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1000</span>;</span><br><span class="line"><span class="keyword">var</span> obj = &#123;</span><br><span class="line">    <span class="attr">a</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="attr">b</span>: <span class="built_in">this</span>.a + <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> obj = &#123;</span><br><span class="line">          <span class="attr">a</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="comment">// 非严格模式 因为是在函数里 所以 this 指向 window</span></span><br><span class="line">        <span class="attr">c</span>: <span class="built_in">this</span>.a + <span class="number">2</span> <span class="comment">//严格模式下这块报错 Cannot read property &#x27;a&#x27; of undefined</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> obj.c;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">console</span>.log(fun());<span class="comment">//1002</span></span><br><span class="line"><span class="built_in">console</span>.log(obj.b);<span class="comment">//1001</span></span><br></pre></td></tr></table></figure>
<h3 id="面试题：在五种情景下，this指针指向谁？"><a href="#面试题：在五种情景下，this指针指向谁？" class="headerlink" title="面试题：在五种情景下，this指针指向谁？"></a>面试题：在五种情景下，this指针指向谁？</h3><p>这五种情景分别为：</p>
<font color="red"> **this 永远指向最后调用它的那个对象**</font>

<ul>
<li>在全局环境或是普通函数中直接调用</li>
<li>作为对象的方法</li>
<li>使用apply和call</li>
<li>作为构造函数</li>
<li>箭头函数中</li>
</ul>
<h4 id="在全局环境或是普通函数中直接调用"><a href="#在全局环境或是普通函数中直接调用" class="headerlink" title="在全局环境或是普通函数中直接调用"></a><strong>在全局环境或是普通函数中直接调用</strong></h4><p>再写☝️🌰：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">var</span> obj  =  &#123;</span><br><span class="line">      <span class="attr">a</span>: <span class="number">2</span>,</span><br><span class="line">      <span class="attr">b</span>: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="comment">// 函数内的函数</span></span><br><span class="line">        <span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">          <span class="comment">// 这个 this 在非严格模式下就是 全局对象 window</span></span><br><span class="line">          <span class="keyword">return</span> <span class="built_in">this</span>.a</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="built_in">console</span>.log(fun());</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line">obj.b();<span class="comment">//1</span></span><br></pre></td></tr></table></figure>
<font color="red">**当this 在函数内独立调用的时候，**</font>

<ul>
<li><strong>在严格模式下它的this指向undefined，</strong></li>
<li><strong>在非严格模式下，当this指向undefined的时候，自动指向全局对象(浏览器中就是window)</strong></li>
</ul>
<h4 id="作为对象的方法"><a href="#作为对象的方法" class="headerlink" title="作为对象的方法"></a><strong>作为对象的方法</strong></h4><p>👆b所引用的匿名函数作为obj的一个方法调用，这时候this指向调用它的对象。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">var</span> obj = &#123;</span><br><span class="line">  <span class="attr">a</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="comment">// 单纯的匿名函数</span></span><br><span class="line">  <span class="attr">b</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 所以 this 指向的是 obj  这里遵循谁调用是谁的原理</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.a;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">console</span>.log(obj.b())<span class="comment">//2</span></span><br></pre></td></tr></table></figure>
<p>那么如果b方法不作为对象方法调用呢？啥意思呢，就是这样👇：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">var</span> obj = &#123;</span><br><span class="line">  <span class="attr">a</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="attr">b</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.a;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 用一个变量取</span></span><br><span class="line"><span class="keyword">var</span> t = obj.b;</span><br><span class="line"><span class="built_in">console</span>.log(t());<span class="comment">//1</span></span><br></pre></td></tr></table></figure>
<p>这就涉及Javascript的内存空间了，就是说，<strong>obj对象的b属性存储的是对该匿名函数的一个引用</strong>，可以理解为一个指针。<strong>当赋值给t的时候，并没有单独开辟内存空间存储新的函数，而是让t存储了一个指针，该指针指向这个函数。</strong>相当于代码变成了：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>) </span>&#123;<span class="comment">//此函数存储在堆中</span></span><br><span class="line">    <span class="comment">// 所以这个 this 相当于第一种情况 函数的直接调用，所以是 window</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.a;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> obj = &#123;</span><br><span class="line">  <span class="attr">a</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="attr">b</span>: fun <span class="comment">//b指向fun函数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> t = fun;<span class="comment">//变量t指向fun函数</span></span><br><span class="line"><span class="built_in">console</span>.log(t());<span class="comment">//1</span></span><br></pre></td></tr></table></figure>
<p>此时的t就是一个指向fun函数的指针，调用t，相当于直接调用fun，套用以上规则，打印出来1自然很好理解了。</p>
<h4 id="使用apply和call-以及bind"><a href="#使用apply和call-以及bind" class="headerlink" title="使用apply和call 以及bind"></a><strong>使用apply和call</strong> 以及bind</h4><p>call 和 apply 方法都可以改变当前指针为 参数的第一个参数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">var</span> obj = &#123;</span><br><span class="line">  <span class="attr">a</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="attr">b</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.a;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line">obj.b()</span><br><span class="line"><span class="comment">// 2 </span></span><br><span class="line">obj.b.call(obj)</span><br></pre></td></tr></table></figure>
<p>这两个其实表现的是一个意思，就是语法糖。<em>指的是在计算机语言中添加的某种语法</em>,这种语法对语言的编译结果和功能并没有实际影响。</p>
<h4 id="作为构造函数"><a href="#作为构造函数" class="headerlink" title="作为构造函数"></a>作为构造函数</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 父类</span><br><span class="line">class Person&#123;</span><br><span class="line">    constructor(name,age)&#123;</span><br><span class="line">        this.name = name</span><br><span class="line">        this.age = age</span><br><span class="line">    &#125;</span><br><span class="line">    say()&#123;</span><br><span class="line">        console.log(this.name, &quot;hello&quot;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 子类</span><br><span class="line">// extends 原型继承</span><br><span class="line">class Student extends Person&#123;</span><br><span class="line">    constructor(name,age,grade)&#123;</span><br><span class="line">        // 实现对 父类属性的继承</span><br><span class="line">        super(name,age)</span><br><span class="line">        this.grade = grade</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 方法 覆盖 并调用父类say方法</span><br><span class="line">    say()&#123;</span><br><span class="line">        super.say()</span><br><span class="line">        console.log(this.name, &quot;congratulate! &quot;, this.grade)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">let obj = new Student(&quot;kaikai&quot;,24,100)</span><br><span class="line">obj.say()</span><br></pre></td></tr></table></figure>
<p><strong>如果函数作为构造函数用，那么其中的this就代表它即将new出来的对象。</strong></p>
<h4 id="箭头函数中"><a href="#箭头函数中" class="headerlink" title="箭头函数中"></a>箭头函数中</h4><font color="blue">箭头函数是一个**不可以用call和apply改变this的典型。**</font>

<p>我们看下面这个🌰：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">var</span> obj = &#123;</span><br><span class="line">  <span class="attr">a</span>: <span class="number">2</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">var</span> fun = <span class="function">() =&gt;</span> <span class="built_in">console</span>.log(<span class="built_in">this</span>.a);</span><br><span class="line"><span class="comment">// 此处 fun函数的上下文是 window 所以this 也是window</span></span><br><span class="line">fun();<span class="comment">//1</span></span><br><span class="line"><span class="comment">// 因为fun是个箭头函数  call 和 apply 只能传参</span></span><br><span class="line">fun.call(obj)<span class="comment">//1</span></span><br></pre></td></tr></table></figure>
<p><strong>箭头函数会捕获其所在上下文的 <code>this</code> 值，作为自己的 <code>this</code> 值</strong>，也就是说箭头函数的this在词法层面就完成了绑定。apply，call方法只是传入参数，却改不了this。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">var</span> obj = &#123;</span><br><span class="line">  <span class="attr">a</span>: <span class="number">2</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> a = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">let</span> f = <span class="function">() =&gt;</span> <span class="built_in">console</span>.log(<span class="built_in">this</span>.a);</span><br><span class="line">    f();</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// fun 的上下文还是 window 所以 this 指向window</span></span><br><span class="line">fun();<span class="comment">//1</span></span><br><span class="line">fun.call(obj);<span class="comment">//2</span></span><br></pre></td></tr></table></figure>
<p>但是这里fun 本身是个普通函数，不是箭头函数，所以 call 的指针改变对她是有效的，所以新的上下文重新被建立了，此时fun的  this 指向的是 obj。</p>
<p>再来一个🌰：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Fun</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.name = <span class="string">&#x27;Damonare&#x27;</span>;</span><br><span class="line">&#125;</span><br><span class="line">Fun.prototype.say = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="built_in">this</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> f = <span class="keyword">new</span> Fun();</span><br><span class="line">f.say();<span class="comment">//this 是 window </span></span><br></pre></td></tr></table></figure>
<p>这个虽然说是 构造函数里的方法，但是他是个箭头函数，所以 this 指的还是他的上下文 也就是 f 对应的 window。</p>
<h2 id="考点8：浅拷贝和深拷贝"><a href="#考点8：浅拷贝和深拷贝" class="headerlink" title="考点8：浅拷贝和深拷贝"></a>考点8：浅拷贝和深拷贝</h2><h3 id="面试题：如何理解深浅拷贝"><a href="#面试题：如何理解深浅拷贝" class="headerlink" title="面试题：如何理解深浅拷贝"></a>面试题：如何理解深浅拷贝</h3><ul>
<li>浅拷贝：一般指的是把对象的<strong>第一层拷贝到一个新对象上去， 并新建地址引用</strong>，其内部第二层及其以后引用地址均不会发生变化。</li>
<li>深拷贝：一般需要借助递归实现，如果对象的值还是个对象，要进一步的深入拷贝，<strong>完全替换掉每一个复杂类型的引用。</strong></li>
</ul>
<p><strong>浅拷贝</strong>🌰</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 浅拷贝</span></span><br><span class="line"><span class="keyword">var</span> a = &#123; <span class="attr">count</span>: <span class="number">1</span>, <span class="attr">deep</span>: &#123; <span class="attr">count</span>: <span class="number">2</span> &#125; &#125;</span><br><span class="line"><span class="keyword">var</span> b = &#123;...a&#125;</span><br><span class="line"></span><br><span class="line">a.count = <span class="number">3</span></span><br><span class="line">b.count = <span class="number">1</span>  <span class="comment">// b 的第一层内容地址是全新的引用地址 所以 改变a 不会引起 b的变化</span></span><br><span class="line">a.deep.count = <span class="number">5</span></span><br><span class="line">b.deep.count <span class="comment">// 5 因为浅拷贝并不改变第二层的引用地址</span></span><br></pre></td></tr></table></figure>
<p><strong>深拷贝</strong>🌰</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 深拷贝</span></span><br><span class="line"><span class="keyword">var</span> a = &#123; <span class="attr">count</span>: <span class="number">1</span>, <span class="attr">deep</span>: &#123; <span class="attr">count</span>: <span class="number">2</span> &#125; &#125;</span><br><span class="line"><span class="keyword">var</span> b = deepCopy(a)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 浅层</span></span><br><span class="line">a.count = <span class="number">3</span></span><br><span class="line">b.count  <span class="comment">// 1  </span></span><br><span class="line"><span class="comment">// 深层</span></span><br><span class="line">a.deep.count = <span class="number">5</span></span><br><span class="line">b.deep.count <span class="comment">// 2  因为深拷贝是 任意一层的 数据引用地址完全发生变化，所以其 算是个独立数据 a的修改 和 b 一点关系没有</span></span><br></pre></td></tr></table></figure>
<h3 id="面试题：实现深拷贝代码-（手写）"><a href="#面试题：实现深拷贝代码-（手写）" class="headerlink" title="面试题：实现深拷贝代码 （手写）"></a>面试题：实现深拷贝代码 （手写）</h3><p><strong>方法一 ： 采用递归去拷贝所有层级属性</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> deepCopy = <span class="function">(<span class="params">obj</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// 判断 obj 是对象还是数组 用对应的进行收纳</span></span><br><span class="line">    <span class="keyword">var</span> newObj = obj <span class="keyword">instanceof</span> <span class="built_in">Array</span>? [] :&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> key <span class="keyword">in</span> obj)&#123;</span><br><span class="line">        <span class="keyword">var</span> value = obj[key]</span><br><span class="line">        newObj[key] = <span class="keyword">typeof</span> value === <span class="string">&quot;object&quot;</span>? deepCopy(value) : obj[key]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> newObj</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">deepCopy(a)  <span class="comment">// a 是个 obj</span></span><br></pre></td></tr></table></figure>
<p><strong>方法二：使用JSON.stringify和JSON.parse实现深拷贝</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">deepCopy</span>(<span class="params">obj1</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> objTemp = <span class="built_in">JSON</span>.stringify(obj1);</span><br><span class="line">    <span class="keyword">let</span> obj2 = <span class="built_in">JSON</span>.parse(objTemp);</span><br><span class="line">    <span class="keyword">return</span> obj2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>方法三：使用node库 lodash</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> lodash = <span class="built_in">require</span>(<span class="string">&#x27;lodash&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> obj1 = &#123;</span><br><span class="line">    <span class="attr">a</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">b</span>: &#123; <span class="attr">f</span>: &#123; <span class="attr">g</span>: <span class="number">1</span> &#125; &#125;,</span><br><span class="line">    <span class="attr">c</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">var</span> obj2 = lodash.cloneDeep(obj1);</span><br></pre></td></tr></table></figure>
<h2 id="考点9：事件冒泡和事件捕获以及事件代理"><a href="#考点9：事件冒泡和事件捕获以及事件代理" class="headerlink" title="考点9：事件冒泡和事件捕获以及事件代理"></a>考点9：事件冒泡和事件捕获以及事件代理</h2><h3 id="面试题：事件冒泡、事件捕获的定义？"><a href="#面试题：事件冒泡、事件捕获的定义？" class="headerlink" title="面试题：事件冒泡、事件捕获的定义？"></a>面试题：事件冒泡、事件捕获的定义？</h3><p>事件冒泡和事件捕获分别由微软和网景公司提出，这两个概念都是为了解决页面中<strong>事件流</strong>（事件发生顺序）的问题。</p>
<font color="blue">假设我们父子两个元素，均有对应的触发事件。</font>

<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;outer&quot;</span> ο<span class="attr">nclick</span>=<span class="string">&quot;method1()&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;inner&quot;</span> ο<span class="attr">nclick</span>=<span class="string">&quot;method2()&quot;</span>&gt;</span>Click me!<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/事件冒泡和事件捕获.png" style="zoom:50%;" /></p>
<font color="blue">JS dom的事件流三个阶段：1-5是事件捕获过程，5-6是处于目标阶段，6-10是事件冒泡阶段；</font>

<p><strong>事件冒泡</strong></p>
<p>微软提出了名为<strong>事件冒泡</strong>(event bubbling)的事件流。</p>
<p>事件冒泡，就是元素自身的事件被触发后，如果父元素有相同的事件，如onclick事件，  那么元素本身的触发状态就会传递，也就是冒到父元素，父元素的相同事件也会一级一 级根据嵌套关系向外触发，直document/window，冒泡过程结束。  </p>
<p>因此上面的例子在事件冒泡的概念下发生click事件的顺序应该是</p>
<p><strong>p -&gt; div -&gt; body -&gt; html -&gt; document</strong></p>
<p><strong>事件捕获</strong></p>
<p>网景提出另一种事件流名为<strong>事件捕获</strong>(event capturing)。与事件冒泡相反，事件会从最外层开始发生，直到最具体的元素。</p>
<p>上面的例子在事件捕获的概念下发生click事件的顺序应该是</p>
<p><strong>document -&gt; html -&gt; body -&gt; div -&gt; p</strong></p>
<h3 id="面试题：如何开启事件冒泡-或者-事件捕获？"><a href="#面试题：如何开启事件冒泡-或者-事件捕获？" class="headerlink" title="面试题：如何开启事件冒泡 或者 事件捕获？"></a>面试题：如何开启事件冒泡 或者 事件捕获？</h3><p>addEventListener 方式（称为dom2级方式）方式中</p>
<p>语法： <code>元素.addEventListener(&#39;事件类型&#39;， 事件处理函数， 冒泡还是捕获)</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">oDiv.addEventListener(&#x27;click&#x27;, function () &#123;</span><br><span class="line">  console.log(&#x27;我是第一个事件&#x27;)</span><br><span class="line">&#125;, false)</span><br><span class="line">// false 表示 开启冒泡 </span><br><span class="line">// true 表示 开启捕获</span><br></pre></td></tr></table></figure>
<font color="blue">注意： 并非所有的事件都支持冒泡，比如focus，blur等等</font>

<h3 id="面试题：如何理解-事件流的优势-即事件委托的优势？"><a href="#面试题：如何理解-事件流的优势-即事件委托的优势？" class="headerlink" title="面试题：如何理解 事件流的优势 即事件委托的优势？"></a>面试题：如何理解 事件流的优势 即事件委托的优势？</h3><p>举个例子 我们现在有 如下的结构</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">&quot;color_list&quot;</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>red<span class="tag">&lt;/<span class="name">li</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>orange<span class="tag">&lt;/<span class="name">li</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>yellow<span class="tag">&lt;/<span class="name">li</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>green<span class="tag">&lt;/<span class="name">li</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>blue<span class="tag">&lt;/<span class="name">li</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>purple<span class="tag">&lt;/<span class="name">li</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/事件委托的例子.png" alt=""></p>
<p>想要实现的功能为：<strong>在点击每个 li 标签时，在下面输出li当中的颜色<code>（innerHTML）</code></strong></p>
<p>如果不使用事件委托，其<strong>常规的做法</strong>应该事 为每个 li 标签都绑定一个功能点击事件。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">var</span> color_list = <span class="built_in">document</span>.querySelector(<span class="string">&quot;.color_list&quot;</span>);     </span><br><span class="line"><span class="keyword">var</span> colors = color_list.getElementsByTagName(<span class="string">&quot;li&quot;</span>);         </span><br><span class="line"><span class="keyword">var</span> box = <span class="built_in">document</span>.querySelector(<span class="string">&quot;.box&quot;</span>);            </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>;i &lt; colors.length; i++)&#123;                </span><br><span class="line">    colors[i].addEventListener(<span class="string">&quot;click&quot;</span>,<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;    </span><br><span class="line">        <span class="comment">// this 由于事普通函数 谁点谁是this</span></span><br><span class="line">        <span class="comment">// 所以 this 指的是 colors[i]</span></span><br><span class="line">        box.innerHTML=<span class="string">&quot;该颜色为 &quot;</span>+<span class="built_in">this</span>.innerHTML;             </span><br><span class="line">    &#125;)            </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这种做法的弊端是，代码比较繁琐，并且 构建了一个循环，如果 li 标签很多性能是很差的。且不能动态的为新添加的 li 元素添加事件。</p>
<p><strong>使用事件委托</strong></p>
<p><strong>事件委托</strong>指的是，不在事件的发生地（直接dom）上设置监听函数，而是在其父 元素上设置监听函数，通过事件冒泡，父元素可以监听到子元素上事件的触发，<font color="blue">通过判断事件发生元素DOM的类型，来做出不同的响应。  </font></p>
<ul>
<li><font color="red">原理是：`evt.target` 永远拿到的都是最深层的目标节点，在点击节点的时候，由于冒泡的原因，触发了父节点的点击事件，这个时候可以通过 evt.target 拿到真正点击的深层子节点，然后做进一步逻辑</font>



</li>
</ul>
<p>使用事件委托，即我们利用事件流的特性，通过将事件绑定在 li 的父组件上。</p>
<p>利用冒泡机制，可以让父元素触发对应的事件。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">colorChange</span>(<span class="params">event</span>)</span>&#123;  </span><br><span class="line">    <span class="comment">//even.target 是事件源</span></span><br><span class="line">    <span class="keyword">if</span>(event.target.nodeName.toLowerCase()===<span class="string">&quot;li&quot;</span>)&#123;         </span><br><span class="line">        box.innerHTML=<span class="string">&quot;该颜色为 &quot;</span>+e.target.innerHTML;         </span><br><span class="line">    &#125;                            </span><br><span class="line">&#125;            </span><br><span class="line">color_list.addEventListener(<span class="string">&quot;click&quot;</span>,colorChange,<span class="literal">false</span>)</span><br></pre></td></tr></table></figure>
<p><strong>由于事件冒泡机制，点击了 li 后会冒泡到 ul ，此时就会触发绑定在 ul 上的点击事件，再利用 target 找到事件实际发生的元素（事件源 即 li），就可以达到预期的效果。</strong></p>
<font color="blue">比较合适动态元素的绑定，新添加的子元素也会有监听函数，也可以有事件触发机制。  </font>



<h3 id="面试题：阻止事件冒泡的-方法有哪些？"><a href="#面试题：阻止事件冒泡的-方法有哪些？" class="headerlink" title="面试题：阻止事件冒泡的 方法有哪些？"></a>面试题：阻止事件冒泡的 方法有哪些？</h3><p><strong>stopPropagation 方法</strong></p>
<p>在某个元素上定义 一个事件 <strong>例如onclick 的自定义函数中，添加 事件对象</strong>，然后就会<strong>阻止冒泡</strong></p>
<p>用法： <code>evt.stopPropagation()</code></p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/阻止事件冒泡.png" alt=""></p>
<ul>
<li><strong>event.target返回的是，触发事件的元素</strong></li>
<li><strong>event.currentTarget返回的是，绑定事件的元素</strong></li>
</ul>
<h3 id="面试题：有哪些方法可以阻止默认行为？"><a href="#面试题：有哪些方法可以阻止默认行为？" class="headerlink" title="面试题：有哪些方法可以阻止默认行为？"></a>面试题：有哪些方法可以阻止默认行为？</h3><p>默认行为 以及对应的阻止效果 指的是，例如：</p>
<ul>
<li>a 标签 一定会进行跳转，阻止的话就是我不跳转，我就要个你的跳转地址</li>
<li>form 表单的 submit button，点击一定会进行表单提交， 阻止的话表示我不先交，我还想验证一下你写的格式对不对等问题</li>
<li>document的oncontextmenu （右击方法），默认是显示浏览器自带的审查列表，我不想要，想自定义</li>
<li>…</li>
</ul>
<h4 id="dom0-onxxx方式-直接-return-false"><a href="#dom0-onxxx方式-直接-return-false" class="headerlink" title="dom0 onxxx方式  直接 return false"></a>dom0 <code>onxxx</code>方式  直接 return false</h4><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">document</span>.oncontextmenu = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;右键点击，自定义右键菜单&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="dom2addEventListener方式-事件对象-preventDefault"><a href="#dom2addEventListener方式-事件对象-preventDefault" class="headerlink" title="dom2addEventListener方式   事件对象.preventDefault()"></a>dom2<code>addEventListener</code>方式   事件对象.preventDefault()</h4><p>实测 IE 高版本 11 也是使用的 <code>事件对象.preventDefault()</code></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">document</span>.addEventListener(<span class="string">&quot;contextmenu&quot;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">evt</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;右键点击，自定义右键菜单&quot;</span>)</span><br><span class="line">    evt.preventDefault()</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="考点10：BOM-与-DOM-操作"><a href="#考点10：BOM-与-DOM-操作" class="headerlink" title="考点10：BOM 与 DOM 操作"></a>考点10：BOM 与 DOM 操作</h2><p><strong>BOM 是即浏览器对象模型。</strong></p>
<p>其属性对象有：<strong>window对象</strong>、window对象的属性 ： location对象、history对象、Navigator对象等</p>
<p><strong>location对象</strong>主要是存储和 URL 有关的东西，例如：</p>
<ul>
<li>location.href— 返回或设置当前文档的URL  </li>
<li>location.host—返回URL中的域名部分</li>
<li>location.hostname— 返回URL中的主域名部分</li>
<li>location.protocol— 返回URL中的协议部分</li>
</ul>
<p><strong>history对象</strong> 存储了浏览器浏览记录</p>
<ul>
<li>history.go()— 前进或后退指定的页面数 history.go(num);  </li>
<li>history.back()— 后退一页  </li>
<li>history.forward()— 前进一页</li>
</ul>
<p><strong>Navigator对象</strong> </p>
<ul>
<li>navigator.userAgent—  返回用户代理头的字符串表示(就是包括浏览器版本信息等的字 符串)  </li>
<li>navigator.cookieEnabled— 返回浏览器是否支持(启用)cookie</li>
</ul>
<p><strong>DOM 是文档对象模型。</strong>利用 DOM 我们可以操作 HTML 中的元素，使得网页被下载到浏览器后，开发者可以根据需求进行页面内容的修改。</p>
<h2 id="考点11：Ajax与跨域"><a href="#考点11：Ajax与跨域" class="headerlink" title="考点11：Ajax与跨域"></a>考点11：Ajax与跨域</h2><h4 id="面试题：原生-js-ajax-请求有哪5个步骤？分别是什么？"><a href="#面试题：原生-js-ajax-请求有哪5个步骤？分别是什么？" class="headerlink" title="面试题：原生 js ajax 请求有哪5个步骤？分别是什么？"></a>面试题：原生 js ajax 请求有哪5个步骤？分别是什么？</h4><p>分为5个步骤：</p>
<p><strong>Step1：</strong>创建 XMLHttpRequest 对象， 使用 xhr 对象发送 ajax 请求</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> xhr = <span class="keyword">new</span> XMLHttpRequest()</span><br></pre></td></tr></table></figure>
<p><strong>Step2：</strong>规定请求的类型、URL 以及是否异步处理请求。</p>
<p>xhr.open(‘请求方式’, ‘请求地址’, 是否异步)</p>
<ul>
<li>请求的方式有：get / post / put</li>
<li>请求地址：本次请求的 url</li>
<li>是否异步：本次请求是否异步，默认 true 表示异步，false 表示同步</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">xhr.open(<span class="string">&quot;GET&quot;</span>,<span class="string">&quot;http://localhost:3000/users?username=kaikai&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Step3：</strong>发送信息至服务器时内容编码类型 （get不需要）</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">xhr.setRequestHeader(<span class="string">&quot;Content-type&quot;</span>, <span class="string">&quot;application/x-www-form-urlencoded&quot;</span> 或者 <span class="string">&quot;application/json&quot;</span>);</span><br></pre></td></tr></table></figure>
<p><strong>Step4</strong>：使用 xhr 对象中的 send 方法来发送请求</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">xhr.send()</span><br><span class="line"><span class="comment">//（）中有没有参数 根据 请求来判断</span></span><br></pre></td></tr></table></figure>
<p><strong>在此时，我们（客户端）已经将请求发送给服务端了，如果服务端正常的话，就会响应东西给客户端</strong>。</p>
<p>但是要想成功的拿到响应，必须有两个条件</p>
<ul>
<li>本次 HTTP 请求是成功的，也就是 Http 状态码 （<code>xhr.status</code>）为 200 ~ 299</li>
<li>ajax 对象 xhr 也有自己的状态码（readyState），用来表示本次 ajax 请求中各个阶段</li>
</ul>
<p><strong>Step5：</strong>验证 Http状态码 和 ajax对象 xhr 状态码，接受服务器响应数据</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">xhr.onreadystatechange = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 每次 readyState 改变的时候都会触发该事件</span></span><br><span class="line">    <span class="comment">// 我们就在这里判断 readyState 的值是不是到 4</span></span><br><span class="line">    <span class="comment">// 并且 http 的状态码是不是 200 ~ 299</span></span><br><span class="line">    <span class="built_in">console</span>.log(xhr.readyState)</span><br><span class="line">    <span class="built_in">console</span>.log(xhr.status)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (xhr.readyState === <span class="number">4</span> &amp;&amp; <span class="regexp">/^2\d&#123;2&#125;$/</span>.test(xhr.status)) &#123;</span><br><span class="line">        <span class="comment">// 这里表示验证通过</span></span><br><span class="line">        <span class="comment">// 我们就可以获取服务端给我们响应的内容了</span></span><br><span class="line">        <span class="comment">// responseText 返回请求响应体内容</span></span><br><span class="line">        <span class="built_in">console</span>.log(<span class="built_in">JSON</span>.parse(xhr.responseText))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 也可以使用 xhr.onload 使用该方法，其指挥监听道 ajax状态码为 4 的时候才会有效。</span></span><br><span class="line">xhr.onload = <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="regexp">/^2\d&#123;2&#125;$/</span>.test(xhr.status))</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="built_in">JSON</span>.parse(xhr.responseText))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="面试题：ajax中-xhr的-readyState有哪几种状态，分别什么含义？"><a href="#面试题：ajax中-xhr的-readyState有哪几种状态，分别什么含义？" class="headerlink" title="面试题：ajax中 xhr的 readyState有哪几种状态，分别什么含义？"></a>面试题：ajax中 xhr的 readyState有哪几种状态，分别什么含义？</h4><p>ajax 状态码 - <code>xhr.readyState</code>   是用来表示一个 ajax 请求的全部过程中的某一个状态</p>
<ul>
<li>当状态码 为 0 时，表示未初始化完成，也就是 <code>open</code> 方法还没有执行</li>
<li>当状态码 为 1 时，表示配置信息已经完成，也就是执行完 <code>open</code> 之后，还未调用send方法</li>
<li>当状态码 为 2 时，表示 <code>send</code> 方法已经执行完成，还没接收到响应</li>
<li>当状态码 为 3 时，表示正在解析响应内容，开始接受到部分数据</li>
<li>当状态码 为 4 时，表示响应内容已经解析完毕，可以在客户端使用了</li>
</ul>
<h4 id="面试题：-ajax-请求的-5种类型"><a href="#面试题：-ajax-请求的-5种类型" class="headerlink" title="面试题： ajax 请求的 5种类型"></a>面试题： ajax 请求的 5种类型</h4><ul>
<li>get  偏向获取数据  常用</li>
<li>post  偏向提交数据  常用</li>
<li>put  偏向更新（全部）   </li>
<li>delete  偏向删除信息</li>
<li>patch 偏向部分修改</li>
</ul>
<h4 id="面试题：-ajax-的封装"><a href="#面试题：-ajax-的封装" class="headerlink" title="面试题： ajax 的封装"></a>面试题： ajax 的封装</h4><p>需要将 原生 js 里的步骤全部封装到文件中，并暴露一个 ajax 方法进行使用</p>
<p>封装代码</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * @作者: kerwin</span></span><br><span class="line"><span class="comment"> * @公众号: 大前端私房菜</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">queryStringify</span>(<span class="params">obj</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> str = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> k <span class="keyword">in</span> obj) &#123;</span><br><span class="line">        str += <span class="string">`<span class="subst">$&#123;k&#125;</span>=<span class="subst">$&#123;obj[k]&#125;</span>&amp;`</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//username=kerwin&amp;password=789&amp;</span></span><br><span class="line">    <span class="keyword">return</span> str.slice(<span class="number">0</span>, -<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 封装 ajax</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">ajax</span>(<span class="params">options</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> defaultoptions = &#123;</span><br><span class="line">        <span class="attr">url</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="attr">method</span>: <span class="string">&quot;GET&quot;</span>,</span><br><span class="line">        <span class="attr">async</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">data</span>: &#123;&#125;,</span><br><span class="line">        <span class="attr">headers</span>: &#123;&#125;,</span><br><span class="line">        <span class="attr">success</span>: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123; &#125;,</span><br><span class="line">        <span class="attr">error</span>: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">let</span> &#123; url, method, <span class="keyword">async</span>, data, headers, success, error &#125; = &#123;</span><br><span class="line">        ...defaultoptions,</span><br><span class="line">        ...options</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// console.log(url, method, async, data, headers, success, error)</span></span><br><span class="line">    <span class="comment">// 这个问号的意思是  ? 如果前面取不到就 返回undefined</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">typeof</span> data === <span class="string">&#x27;object&#x27;</span> &amp;&amp; headers[<span class="string">&quot;content-type&quot;</span>]?.indexOf(<span class="string">&quot;json&quot;</span>) &gt; -<span class="number">1</span>) &#123;</span><br><span class="line">        data = <span class="built_in">JSON</span>.stringify(data)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        data = queryStringify(data)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// // 如果是 get 请求, 并且有参数, 那么直接组装一下 url 信息</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="regexp">/^get$/i</span>.test(method) &amp;&amp; data) url += <span class="string">&#x27;?&#x27;</span> + data</span><br><span class="line"></span><br><span class="line">    <span class="comment">// // 4. 发送请求</span></span><br><span class="line">    <span class="keyword">const</span> xhr = <span class="keyword">new</span> XMLHttpRequest()</span><br><span class="line">    xhr.open(method, url, <span class="keyword">async</span>)</span><br><span class="line">    xhr.onload = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!<span class="regexp">/^2\d&#123;2&#125;$/</span>.test(xhr.status)) &#123;</span><br><span class="line">            <span class="comment">// console.log(error)</span></span><br><span class="line">            error(<span class="string">`错误状态码:<span class="subst">$&#123;xhr.status&#125;</span>`</span>) <span class="comment">//回调</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行解析</span></span><br><span class="line">        <span class="comment">// try catch 是防止你返回来的不是 json 格式导致报错</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> result = <span class="built_in">JSON</span>.parse(xhr.responseText)</span><br><span class="line">            success(result)</span><br><span class="line">        &#125; <span class="keyword">catch</span> (err) &#123;</span><br><span class="line">            error(<span class="string">&#x27;解析失败 ! 因为后端返回的结果不是 json 格式字符串&#x27;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// console.log(22222)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 请求头内表示传递的参数格式 </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> k <span class="keyword">in</span> headers)</span><br><span class="line">        xhr.setRequestHeader(k, headers[k])</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是 GET 就直接发送</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="regexp">/^get$/i</span>.test(method)) &#123;</span><br><span class="line">        xhr.send()</span><br><span class="line">        <span class="comment">// 否则需要传入data</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        xhr.send(data)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> ajax</span><br></pre></td></tr></table></figure>
<p><strong>调用 ajax 方法</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">ajax(&#123;</span><br><span class="line">    <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/users&quot;</span>,</span><br><span class="line">    <span class="attr">method</span>:<span class="string">&quot;POST&quot;</span>,</span><br><span class="line">    <span class="attr">data</span>:&#123;</span><br><span class="line">        <span class="attr">username</span>:<span class="string">&quot;kerwin3333&quot;</span>,</span><br><span class="line">        <span class="attr">password</span>:<span class="string">&quot;789&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">headers</span>:&#123;</span><br><span class="line">        <span class="string">&quot;content-type&quot;</span>:<span class="string">&quot;application/x-www-form-urlencoded&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">success</span>:<span class="function"><span class="keyword">function</span>(<span class="params">res</span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;sucess&quot;</span>,res)</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">error</span>:<span class="function"><span class="keyword">function</span>(<span class="params">err</span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;error&quot;</span>,err)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>url: 是服务器的地址，Get和Post是不需要引入参数的   其他需要定位的需要引入参数 如id号</li>
<li>method：传入的请求方法 </li>
<li>data:用来定义传入的数据，一定要是 obj格式的</li>
<li>headers: 也就是我们data输入的是什么形式的   就两种  我们一般采取第二种，后面看成JSON处理即可，第一种的话，后面会用字符串的形式，拼成可以使用的obj类型<ul>
<li><code>&quot;content-type&quot;:&quot;application/x-www-form-urlencoded&quot;</code></li>
<li><code>&quot;content-type&quot;:&quot;application/json&quot;</code></li>
</ul>
</li>
<li>success：成功返回的内容 res ，对其进行操作</li>
<li>error： 失败返回的内容 err，对其进行操作</li>
</ul>
<h4 id="面试题：跨域产生的原因？"><a href="#面试题：跨域产生的原因？" class="headerlink" title="面试题：跨域产生的原因？"></a>面试题：跨域产生的原因？</h4><p>同源策略限制，不同源会造成跨域。以下任意一种情况不同，都是不同源。</p>
<p><strong>同源：1. 协议；2.域名；3.端口号三者要求全部相同，只要有一个不相同就是非同源策略。</strong></p>
<h4 id="面试题：跨域解决方案有哪些？"><a href="#面试题：跨域解决方案有哪些？" class="headerlink" title="面试题：跨域解决方案有哪些？"></a>面试题：跨域解决方案有哪些？</h4><ul>
<li><p>cors 由后端设置 <strong>Access-Control-Allow-Origin</strong>   <strong>设置为* 则表示所有域名可控制。</strong></p>
<font color="red">但是此方法需要后端进行配合。</font>

<p>例如数据是用json-server 搭建在 3000端口号上的，但是 preview on browser 是在 8080 端口上，这明显是个跨域访问的问题。</p>
<p>json-server 在 response headers 中 可以传递给8080端口 <code>http://localhost:8080</code></p>
<blockquote>
<p>CORS 需要浏览器和后端同时支持。IE 8 和 9 需要通过 XDomainRequest 来实现。</p>
<p>浏览器会自动进行 CORS 通信，实现 CORS 通信的关键是后端。只要后端实现了 CORS，就实现了跨域。</p>
<p>服务端设置 Access-Control-Allow-Origin 就可以开启 CORS。 该属性表示哪些域名可以访问资源，如果设置通配符则表示所有网站都可以访问资源。</p>
</blockquote>
<p><img src="http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/QQ截图20221130144553.png" style="zoom:67%;" /></p>
</li>
<li><p>jsonp  前后端交互实现 （因为前后端都要干 所以不常用  而且其只能解决 get 请求，其他不行，<font color="red"><strong>但是面试很喜欢考这个</strong></font>）</p>
<p>jsonp 原理：<strong>动态创建script标签，因为其src属性指向没有跨域限制</strong>，其指向一个接口，接口返回的格式一定是 某某方法名（）函数表达式。</p>
<p>所有的 src 属性和 href 属性都不受同源策略限制。可以请求第三方服务器数据内容。</p>
<p><strong>jsonp 的缺点</strong></p>
<ol>
<li><p>后端接口形式必须是  <strong>某某名字（），需要后端进行配合</strong></p>
<p>这个是可以改的，一般键叫做cb，我后面的函数某某名字 可以根据前端写的进行修改</p>
<p>例如百度联想提供的搜索引擎：&amp;cb=test&amp;_=1669794337686，test为前端写的方法，cb是后端暴露的接口</p>
</li>
<li><p>会一直动态叠加相同的script标签，所以在onload时删除script标签</p>
</li>
<li><p>只能进行 get 请求，不能post put patch 和 delete。</p>
</li>
</ol>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">id</span>=<span class="string">&quot;mybtn&quot;</span>&gt;</span>jsonp<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">        <span class="function"><span class="keyword">function</span> <span class="title">test</span>(<span class="params">obj</span>)</span>&#123;</span></span><br><span class="line"><span class="javascript">            <span class="built_in">console</span>.log(obj)</span></span><br><span class="line"><span class="javascript">        &#125;</span></span><br><span class="line"><span class="javascript">        mybtn.onclick = <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">var</span> oscript = <span class="built_in">document</span>.createElement(<span class="string">&quot;script&quot;</span>)</span></span><br><span class="line"><span class="javascript">            <span class="comment">// 配置script结点的src属性</span></span></span><br><span class="line"><span class="javascript">            oscript.src = <span class="string">&quot;01.txt&quot;</span> <span class="comment">// 未来地址 可以是 txt文本 也可以是 服务器地址</span></span></span><br><span class="line"><span class="javascript">            <span class="built_in">document</span>.body.appendChild(oscript)</span></span><br><span class="line"><span class="javascript">            oscript.onload = <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span></span><br><span class="line"><span class="javascript">                <span class="comment">//删除当前结点</span></span></span><br><span class="line"><span class="javascript">                oscript.remove()</span></span><br><span class="line"><span class="javascript">            &#125;</span></span><br><span class="line"><span class="javascript">        &#125;</span></span><br><span class="line"><span class="javascript">    </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>反向代理</strong>   比如常见的 nginx反向代理，Vue 中的 vue-cli 脚手架配置的反向代理等。</p>
<p>其实现的原理为：</p>
<p><img src="https://gitee.com/kaikai-superman/imgs/raw/master/img/384df09d184a4d4eb576ff000a433413.png" style="zoom: 67%;" /></p>
<p>​     反向代理的 协议，服务器地址和端口与  客户端保持一致， 客户端 通过 ajax 将请求发给 代理服务器（因为同源所以成功）; 代理服务器将请求再发给 真正的服务端 ，然后获取数据再 response给 客户端</p>
<font color="red">**为什么 代理服务器和 服务端 不同源也可以？**</font>

<p>因为他压根用的不是 ajax，只有前端采用这个，其使用普通 http 协议就可以通信了！</p>
</li>
</ul>
<h2 id="考点12：ES6-一般指-ES6-ES13-篇"><a href="#考点12：ES6-一般指-ES6-ES13-篇" class="headerlink" title="考点12：ES6 (一般指 ES6- ES13)篇"></a>考点12：ES6 (一般指 ES6- ES13)篇</h2><h3 id="面试题：ES6的新特性有哪些？"><a href="#面试题：ES6的新特性有哪些？" class="headerlink" title="面试题：ES6的新特性有哪些？"></a>面试题：ES6的新特性有哪些？</h3><p><a href="https://juejin.cn/post/7087403522806775815">https://juejin.cn/post/7087403522806775815</a></p>
<ul>
<li><p>引入了 class 类，让js面向对象的变成更易于理解。<strong>ES6的class不是新的对象继承模型，它只是原型链的语法糖表现形式。</strong></p>
</li>
<li><p>ES6中模块作为重要的组成部分被添加进来。模块的功能主要由 export 和 import 组成。</p>
</li>
<li><p>箭头函数</p>
<p><find>不论是箭头函数还是bind，每次被执行都返回的是一个新的函数引用，因此如果你还需要函数的引用去做一些别的事情（譬如卸载监听器），那么你必须自己保存这个引用。&lt;/font&gt;</p>
</li>
<li><p>函数参数默认值</p>
</li>
<li><p>模板字符串</p>
</li>
<li><p><strong>解构赋值 （数组 对象均使用）</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">sum</span>(<span class="params">x, y, z</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x + y + z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">const</span> numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line"><span class="comment">//不使用延展操作符</span></span><br><span class="line"><span class="built_in">console</span>.log(sum.apply(<span class="literal">null</span>, numbers));</span><br><span class="line"><span class="comment">//使用延展操作符</span></span><br><span class="line"><span class="built_in">console</span>.log(sum(...numbers));<span class="comment">// 6</span></span><br></pre></td></tr></table></figure>
<p>例如：用于构造数组/对象</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> stuendts = [<span class="string">&#x27;Jine&#x27;</span>,<span class="string">&#x27;Tom&#x27;</span>]; </span><br><span class="line"><span class="keyword">const</span> persons = [<span class="string">&#x27;Tony&#x27;</span>,... stuendts,<span class="string">&#x27;Aaron&#x27;</span>,<span class="string">&#x27;Anna&#x27;</span>];</span><br><span class="line">conslog.log(persions)<span class="comment">// [&quot;Tony&quot;, &quot;Jine&quot;, &quot;Tom&quot;, &quot;Aaron&quot;, &quot;Anna&quot;]</span></span><br></pre></td></tr></table></figure>
<p>数组/对象拷贝和连接多个数组/对象</p>
<font color="red">**注意：拷贝都是浅拷贝**</font>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line"><span class="keyword">var</span> arr2 = [...arr]; <span class="comment">// 等同于 arr.slice()</span></span><br><span class="line"><span class="keyword">var</span> arr2 = <span class="built_in">Object</span>.assign(arr)  <span class="comment">// 与上面一致</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> arr1 = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>];</span><br><span class="line"><span class="keyword">var</span> arr2 = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line"><span class="keyword">var</span> arr3 = [...arr1, ...arr2];<span class="comment">// 将 arr2 中所有元素附加到 arr1 后面并返回</span></span><br><span class="line"><span class="comment">//等同于</span></span><br><span class="line"><span class="keyword">var</span> arr4 = arr1.concat(arr2);</span><br></pre></td></tr></table></figure>
</li>
<li><p>对象属性简写  </p>
<p>例如再 obj 中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> student = &#123;</span><br><span class="line">	<span class="attr">name</span>:name,</span><br><span class="line">	<span class="attr">age</span>:age</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 因为键和值(变量)相同，所以可以简写</span></span><br><span class="line"><span class="keyword">const</span> student = &#123;</span><br><span class="line">	name</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Promise  异步编程串行化 解决回调地狱</p>
</li>
<li><p>let 和 const 出现  他们与 var 的区别主要在于 其<strong>具有块级作用域</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="keyword">var</span> a = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(a); <span class="comment">// 输出10</span></span><br><span class="line">——————————————————————————————————————————————————————————————————</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">let</span> a = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(a); <span class="comment">//-1 or Error“ReferenceError: a is not defined”</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="面试题：ES7-有哪些新特性？"><a href="#面试题：ES7-有哪些新特性？" class="headerlink" title="面试题：ES7 有哪些新特性？"></a>面试题：ES7 有哪些新特性？</h3><ul>
<li>数组<code>includes()</code>方法 【Array.prototype.includes()】，用来判断一个数组是否包含一个指定的值，根据情况，如果包含则返回true，否则返回false。</li>
<li>a ** b指数运算符，它与 Math.pow(a, b)相同。</li>
</ul>
<h3 id="面试题：ES8-有哪些新特性？"><a href="#面试题：ES8-有哪些新特性？" class="headerlink" title="面试题：ES8 有哪些新特性？"></a>面试题：ES8 有哪些新特性？</h3><ul>
<li><p><font  color="red"><strong>async/await</strong></font>    <strong>非常重要</strong></p>
</li>
<li><p>```javascript<br>// 直接获取对象属性<br>Object.values()<br>// 可以迭代遍历 对象键+值了<br>for(let [key,value] of Object.entries(obj1))</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- String padding: `padStart()`和`padEnd()`，填充字符串达到当前长度</span><br><span class="line"></span><br><span class="line">- 函数参数列表结尾允许逗号</span><br><span class="line"></span><br><span class="line">- ```javascript</span><br><span class="line">  //函数用来获取一个对象的所有自身属性的描述符,如果没有任何自身属性，则返回空对象。</span><br><span class="line">  Object.getOwnPropertyDescriptors()</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>ShareArrayBuffer</code>和<code>Atomics</code>对象，用于从共享内存位置读取和写入。 这个忽略不看，我觉得不重要。</p>
</li>
</ul>
<h3 id="面试题：ES9-有哪些新特性？"><a href="#面试题：ES9-有哪些新特性？" class="headerlink" title="面试题：ES9 有哪些新特性？"></a>面试题：ES9 有哪些新特性？</h3><ul>
<li><p>异步迭代</p>
</li>
<li><font color="red">**Promise.finally()**</font>

<p>一个Promise调用链要么成功到达最后一个<code>.then()</code>，要么失败触发<code>.catch()</code>。在某些情况下，你想要在无论Promise运行成功还是失败，运行相同的代码，例如清除，删除对话，关闭数据库连接等。</p>
<p><code>.finally()</code>允许你指定最终的逻辑：</p>
</li>
<li><p><strong>Rest/Spread 属性</strong></p>
<p>Rest参数语法允许我们将<strong>一个不定数量的参数表示为一个数组/对象</strong>。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">restParam(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// P3 会接剩下的部分</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">restParam</span>(<span class="params">p1, p2, ...p3</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// p1 = 1</span></span><br><span class="line">  <span class="comment">// p2 = 2</span></span><br><span class="line">  <span class="comment">// p3 = [3, 4, 5]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="面试题：ES10-有哪些新特性？"><a href="#面试题：ES10-有哪些新特性？" class="headerlink" title="面试题：ES10 有哪些新特性？"></a>面试题：ES10 有哪些新特性？</h3><ul>
<li><p><font color="blue">新增了Array的<code>flat()</code>方法和<code>flatMap()</code>方法</font>  <code>flat()</code>和<code>flatMap()</code>本质上就是是归纳（reduce） 与 合并（concat）的操作。</p>
<p>flat() 方法主要是用于 <strong>数组降维</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr2 = [<span class="number">1</span>, <span class="number">2</span>, [<span class="number">3</span>, <span class="number">4</span>, [<span class="number">5</span>, <span class="number">6</span>]]];</span><br><span class="line">arr2.flat();</span><br><span class="line"><span class="comment">// [1, 2, 3, 4, [5, 6]]</span></span><br></pre></td></tr></table></figure>
<p>其次，还可以利用<code>flat()</code>方法的特性来去除数组的空项</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr4 = [<span class="number">1</span>, <span class="number">2</span>, , <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line">arr4.flat();</span><br><span class="line"><span class="comment">// [1, 2, 4, 5]</span></span><br></pre></td></tr></table></figure>
<p>flatMap() 暂时没看到非常有用的用处，应该不考</p>
</li>
<li><font color="blue">String 的去除前后空白字符   String的`trimStart()`方法和`trimEnd()`方法</font>



</li>
</ul>
<h2 id="考点13：Js的五种模块化的方式有哪些？有什么区别？"><a href="#考点13：Js的五种模块化的方式有哪些？有什么区别？" class="headerlink" title="考点13：Js的五种模块化的方式有哪些？有什么区别？"></a>考点13：Js的五种模块化的方式有哪些？有什么区别？</h2><ul>
<li>AMD (异步模块定义)和 CMD （公共模块定义）都是<strong>浏览器端</strong>的JS模块化规范，分别由require.js和sea.js实现</li>
<li>CommonJS（缩写：CJS ）是<strong>服务器端</strong>的js模块化规范，<strong>由NodeJS实现</strong>  模块输出，modules.exports，模块加载require()引入模块。  </li>
<li>ES6 提出的方案（ESM），使用 import 和 export 的形式来导入导出模块，在nodeJS新版本中可以直接使用。</li>
<li>另外还有一些独特的例如  <strong>UMD</strong> （通用模块定义）他是 AMD 和 Common JS 糅合的产物。</li>
</ul>
<h2 id="考点14：基于ajax-更新的异步通信的方式有哪些"><a href="#考点14：基于ajax-更新的异步通信的方式有哪些" class="headerlink" title="考点14：基于ajax 更新的异步通信的方式有哪些"></a>考点14：基于ajax 更新的异步通信的方式有哪些</h2><p>ajax存在的问题就是   <font color="blue">比如使用Ajax 对某个数据的获取，需要先访问上一个数据拿到对应的索引再获取。这样重复，就会导致可读性非常的差，而且不好维护，因为嵌套的过于难看，不清晰。</font> 产生回调地狱，代码横向生长了。</p>
<h3 id="面试题：谈一下对Promise的理解"><a href="#面试题：谈一下对Promise的理解" class="headerlink" title="面试题：谈一下对Promise的理解"></a>面试题：谈一下对Promise的理解</h3><p>promise 的目的是为了解决ajax的回调地狱问题，将原来的嵌套访问，变成了链式访问。是一个成熟方案。</p>
<p>其基础语法定义为：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function"><span class="keyword">function</span> (<span class="params">resolve, reject</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// resolve 表示成功的回调</span></span><br><span class="line">  <span class="comment">// reject 表示失败的回调</span></span><br><span class="line">    这里面一定要调用 resolve/reject 才能跳转到对应的 then 或者 err中</span><br><span class="line">&#125;).then(<span class="function"><span class="keyword">function</span> (<span class="params">res</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="string">&quot;成功&quot;</span>,res)</span><br><span class="line">  <span class="comment">// 成功的函数</span></span><br><span class="line">&#125;).catch(<span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="string">&quot;失败&quot;</span>,err)</span><br><span class="line">  <span class="comment">// 失败的函数</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>每一个异步事件的执行，都有三种状态 <font color="red"><strong>执行中（pending） / 成功（fulfilled） / 失败（Rejected）</strong></font></p>
<p><code>Promise</code>对象的状态改变，只有两种可能：从<code>Pending</code>变为<code>fulfilled</code>和从<code>Pending</code>变为<code>Rejected</code>。</p>
<p><strong>总结</strong></p>
<p>是用来解决回调地域的，其解决回调地域的思想就是promise构造函数生成promise对象之后，就会处于执行中（pending）这个状态。如果在异步结束成功了，这个对象就会调用resolve回调，也就是到了成功（fulfilled）状态，就会调用then里面的内容执行成功的函数，反之就会调用reject回调 进入失败（reject）状态 在catch中执行失败函数。</p>
<p><strong>封装 Promise 再 ajax 后</strong></p>
<p>如何封装看下面：比如封装成 <code>pajax</code>方法</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">pajax</span>(<span class="params">options</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="comment">// 这里是封装的 ajax</span></span><br><span class="line">        ajax(&#123;</span><br><span class="line">            ...options,</span><br><span class="line">            <span class="function"><span class="title">success</span>(<span class="params">res</span>)</span> &#123;</span><br><span class="line">                resolve(res)</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="function"><span class="title">error</span>(<span class="params">err</span>)</span> &#123;</span><br><span class="line">                reject(err)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 嵌套变成链式调用  == 每次成功就return一个 pajax回去  我们总体最后返回一个错误catch即可</span></span><br><span class="line">pajax(&#123;</span><br><span class="line">    <span class="comment">// options 传入</span></span><br><span class="line">    <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/news&quot;</span>,</span><br><span class="line">    <span class="attr">data</span>:&#123;</span><br><span class="line">        <span class="attr">author</span>:<span class="string">&quot;tiechui&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 源码执行了 success</span></span><br><span class="line">&#125;).then(<span class="function"><span class="params">res</span> =&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> pajax(&#123;</span><br><span class="line">        <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/comments&quot;</span>,</span><br><span class="line">        <span class="attr">data</span>:&#123;</span><br><span class="line">            <span class="attr">newsId</span>: res[<span class="number">0</span>].id,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;).then(<span class="function"><span class="params">res</span> =&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;success&quot;</span>, res)</span><br><span class="line">&#125;).catch(<span class="function"><span class="params">err</span> =&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;error&quot;</span>, err)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="面试题：谈一下对-Promise-all-的理解"><a href="#面试题：谈一下对-Promise-all-的理解" class="headerlink" title="面试题：谈一下对 Promise.all 的理解"></a>面试题：谈一下对 Promise.all 的理解</h3><p>请求如果顺序写，并不能实现并行的效果。因为请求一定是先后请求服务器，获取结果有时间差。</p>
<p>为了展示出并行的效果，我们使用 Promise.all 方法，其可以使得引入的 请求列表，在所有请求的完成之后，then返回一个整体的结果，如果出错则在catch中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 可以使用 Promise.all 来将两个 promise封装的ajax请求同步获取最后结果</span></span><br><span class="line"><span class="keyword">let</span> q1 = pajax(&#123;</span><br><span class="line">    <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/looplist&quot;</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">let</span> q2 = pajax(&#123;</span><br><span class="line">    <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/datalist&quot;</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment">// 为了不是分别加载，所以这里要两个q1和q2 ajax请求全部到位（模拟出并发），res中得到两个请求返回 整合在一起了</span></span><br><span class="line"><span class="built_in">Promise</span>.all([q1,q2]).then(<span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(res)</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;隐藏加载中&quot;</span>)</span><br><span class="line">&#125;).catch(<span class="function"><span class="params">err</span> =&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(err)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="面试题：如何理解-aync-await？"><a href="#面试题：如何理解-aync-await？" class="headerlink" title="面试题：如何理解 aync/await？"></a>面试题：如何理解 aync/await？</h3><p>使用 <code>Promise</code> 能很好地解决回调地狱的问题，但是这种方式充满了 <code>Promise</code> 的 <code>then()</code> 方法，如果处理流程比较复杂的话，那么整段代码将充斥着 <code>then</code>，语义化不明显，代码不能很好地表示执行流程。</p>
<p>基于这个原因，ES7 引入了 <code>async</code>/<code>await</code>，这是 JavaScript 异步编程的一个重大改进，提供了 <strong>在不阻塞主线程的情况下使用同步代码实现异步访问资源的能力</strong>，并且使得代码逻辑更加清晰。<font color="red">也就是 我可以直接顺序写。</font></p>
<font color="red">ASYNC 和 AWAIT 需要配合使用 的**封装后的 promise对象**</font>

<p>语法格式为：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">test</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// await 用于同步代码 或者 promise对象（因为其为异步）</span></span><br><span class="line">    <span class="keyword">await</span> pajax(&#123;</span><br><span class="line">        <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/list&quot;</span>,</span><br><span class="line">        <span class="attr">data</span>:&#123;</span><br><span class="line">            <span class="attr">value</span>:<span class="string">&quot;凯凯超人&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;).then( <span class="function"><span class="params">res</span> =&gt;</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;请求成功&quot;</span>,res)</span><br><span class="line">    &#125;).catch(<span class="function"><span class="params">err</span> =&gt;</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;请求失败&quot;</span>,err)</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="number">2222</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>下面才是 真正的 async/await 使用的方法</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">test</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// await 用于同步代码 或者 promise对象（因为其为异步）</span></span><br><span class="line">    <span class="keyword">let</span> res = <span class="keyword">await</span> pajax(&#123;</span><br><span class="line">        <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/news&quot;</span>,</span><br><span class="line">        <span class="attr">data</span>:&#123;</span><br><span class="line">            <span class="attr">author</span>:<span class="string">&quot;tiechui&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">let</span> res1 = pajax(&#123;</span><br><span class="line">        <span class="attr">url</span>:<span class="string">&quot;http://localhost:3000/comments&quot;</span>,</span><br><span class="line">        <span class="attr">data</span>:&#123;</span><br><span class="line">            <span class="attr">newsId</span>: res[<span class="number">0</span>].id</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span> res1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">test().then( <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;成功获取&quot;</span>,res)</span><br><span class="line">&#125;).catch( <span class="function"><span class="params">err</span> =&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&quot;获取失败&quot;</span>,err)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><img src="http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/QQ截图20221127200934.png" alt=""></p>
<h3 id="面试题：如何理解-xhr-和-fetch-的区别？"><a href="#面试题：如何理解-xhr-和-fetch-的区别？" class="headerlink" title="面试题：如何理解  xhr 和 fetch 的区别？"></a>面试题：如何理解  xhr 和 fetch 的区别？</h3><p><code>XMLHttpRequest</code> 是一个设计粗糙的 API，配置和调用方式非常混乱， 而且基于事件的异步模型写起来不友好。其含有多步骤，主要分为三步  （按照传输方式，细节有所不同，查看 <strong>ajax获取数据方式章节</strong>）</p>
<ul>
<li>创建一个 ajax 对象</li>
<li>配置链接信息</li>
<li>发送请求</li>
</ul>
<p>fetch 是用来后续替代 xhr 的，但是目前能支持fetch的浏览器版本比较高，所以现在常用的还是 xhr。</p>
<font color="red">**fetch实际上是基于Promise做的操作**。</font>

<p>fetch 比 xhr 相对便捷的地方在于，<strong>其不需要引入一个 util.js 专门封装 xhr 实现 ajax 的文件</strong>。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// fetch 返回的 res 是个结构体，里面包含很多信息，包括是否成功，以及错误类型和返回数据等等</span></span><br><span class="line">myget.addEventListener(<span class="string">&quot;click&quot;</span>,<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 这个返回的是一个promise对象 pending状态 状态如果成功就是 fulfilled态，此时结果是个 ResPonse结构体，里面包含很多信息</span></span><br><span class="line">    fetch(<span class="string">&quot;http://localhost:3000/users&quot;</span>)    </span><br><span class="line">    .then(<span class="function"><span class="params">res</span> =&gt;</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(res.ok)</span><br><span class="line">            <span class="keyword">return</span> res.json()  <span class="comment">// res.text() 是获取字符格式的 obj   res.join() 会自动解析成obj  这里相当于成功回调resolve 走then</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="comment">// 这里使用了一个 Promise 拒绝回调相当于之前的 reject 会去执行下面的 catch （这里有个特点 如果不写的话，他默认会走then的 无论你是不是返回成功，一定要拒绝才可以）</span></span><br><span class="line">            <span class="comment">// 同样也有 Promise.resolve() 同意回调 但这里用不到，这里要拒绝</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">Promise</span>.reject(&#123;</span><br><span class="line">                <span class="attr">status</span>:res.status,</span><br><span class="line">                <span class="attr">statusText</span>:res.statusText</span><br><span class="line">            &#125;)</span><br><span class="line">    &#125;)  <span class="comment">// 这个返回的是一个promise对象 处于pending状态 状态转换看是否成功 分别指向下面两处</span></span><br><span class="line">    .then(<span class="function"><span class="params">res</span> =&gt;</span>&#123;   <span class="comment">// 这里相当于成功返回之后要干嘛 我拿到了返回的数据</span></span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;成功获取&quot;</span>, res)</span><br><span class="line">    &#125;)</span><br><span class="line">    .catch(<span class="function"><span class="params">err</span> =&gt;</span>&#123;  <span class="comment">// 正常是打印 失败的信息手动在前面的拒绝中返回 我们需要的东西</span></span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&quot;获取失败&quot;</span>, err)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="考点15：JS的事件循环（事件队列）-（宏任务和微任务）"><a href="#考点15：JS的事件循环（事件队列）-（宏任务和微任务）" class="headerlink" title="考点15：JS的事件循环（事件队列） （宏任务和微任务）"></a>考点15：JS的事件循环（事件队列） （宏任务和微任务）</h2><h3 id="面试题：JS的-同步任务与异步任务-起因？"><a href="#面试题：JS的-同步任务与异步任务-起因？" class="headerlink" title="面试题：JS的 同步任务与异步任务 起因？"></a>面试题：JS的 同步任务与异步任务 起因？</h3><p>JS是一门单线程语言，单线程就意味着，所有的任务需要排队，前一个任务结束，才会执行下一个任务。</p>
<p>这样所导致的问题是：如果JS执行的时间过长，这样就会造成页面的渲染不连贯，导致页面渲染加载阻塞</p>
<p>为了解决这个问题，JS中出现了同步和异步。他们的本质区别是：一条流水线上各个流程的执行顺序不同。在讲JS任务执行机制前，先要了解一下什么是同步任务与异步任务。</p>
<ul>
<li><strong>同步任务：</strong>即主线程上的任务，按照顺序由上⾄下依次执⾏，当前⼀个任务执⾏完毕后，才能执⾏下⼀个任务。</li>
<li><strong>异步任务：</strong>不进⼊主线程，⽽是进⼊任务队列的任务，执行完毕之后会产生一个回调函数,并且通知主线程。当主线程上的任务执行完后，就会调取最早通知自己的回调函数，使其进入主线程中执行。</li>
</ul>
<h3 id="面试题：什么是-JS的事件循环（loop-或队列），宏任务和微任务的定义？-loop具体的执行机制描述？"><a href="#面试题：什么是-JS的事件循环（loop-或队列），宏任务和微任务的定义？-loop具体的执行机制描述？" class="headerlink" title="面试题：什么是 JS的事件循环（loop 或队列），宏任务和微任务的定义？ loop具体的执行机制描述？"></a>面试题：什么是 JS的事件循环（loop 或队列），宏任务和微任务的定义？ loop具体的执行机制描述？</h3><p>事件循环指的是<font color="blue"><strong>js代码所在运行环境（浏览器、nodejs）编译器的一种解析执行规则</strong></font>。事件循环不属于js代码本身的范畴，而是属于<strong>js编译器的范畴</strong>，在js中讨论事件循环是没有意义的。</p>
<p>换句话说，js代码可以理解为是一个人在公司中具体做的事情， 而 事件循环 相当于是公司的一种规章制度。 两者不是一个层面的概念。</p>
<h4 id="微任务、宏任务"><a href="#微任务、宏任务" class="headerlink" title="微任务、宏任务"></a>微任务、宏任务</h4><ol>
<li><p>微任务与宏任务就属于js代码的范畴</p>
</li>
<li><p>js代码主要分为两大类： 同步代码、异步代码</p>
<font color="red">**注意：Promise 和 async/await 是同步代码，await XXX    XXX是同步代码**</font>
</li>
<li><p><strong>异步代码又分为：微任务与宏任务</strong></p>
<font color="red">**Promise的 .then是一个微任务， await 下一行及其之后的代码也是微任务。**</font>

</li>
</ol>
<p>宏任务包括：</p>
<ul>
<li><p><strong>setTimeout 和 setInterval</strong>， I/O文件读取 例如 fs.readFile()， 事件</p>
</li>
<li><p>postMessage</p>
</li>
<li><p>setImmediate (node中的特性，浏览器已经废弃该API)</p>
</li>
<li><p>requestAnimationFrame() 请求动画帧</p>
<p>他的作用就是代替定时器做更加<strong>流畅高性能</strong>的动画，做可以匹配设备刷新率的动画，他解决了<strong>定时器做动画时间间隔不稳定的问题</strong>（也就是解决定时器做动画不流畅的问题）。他的用法与setTimeout差不多。</p>
</li>
<li><p>UI渲染</p>
</li>
<li><p>ajax</p>
</li>
</ul>
<p>微任务包括：</p>
<ul>
<li>Promise.then  catch finally</li>
<li>async/await</li>
<li>MutationObserver（chrome种 node无）</li>
<li>process.nextTick (node中)</li>
</ul>
<h4 id="事件循环Event-Loop执行机制"><a href="#事件循环Event-Loop执行机制" class="headerlink" title="事件循环Event Loop执行机制"></a>事件循环Event Loop执行机制</h4><p>1.进入到script标签,就进入到了第一次事件循环.</p>
<p>2.遇到同步代码，立即执行，然后继续读</p>
<p>3.如果遇到宏任务,放入到宏任务队列里，跳过宏任务的代码，继续顺序读同步的</p>
<p>4.如果遇到微任务,放入到微任务队列里，也跳过微任务的代码，继续顺序读同步的</p>
<p>5.程序到最后了，所有同步代码都执行完毕</p>
<p>6.这个时候我们开始读取微任务队列，采取先进先出的原则，执行第一个先存入的微任务代码。 执行过程同样是一次 先同步，碰到宏任务进宏任务队列，微任务进微任务队列的做法。</p>
<p>7.微任务队列中，所有微任务代码执行完毕，本次队列清空</p>
<p>8.这个时候开始执行 宏任务队列中的任务，同样先执行第一个先存入的宏任务，执行过程同样是一次 先同步，碰到宏任务进宏任务队列，微任务进微任务队列的做法。</p>
<p>直到所有同步，微任务，宏任务全部完事，叫执行完毕。</p>
<p>面试中经常碰到题目：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/55a2699ee99c456186b774afecd78a4e~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt=""></p>
<p>解答：</p>
<font color="blue">promise本身是一个同步的代码(只是容器)，只有它后面调用的then()方法里面的回调才是微任务。</font>

<p>所以先顺序执行同步代码，发现有个 Promise是个同步代码，所以先执行。执行发现里面有个同步代码 打印777，所以先打印777，然后顺序同步执行resolve()，发现微任务 Promise.then。将.then对于的回调函数存入 微任务队列。然后我再顺序执行同步代码，发现999，打印999。这个时候发现我们已经读到最后了，这个时候去找微任务队列，发现不为空，取出第一个（也是唯一一个），顺序执行里面的代码，发现同步代码 打印888，所以我们打印888，然后代码结束。微任务队列中没有其他微任务了，然后看宏任务队列，发现也是空的。所以程序彻底结束。</p>
<p><strong>正确答案：  7777  9999  8888</strong></p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9beb8dd124454046b53f74a472717b5e~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt=""></p>
<font color="blue">await右边的表达式还是会立即执行,表达式之后的代码才是微任务, await微任务可以转换成等价的promise微任务分析</font>

<p>顺序执行同步代码，发现打印1，所以打印了1。然后顺序发现 async 方法 async1() (<strong>中间一堆需要被调用才会执行奥，别搞错我说的是最后一行那个调用的</strong>)，其await 紧跟的方法是同步代码会立即执行，所以跳转到 async2方法，其也是一个 async方法，顺序同步执行，里面的函数内容同样是顺序执行，打印3。然后 async2 方法执行结束，其后面的部分代码全被定义为 微任务，所以整个存入 微任务队列。 这个时候发现已经到底了，所以我们去查看微任务队列，发现里面有，拿出第一个，然后顺序同步执行里面的代码，发现只有 打印2，所以打印2之后。发现微任务队列和宏任务队列全部为空，所以程序结束。</p>
<p><strong>正确答案： 1 3 2</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/27f658ad77f146608950bccebe7dff97~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt=""></p>
<font color="blue">script标签本身是一个`宏任务`， 当页面出现多个script标签的时候，浏览器会把script标签作为宏任务来解析</font>

<p>我们也是顺序读同步代码，发现第一个script标签，是个宏任务，所以存入宏任务队列，然后跳过整个宏任务代码，我们继续读同步代码。又发现一个  script标签，也是一个宏任务，我继续存入宏任务队列。这个时候我们的程序到底了，所以我们先去看微任务队列，发现为空。所以我们再去找宏任务队列，发现不为空，取出第一个，即第一次存入的script标签，然后顺序执行里面的同步代码，发现同步代码打印1，然后又看到一个宏任务 setTimeOut 将这个宏任务也存入宏任务队列。这个时候这个宏任务执行完毕，开始下一个宏任务，顺序执行打印出3，然后再下一个宏任务也就是刚才存入的 setTimeOut，顺序执行里面的函数，执行同步代码 打印2。此时发现微任务队列和宏任务队列全部为空，所以程序结束。</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4860b43cd48d42028f3c6a7adf1f1a0a~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt=""></p>
<p>正确答案：1 4 6 2 5 3</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a09ff1dcda4e44858fd3416bff1d0283~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt=""></p>
<p>正确答案：1 5 7 6 2 3 4</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/72d83f696a654b7994616e0d2137ea13~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt=""></p>
<p>注意连续的两次 .then 上一个.then执行完毕之后，才会继续顺序读后面，后面这个then相当于第一个 then 的内容。</p>
<p>正确答案：1 4 7 2 5 8 3 9 6</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3dbddbe92d96489a86242d5b66f0bb96~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt=""></p>
<p>正确答案：</p>
<p><strong>必须 resolve 顺序执行之后，才会调用 .then方法，才会将 then 放入微任务。</strong></p>
<p>1 2 4 3 7 6 9 5 8 </p>
<h2 id="考点16：JS-面试代码题目"><a href="#考点16：JS-面试代码题目" class="headerlink" title="考点16：JS 面试代码题目"></a>考点16：JS 面试代码题目</h2><h3 id="面试题：js中两个数组怎么取交集-差集、并集、补集"><a href="#面试题：js中两个数组怎么取交集-差集、并集、补集" class="headerlink" title="面试题：js中两个数组怎么取交集+(差集、并集、补集)"></a>面试题：js中两个数组怎么取交集+(差集、并集、补集)</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="keyword">var</span> b = [<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 两个数组去重</span></span><br><span class="line"><span class="keyword">var</span> sa = <span class="keyword">new</span> <span class="built_in">Set</span>(a);</span><br><span class="line"><span class="keyword">var</span> sb = <span class="keyword">new</span> <span class="built_in">Set</span>(b);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 交集</span></span><br><span class="line"><span class="comment">// a 当中过滤出 sb 中有的数</span></span><br><span class="line"><span class="keyword">let</span> intersect = a.filter(<span class="function"><span class="params">x</span> =&gt;</span> sb.has(x));</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&quot;交集为：&quot;</span>, intersect)  <span class="comment">// [ 2, 4 ]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 并集</span></span><br><span class="line"><span class="keyword">let</span> unionSet = <span class="built_in">Array</span>.from(<span class="keyword">new</span> <span class="built_in">Set</span>([...a, ...b]));</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&quot;并集为：&quot;</span>, unionSet) <span class="comment">//  [1, 2, 3,  4, 5, 6, 8, 10]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 差集</span></span><br><span class="line"><span class="comment">// a 当中过滤出 sb 中没有的数</span></span><br><span class="line"><span class="keyword">let</span> minus = a.filter(<span class="function"><span class="params">x</span> =&gt;</span> !sb.has(x));</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&quot;差集为：&quot;</span>, minus)  <span class="comment">// [ 1, 3, 5 ]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 补集  （就是 并集 - 交集）</span></span><br><span class="line"><span class="comment">// a 当中过滤出 sb 中没有的数  b 当中过滤出 sa 中没有的数 </span></span><br><span class="line"><span class="keyword">let</span> complement  = [...a.filter(<span class="function"><span class="params">x</span> =&gt;</span> !sb.has(x)), ...b.filter(<span class="function"><span class="params">x</span> =&gt;</span> !sa.has(x))];</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&quot;补集为：&quot;</span>, complement)  <span class="comment">// [ 1, 3, 5, 6, 8, 10 ]</span></span><br></pre></td></tr></table></figure>
<h3 id="面试题：用正则和非正则实现123456789-12-》123-456-789-12"><a href="#面试题：用正则和非正则实现123456789-12-》123-456-789-12" class="headerlink" title="面试题：用正则和非正则实现123456789.12=》123,456,789.12"></a>面试题：用正则和非正则实现123456789.12=》123,456,789.12</h3><ul>
<li>没有小数点，用专属的 API  <code>toLocaleString</code></li>
<li>否则用正则表达式</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">numFormat</span>(<span class="params">num</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> c = (num.toString().indexOf (<span class="string">&#x27;.&#x27;</span>) !== -<span class="number">1</span>) ? num.toLocaleString() : </span><br><span class="line">             num.toString().replace(<span class="regexp">/(\d)(?=(?:\d&#123;3&#125;)+$)/g</span>, <span class="string">&#x27;$1,&#x27;</span>);</span><br><span class="line">    <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：-写一个判断是否是空对象的函数"><a href="#面试题：-写一个判断是否是空对象的函数" class="headerlink" title="面试题： 写一个判断是否是空对象的函数"></a>面试题： 写一个判断是否是空对象的函数</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">isEmpty</span>(<span class="params">value</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        value === <span class="literal">null</span> || value === <span class="literal">undefined</span> ||</span><br><span class="line">        (<span class="keyword">typeof</span> value === <span class="string">&#x27;object&#x27;</span> &amp;&amp; <span class="built_in">Object</span>.keys(value).length === <span class="number">0</span>) </span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：颜色值16进制转10进制rgb"><a href="#面试题：颜色值16进制转10进制rgb" class="headerlink" title="面试题：颜色值16进制转10进制rgb"></a>面试题：颜色值16进制转10进制rgb</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">toRGB</span>(<span class="params">color</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> regex = <span class="regexp">/^#([0-9a-fA-F]&#123;2&#125;)([0-9a-fA-F]&#123;2&#125;)([0-9a-fA-F]&#123;2&#125;)$/</span> <span class="comment">//匹配十六进制的正则</span></span><br><span class="line">    match = color.match(regex)  <span class="comment">// 判断是否是十六进制颜色值</span></span><br><span class="line">    <span class="keyword">return</span> match ? <span class="string">&#x27;rgb(&#x27;</span>+<span class="built_in">parseInt</span>(match[<span class="number">1</span>], <span class="number">16</span>)+<span class="string">&#x27;,&#x27;</span>+<span class="built_in">parseInt</span>(match[<span class="number">2</span>], <span class="number">16</span>)+<span class="string">&#x27;,&#x27;</span>+<span class="built_in">parseInt</span>(match[<span class="number">3</span>], <span class="number">16</span>)+<span class="string">&#x27;)&#x27;</span> : color</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：数组扁平化-常考"><a href="#面试题：数组扁平化-常考" class="headerlink" title="面试题：数组扁平化  常考"></a>面试题：数组扁平化  常考</h3><p><strong>方法1：最正常的想法 使用递归</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr = [<span class="number">1</span>, [<span class="number">2</span>, [<span class="number">3</span>, <span class="number">4</span>]]];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">flatten</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> result = [];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>, len = arr.length; i &lt; len; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">Array</span>.isArray(arr[i])) &#123;</span><br><span class="line">            result = result.concat(flatten(arr[i]))</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            result.push(arr[i])</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">console</span>.log(flatten(arr))</span><br></pre></td></tr></table></figure>
<p><strong>方法2：使用 reduce 函数</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr = [<span class="number">1</span>, [<span class="number">2</span>, [<span class="number">3</span>, <span class="number">4</span>]]];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">flatten</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> arr.reduce(<span class="function"><span class="keyword">function</span>(<span class="params">prev, next</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> prev.concat(<span class="built_in">Array</span>.isArray(next) ? flatten(next) : next)</span><br><span class="line">    &#125;, [])</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">console</span>.log(flatten(arr))</span><br></pre></td></tr></table></figure>
<h3 id="面试题：实现一个数组对象的去重，相同value的只保留最后一个"><a href="#面试题：实现一个数组对象的去重，相同value的只保留最后一个" class="headerlink" title="面试题：实现一个数组对象的去重，相同value的只保留最后一个"></a>面试题：实现一个数组对象的去重，相同value的只保留最后一个</h3><p><strong>方法1：最佳肯定是使用 ES6 的 Set 方法</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">unique5</span>(<span class="params">arr</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">var</span> x = <span class="keyword">new</span> <span class="built_in">Set</span>(arr);</span><br><span class="line">   <span class="keyword">return</span> [...x];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其他的方法都是 ES5 的</p>
<p><strong>方法2：呆方法，遍历每个碰到没存过的存一下</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">unique5</span>(<span class="params">arr</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> temp = []</span><br><span class="line">    arr.forEach(<span class="function"><span class="params">element</span> =&gt;</span> &#123;</span><br><span class="line">       <span class="comment">// 或者 ES6 方法 temp.includes(element) 直接判断 True/False</span></span><br><span class="line">       <span class="keyword">if</span>(temp.indexOf(element) == -<span class="number">1</span>) </span><br><span class="line">            temp.push(element)</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> temp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：function-rand-min-max-N-：生成长度是N，且在min、max内不重复的整数随机数组"><a href="#面试题：function-rand-min-max-N-：生成长度是N，且在min、max内不重复的整数随机数组" class="headerlink" title="面试题：function rand(min, max, N)：生成长度是N，且在min、max内不重复的整数随机数组"></a>面试题：function rand(min, max, N)：生成长度是N，且在min、max内不重复的整数随机数组</h3><p>把考点拆成了4个小项；需要用递归算法实现：<br>a) 生成一个长度为n的空数组arr。<br>b) 生成一个（min－max）之间的随机整数rand。<br>c) 把随机数rand插入到数组arr内，如果数组arr内已存在与rand相同的数字，则重新生成随机数rand并插入到 arr内[需要使用递归实现，不能使用for/while等循环]<br>d) 最终输出一个长度为n，且内容不重复的数组arr。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">buildArray</span>(<span class="params">n, min, max</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> arr = []</span><br><span class="line">    dfsCreate(arr)</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">dfsCreate</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> num = <span class="built_in">Math</span>.floor(<span class="built_in">Math</span>.random() * (max - min + <span class="number">1</span>)) + min</span><br><span class="line">        <span class="keyword">if</span> (!arr.includes(num)) </span><br><span class="line">            arr.push(num)</span><br><span class="line">        <span class="keyword">return</span> arr.length === n ? arr : dfsCreate(arr);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：字符串中的单词逆序输出（手写）"><a href="#面试题：字符串中的单词逆序输出（手写）" class="headerlink" title="面试题：字符串中的单词逆序输出（手写）"></a>面试题：字符串中的单词逆序输出（手写）</h3><p><strong>方法1：快速法  推荐</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">strReverse</span>(<span class="params">str</span>) </span>&#123;</span><br><span class="line">     <span class="keyword">return</span> str.split(<span class="string">&quot;&quot;</span>).reverse().join(<span class="string">&quot;&quot;</span>) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>方法2：傻逼呆逼法</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">strReverse</span>(<span class="params">str</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> i=str.length;</span><br><span class="line">    <span class="keyword">var</span> result = <span class="string">&quot;&quot;</span>; </span><br><span class="line">    i=i-<span class="number">1</span>; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> x = i; x &gt;=<span class="number">0</span>; x--) &#123; </span><br><span class="line">            result += str[x]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>方法3：高级一点使用 reduce 法</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">strReverse</span>(<span class="params">str</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> str.split(<span class="string">&quot;&quot;</span>).reduce(<span class="function">(<span class="params">prev, next</span>) =&gt;</span> next + prev);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：给定一个字符串，请你找出其中不含有重复字符的-最长子串-的长度-（力扣）"><a href="#面试题：给定一个字符串，请你找出其中不含有重复字符的-最长子串-的长度-（力扣）" class="headerlink" title="面试题：给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度   （力扣）"></a>面试题：<strong>给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度</strong>   （力扣）</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> lengthOfLongestSubstring = <span class="function"><span class="keyword">function</span>(<span class="params">s</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> res = []</span><br><span class="line">  <span class="keyword">let</span> max = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">let</span> letter <span class="keyword">of</span> s) &#123;</span><br><span class="line">    <span class="keyword">while</span> (res.includes(letter)) &#123;</span><br><span class="line">      res.shift()</span><br><span class="line">    &#125;</span><br><span class="line">    res.push(letter)</span><br><span class="line">    max = <span class="built_in">Math</span>.max(max,res.length)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> max</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="面试题：去掉字符串前后的空格"><a href="#面试题：去掉字符串前后的空格" class="headerlink" title="面试题：去掉字符串前后的空格"></a>面试题：去掉字符串前后的空格</h3><p>这个可以用 新的ES6  API <strong>trim</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> str = <span class="string">&quot;   hello world   &quot;</span>;</span><br><span class="line"><span class="keyword">const</span> trimmedStr = str.trim(); <span class="comment">// &quot;hello world&quot;</span></span><br></pre></td></tr></table></figure>
<p>如果遇到需要去掉 字符串内所有的空格，并且空格不定长度，可以使用正则表达式来做</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> str = <span class="string">&quot;  hello   world!  &quot;</span>;</span><br><span class="line"><span class="keyword">const</span> trimmedStr = str.replace(<span class="regexp">/\s+/g</span>, <span class="string">&quot;&quot;</span>); <span class="comment">// &quot;helloworld!&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="面试题：三数之和-（力扣）"><a href="#面试题：三数之和-（力扣）" class="headerlink" title="面试题：三数之和  （力扣）"></a>面试题：三数之和  （力扣）</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> threeSum = <span class="function"><span class="keyword">function</span>(<span class="params">nums</span>) </span>&#123;</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">let</span> length = nums.length</span><br><span class="line">        <span class="comment">// 从小到大排序</span></span><br><span class="line">        nums.sort( <span class="function">(<span class="params">a,b</span>) =&gt;</span> a - b)</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length ; i++) &#123;</span><br><span class="line">            <span class="comment">// 如果当前数字大于0，则三数之和一定大于0，所以结束循环</span></span><br><span class="line">            <span class="keyword">if</span>(nums[i] &gt; <span class="number">0</span>) </span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment">// 去重</span></span><br><span class="line">            <span class="keyword">if</span>(i &gt; <span class="number">0</span> &amp;&amp; nums[i] == nums[i-<span class="number">1</span>]) </span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment">// 二分法寻找</span></span><br><span class="line">            <span class="keyword">let</span> left = i + <span class="number">1</span></span><br><span class="line">            <span class="keyword">let</span> right = length - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span>(left &lt; right)&#123;</span><br><span class="line">                <span class="keyword">let</span> sum = nums[i] + nums[left] + nums[right]</span><br><span class="line">                <span class="keyword">if</span>(sum == <span class="number">0</span>)&#123;</span><br><span class="line">                    result.push(<span class="keyword">new</span> <span class="built_in">Array</span>(nums[i], nums[left], nums[right]))</span><br><span class="line">                    <span class="keyword">while</span> (left &lt; right &amp;&amp; nums[left] == nums[left + <span class="number">1</span>]) </span><br><span class="line">                        left++; <span class="comment">// 去重</span></span><br><span class="line">                    <span class="keyword">while</span> (left &lt; right &amp;&amp; nums[right] == nums[right-<span class="number">1</span>]) </span><br><span class="line">                        right--; <span class="comment">// 去重</span></span><br><span class="line">                    left ++;</span><br><span class="line">                    right --;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 说明 左指针小了</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sum &lt; <span class="number">0</span>) left ++;</span><br><span class="line">                <span class="comment">// 说明 右指针大了</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sum &gt; <span class="number">0</span>) right --;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;        </span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
</search>
