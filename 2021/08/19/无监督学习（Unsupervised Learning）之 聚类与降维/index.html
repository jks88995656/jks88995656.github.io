<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>无监督学习（Unsupervised Learning）之 聚类与降维 | 一只柴犬</title><meta name="keywords" content="深度学习,李宏毅,无监督学习"><meta name="author" content="凯凯超人"><meta name="copyright" content="凯凯超人"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="@TOC   总结 无监督学习 的要点：1、无监督学习的概念  - 什么叫无监督学习（输入都是无label的数据，没有训练集之说，也就是**只能从一些无label的数据中自己寻找规律**）  - 无监督学习的两大任务：“化繁为简”（聚类、降维）、“无中生有” 2、聚类Clustering（K-means、HAC）3、降维Dimension Reduction（PCA）  无监督学习的具体分类？">
<meta property="og:type" content="article">
<meta property="og:title" content="无监督学习（Unsupervised Learning）之 聚类与降维">
<meta property="og:url" content="http://example.com/2021/08/19/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%88Unsupervised%20Learning%EF%BC%89%E4%B9%8B%20%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/index.html">
<meta property="og:site_name" content="一只柴犬">
<meta property="og:description" content="@TOC   总结 无监督学习 的要点：1、无监督学习的概念  - 什么叫无监督学习（输入都是无label的数据，没有训练集之说，也就是**只能从一些无label的数据中自己寻找规律**）  - 无监督学习的两大任务：“化繁为简”（聚类、降维）、“无中生有” 2、聚类Clustering（K-means、HAC）3、降维Dimension Reduction（PCA）  无监督学习的具体分类？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/2.jpg">
<meta property="article:published_time" content="2021-08-19T14:36:01.000Z">
<meta property="article:modified_time" content="2021-10-29T15:00:16.070Z">
<meta property="article:author" content="凯凯超人">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="李宏毅">
<meta property="article:tag" content="无监督学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/2.jpg"><link rel="shortcut icon" href="/img/favicon2.png"><link rel="canonical" href="http://example.com/2021/08/19/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%88Unsupervised%20Learning%EF%BC%89%E4%B9%8B%20%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '无监督学习（Unsupervised Learning）之 聚类与降维',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-10-29 23:00:16'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mycss.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/pool.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/iconfont.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/flink.min.css"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="一只柴犬" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/admin.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">68</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">37</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/2.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">一只柴犬</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">无监督学习（Unsupervised Learning）之 聚类与降维</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-08-19T14:36:01.000Z" title="发表于 2021-08-19 22:36:01">2021-08-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-10-29T15:00:16.070Z" title="更新于 2021-10-29 23:00:16">2021-10-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">机器学习基础</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="无监督学习（Unsupervised Learning）之 聚类与降维"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>@<a href="无监督学习 Unsupervised  Learning">TOC</a></p>
<p><img src="https://img-blog.csdnimg.cn/9d69260c8d1442429d24ca7190dd4e5f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>总结 无监督学习 的要点：<br>1、无监督学习的概念</p>
<pre><code> - 什么叫无监督学习（输入都是无label的数据，没有训练集之说，也就是**只能从一些无label的数据中自己寻找规律**）
 - 无监督学习的两大任务：“化繁为简”（聚类、降维）、“无中生有”
</code></pre><p>2、聚类Clustering（K-means、HAC）<br>3、降维Dimension Reduction（PCA）</p>
</blockquote>
<h1 id="无监督学习的具体分类？"><a href="#无监督学习的具体分类？" class="headerlink" title="无监督学习的具体分类？"></a>无监督学习的具体分类？</h1><p><img src="https://img-blog.csdnimg.cn/a3a3f30810614f508add1fd431cb5047.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="无监督学习的分类"></p>
<ul>
<li>化繁为简：找一个函数，将本来复杂的输入，变成比较简单的输出。<strong>比如找一个函数，可以把所有的树都变成抽象的树</strong>。因此我们拥有一大堆各种不同的图像的数据，但不知它的 output 长什么样子。</li>
<li>无中生有：找一个函数，随机给它一个input（比如一个数字1），然后output一棵树，输入数字2，output另外一棵树，输入3，又是另外一棵树。<strong>输入一个随机数，就自动画一张图出来，不同的数画出来的图不一样</strong>。这个任务里面，要找的可以画图的函数，只有output没有input。只有一大堆的图像，但是不知道输入什么数字才可以得到这些图像。</li>
</ul>
<h2 id="化繁为简包括-聚类"><a href="#化繁为简包括-聚类" class="headerlink" title="化繁为简包括 聚类"></a>化繁为简包括 聚类</h2><p><img src="https://img-blog.csdnimg.cn/436d9bf4a5a94f78b4ed65378066bcec.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="K-means聚类"></p>
<blockquote>
<p><strong>Q：什么是 聚类？</strong></p>
<p><font color="red"><strong>假设做图像的聚类，现在有一大堆的图像，然后把它们分成各类</strong>。</font>如上图左边的图像都属于 簇1，右边的图像都属于 簇2，上方的图像都属于 簇3。<strong>这就像给图像贴标签，把类似的图像，都用同一个簇表示</strong>，就做到化繁为简这件事情。</p>
<p><strong>Q：聚类的注意点是什么？</strong><br> 是 这些数据到底有多少个簇！ 这和神经网络需要设计几层一样，是需要算法工程师的个人经验的。</p>
<p><font color="red"><strong>这个簇不能太多也不能太少。</strong> </font>比如多到说9张图像9个簇，那聚类就没有意义，直接每个图像一个簇就好了，或者说全部图像都是一个簇，也跟没有做一样。</p>
</blockquote>
<p>聚类方法最常用的就是K-means，有一大堆未标注数据 $x^{1}$ 到 $x^{n}$ ，每一个 $x$ 代表一张图像，做成 K 个簇。</p>
<h3 id="K-means聚类算法怎么做？"><a href="#K-means聚类算法怎么做？" class="headerlink" title="K-means聚类算法怎么做？"></a>K-means聚类算法怎么做？</h3><p>先找簇的中心，假如每一个对象都用一个向量表示，有 K 个簇就需要 $c^{1}$  到 $c^{K}$  个中心。可以从训练数据里<strong>随机找 K个对象出来作为初始化中心。</strong><br>而后对所有数据，决定属于哪一个簇。假设 $x^{n}$  和 $c^{i}$  最接近，那么 $x^{n}$ 就属于 $c^{i}$ ，用 $b_{n}^{i}$ 表示。然后更新簇，所有属于 $c^{i}$ 的数据做平均，就是第 $i$ 个簇新的中心，更新要反复进行。</p>
<blockquote>
<p><strong>Q：为什么 是从数据集中挑选 K 个样本做初始化 簇中心？</strong><br><strong>答</strong>：之所以从数据集挑选K个样本做初始化簇中心，有一个很重要的原因是，如果是纯粹随机的（不从数据集里挑），那很可能在第一次分配这个簇中心的时候，没有任何一个样本跟这个中心很像，也可以说这个簇没有任何样本，再次更新就会出错。</p>
</blockquote>
<p>K-means 用更简单的话来说：<br>其算法思想大致为：先从样本集中随机选取 K 个样本作为簇中心，并计算所有样本与这 K 个“簇中心”的距离，对于每一个样本，将其划分到与其距离最近的“簇中心”所在的簇中，对于新的簇计算各个簇的新的“簇中心”。循环反复。</p>
<blockquote>
<p><strong>Q：总结一下 K-means 算法的 主要流程</strong></p>
<ol>
<li>簇个数 K 的选择</li>
<li>初始化簇中心（可以从你的train data里面随机找K个x出来，就是你的k个center）</li>
<li>while（收敛——聚类结果不再变化）<br>　　{<br>　　　　 各个样本点到“簇中心”的距离 ；<br>  　　 根据新划分的簇，更新“簇中心”（求均值）;<br>　　}</li>
</ol>
</blockquote>
<h3 id="层次凝聚聚类算法（HAC）怎么做？"><a href="#层次凝聚聚类算法（HAC）怎么做？" class="headerlink" title="层次凝聚聚类算法（HAC）怎么做？"></a>层次凝聚聚类算法（HAC）怎么做？</h3><p>首先 我们要做一个树结构 （<strong>其过程 非常像 哈夫曼树的构造</strong>）<br><img src="https://img-blog.csdnimg.cn/463ed5f3dfb84f1bb525e37a39dfd42b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="HAC构建树"></p>
<p>假设有5个样本做层次聚类，先要做一个树结构。计算两两样本的相似度，挑出最相似的数据对。</p>
<p>比如第一个和第二个样本最相似，那就合并（比如用平均值代表），5个样本变为4个样本；再计算相似度，配对的是4，5样本，然后把他们合并（平均值），变成3个样本；接着计算相似度，配对的是黄色数据点和剩下的蓝色数据点，再次合并（平均），最后只剩红色和绿色，那么最后平均起来得到root。根据5笔数和之间的相似度，就建立出了一个树结构。</p>
<p><strong>但树结构只是告诉我们说哪些样本比较像，还没有做聚类。</strong></p>
<blockquote>
<p><strong>Q：那怎么做聚类呢？或者说我怎么看我分的那几个聚类？</strong><br><strong>答</strong>： 看你怎么切，如图上面不同颜色的切线。</p>
<ul>
<li>比如在上图蓝线初切一刀，意味着把数据分成3簇，1、2为一簇，3单独为一簇，4、5为一簇。</li>
<li>在红色线切一刀，则1、2、3为一簇，4、5为一簇。</li>
<li>在绿色点切一刀，则1、2为一簇，3、 4、 5单独为一簇。</li>
</ul>
<p><strong>Q：层次聚类 和 K-means的差别？</strong></p>
<ul>
<li>在K-means里要自己决定K的值，也就是你要分多少个簇。<ul>
<li>在层次聚类里要决定的是在哪里切一刀，如果切比较容易考虑的话，那层次聚类可能更好。</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="化繁为简包括-降维"><a href="#化繁为简包括-降维" class="headerlink" title="化繁为简包括 降维"></a>化繁为简包括 降维</h2><blockquote>
<p><strong>Q：什么是降维？</strong><br><strong>答</strong>：降维意思是说，原本高维的东西，其实是可以用低维去表示它。就是找出数据里最主要的方面，用数据里最主要的方面来代替原始数据。换句话说，可以减少数据的维度。就是 </p>
<script type="math/tex; mode=display">z = Wx</script><p><img src="https://img-blog.csdnimg.cn/0f4adf004785425fa8e753ffc1e8c025.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>Q：为什么降维有用？</strong><br><strong>答</strong>：假设数据分布如上图左边，在3D空间里分布是螺旋的样子，但是用3D描述数据分布比较浪费的，直觉上也可以感觉可以摊开变成右边2D的样子，只需要2D的空间就可以描述3D的信息。在3D空间里面解比较麻烦，那就在2D里做这个任务。<br>考虑一个实际的简单栗子：<br>每一个input的数字都是28 × 28的矩阵来描述。但是实际上，多数28 × 28矩阵转成一个图像看起来都不像数字，在28 × 28空间里是数字的矩阵是很少的。所以要描述一个数字，或许不需要用到28 × 28维，远比28 × 28维少。<br><img src="https://img-blog.csdnimg.cn/1d2cd0f03fb540a886301947ef7bef60.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>所以举一个极端的例子，有一堆3，从像素点看要用28 × 28维来描述每张图像。实际上，只要用一个维度就可以表示，中间的是3，其他的3都是中间的3左转右转10、 20度。所以唯一需要记录的就是中间的3，左转和右转了多少度，即只需要角度的变化，就可以知道28维空间中的变化。</p>
<p><strong>Q：怎么做降维？</strong><br><strong>答</strong>：找一个函数，input是一个向量x，output是另外一个向量z（z的维度比x小）。</p>
<ul>
<li><p>在降维里最简单的方法是特征选择，把数据的分布拿出来看一下，    如在二维平面上发现数据集中在 $x$ 维度，所以 $y$ 这个维度没什么用，那么就把他拿掉，等于是降维这件事。<strong>特征选择不一定有用，有可能case里面任何一个维度都不能拿掉。</strong></p>
</li>
<li><p>另一个常见的方法是<strong>PCA</strong>，函数是一个很简单的线性函数，input x和output z之间的关系就是一个线性的transform，即 $x$ 乘上一个矩阵 $W$ 得到 $z$ 。现在不知道  $z$ 长什么样子，要根据一大堆的 $x$ 把 $W$ 找出来。</p>
</li>
</ul>
</blockquote>
<h3 id="分布式表示（Distributed-Representation）"><a href="#分布式表示（Distributed-Representation）" class="headerlink" title="分布式表示（Distributed Representation）"></a>分布式表示（Distributed Representation）</h3><blockquote>
<p><strong>Q：光做聚类的话是非常以偏概全的。为什么呢？</strong><br><strong>答</strong>：因为在聚类思想中，每个样本都必须属于某一个簇。就好像念力分成6大类，每个人都会被分配到6个大类其中一类。但这样分配太过粗糙，比如某个人的能力既有强化系的特性又有放出系的特性，只分为一类就会丢失很多信息。<img src="https://img-blog.csdnimg.cn/1ee8b3f2f1754e63bdc4826eba1aa3dc.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</blockquote>
<font color="red">**只分为一类就是以偏概全了，应该要用一个向量来表示每个对象，向量的每个维度代表了某一种特质（属性）。这件事情叫做Distributed Representation**。</font> 比如上图所示，这个人每个系都可以有固定的能力占比。

<font color="green">如果对象是一个高维的东西，例如图像，现在用它的特性来表示，就会把它从高维空间变成低维空间，这件事情叫做降维。</font> Distributed Representation和**降维**是一样的东西，不同的称呼。


### 主成分分析（PCA）
函数是一个很简单的线性函数，input x和output z之间的关系就是一个线性的transform，即 $x$ 乘上一个矩阵 $W$ 得到 $z$ 。现在不知道  $z$ 长什么样子，要根据一大堆的 $x$ 把 $W$ 找出来。

PCA的实现一般有两种：
 - 一种是用特征值分解去实现的
 - 一种是用奇异值分解去实现的

#### PCA-用特征值分解实现
![在这里插入图片描述](https://img-blog.csdnimg.cn/3acdbf6ffca44f85b12bb6a0719ae8c9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
刚才讲过PCA要做的事是找 $W$ ，假设一个比较简单的case，考虑一个维度的case。假设要把我们的数据投射到一维空间上，即 $z$ 只是一维的向量。 $w^{1}$ 是W的第一行，和 $x$ （列向量）做内积得到一个标量 $z_{1}$ 。

> **Q：$w^{1}$应该长什么样子？**
> 首先假设 $w^{1}$ 的长度是1，即 $||w^{1}||_{2}=1$ 。如果$||w^{1}||_{2}=1$，$w^{1}$ 是高维空间中的一个向量，那么 $z_{1}$ 就是就是 $x$ 在 $w^{1}$ 上的投影长度。现在要求出每一个 $x$ 在 $w^{1}$ 上的投影，那 $w^{1}$ 应该长什么样子？
举个例子，假设上图右上方是 $x$ 的分布，$x$ 都是二维的，每个点代表一只宝可梦，横坐标是攻击力，纵坐标是防御力。<font color="blue">现在要把二维投影到一维，应该要选什么样的 $w^{1}$ ?</font>  可以选 $w^{1}$ 为上图右上方右斜方向，也可以选左斜方向，**选不同的方向，最后得到的投影的结果会不一样**。

那总要给我们一个目标，我们才知道要选什么样的 $w^{1}$ ，现在目标是经过投影后得到的 $z_{1}$ 的分布越大越好。我们不希望投影后所有的点都挤在一起，把本来数据点之间的奇异度消去。我们希望投影后，数据点之间的区别仍然看得出来，那么我们可以找投影后方差越大的那个 $w^{1}$ 。

看上面的例子，如果是右斜方向，那么方差较大，左斜方向方差则较小，所以更可能选择右斜方向作为 $w^{1}$ 。

从上面的例子里看， $w^{1}$ 代表了宝可梦的强度，宝可梦可能有一个隐藏的向量代表它的强度，这个隐藏的向量同时影响了防御力和攻击力，所以防御力和攻击力会同时上升。
![在这里插入图片描述](https://img-blog.csdnimg.cn/dd45a73b7b0640d1bbb675b9132e5044.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
开始计算：
　　　　1、把方差式子展开，转化成协方差（具体转化过程不描述了）
　　　　2、<font color="red">结论：我们要找的 $w^{1}$ 就是协方差矩阵 $S$ 的最大特征值所对应的特征向量， $w^{2}$ 就是协方差矩阵 $S$ 的第二大特征值所对应的特征向量，以此类推 .</font>

<h4 id="PCA-用奇异值分解（SVD）"><a href="#PCA-用奇异值分解（SVD）" class="headerlink" title="PCA - 用奇异值分解（SVD）"></a>PCA - 用奇异值分解（SVD）</h4><p>特征值分解是一个提取矩阵特征很不错的方法，但是<strong>特征值分解只是对方阵而言的</strong>，在现实的世界中，我们看到的<strong>大部分矩阵都不是方阵</strong>。奇异值分解是一个能适用于任意的矩阵的一种分解的方法。<br><img src="https://img-blog.csdnimg.cn/31679a1b2ba54844b2799661d9c1ff6c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>假设现在考虑手写数字识别，我们知道手写数字其实是由一些基本成分组成的，这些基本成分可能是笔画。例如斜的直线，横的直线，比较长的直线，小圈、大圈等等，这些基本成分加起来以后得到一个数字。</p>
<p>基本成分我们写作 $u^{1},u^{2},u^{3}…$，这些基本的成分其实就是一个一个的向量。考虑 MNIST数据集 ，一张图像是28 × 28像素，就是28 × 28维的向量。基本成分其实也是28 × 28维的向量，把这些基本成分向量加起来，得到的向量就代表了一个数字。</p>
<p>如果写成公式的话，就如上图最下方所示的公式。$x$ 代表某一张图像的像素，用向量表示。$x$ 会等于 $u^{1}$ 这个成分乘上 $c<em>{1}$ ，加上 $u^{2}$ 这个成分乘上 $c</em>{2}$，一直加到 $u^{K}$ 这个成分乘上$c_{K}$，再加上 $\bar{x}$（$\bar{x}$ 是所有图像的平均）。所以每一张图像，就是一堆成分的线性组合加上所有图像的平均所组成的。</p>
<p>例如数字7是 $u^{1},u^{3},u^{5}$ 加起来的结果，那么对数字7来说，公式里的 $c<em>{1}=1 ,c</em>{2}=0, c<em>{3}=1…$，所以可以用  $c</em>{1},c<em>{2},c</em>{3}…,c<em>{K}$ 来表示一张图像，如果成分远比像素维度小的话，那么用$\begin{bmatrix}<br>c</em>{1}\<br>c<em>{2}\<br>…\<br>c</em>{K}\<br>\end{bmatrix}$表示一张图片是会比较有效的比如7可以由向量 $\begin{bmatrix}<br>1\<br>0\<br>1\<br>0\<br>1\<br>…\<br>\end{bmatrix}$ 描述。</p>
<p><img src="https://img-blog.csdnimg.cn/dc78fa3c54bc4b2f94be1efcc5bdf034.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们把公式里的 $\bar{x}$ 移到左边，$x$ 减 $\bar{x}$ 等于一堆成分的线性组合，写作 $\hat{x}$  。</p>
<blockquote>
<p><strong>Q：如果我们不知道K个u（成分）是什么，那怎么找出这K个向量？</strong> 找K个u，让$x−\bar{x}$ 和 $\hat{x}$  越接近越好，$||(x-\bar{x})-\hat{x}||<em>{2}$ 称为重构误差，代表没办法用成分描述的部分。接下来，最小化 $||(x-\bar{x})-\hat{x}||</em>{2}$，损失函数如上图 $L$。</p>
<p>回忆下PCA，$w<em>{1},w</em>{2},w<em>{3}…w</em>{K}$ 是 $x$ 协方差矩阵的特征向量，事实上 $L$ 的解就是PCA的 $w<em>{1},w</em>{2},w<em>{3}…w</em>{K}$。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/cf51702d73ef4fa3ac7f2dd6c47ec6d6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h1 id="PCA实例"><a href="#PCA实例" class="headerlink" title="PCA实例"></a>PCA实例</h1><h2 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h2><p><img src="https://img-blog.csdnimg.cn/9581a527b4a0468f97458d5954e6bb89.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>以把每一张数字图像拆成成分的线性组合，每一个成分也是一张图像（28 × 28 维的向量），所以可以把成分画在图上变成一张图像。</p>
<font color="blue">通过PCA画出前30个成分如上图所示，白色的地方代表有笔画。用这些成分做线性组合，就可以得到0-9的数字，所以这些成分叫做Eigen-digit。</font> 
Eigen（本征）是说，这些成分都是协方差矩阵的特征向量。

## 人脸识别
![在这里插入图片描述](https://img-blog.csdnimg.cn/9e97b877a5114592ac90e2b7f5f3c0f6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
上图右上方有一大堆人脸，找它们前30个主成分。找出来就如上图最下方所示，每张图像都是哀怨的脸，叫做Eigen-face。把这些脸做线性组合，就可以得到所有的脸。


> **Q：但这边有没有觉得有问题，因为主成分找出来的是成分，但是现在找出来的几乎都是完整的脸，也不像是成分啊？像前面的数字识别，成分看起来也像是玛雅文字，而不是笔画，看起来也不是成分啊？**
![在这里插入图片描述](https://img-blog.csdnimg.cn/1215e23adb994fd6b8380a73b1e64527.png#pic_center)> **答**：仔细想想PCA的特性，$α_{1},α_{2}$ 这种权重可以是任何值，可以是正的，也可以是负的。所以当我们用这些主成分组成一张图像的时候，<font color="blue">可以把这些成分相加，也可以把这些成分相减，这就会导致你找出的东西不见得是一个图的基本的结构。</font>> > 比如我画一个9，那可以先画一个8，然后把下面的圆圈减掉，再把一杠加上去。我们不一定是把成分加起来，也可以相减，<font color="blue">所以说就可以先画一个很复杂的图，然后再把多余的东西减掉。这些成分不见得就是类似笔画的这种东西。</font>
> 
> 如果要得到类似笔画的东西，就要用另一个技术*NMF（非负矩阵分解）*。PCA可以看成是对矩阵X做SVD，SVD就是一种矩阵分解的技术。**如果使用NMF，就会强迫所有成分的权重都是正的，正的好处就是一张图像必须由成分叠加得到，不能说先画一个复杂的东西再去掉一部分，再来就是所有成分的每个维度都必须是正的。**


所以在同样的任务上，例如手写数字的测试上，使用NMF时，找出来的主成分会如下图所示。
![在这里插入图片描述](https://img-blog.csdnimg.cn/ac0fc298e03847819527bc49a3198b45.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
你会发现，白色图案类似于笔画，找出来的主成分就成了笔画了。
![在这里插入图片描述](https://img-blog.csdnimg.cn/36c61755d6ce40318f4df22c47721ab5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
看脸的话，会发现如上图所示。比较像脸的一部分，比如人中、眉毛、嘴唇、下巴。

## 宝可梦
![在这里插入图片描述](https://img-blog.csdnimg.cn/c19d6fca60984ad6a435fd0750f485fa.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
有800种宝可梦，每种宝可梦可以用6个特征来表示。所以每个宝可梦就是6维的数据点，6维向量。

现在用PCA来分析，PCA里常有的问题是到底需要几个成分，即到底要把数据降到几维。这个一般取决于你的目的是什么，比如你想做可视化，分析宝可梦特性之间的关系，6维没办法可视化的，那就投影到二维。要用几个主成分就好像是神经网络需要几层，每层几个神经元一样。

一个常见决定使用几个主成分的方法是，去计算每个主成分（特征向量）对应的特征值，这个特征值代表在该主成分上投影数据的方差。

现在的例子里宝可梦是6维的，那就有6 × 6维的协方差矩阵，所以有6个特征值，如上图计算每个特征值比例，结果是0.45，0.18，0.13，0.12，0.07，0.04。那第5、6个主成分的作用比较小，意味着投影数据的方差很小，宝可梦的特性在这两个主成分上信息很少。那么分析宝可梦特性只需要前4个主成分。
![在这里插入图片描述](https://img-blog.csdnimg.cn/8fcb23f86b76476e9b66585379b04cbb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)

PCA后选择4个主成分，每个主成分是一个6维向量（因为原来每个特征都要投影，那就有6种投影数据）。

每个宝可梦可以想成是4主成分向量做线性组合的结果，且每只宝可梦组合的权重不同。

看第一个主成分PC1，数值都是正的，如果给它的权重大，意味着宝可梦6维都是强的，给它的权重小，意味着宝可梦6维都是弱的，所以第一个主成分，代表了这只宝可梦的强度。

看第二个主成分PC2，Def防御力是正值，速度是负值，那么增加权重的时候，会增加防御力并减小速度。

把第一个和第二个主成分画出来如上图最下方，图上有800个点，每个点代表一只宝可梦。
![在这里插入图片描述](https://img-blog.csdnimg.cn/995d8f5d622b4b3691e432d0e2554a0e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
第三个主成分PC3，特殊防御力是正的，攻击力和HP都是负的，也就是说这是用攻击力和HP来换取特殊防御力的宝可梦。

第四个主成分PC4，HP是正的，攻击力和防御力是负的，这是用攻击力和防御力换取生命值的宝可梦。

把第三、第四主成分画出来如上图最下方，维度是去相关的。


## 矩阵分解-推荐系统
有时候，你会有两种东西，两种对象，它们之间受到某种共通的潜在因素操控。
假设现在做一个调查，调查每个人手上买的公仔的数目，有5个宅男同学A,B,C,D,E，横轴的公仔人物是凉宫春日、御坂美琴、小野寺、小唯，调查结果如下图。
![在这里插入图片描述](https://img-blog.csdnimg.cn/7557d3f48de34c97be70ec2ca4212e74.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
看这个矩阵可以发现，买凉宫春日的人，比较有可能有御坂美琴；买小野寺的人，也比较有可能买小唯。这说明人和公仔有一些共同的特性，有共同的因素在操控这些事情发生。

动漫宅获取可以分成两种，一种是萌傲娇的，一种萌天然呆的。每个人都是萌傲娇和萌天然呆平面上的一个点，可以用一个向量表示，那么看上图，A是偏萌傲娇。每一个公仔角色，可能有傲娇属性或者天然呆属性，所以每一个角色，也是平面上一个点，可以用一个向量描述。

如果某个人的属性和角色的属性匹配的话，他们背后的向量就很像（比如做内积的时候值很大），那么A就会买很多的凉宫春日。他们匹配的程度取决于潜在因素是不是匹配的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/d5f8553af83f4034bbcff5b07c95251a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)


所以ABC的属性如上图最左边所示，A、B是萌傲娇的，B稍微没有那么傲娇，C是萌天然呆。每个动漫角色后面也有傲娇、天然呆这两种属性，如果人物属性和角色属性匹配的话，人买角色的可能性就很大。
![在这里插入图片描述](https://img-blog.csdnimg.cn/006698ec686f439ea7e5161e55e7213f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center)
上图中右下方矩阵公式中，右边两个矩阵的N应该是M，代表M个人。
我们知道的只有人买的角色的数目，然后凭着这种关系去推论每个人和每个动漫人物背后的潜在因素。每个人背后都有一个向量，代表萌傲娇或者萌天然呆的程度。每个角色后面也有一个序列，代表是傲娇或天然呆的属性。

我们可以把购买的公仔数量合起来看做是一个矩阵X ，行数是人的数量，列数是公仔角色的数量。

现在有一个假设，矩阵X里的每个元素都来自于两个向量的内积。为什么A会有5个凉宫春日的公仔，是因为 $r^{A}·r^{1}$ 的内积很大，约等于5。这件事情用数学公式表达的话，可以把 $r^{A}$ 到 $r^{M}$ 按列排起来，把 $r^{1}$ 到 $r^{4}$ 按行排起来，<font color="red">K是潜在因素的个数，一般没办法知道，需要自己测试出来。</font>

<blockquote>
<p><strong>Q：矩阵X的每个维度是什么？</strong><br>我们要做的事情就是找一组rA到rE，找一组r1到r4 ，让两个矩阵相乘后和矩阵X越接近越好，就是最小化重构误差。这个就可以用SVD来解，把Σ并到左边或右边变成两个矩阵就可以了。<br><img src="https://img-blog.csdnimg.cn/b2a2e51b938840b49fad8bcf3521f71b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>有时候有些信息是缺失的，比如上图所示的，你不知道A、B、C手上有没有小野寺，可能在那个地区没有发行，所以不知道发行的话到底会不会买。那用SVD就很怪，也可以把缺失值用0代替，但也很奇怪。</p>
<p>Q：那有缺失值怎么办呢？<br>可以用梯度下降的方法来做，写一个损失函数，让$r^{i}$（每个人背后的潜在因素）和$r^{j}$（角色背后的潜在因素）的内积和角色购买数量越接近越好。现在重点是，在<br>summation over<br>元素的时候，可以避开缺失的数据，如果值是缺失的，就不计算。有了损失函数后，就可以使用梯度下降了。<img src="https://img-blog.csdnimg.cn/7da15f3364a64482b6e8a8ed3d751acb.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>根据刚才的方法实际计算一下，假设潜在因素的数量是2。那么A到E都是二维的向量，每个角色也是二维的向量。<br>数值代表了属性的程度，把大的用红色框框圈出来，会发现A、B萌同一组属性，C、D、E萌同一种属性，1,2有同样的属性，3,4有同样的属性。没有办法知道每个属性代表什么，要先找出这些潜在因素，再去分析它的结果。有了这些潜在因素数据，就可以用来预测缺失值。已经知道了$r^{A}$和$r^{3}$，那只要$r^{A}$和$r^{3}$做内积就可以了。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/d1cb16fb971b456ebe4b9e64b666e212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2prczg4OTk1NjU2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>之前的model可以做得更精致一点，刚才说A背后的潜在因素乘上 春日 背后的潜在因素，得到的结果就是矩阵里的数值。但是事实上，可能还会有其他因素操控这些数值。<br>那么更精确的写法就可以写成。</p>
<script type="math/tex; mode=display">r^{A}⋅r^{1}+b_{A}+b_{1}≈5</script><p>$b<em>{A}$是跟 $A$ 有关的标量，代表了 $A$ 有多喜欢买公仔，有的人就是喜欢买公仔，也不是喜欢某个角色。$b</em>{1}$是跟 春日 有关的标量，代表了角色有多想让人购买，这个事情是跟属性无关的，本来人就会买这个角色。</p>
<p>然后修改损失函数如上图所示，使用梯度下降求解即可。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">凯凯超人</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/08/19/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%88Unsupervised%20Learning%EF%BC%89%E4%B9%8B%20%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/">http://example.com/2021/08/19/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%88Unsupervised%20Learning%EF%BC%89%E4%B9%8B%20%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">一只柴犬</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/">李宏毅</a><a class="post-meta__tags" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">无监督学习</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/08/21/Numpy%E3%80%81Pandas%E3%80%81Matplotlib%20%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Numpy、Pandas、Matplotlib  常用代码</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/17/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%20Semi-Supervised/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/5.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">半监督学习 Semi-Supervised</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/08/10/为什么要Deep？深而不是宽/" title="为什么要Deep？深而不是宽"><img class="cover" src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-10</div><div class="title">为什么要Deep？深而不是宽</div></div></a></div><div><a href="/2021/08/07/深度学习 Deep Learning 基础/" title="深度学习 Deep Learning 基础"><img class="cover" src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-07</div><div class="title">深度学习 Deep Learning 基础</div></div></a></div><div><a href="/2021/08/12/卷积神经网络CNN（Convolutional Neural Network）/" title="卷积神经网络CNN（Convolutional Neural Network）"><img class="cover" src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/14.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-12</div><div class="title">卷积神经网络CNN（Convolutional Neural Network）</div></div></a></div><div><a href="/2021/08/17/半监督学习 Semi-Supervised/" title="半监督学习 Semi-Supervised"><img class="cover" src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-17</div><div class="title">半监督学习 Semi-Supervised</div></div></a></div><div><a href="/2021/08/09/深度学习 Deep Learning 模型优化/" title="深度学习 Deep Learning 模型优化"><img class="cover" src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-09</div><div class="title">深度学习 Deep Learning 模型优化</div></div></a></div><div><a href="/2021/10/29/AlexNet 元老 开创的创新点/" title="AlexNet 元老 开创的创新点"><img class="cover" src="http://kyle-pic.oss-cn-hangzhou.aliyuncs.com/img/1028_7.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-10-29</div><div class="title">AlexNet 元老 开创的创新点</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/admin.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">凯凯超人</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">68</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">37</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xxxxx" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:xxxxxx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://gitee.com/×××" target="_blank" title="Gitee"><i class="iconfont gitee"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%85%B7%E4%BD%93%E5%88%86%E7%B1%BB%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">无监督学习的具体分类？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8C%96%E7%B9%81%E4%B8%BA%E7%AE%80%E5%8C%85%E6%8B%AC-%E8%81%9A%E7%B1%BB"><span class="toc-number">1.1.</span> <span class="toc-text">化繁为简包括 聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-number">1.1.1.</span> <span class="toc-text">K-means聚类算法怎么做？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%82%E6%AC%A1%E5%87%9D%E8%81%9A%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%EF%BC%88HAC%EF%BC%89%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-number">1.1.2.</span> <span class="toc-text">层次凝聚聚类算法（HAC）怎么做？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8C%96%E7%B9%81%E4%B8%BA%E7%AE%80%E5%8C%85%E6%8B%AC-%E9%99%8D%E7%BB%B4"><span class="toc-number">1.2.</span> <span class="toc-text">化繁为简包括 降维</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%A1%A8%E7%A4%BA%EF%BC%88Distributed-Representation%EF%BC%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">分布式表示（Distributed Representation）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PCA-%E7%94%A8%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%EF%BC%88SVD%EF%BC%89"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">PCA - 用奇异值分解（SVD）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PCA%E5%AE%9E%E4%BE%8B"><span class="toc-number">2.</span> <span class="toc-text">PCA实例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="toc-number">2.1.</span> <span class="toc-text">手写数字识别</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/03/20/axios%20%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%B0%81%E8%A3%85_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题"><img src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/14.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2023/03/20/axios%20%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%B0%81%E8%A3%85_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题">无题</a><time datetime="2023-03-20T10:12:35.973Z" title="发表于 2023-03-20 18:12:35">2023-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/20/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题"><img src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/14.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2023/03/20/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题">无题</a><time datetime="2023-03-20T10:12:35.969Z" title="发表于 2023-03-20 18:12:35">2023-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/20/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题"><img src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/14.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2023/03/20/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题">无题</a><time datetime="2023-03-20T10:12:35.965Z" title="发表于 2023-03-20 18:12:35">2023-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/20/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题"><img src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/14.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2023/03/20/%E5%89%8D%E7%AB%AF%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E9%9D%A2%E8%AF%95%E9%A2%98_%E5%87%AF%E5%87%AF%E8%B6%85%E4%BA%BA%E7%89%88%E6%9C%AC/" title="无题">无题</a><time datetime="2023-03-20T10:12:35.961Z" title="发表于 2023-03-20 18:12:35">2023-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/20/%E5%89%8D%E7%AB%AF%EF%BC%88JS%EF%BC%89%E4%BB%A3%E7%A0%81%E7%BC%96%E7%A8%8B%E9%A2%98/" title="无题"><img src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/media/image/14.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2023/03/20/%E5%89%8D%E7%AB%AF%EF%BC%88JS%EF%BC%89%E4%BB%A3%E7%A0%81%E7%BC%96%E7%A8%8B%E9%A2%98/" title="无题">无题</a><time datetime="2023-03-20T10:12:35.954Z" title="发表于 2023-03-20 18:12:35">2023-03-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 凯凯超人</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/js/pool.min.js"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"><script src="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/js/pool.min.js"></script><script src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"></script><script src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/hideMobileSidebar.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>